---
title: 机器学习之线性回归
date: 2018-03-24 23:27:53
tags: 机器学习
categories: 机器学习
comments: true
mathjax: true
---

### 1.回归分析（Regression Analysis）
**回归分析（Regression Analysis）**：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围的。
通俗来讲就是我们在做数学题的时候，解未知数的方法，是给定自变量和函数，通过函数处理自变量，然后获得函数的解。而回归分析便是相当于给定自变量和函数的解，然后去求函数。如下图所示，我们已经知道红色点坐标，然后回归得到直线，回归分析属于**监督学习**。
![图片01](机器学习之线性回归/图片01.png)
当然上述只是简单的一元线性分析，回归后我们可以得到如$f(x)=a*x+b$的函数表达式，但如果求解多元线性回归问题，我们应该解决呢。
### 2.模型表达

建立数学模型之前，我们先定义如下变量。
-  $x_i$表示输入数据（Feature）
-  $y_i$表示输出数据（Target）
-  $(x_i,y_i)$表示一组训练数据（Training example）
- m表示训练数据的个数
- n表示特征数量

监督学习目标便是根据给定的训练数据，可以得到函数方法，使得假设函数$h$(hypothesis)满足$h(x)->y$。针对线性回归而言，函数$h(x)$表达式为
$$h(x)=\theta_0+\theta_1*x_i+\theta_2*x_2+...+\theta_n*x_n$$
为方便我们使用矩阵来表达，$h(x)=\theta^T*x$，其中$\theta^T$为$\theta$的转置。









