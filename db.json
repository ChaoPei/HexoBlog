{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/robots.txt","path":"robots.txt","modified":0,"renderable":0},{"_id":"themes/next/source/CNAME","path":"CNAME","modified":0,"renderable":1},{"_id":"source/about/index/公众号.jpg","path":"about/index/公众号.jpg","modified":0,"renderable":0},{"_id":"source/favorite/index/千只鹤.png","path":"favorite/index/千只鹤.png","modified":0,"renderable":0},{"_id":"source/favorite/index/呼兰河传.png","path":"favorite/index/呼兰河传.png","modified":0,"renderable":0},{"_id":"source/favorite/index/南极之恋.png","path":"favorite/index/南极之恋.png","modified":0,"renderable":0},{"_id":"source/favorite/index/围城.png","path":"favorite/index/围城.png","modified":0,"renderable":0},{"_id":"source/favorite/index/啪嗒啪嗒.png","path":"favorite/index/啪嗒啪嗒.png","modified":0,"renderable":0},{"_id":"source/favorite/index/小王子.png","path":"favorite/index/小王子.png","modified":0,"renderable":0},{"_id":"source/favorite/index/平凡的世界.png","path":"favorite/index/平凡的世界.png","modified":0,"renderable":0},{"_id":"source/favorite/index/挪威的森林.png","path":"favorite/index/挪威的森林.png","modified":0,"renderable":0},{"_id":"source/favorite/index/时间简史.png","path":"favorite/index/时间简史.png","modified":0,"renderable":0},{"_id":"source/favorite/index/斯里兰卡.png","path":"favorite/index/斯里兰卡.png","modified":0,"renderable":0},{"_id":"source/favorite/index/暴裂无声.png","path":"favorite/index/暴裂无声.png","modified":0,"renderable":0},{"_id":"source/favorite/index/瓦尔登湖.png","path":"favorite/index/瓦尔登湖.png","modified":0,"renderable":0},{"_id":"source/favorite/index/来自风平浪静的明天.png","path":"favorite/index/来自风平浪静的明天.png","modified":0,"renderable":0},{"_id":"source/favorite/index/白鹿原.png","path":"favorite/index/白鹿原.png","modified":0,"renderable":0},{"_id":"source/favorite/index/看见.png","path":"favorite/index/看见.png","modified":0,"renderable":0},{"_id":"source/favorite/index/羊脂球.png","path":"favorite/index/羊脂球.png","modified":0,"renderable":0},{"_id":"source/favorite/index/老人与海.png","path":"favorite/index/老人与海.png","modified":0,"renderable":0},{"_id":"source/favorite/index/解密.png","path":"favorite/index/解密.png","modified":0,"renderable":0},{"_id":"source/favorite/index/边城.png","path":"favorite/index/边城.png","modified":0,"renderable":0},{"_id":"source/favorite/index/雪国.png","path":"favorite/index/雪国.png","modified":0,"renderable":0},{"_id":"source/favorite/index/骄傲的印度.png","path":"favorite/index/骄傲的印度.png","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.png","path":"images/avatar.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"source/favorite/index/万物理论.png","path":"favorite/index/万物理论.png","modified":0,"renderable":0},{"_id":"source/favorite/index/刻刻.png","path":"favorite/index/刻刻.png","modified":0,"renderable":0},{"_id":"source/favorite/index/越禁忌越美丽.png","path":"favorite/index/越禁忌越美丽.png","modified":0,"renderable":0},{"_id":"source/favorite/index/霸王别姬.png","path":"favorite/index/霸王别姬.png","modified":0,"renderable":0},{"_id":"source/favorite/index/唐人街探案2.png","path":"favorite/index/唐人街探案2.png","modified":0,"renderable":0},{"_id":"source/favorite/index/捉妖记2.png","path":"favorite/index/捉妖记2.png","modified":0,"renderable":0},{"_id":"source/favorite/index/未闻花名.png","path":"favorite/index/未闻花名.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"source/favorite/index/老炮儿.png","path":"favorite/index/老炮儿.png","modified":0,"renderable":0},{"_id":"source/favorite/index/超能陆战队.png","path":"favorite/index/超能陆战队.png","modified":0,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"source/favorite/index/神偷奶爸.png","path":"favorite/index/神偷奶爸.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"source/favorite/index/喊山.png","path":"favorite/index/喊山.png","modified":0,"renderable":0},{"_id":"source/favorite/index/无敌破坏王.png","path":"favorite/index/无敌破坏王.png","modified":0,"renderable":0},{"_id":"source/favorite/index/驯龙高手.png","path":"favorite/index/驯龙高手.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"source/favorite/index/北京遇上西雅图.png","path":"favorite/index/北京遇上西雅图.png","modified":0,"renderable":0},{"_id":"source/favorite/index/血战钢锯岭.png","path":"favorite/index/血战钢锯岭.png","modified":0,"renderable":0},{"_id":"source/favorite/index/V字仇杀队.png","path":"favorite/index/V字仇杀队.png","modified":0,"renderable":0},{"_id":"source/favorite/index/二十二.png","path":"favorite/index/二十二.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"source/favorite/index/机器人总动员.png","path":"favorite/index/机器人总动员.png","modified":0,"renderable":0},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"source/favorite/index/冰雪奇缘.png","path":"favorite/index/冰雪奇缘.png","modified":0,"renderable":0},{"_id":"source/favorite/index/魁拔.png","path":"favorite/index/魁拔.png","modified":0,"renderable":0},{"_id":"source/favorite/index/麦兜我和我妈妈.png","path":"favorite/index/麦兜我和我妈妈.png","modified":0,"renderable":0},{"_id":"source/favorite/index/飞屋环游记.jpg","path":"favorite/index/飞屋环游记.jpg","modified":0,"renderable":0},{"_id":"source/favorite/index/少年派的奇幻漂流.png","path":"favorite/index/少年派的奇幻漂流.png","modified":0,"renderable":0},{"_id":"source/favorite/index/让子弹飞.png","path":"favorite/index/让子弹飞.png","modified":0,"renderable":0},{"_id":"source/favorite/index/你得名字.png","path":"favorite/index/你得名字.png","modified":0,"renderable":0},{"_id":"source/favorite/index/大护法.png","path":"favorite/index/大护法.png","modified":0,"renderable":0},{"_id":"source/favorite/index/湄公河行动.png","path":"favorite/index/湄公河行动.png","modified":0,"renderable":0},{"_id":"source/favorite/index/寻梦环游记.png","path":"favorite/index/寻梦环游记.png","modified":0,"renderable":0},{"_id":"source/favorite/index/摔跤吧！爸爸.png","path":"favorite/index/摔跤吧！爸爸.png","modified":0,"renderable":0},{"_id":"source/favorite/index/哆啦A梦：伴我同行.png","path":"favorite/index/哆啦A梦：伴我同行.png","modified":0,"renderable":0},{"_id":"source/favorite/index/百鸟朝凤.png","path":"favorite/index/百鸟朝凤.png","modified":0,"renderable":0},{"_id":"source/favorite/index/厉害了我的国.png","path":"favorite/index/厉害了我的国.png","modified":0,"renderable":0},{"_id":"source/favorite/index/功夫熊猫.png","path":"favorite/index/功夫熊猫.png","modified":0,"renderable":0},{"_id":"source/favorite/index/小羊肖恩.png","path":"favorite/index/小羊肖恩.png","modified":0,"renderable":0},{"_id":"source/favorite/index/盗梦空间.png","path":"favorite/index/盗梦空间.png","modified":0,"renderable":0},{"_id":"source/favorite/index/寒战.png","path":"favorite/index/寒战.png","modified":0,"renderable":0},{"_id":"source/favorite/index/麦兜当当伴我心.png","path":"favorite/index/麦兜当当伴我心.png","modified":0,"renderable":0},{"_id":"source/favorite/index/人在囧途.png","path":"favorite/index/人在囧途.png","modified":0,"renderable":0},{"_id":"source/favorite/index/昆虫总动员.png","path":"favorite/index/昆虫总动员.png","modified":0,"renderable":0},{"_id":"source/favorite/index/星际穿越.png","path":"favorite/index/星际穿越.png","modified":0,"renderable":0},{"_id":"source/favorite/index/绣春刀.png","path":"favorite/index/绣春刀.png","modified":0,"renderable":0},{"_id":"source/favorite/index/西游记之大圣归来.png","path":"favorite/index/西游记之大圣归来.png","modified":0,"renderable":0},{"_id":"source/favorite/index/诺亚方舟漂流记.png","path":"favorite/index/诺亚方舟漂流记.png","modified":0,"renderable":0},{"_id":"source/favorite/index/金蝉脱壳.png","path":"favorite/index/金蝉脱壳.png","modified":0,"renderable":0},{"_id":"source/favorite/index/疯狂动物城.jpg","path":"favorite/index/疯狂动物城.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"82e01d04bd88ce92bca3f88aef58e0c58bf59fbe","modified":1524218008850},{"_id":"source/.me_configs.data","hash":"be0d1ba93f31dadd375f266a8a131bab230e5522","modified":1521978664283},{"_id":"source/.md_configs.data","hash":"8842f205e55d4dee88e990327ceeebfc55470fe5","modified":1521978664289},{"_id":"source/.z_sync_configs.data","hash":"d35bb00a1634c739a93585c06ebea3d272c9a023","modified":1522057383406},{"_id":"source/robots.txt","hash":"2be28bdb6f77c8f7627632bea984e2b3d735b411","modified":1521046018000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1515072990000},{"_id":"themes/next/.DS_Store","hash":"b178dc567c0504e692e1a5ddeddd4b0ccc1bd3a9","modified":1521277719162},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1515072990000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1515072990000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1515072990000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1515072990000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1515072990000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1515072990000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1515072990000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1515072990000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1515072990000},{"_id":"themes/next/README.cn.md","hash":"5d8af3d8de8d3926126a738519e97c8442b0effe","modified":1515072990000},{"_id":"themes/next/README.md","hash":"44b28d995681a7c48bfe3d0577d6203812d07e59","modified":1515072990000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1515072990000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1515072990000},{"_id":"themes/next/_config.yml","hash":"02e65e346da2f49601a22267c631bfb5c0342249","modified":1522316624010},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1515072990000},{"_id":"source/_posts/.me_configs.data","hash":"65f09b99475d152a6e9f0bb6fe935aa0013c06b7","modified":1521978792538},{"_id":"source/_posts/.DS_Store","hash":"0eeafb8fb951cee5a619797b173a73b3d92758e5","modified":1524146572036},{"_id":"source/_posts/.md_configs.data","hash":"8842f205e55d4dee88e990327ceeebfc55470fe5","modified":1521978792542},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程.md","hash":"7d29cba206b63a40203d3340875f57115224cf9b","modified":1521282184618},{"_id":"source/_posts/Markdown写作教程.md","hash":"6c8017412a5aa44a943d5c7f39222c8f35a53397","modified":1522082235932},{"_id":"source/_posts/Python之NumPy使用教程.md","hash":"b9f70712ccacbb533082563ebe4af95f550198de","modified":1520997413604},{"_id":"source/_posts/Python之MatPlotLib使用教程.md","hash":"ed5285c90b220de16a24ace0a9ec6b3167c03fee","modified":1521979165077},{"_id":"source/_posts/Python之Pandas使用教程.md","hash":"3b4633ac2ac2ea2396d134bad5d6930879462ad6","modified":1521079444778},{"_id":"source/_posts/Python之Sklearn使用教程.md","hash":"38fe9c817675e9421c07c1bc00bd87d4b6548253","modified":1524101186055},{"_id":"source/_posts/机器学习之Logistic回归.md","hash":"c4237876b04f71831a90d84e2a87fd95c558dac6","modified":1522255415044},{"_id":"source/_posts/机器学习之SVM支持向量机（一）.md","hash":"a3619c763746e5362f1b52835e49ac5be990dcd6","modified":1522723962498},{"_id":"source/_posts/机器学习之SVM支持向量机（二）.md","hash":"c1a1e2a1d1b25ef7569fbe74f032997b1ae33261","modified":1523020283223},{"_id":"source/_posts/机器学习之决策树-C4-5算法.md","hash":"3053732c19781465b787b48f29a6812365f15557","modified":1524218602852},{"_id":"source/_posts/机器学习之线性回归.md","hash":"6995348b2d97b5ee71a61756b0ddea18bf019295","modified":1522081790742},{"_id":"source/_posts/机器学习知识体系.md","hash":"0e24a6d9ec95380259b42e344e4600adf35dc5ae","modified":1522308274332},{"_id":"source/_posts/面向知乎的个性化推荐模型研究论文.md","hash":"fc8f9cb053c02f0ab9e8818d5e3e322c3d4ab27d","modified":1520997428367},{"_id":"source/about/index.md","hash":"7a161311e81a66b97f14e11cbd4cebb424ca7b52","modified":1522133357983},{"_id":"source/categories/index.md","hash":"953b432e5293289c926e7eff1b5594652d0bab40","modified":1520961992190},{"_id":"source/about/.DS_Store","hash":"07fcad405c7168836b16dd5fce0ddf8bc8522fd7","modified":1522310181050},{"_id":"source/favorite/.DS_Store","hash":"fbb0016f7a6a6b061001fd918abb275186223254","modified":1523811812404},{"_id":"source/favorite/index.md","hash":"f6f8cc8484f08b2772617f9da74f9687f6b158d3","modified":1523809479461},{"_id":"source/tags/index.md","hash":"04610e91300b8e0df44c872460f285b6a6595f14","modified":1520962000814},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1515072990000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1515072990000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1515072990000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1515072990000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1515072990000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1515072990000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1515072990000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1515072990000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1515072990000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1515072990000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1515072990000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1515072990000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1515072990000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1515072990000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1515072990000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1515072990000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1515072990000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1515072990000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"a888ae4be4048b42fee05a43bdf92238b98e45b8","modified":1521093680028},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1515072990000},{"_id":"themes/next/layout/.DS_Store","hash":"756ed2b2f5c66835aa27bafa65f413433de58884","modified":1521277719160},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1515072990000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1515072990000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1515072990000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1515072990000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1515072990000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1515072990000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1515072990000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1515072990000},{"_id":"themes/next/scripts/image-stream.js","hash":"785a68463d9e6584ae7cbe304d9854fda9558dcc","modified":1521096807734},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1515072990000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1515072990000},{"_id":"themes/next/source/CNAME","hash":"5455120583e7a62be755f95d1b53d5efbbec5bf4","modified":1521078314026},{"_id":"themes/next/source/.DS_Store","hash":"455304e66a0a3ebaa984c5bd0031b0aa8df78cd0","modified":1520954592745},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1515072990000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1515072990000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1515072990000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"source/_posts/Markdown写作教程/.DS_Store","hash":"0e67b693bce4e8dbc97f39025f629fc6cb30ae35","modified":1521446575930},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/.DS_Store","hash":"0c3c383472616d584b5d541505642243bfefef75","modified":1521280981924},{"_id":"source/_posts/Python之MatPlotLib使用教程/.DS_Store","hash":"17e17dcee88fab62efa4a8d27c70c43ec11b5c07","modified":1521280973916},{"_id":"source/_posts/Python之MatPlotLib使用教程/02.png","hash":"e68d02686e078ee777ecb9c62586843dc0fa4d95","modified":1520751248093},{"_id":"source/_posts/Python之MatPlotLib使用教程/03.png","hash":"613cb5e4cfc842bd987ed3a3da446ff779605ff4","modified":1520752253049},{"_id":"source/_posts/Python之MatPlotLib使用教程/05.png","hash":"abe67138ba5186ca80125b35f68a24ada5da397a","modified":1520753289453},{"_id":"source/_posts/Python之MatPlotLib使用教程/04.png","hash":"29b910fc5dd61d9dc017a43ebe5fa7835a7cd33c","modified":1520752577517},{"_id":"source/_posts/Python之MatPlotLib使用教程/07.png","hash":"7f0e85e07ca1ae562025c8031cfc87eb9a99b51a","modified":1520757420269},{"_id":"source/_posts/Python之MatPlotLib使用教程/06.png","hash":"07003112ee77f408788693ccdb71fa6578d635f2","modified":1520753426282},{"_id":"source/_posts/Python之MatPlotLib使用教程/08.png","hash":"4e3061fc73c47c5040c2920567185f906298fab7","modified":1520758048771},{"_id":"source/_posts/Python之MatPlotLib使用教程/09.png","hash":"352b9d0ab5678717465660ca2f7d243ac605166a","modified":1520760208929},{"_id":"source/_posts/Python之MatPlotLib使用教程/11.png","hash":"44dfb34c533a659f62e0213a9b6320329503857c","modified":1520763424602},{"_id":"source/_posts/Python之MatPlotLib使用教程/13.png","hash":"e10a1daaaac28c0d04bf4a3183e08ae9b5e0b985","modified":1520767651002},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像20.png","hash":"414c76614aa0e1f9b0832aced52ed8e0702fcb1d","modified":1521018437593},{"_id":"source/_posts/Python之Sklearn使用教程/.DS_Store","hash":"eff22146e8828ad9dd12c68c3007d69338ed803e","modified":1523788258093},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程03.png","hash":"ef9781638e5f177bb192245d906da889af3f6aa3","modified":1523772589009},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程09.png","hash":"56374280cab86a969f853c967201d3d3729cf920","modified":1523780341443},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程10.png","hash":"b89f99c644b86aec73b4f6b0a93566ddd765ad15","modified":1523780543763},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程11.png","hash":"bddde196beb8e1f8b8fe1ec4b9ddb82682953f38","modified":1523780896578},{"_id":"source/_posts/机器学习之Logistic回归/.DS_Store","hash":"16ae78eba755b9bc559e864077fef80bd911fd16","modified":1522245286031},{"_id":"source/_posts/机器学习之Logistic回归/机器学习之Logistic回归01.png","hash":"1817f152628ed2d0e63b71a9071cbcb7765edd41","modified":1522221930283},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/.DS_Store","hash":"298e9892310d3c33cc36aed29eb22b7ee50c6f65","modified":1523008752797},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片01.png","hash":"2c766de1fa96945fbadff336ad36ddb470026c58","modified":1522719717371},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/.DS_Store","hash":"08974a08332afa53d94a33f0a6d9d44761e68a2e","modified":1523016650880},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像01.png","hash":"f5b42a7d64bcf4e42dbddea25f9d91dacd47ae8e","modified":1519290534407},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像02.png","hash":"911aacc5c8458e2a9789dabcf11bee3b8fb08254","modified":1519290529866},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像03.png","hash":"db3af154b414462add94cafcf711c95dc8fce7d2","modified":1519290530309},{"_id":"source/_posts/机器学习之决策树-C4-5算法/机器学习之决策树图片01.png","hash":"94ede414f10507f9d1a5433b3db69e819d36b605","modified":1524212210853},{"_id":"source/_posts/机器学习之决策树-C4-5算法/.DS_Store","hash":"68e4aef0339f605f365952692815a0cf05dcbc0c","modified":1524217176457},{"_id":"source/_posts/机器学习之线性回归/.DS_Store","hash":"cc59d5c34db63e8223e7bee9d0ae80c905291e9b","modified":1522075010225},{"_id":"source/_posts/机器学习之线性回归/图片01.png","hash":"2b715466ee24cacfb4596159b9e5d548c7508a98","modified":1521907108234},{"_id":"source/_posts/机器学习知识体系/.DS_Store","hash":"0cf9f687c90ec4689d06e3b9b90988365ace4a2b","modified":1521904877534},{"_id":"source/_posts/机器学习知识体系/图片02.png","hash":"0a2bb3b98d4750f7b7f7830aefb1347ea1e6414c","modified":1521874559462},{"_id":"source/_posts/机器学习知识体系/图片01.png","hash":"2242e0694775cb96fac26c3d88feabbc965c0c59","modified":1521874547062},{"_id":"source/about/index/.DS_Store","hash":"6f6d730c6b9445730cf530e7ce6e24ff2474bbcb","modified":1522310371259},{"_id":"source/about/index/公众号.jpg","hash":"df033d0e4e9de400ba207e9b6b7f28817d5996d8","modified":1520581948988},{"_id":"source/favorite/index/.DS_Store","hash":"b3c580ad9ecfe0afdd65ae78548bd02703150694","modified":1523031763810},{"_id":"source/favorite/index/千只鹤.png","hash":"40648286cd3ec51788feb38751955ce87b2c1187","modified":1523031174082},{"_id":"source/favorite/index/呼兰河传.png","hash":"3c6265050366c20f364d81ca51c4cae1e048e10f","modified":1523030253646},{"_id":"source/favorite/index/南极之恋.png","hash":"d676feb96ad6ba07864fba120e2fecdc246bf181","modified":1522588483415},{"_id":"source/favorite/index/围城.png","hash":"1666c5acc5f44e80810156baf52c442fe3e8547a","modified":1523029929186},{"_id":"source/favorite/index/啪嗒啪嗒.png","hash":"cbd9ecc5165e0d7f95e878589b743dc8966b3ae6","modified":1523798411056},{"_id":"source/favorite/index/小王子.png","hash":"4ae6257100eac358302726019c661b96d6cd9dcb","modified":1523029855294},{"_id":"source/favorite/index/平凡的世界.png","hash":"e9f2fdd7030ef334716e1eeed61f570521d8ea88","modified":1523030491413},{"_id":"source/favorite/index/挪威的森林.png","hash":"0c7bdd6bf72bc5f8756b25451ed05a3fe27c5c12","modified":1523030020959},{"_id":"source/favorite/index/时间简史.png","hash":"55e985e54c09ec887967afa5a5140db4b046cf99","modified":1523030781408},{"_id":"source/favorite/index/斯里兰卡.png","hash":"b452d7a35655784028a733e13d857fcc49b8581c","modified":1523011664219},{"_id":"source/favorite/index/暴裂无声.png","hash":"910d373523d48e647474554de50320180431e470","modified":1523011298640},{"_id":"source/favorite/index/瓦尔登湖.png","hash":"4e366a14a8f180cfe58a1489a2fb37c520fbc375","modified":1523029771431},{"_id":"source/favorite/index/来自风平浪静的明天.png","hash":"ea3c22cd9345acc2690487aee43516ffd4f54b6f","modified":1522310977851},{"_id":"source/favorite/index/白鹿原.png","hash":"d7daa85ece656b85a22b578be70a66153c6692d6","modified":1523030417644},{"_id":"source/favorite/index/看见.png","hash":"7ea7eabe0eaabf712456e0f366ff1265d8ce7073","modified":1523029676757},{"_id":"source/favorite/index/羊脂球.png","hash":"02904a61fb3f435f9652b7285e1f776da08fd335","modified":1523031301721},{"_id":"source/favorite/index/老人与海.png","hash":"23b3135f7031ecbf120e0b542d1c491397c95f1c","modified":1523031007307},{"_id":"source/favorite/index/解密.png","hash":"ff9fdc5d9d260a700a5244308ff86de0cc991f66","modified":1523031484004},{"_id":"source/favorite/index/边城.png","hash":"322d9c89b128634232bab0443b48a4fe6a8ae179","modified":1523030297016},{"_id":"source/favorite/index/雪国.png","hash":"5be6a1b4447a4845817cbe9876e555ec99947305","modified":1523031119522},{"_id":"source/favorite/index/骄傲的印度.png","hash":"92b8064589a886fdc99b61eaa6682dcae42cee5d","modified":1523011709977},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1515072990000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1515072990000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1515072990000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1515072990000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1515072990000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1515072990000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1515072990000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1515072990000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1515072990000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1515072990000},{"_id":"themes/next/layout/_partials/.DS_Store","hash":"887f56f2e7e4a796c76f3f195914664b20c6cad9","modified":1521276321750},{"_id":"themes/next/layout/_partials/head.swig","hash":"9423bedc0ab1e1eccb824d52c19ee8d75e1911a9","modified":1521276757341},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1515072990000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1515072990000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1515072990000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1515072990000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1515072990000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1515072990000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1515072990000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1515072990000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1515072990000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1515072990000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1515072990000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1515072990000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1515072990000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1515072990000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1515072990000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1515072990000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1515072990000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1515072990000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1515072990000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1515072990000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1515072990000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1515072990000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1515072990000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1515072990000},{"_id":"themes/next/source/images/.DS_Store","hash":"36403ad01e4062c0e368be912b852990811a87af","modified":1520953865632},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1515072990000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1515072990000},{"_id":"themes/next/source/images/avatar.png","hash":"d985c17188c7c966df863e797976d98ce8b40771","modified":1520578140450},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1515072990000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1515072990000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1515072990000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1515072990000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1515072990000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1515072990000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1515072990000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"78aec0fd86b154f1483a3fddf8bacb4632404bb5","modified":1520934309231},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1515072990000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1515072990000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"78aec0fd86b154f1483a3fddf8bacb4632404bb5","modified":1520934309231},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1515072990000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1515072990000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1515072990000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1515072990000},{"_id":"source/_posts/Markdown写作教程/图片01.png","hash":"37bf22348a323e3708cfe540ae74e6d8e89bd4d6","modified":1521443192789},{"_id":"source/_posts/Markdown写作教程/推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/Python之MatPlotLib使用教程/01.png","hash":"33e230638dfea5aecb04dfbdd3a6099c248ef2c3","modified":1520750712546},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像18.png","hash":"3eb66a4726829f310e9317433813bafcae824183","modified":1521017855982},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像21.png","hash":"6c844ab24a7b2fa744f14a70bac46b613fc4cca3","modified":1521019203108},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像19.png","hash":"a9ce5acc9a9bd616faf50581b802aa69d4ec5e5d","modified":1521018063252},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像22.png","hash":"e9cf3a459468a6696855da633138be48e6ee3d7b","modified":1521019668154},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像23.png","hash":"84f4972fd31cc00510f9cd5b5b5c23bce1661072","modified":1521022889615},{"_id":"source/_posts/Python之MatPlotLib使用教程/图片16.png","hash":"f61b216e3015ff8461953b80a41c404ab9c05f7a","modified":1521014672819},{"_id":"source/_posts/Python之MatPlotLib使用教程/图片17.png","hash":"05d26db61bbd1b7ad73219630d6423e1c712d91c","modified":1521014682865},{"_id":"source/_posts/Python之MatPlotLib使用教程/推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程04.png","hash":"54e7eb64aeff4e62baa1f465b9ecd8b0163c298d","modified":1523775847000},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程06.png","hash":"397f01c175a32a327bd0f5e25737bebfb30a429a","modified":1523778871147},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程07.png","hash":"f73d270ea01afc9494a85cb642779e25ceb87aa7","modified":1523779122431},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/机器学习之Logistic回归/机器学习之Logistic回归03.png","hash":"414ee5813fc11417114610e2e6af70a89650f185","modified":1522244498598},{"_id":"source/_posts/机器学习之Logistic回归/推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片推广.png.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像05.png","hash":"b44c4687d5db6136f7ad2d8c07ce5f8810315df5","modified":1523007080985},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图片推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/机器学习之线性回归/推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/_posts/机器学习知识体系/推广.png","hash":"fdc0ae32fe7c6bcfaf9d72ee6dbe92aeec6b63ea","modified":1521024709018},{"_id":"source/favorite/index/万物理论.png","hash":"5b85ade7a7d500b0ab5272265bc9b36598b7a5de","modified":1522310637211},{"_id":"source/favorite/index/刻刻.png","hash":"ad0d0841c6216abbf4529e292094491fcdfa36eb","modified":1522310945139},{"_id":"source/favorite/index/越禁忌越美丽.png","hash":"7a77baab7178ecf9a14fc1e27c198e0790896d91","modified":1523011470391},{"_id":"source/favorite/index/霸王别姬.png","hash":"80f6b6bbbf64276eb091219d0dae55c0338fb2a8","modified":1523797461170},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1515072990000},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 20-10-45.md","hash":"049fb26ee773eaf41946ef49b09daf6bb243fe2f","modified":1521979845135},{"_id":"source/_posts/.Archive/Python之MatPlotLib使用教程.md/2018-03-25 19-59-25.md","hash":"d4f91fd5d44d6beddd58eec9f426f0887583e1a6","modified":1521979165076},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 20-19-07.md","hash":"4b912fca9b44721a93d346f24902fcc1d9518a4b","modified":1521980347112},{"_id":"source/_posts/.Archive/Python之MatPlotLib使用教程.md/2018-03-25 19-55-55.md","hash":"eb5a4de8344a6843371745efa3cbccee02fef7a3","modified":1521978955153},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 21-55-10.md","hash":"32350f1cd9bc33d88c34ad2627911fd2c896b220","modified":1521986110893},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 21-56-10.md","hash":"c168af8ad8b522e4e48e7cf3b148376e70396ade","modified":1521986170894},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 20-40-57.md","hash":"d0cfca39104d291dee12c76bcfcce956d20b39d7","modified":1521981657156},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 21-52-20.md","hash":"f46cc95f707d6ef281191a30f6184020cff607fd","modified":1521985940888},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-01-20.md","hash":"c39ea2086a8b044afe3e18c065fe8b10f04843c1","modified":1521986480927},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 21-57-50.md","hash":"3fbf2ab4576c8e8e5142583adcfbef684a5ede9b","modified":1521986270896},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-04-40.md","hash":"e9c2d0a19630ffb04a3eae8540d8841ed8c71d56","modified":1521986680909},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-02-50.md","hash":"e452abb9fca7c44053cd2e998f9eb1d82ac273de","modified":1521986570905},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-08-30.md","hash":"f9b76652cee53c59c03f4c0d83b8db0ad616b8e4","modified":1521986910913},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-10-40.md","hash":"ad568931dda35f76d84d7b8403c47a2ebe36c7ea","modified":1521987040916},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-12-00.md","hash":"22cc0ff5ac4cc3818c442182f02bbd4a7bce1982","modified":1521987120919},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-07-10.md","hash":"bf01038be7871345ae5e13d67fcf2bf40dd3a116","modified":1521986830916},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-15-30.md","hash":"74864eb152380179f7e65e77fc154c234a03779e","modified":1521987330923},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-16-30.md","hash":"a0dd34efea9fe196efe06452b3b2d7b8f87774a7","modified":1521987390926},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-20-30.md","hash":"d9579c4616c8cb15464eafe998c00bc98f8fc033","modified":1521987630931},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-22-00.md","hash":"7af87c891b584f41c215ee7d1ce56ef05d39cb27","modified":1521987720935},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-40-21.md","hash":"483109e9481cff47d6780cde0909c38b45a254ef","modified":1521988821126},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 23-25-31.md","hash":"be501dc660ce5477c996116d45d4c509a013a836","modified":1521991531474},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 22-23-40.md","hash":"19cfae3d212a34d0c0de41ccc2534d96f1376e2a","modified":1521987820939},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 23-17-48.md","hash":"d7378f3302b3427c4ef0aa51d87bbbcdab7f2e42","modified":1521991068510},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 00-40-11.md","hash":"3eef9d1b2d90e4cbd9ada9e6828956a699fd7c2e","modified":1521996011594},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-25 23-32-38.md","hash":"54af3335021febd12841463741bac435ce78aed3","modified":1521991958983},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 00-41-36.md","hash":"a16b36716e6bd24fd078622801c7abe58e97d8ac","modified":1521996096036},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-21-06.md","hash":"6db531e0dffd53d94d09af155f768568699f5259","modified":1522034466685},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-22-26.md","hash":"69e3b51eab2d30816d8b8b1326dfa738e34242e8","modified":1522034546704},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-23-56.md","hash":"c66db085f5534adccc3f2a29958b2f6ca908954a","modified":1522034636691},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-31-16.md","hash":"df215088593c0372eabcaa8f86814f48bb2fce68","modified":1522035076748},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-33-06.md","hash":"aac252ce042db8a06086a02d4f45cd094fe0b4b0","modified":1522035186706},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-35-36.md","hash":"bd1dafa423779089e951fed3b68fffda1b649af7","modified":1522035336708},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-36-46.md","hash":"fbdbeff0a51aeacd2ebd0a07e3bfd45f34345390","modified":1522035406710},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-34-26.md","hash":"ef03e21c450b5c01291525905bf3d6e47f556dcb","modified":1522035266725},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-37-46.md","hash":"58c78bf8b049e9b29b10c2979bed346583ee424f","modified":1522035466715},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-40-46.md","hash":"20651a1855db4f2389033635e5d20ee7758f113d","modified":1522035646716},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-42-46.md","hash":"33a3d5d5e4fb23a23ec5fc5c127dfc4baf7ce0b4","modified":1522035766724},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-41-46.md","hash":"b80095e406003ec53a4d6c7a26fdbd0cc0cd08c6","modified":1522035706717},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-39-26.md","hash":"bac24c55eedc782459b12c8b26c2b02c61ad8e79","modified":1522035566714},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-45-06.md","hash":"6a78156cf700bf4d80bd4ac9bb0ca799d44a6646","modified":1522035906724},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-44-06.md","hash":"e827a734db603b0b4a48b63f9b71250833268059","modified":1522035846723},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-21-28.md","hash":"a1f09efb8dfbcd09c5acd39c66feae094721a6ff","modified":1522038088951},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 11-46-44.md","hash":"7a7096c08001cb5c21eb1de2011a0d00d1d7fa32","modified":1522036004961},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-22-38.md","hash":"56f392a82fafaa724043fcc173b0ed60aba88559","modified":1522038158950},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-23-48.md","hash":"da3d957091a84bf19391bcc51cb9b840eef82026","modified":1522038228952},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-31-58.md","hash":"34b3ef1e8a026e9079f33a9463729e13a1f827a3","modified":1522038718949},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-25-38.md","hash":"87a8eb8d631ecba93341319704ba8e27d74707fa","modified":1522038338949},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-34-29.md","hash":"ab40e56cdf66dc96cf2e616d6b262b8a83f0029d","modified":1522038869416},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-38-49.md","hash":"151224915158d949e45a855f869a5fdbcaf32230","modified":1522039129424},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-33-29.md","hash":"6ee8200a93119f6221cfd4384d68753e8d18792d","modified":1522038809022},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-42-49.md","hash":"33a29aad02da9bd2d15b8a4e39dd6d3072734b57","modified":1522039369554},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-43-59.md","hash":"6ead39fb81ce29b51a3dc45a5e7b60f29313d666","modified":1522039439411},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-45-29.md","hash":"88cd551cb991c96982436b921d72abbda9812656","modified":1522039529449},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-48-09.md","hash":"40998f1150b08de3784b3e1b217fe49830d9517a","modified":1522039689466},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-47-09.md","hash":"a78752c4a66a15abe83e8e17012a2b6bf7c99bf4","modified":1522039629411},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-50-29.md","hash":"cc5d24a1e98f874dc399c5c524c51c3e269ef87b","modified":1522039829436},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-51-39.md","hash":"218a24d8cbd0f93077d86faf8bef3185160d4802","modified":1522039899443},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-52-39.md","hash":"f7b85011363e9533f202e843b254fa312c2fc464","modified":1522039959570},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-53-49.md","hash":"cec8c17a758b931b28659172e7eff49a6b7f14e2","modified":1522040029551},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-54-59.md","hash":"ab08bc472e72d309786c16e77f03caf6746f387e","modified":1522040099440},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-55-59.md","hash":"890b192408dc5f4e27a9101151082331a156fadb","modified":1522040159442},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-59-29.md","hash":"33d5e6ec3b7c9c89ce5ae8ceb676e166176d06be","modified":1522040369443},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 12-57-59.md","hash":"6d9f2de0e3cd46f82c351422777655371ca87ad9","modified":1522040279443},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-00-39.md","hash":"373df51de30881e6d6943be5f9a4768db52dbb1d","modified":1522040439446},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-07-09.md","hash":"b9039a1b1b0a792611fbe471bc23fa4ade6077d7","modified":1522040829468},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-08-09.md","hash":"ab3a5085c37fc851054050d5477ca9606fbf6d2b","modified":1522040889470},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-10-19.md","hash":"21d1eed734d5425872fb57e15049efb8a19eebde","modified":1522041019477},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-11-29.md","hash":"b30fe788bb1acff82e9bae45017f59f64958f2fc","modified":1522041089476},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-17-49.md","hash":"57f684edb79da0ca486029db3379deb06f76b579","modified":1522041469488},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-19-09.md","hash":"187db145fa18ea582f965dbf849ffd66fb09de95","modified":1522041549488},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-21-09.md","hash":"fa41b1fda333357495ff41d7fd2470417d94f90e","modified":1522041669616},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-22-19.md","hash":"9925fe82ebd2b81377e12e85fc024583e5dc4caf","modified":1522041739495},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 13-24-29.md","hash":"a233a10461172c85b8c0f77aa403df112a2358c3","modified":1522041869583},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-04-32.md","hash":"68fd4dd7c304738f8ed74cea3bfc7c7578324b4a","modified":1522055072770},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-05-42.md","hash":"c0abdf7d187ef4ef2779c9c308c40dfd3024987e","modified":1522055142716},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-06-42.md","hash":"2439b5a290bdf02d0b90ecc99a8870ab060a055f","modified":1522055202723},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-08-22.md","hash":"0f9dd1f345389999e3abcca0118eb7d1abce791b","modified":1522055302717},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-09-22.md","hash":"ee47ba3255a6528bd3887a557b6312334c8367d4","modified":1522055362808},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-11-42.md","hash":"7e9c35e90f602ee22419a4bd851505f55b6cef8c","modified":1522055502726},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-10-32.md","hash":"22ca7f872bf5bdcd8bfe56cec7fe58289c38476d","modified":1522055432813},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-13-22.md","hash":"46f1e288b3ae476af2ba9a6d1516e8d031091e18","modified":1522055602746},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-14-22.md","hash":"94b4a9eb03304f851dc4ee069584aed9d81810ed","modified":1522055662770},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-15-22.md","hash":"75b349c8f2df5af30e3418b42a508f248b420653","modified":1522055722808},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-16-42.md","hash":"b92eef8a9f13713d6aeba4ed75eea9199560a293","modified":1522055802746},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-19-52.md","hash":"237f34cb4e7b927abd307445dd7bff3bfa454e9c","modified":1522055992746},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-18-22.md","hash":"ca5df8507ac02d0c686037e50888b9fbf8929df8","modified":1522055902791},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-22-22.md","hash":"219c7feb17f955025807a13fa83ea12c0842e0d6","modified":1522056142751},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-24-13.md","hash":"17eb8fd7a29cf7b1b77725e05d659d2c6a840feb","modified":1522056253756},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-46-23.md","hash":"2f31e399a623554c0c26a915151d3ab25f85d4ae","modified":1522057583799},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-50-13.md","hash":"def480dd8ca7d7e7863b09112d7df1a1e307e167","modified":1522057813809},{"_id":"source/_posts/.Archive/机器学习之线性回归.md/2018-03-26 17-52-32.md","hash":"0ab39dbd96b12445c3df9139e996bcd67117309c","modified":1522057952914},{"_id":"source/_posts/Markdown写作教程/图片03.png","hash":"244052c1fc5344f9d755cb942517d9d5da14afe3","modified":1521444578570},{"_id":"source/_posts/Python之MatPlotLib使用教程/12.png","hash":"4812b5371a7cb9d823327f8e95dffa5aaf97934b","modified":1520763832783},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程图片02.png","hash":"2be19ce3efa76780e9a18a93a1dac729b1b7a3f5","modified":1523772055010},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片03.png","hash":"2f7a3455e1fd13aaa582f7274d4c7d50e8fae5d9","modified":1522677611570},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片05.png","hash":"ed89cf8ee5f651f2e1769321716565748b043bc3","modified":1522656180663},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像06.png","hash":"ed008a6f9a39ee597bf965da9cf3349181e88980","modified":1523007598843},{"_id":"source/_posts/机器学习之线性回归/公式03.png","hash":"3ce320dce755145da770585a40c55c22da3d671e","modified":1522074870692},{"_id":"source/_posts/机器学习之线性回归/公式01.png","hash":"e3afd52d851957f06f23168c198ccd1814e9de25","modified":1522074544547},{"_id":"source/_posts/机器学习之线性回归/图片03.png","hash":"e322d56b0e286a2ca13cbbb470ce25010f8b1c5b","modified":1522054969819},{"_id":"source/favorite/index/唐人街探案2.png","hash":"219b7aba70b09709b44844d891dbea2913112fc4","modified":1522310858709},{"_id":"source/favorite/index/捉妖记2.png","hash":"bebe111082fcb7094408f3bfa6db4e36ecbeb597","modified":1522310905399},{"_id":"source/favorite/index/未闻花名.png","hash":"d294bca224d47f80814e484461a8d6241b1eb909","modified":1522311158271},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1515072990000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1515072990000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1515072990000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1515072990000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1515072990000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1515072990000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1515072990000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1515072990000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1515072990000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1515072990000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1515072990000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1515072990000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1515072990000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1515072990000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1515072990000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1515072990000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1515072990000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1515072990000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1515072990000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1515072990000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1515072990000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1515072990000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1515072990000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1515072990000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1515072990000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1515072990000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1515072990000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1515072990000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1515072990000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1515072990000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1515072990000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1515072990000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1515072990000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1515072990000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1515072990000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1515072990000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1515072990000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1515072990000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1515072990000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1515072990000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1515072990000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1515072990000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1515072990000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1515072990000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1515072990000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1515072990000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1515072990000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1515072990000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1515072990000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1515072990000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1515072990000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1515072990000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1515072990000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1515072990000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1515072990000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1515072990000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1515072990000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1515072990000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1515072990000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1515072990000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1515072990000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1515072990000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1515072990000},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.3.png","hash":"9c5d6ffa38f3ff94979444e7ac5e38943c2404f8","modified":1521171912741},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程05.png","hash":"256d9aadf22876b4fe5beea1c6fb126d245df262","modified":1523777912548},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片04.png","hash":"c6c24fbb1b1f06aee99d1c7ed558d54edf48e1ed","modified":1522655857701},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片11.png","hash":"f6aea31b36824cf4958541fd47067965a5057d81","modified":1522717780858},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片14.png","hash":"8e40abc5b044df8a0b256edbbca383df20e1a485","modified":1522717929705},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片17.png","hash":"28a4092973b644020d1b7b8f4d7ce80619006334","modified":1522670595184},{"_id":"source/_posts/机器学习之线性回归/公式02.png","hash":"09937e4c48b4bfaf597eb85131c7db518c73fce9","modified":1522074559149},{"_id":"source/_posts/机器学习知识体系/图片03.png","hash":"8d75e5be4fbaa92f0ab0e411159cbfbb201673df","modified":1521872892514},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1515072990000},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片7.2.png","hash":"02359d570ab5830d815f61d8fe16ab25179c9c89","modified":1521278826350},{"_id":"source/_posts/Python之MatPlotLib使用教程/15.png","hash":"9adb17a88751a53d34588418786ee941c412ee1f","modified":1520768401624},{"_id":"source/_posts/机器学习之Logistic回归/机器学习之Logistic回归02.png","hash":"bfa20ad1c15607d24bd562d56286006dad364d9f","modified":1522244886133},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片02.png","hash":"6cb18abfc66ca9a0570bcd2dd2149a9568714ef2","modified":1522718276755},{"_id":"source/_posts/机器学习之线性回归/图片02.png","hash":"bfa20ad1c15607d24bd562d56286006dad364d9f","modified":1522055595336},{"_id":"source/favorite/index/老炮儿.png","hash":"f0549a847f9a548afbe42d92f1d49fbbc18dfd49","modified":1523799257935},{"_id":"source/favorite/index/超能陆战队.png","hash":"474e6d709f041d409c6c973b545f1924bb30f48d","modified":1523798106002},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1515072990000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1515072990000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1515072990000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1515072990000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1515072990000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1515072990000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1515072990000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1515072990000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1515072990000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1515072990000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1515072990000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1515072990000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1515072990000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1515072990000},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片4.1.png","hash":"faa30796bf710258a987c3277c77de1e5af0e709","modified":1521185354700},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.1.png","hash":"6e71a79873cf1b4ce889c6bfd9bfdf7be1ac9009","modified":1521171871303},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.4.png","hash":"36ce82cebff199c501a9cba78fef0169aae62225","modified":1521206164160},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程图片01.png","hash":"4d8692aec2e5ac5ead5da05c1833bdef07aa1d6e","modified":1523707430660},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片06.png","hash":"29d5e6087b241a8a4eae416a0997028f28b066e2","modified":1522717387984},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片08.png","hash":"6def4e9f93f518f2210e44d9c7d23aad339ffa56","modified":1522717592439},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片10.png","hash":"11f3b12ef3ea65d97c6a92fffc71d73c094807b4","modified":1522717742465},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片13.png","hash":"840d9444a423bb1e43200f77bf6b2b6b4ef5f200","modified":1522717855374},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片16.png","hash":"4cf2f1a3596e6381019ac52c02a6fb7d78b02ac2","modified":1522717997105},{"_id":"source/favorite/index/神偷奶爸.png","hash":"82a7aed9f6aa007408b1e469b95a8e56d2fc866e","modified":1523798310821},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1515072990000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1515072990000},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片07.png","hash":"7f105dfa87769b6894feb53226af206130ae2a0a","modified":1522717496601},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片09.png","hash":"c4aa4e10466b8af8ee430875266251cfd8669822","modified":1522717674777},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片12.png","hash":"562f9f4ef0d0b6fe7b1dbdd274ea417385b2e8cb","modified":1522718108545},{"_id":"source/favorite/index/喊山.png","hash":"f1f891de5a0fcdac83df0ca31130685b3e0ef482","modified":1523799421801},{"_id":"source/favorite/index/无敌破坏王.png","hash":"e1b11a72779168c4912998732738feb6a53a602c","modified":1523798178422},{"_id":"source/favorite/index/驯龙高手.png","hash":"71ce7b9f10f49f71bbb1fb03f7e5ea094b410e40","modified":1523797878411},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1515072990000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1515072990000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1515072990000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1515072990000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1515072990000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1515072990000},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.5.png","hash":"bec5459c79cfa6fdabea06979fe34404781e106b","modified":1521207413223},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片7.1.png","hash":"f70709d5d8b754a9fc2869781dc69a935d711de0","modified":1521274188922},{"_id":"source/_posts/Python之MatPlotLib使用教程/10.png","hash":"edb7d8ae73e7c28e9dc0af865e00422e93ae9fc4","modified":1520761621071},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片15.png","hash":"d8ed9a84f2cb143da24a448a746eb27a6b948110","modified":1522718172862},{"_id":"source/_posts/机器学习知识体系/图片04.png","hash":"078a6395cfe259faaaafc9509152721c309ae446","modified":1521872847278},{"_id":"source/favorite/index/北京遇上西雅图.png","hash":"7b999bd5ead37f89da6c6afaf748a08b56548511","modified":1523799851147},{"_id":"source/favorite/index/血战钢锯岭.png","hash":"658f64fb22d38e9bba651ed17ea5f5e523dd8e8e","modified":1523798032507},{"_id":"source/_posts/机器学习之决策树-C4-5算法/机器学习之决策树图片02.png","hash":"a0bd7baea72ce6eb49b8e443fffa61cb4ce8fafc","modified":1524194884897},{"_id":"source/favorite/index/V字仇杀队.png","hash":"ddd2983f339c16b779138b5952c4a4840ccff667","modified":1523797793542},{"_id":"source/favorite/index/二十二.png","hash":"f7c0fe26ec2e355475e68f090f4ce4ff553bf352","modified":1523797714335},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1515072990000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1515072990000},{"_id":"source/favorite/index/机器人总动员.png","hash":"0104e6c18523402b8cfad29f0c6633f4b1f10d8d","modified":1523796874345},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1515072990000},{"_id":"source/_posts/Python之MatPlotLib使用教程/14.png","hash":"43f3564c467b1029cf25e46c2749b93e408be3cf","modified":1520768005391},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程08.png","hash":"12a6e73e9a4c6a21addd5542ebc96addfd889498","modified":1523779527345},{"_id":"source/favorite/index/冰雪奇缘.png","hash":"45b1536afc886118d39b0f6158e401c5ae1a132f","modified":1523799016016},{"_id":"source/favorite/index/魁拔.png","hash":"569af321553952d49b209518971e70cad14b01b1","modified":1523799124891},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.6.png","hash":"fdfdc025a22244646018a4105b4ffaa6b3ecdef6","modified":1521208606331},{"_id":"source/favorite/index/麦兜我和我妈妈.png","hash":"7ec11daa5514eb3c38d62e3d768db905ffb8b7b5","modified":1523798646657},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.2.png","hash":"34877fc9266906c05387350a9c9d13b0c8411f92","modified":1521171886540},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片3.3.png","hash":"4e466a4caae62c4d477208251f8f9ad259faeebe","modified":1521186691269},{"_id":"source/favorite/index/飞屋环游记.jpg","hash":"ec6b432f42c303f8dd4f6422ac9f8f243cb5c938","modified":1523797642824},{"_id":"source/favorite/index/少年派的奇幻漂流.png","hash":"b23028378467f11401a0dbe8004e52fcfd17558f","modified":1523797537340},{"_id":"source/favorite/index/让子弹飞.png","hash":"3660d7f75f54215e11d58c6ad62a1f81ad05ed59","modified":1523797938455},{"_id":"source/favorite/index/你得名字.png","hash":"aa632b03a5d45bebf4c97040683c30908bbefe70","modified":1523798248612},{"_id":"source/favorite/index/大护法.png","hash":"f127416a1710249487509b77575c491acc1d1746","modified":1523799319266},{"_id":"source/favorite/index/湄公河行动.png","hash":"51e05a65c72bba94bb0b7b67cb49a4466e5ac51a","modified":1523798952585},{"_id":"source/favorite/index/寻梦环游记.png","hash":"799928b5d36222b7d4255385dfbe17d38e7f3248","modified":1523797171376},{"_id":"source/favorite/index/摔跤吧！爸爸.png","hash":"a671de11641c65c076b0042eb7419803961c3fef","modified":1523797158095},{"_id":"source/favorite/index/哆啦A梦：伴我同行.png","hash":"c10e2e21782ccd15eb527012f590055f740c5d6b","modified":1523798737172},{"_id":"source/favorite/index/百鸟朝凤.png","hash":"6ea959d7080f097a721e443a828aeac4d60bedd8","modified":1523799076615},{"_id":"source/favorite/index/厉害了我的国.png","hash":"027fdadc5b22e083bf9b46813e7fbab46be36312","modified":1521092822308},{"_id":"source/favorite/index/功夫熊猫.png","hash":"4db0417a5928b5a8b772b350c17dd506db5d475e","modified":1523799489047},{"_id":"source/_posts/Markdown写作教程/图片02.png","hash":"4becc8fdd53dbe2c6e7117270d2297a27abb3c2d","modified":1521430634072},{"_id":"source/favorite/index/小羊肖恩.png","hash":"6efefbcecd5f6251ad9378ecfe780040920b0a1b","modified":1523798518535},{"_id":"source/favorite/index/盗梦空间.png","hash":"8e3e76b81eed64915e674f37589fed7c5de870c1","modified":1523796858731},{"_id":"source/favorite/index/寒战.png","hash":"ccd80105101aad9c416581709cff0c412b7fa640","modified":1523799744567},{"_id":"source/favorite/index/麦兜当当伴我心.png","hash":"32aded97cb38ba3397859371f6edb219d3dd81fb","modified":1523798592078},{"_id":"source/favorite/index/人在囧途.png","hash":"802d2fa695a76b83f45ce8f20fd56c99d5063a97","modified":1523799816035},{"_id":"source/favorite/index/昆虫总动员.png","hash":"5179b14b1d28ca6d96a7163ad31342721eb81e6f","modified":1523798922540},{"_id":"source/favorite/index/星际穿越.png","hash":"c0c28971ac6adf18bf3e10ff322a9a41acce4fdb","modified":1523797326474},{"_id":"source/favorite/index/绣春刀.png","hash":"6456f00b03996e7c4309d7cff846fbff10fdf1b1","modified":1523799658272},{"_id":"source/favorite/index/西游记之大圣归来.png","hash":"1a8b8b28321b56509e8911f06e96ea8e729ae29f","modified":1523798862566},{"_id":"source/favorite/index/诺亚方舟漂流记.png","hash":"aba0601e653699463efd6a1cdcab50d41e510a5b","modified":1523799980164},{"_id":"source/favorite/index/金蝉脱壳.png","hash":"3ac6bd32b182db8191535737e990915daff26b5b","modified":1523799564962},{"_id":"source/favorite/index/疯狂动物城.jpg","hash":"39b00aca0a9c5b5b040922c8cc8fb08b89f3b6fe","modified":1523796629699},{"_id":"public/baidusitemap.xml","hash":"f9f8de444a6118c6bb5e7482a73deb5523da9d9f","modified":1524218707487},{"_id":"public/sitemap.xml","hash":"32f0b8d8aab2daec82ab17e04612b874ec084d03","modified":1524218707508},{"_id":"public/search.xml","hash":"e4f86069e96b44fe8fc72bb15b24fe96f71e94f9","modified":1524218707509},{"_id":"public/about/index.html","hash":"6038efce20697c015986e2f5a0ca57f2d105a985","modified":1524218707631},{"_id":"public/categories/index.html","hash":"e0e0e4bdb1b76b9b19926c9790535d8724a76333","modified":1524218707632},{"_id":"public/favorite/index.html","hash":"04ad334ab751f94caf368daaa4fc23529e0e0cac","modified":1524218707632},{"_id":"public/tags/index.html","hash":"6ad89e172829e5a1e003afa004fae7f045ff832b","modified":1524218707632},{"_id":"public/2018/04/19/机器学习之决策树-C4-5算法/index.html","hash":"223caec94940c61d6c3e0aad123f6f60ab379180","modified":1524218707632},{"_id":"public/2018/04/15/Python之Sklearn使用教程/index.html","hash":"15e15a546ca37392bcacb965f3bd3af269382583","modified":1524218707632},{"_id":"public/2018/04/04/机器学习之SVM支持向量机（二）/index.html","hash":"bce3e77dde985b33d11016b9b9349d9a68063eab","modified":1524218707632},{"_id":"public/2018/03/29/机器学习之SVM支持向量机（一）/index.html","hash":"f652a193dec12d8614a897c28788e902d4bcddee","modified":1524218707632},{"_id":"public/2018/03/27/机器学习之Logistic回归/index.html","hash":"49656e2b2e23e2d8f30bc5758b90362df47a2a70","modified":1524218707632},{"_id":"public/2018/03/24/机器学习之线性回归/index.html","hash":"522a6e79b6598aa202e193de4235fe5423f843dc","modified":1524218707632},{"_id":"public/2018/03/24/机器学习知识体系/index.html","hash":"81e6eebdf20d7b09eef6f48b878145ccc692807f","modified":1524218707632},{"_id":"public/2018/03/18/Markdown写作教程/index.html","hash":"1453d09ee690b76b77e9e54d7a7ae0cef92888a6","modified":1524218707632},{"_id":"public/2018/03/16/Mac+Hexo+GitHub博客搭建教程/index.html","hash":"5167369c280756b5d9cce03fab53aeac029f503b","modified":1524218707632},{"_id":"public/2018/03/14/Python之MatPlotLib使用教程/index.html","hash":"8ad2787c8a6d334440563dea148a2a2fbb9ac285","modified":1524218707633},{"_id":"public/2018/03/13/Python之NumPy使用教程/index.html","hash":"b8611421d962e38348b7c968c92a9842f109db26","modified":1524218707633},{"_id":"public/2018/03/12/Python之Pandas使用教程/index.html","hash":"b3477c15f6f01a34fdad85525a049e38cee38cbf","modified":1524218707633},{"_id":"public/2018/03/12/面向知乎的个性化推荐模型研究论文/index.html","hash":"b483f300a8a4c816305fa96350b22ea2d008c5a8","modified":1524218707633},{"_id":"public/archives/index.html","hash":"00dac58c026584181c2330010ed9c88397ca0abc","modified":1524218707633},{"_id":"public/archives/page/2/index.html","hash":"118a0310fb3dff5aa6e513ff8c8a26cb5641c96e","modified":1524218707633},{"_id":"public/archives/2018/index.html","hash":"0ad69b75c16aa8f8dba4e9dac742f7dcf9586ab6","modified":1524218707633},{"_id":"public/archives/2018/page/2/index.html","hash":"994ce30952f9a606853fb31b54a33fa5b1eefe85","modified":1524218707633},{"_id":"public/archives/2018/03/index.html","hash":"7b0c34c48c2355238ab4315c964f6b03fa4a1d3e","modified":1524218707633},{"_id":"public/archives/2018/04/index.html","hash":"c458b9739331407b76d635cd95188d3002596fae","modified":1524218707633},{"_id":"public/categories/Python库/index.html","hash":"1363e81858a2ccf50d024389fb7742264506b039","modified":1524218707633},{"_id":"public/categories/教程/index.html","hash":"45a1d95eee0bead7dba2065277f1ded5123046c2","modified":1524218707633},{"_id":"public/categories/机器学习/index.html","hash":"eace60bd2a54023d492e8ca6f9bf9780d49015d1","modified":1524218707634},{"_id":"public/categories/推荐系统/index.html","hash":"7a569ea052fb99eda190a84d68ac8951c2dccdcb","modified":1524218707634},{"_id":"public/index.html","hash":"31d9e8a2c3eb6c8938dadc44cf0cb33ec1f16cc5","modified":1524218707634},{"_id":"public/page/2/index.html","hash":"27dc7c9abb879c12330cb504d524239e6a62f477","modified":1524218707634},{"_id":"public/tags/Markdown/index.html","hash":"4319a49bbedf6b357bba60ad5c1c8fee26640924","modified":1524218707634},{"_id":"public/tags/博客/index.html","hash":"8378a1e9b65fe4072f5acc3e8319ce59e4ddb6fc","modified":1524218707634},{"_id":"public/tags/教程/index.html","hash":"fa8a391ad460f7d73d857f3ae98a161872f13251","modified":1524218707634},{"_id":"public/tags/python/index.html","hash":"1b7cf9c791a4762078b8c97a8473c9f781314e84","modified":1524218707635},{"_id":"public/tags/Mac/index.html","hash":"7097b3608ac6ba88a6bcda7f80ed128682f75e0b","modified":1524218707635},{"_id":"public/tags/Hexo/index.html","hash":"f958c50d766fe56151a3691fc026664af6ee301f","modified":1524218707635},{"_id":"public/tags/GitHub/index.html","hash":"72b41f9265eacac997ecc806bc2ac76fe8557f6c","modified":1524218707635},{"_id":"public/tags/机器学习/index.html","hash":"07934496e30135cdc677172e0c7e5ebcfb841129","modified":1524218707635},{"_id":"public/tags/算法/index.html","hash":"9c6f40320e62bef07da23b865c204b8db28d1b25","modified":1524218707635},{"_id":"public/tags/推荐系统/index.html","hash":"b586d9efb6c5bf3331e85507f120fb3b5b272e97","modified":1524218707635},{"_id":"public/tags/Python/index.html","hash":"1e2480e5a648fe16fc85814238dda45abed92c55","modified":1524218707637}],"Category":[{"name":"Python库","_id":"cjg7s0pq400073201cbz65wzu"},{"name":"教程","_id":"cjg7s0pqo000i3201mtz3burd"},{"name":"机器学习","_id":"cjg7s0pqt000o3201q3667juk"},{"name":"推荐系统","_id":"cjg7s0pr500173201z8cfbskk"}],"Data":[],"Page":[{"title":"关于","date":"2018-03-13T13:34:44.000Z","comments":1,"_content":"「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活...\n\n - 知乎：@[谓之小一](https://www.zhihu.com/people/weizhixiaoyi/activities)  \n - GitHub：@[weizhixiaooyi](https://github.com/weizhixiaoyi)\n - 邮箱: zhenhai.gl@gmail.com\n - 微信公众号：@谓之小一\n![公众号](index/公众号.jpg)","source":"about/index.md","raw":"---\ntitle: 关于\ndate: 2018-03-13 21:34:44\ncomments: true\n---\n「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活...\n\n - 知乎：@[谓之小一](https://www.zhihu.com/people/weizhixiaoyi/activities)  \n - GitHub：@[weizhixiaooyi](https://github.com/weizhixiaoyi)\n - 邮箱: zhenhai.gl@gmail.com\n - 微信公众号：@谓之小一\n![公众号](index/公众号.jpg)","updated":"2018-03-27T06:49:17.983Z","path":"about/index.html","layout":"page","_id":"cjg7s0ppq00013201ts4f64hu","content":"<p>「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活…</p>\n<ul>\n<li>知乎：@<a href=\"https://www.zhihu.com/people/weizhixiaoyi/activities\" target=\"_blank\" rel=\"noopener\">谓之小一</a>  </li>\n<li>GitHub：@<a href=\"https://github.com/weizhixiaoyi\" target=\"_blank\" rel=\"noopener\">weizhixiaooyi</a></li>\n<li>邮箱: zhenhai.gl@gmail.com</li>\n<li>微信公众号：@谓之小一<br><img src=\"/about/index/公众号.jpg\" alt=\"公众号\"></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活…</p>\n<ul>\n<li>知乎：@<a href=\"https://www.zhihu.com/people/weizhixiaoyi/activities\" target=\"_blank\" rel=\"noopener\">谓之小一</a>  </li>\n<li>GitHub：@<a href=\"https://github.com/weizhixiaoyi\" target=\"_blank\" rel=\"noopener\">weizhixiaooyi</a></li>\n<li>邮箱: zhenhai.gl@gmail.com</li>\n<li>微信公众号：@谓之小一<br><img src=\"/about/index/公众号.jpg\" alt=\"公众号\"></li>\n</ul>\n"},{"title":"分类","type":"categories","comments":0,"date":"2018-03-13T15:29:19.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ntype: \"categories\"\ncomments: false\ndate: 2018-03-13 23:29:19\n---\n","updated":"2018-03-13T17:26:32.190Z","path":"categories/index.html","layout":"page","_id":"cjg7s0ppv000332010pisxr29","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"喜欢","date":"2018-03-15T05:41:17.000Z","_content":"\n## 1.书籍\n\n{% stream %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2.png  [《时间简史》 ](https://book.douban.com/subject/1034282/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%9C%8B%E8%A7%81.png  [《看见》 ](https://book.douban.com/subject/20427187/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96.png  [《瓦尔登湖》 ](https://book.douban.com/subject/3522695/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%8E%8B%E5%AD%90.png  [《小王子》 ](https://book.douban.com/subject/1084336/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%9B%B4%E5%9F%8E.png  [《围城》 ](https://book.douban.com/subject/1069848/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%8C%AA%E5%A8%81%E7%9A%84%E6%A3%AE%E6%9E%97.png  [《挪威的森林》 ](https://book.douban.com/subject/1046265/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%91%BC%E5%85%B0%E6%B2%B3%E4%BC%A0.png  [《呼兰河传》 ](https://book.douban.com/subject/4843155/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%BE%B9%E5%9F%8E.png  [《边城》 ](https://book.douban.com/subject/1852117/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%99%BD%E9%B9%BF%E5%8E%9F.png  [《白鹿原》 ](https://book.douban.com/subject/1085799/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C.png  [《平凡的世界》 ](https://book.douban.com/subject/1200840/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7.png  [《老人与海》 ](https://book.douban.com/subject/1880992/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%9B%AA%E5%9B%BD.png  [《雪国》 ](https://book.douban.com/subject/24736899/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8D%83%E5%8F%AA%E9%B9%A4.png  [《千只鹤》 ](https://book.douban.com/subject/24736900/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%BE%8A%E8%84%82%E7%90%83.png  [《羊脂球》 ](https://book.douban.com/subject/3144827/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%A7%A3%E5%AF%86.png  [《解密》 ](https://book.douban.com/subject/1881118/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%AA%84%E5%82%B2%E7%9A%84%E5%8D%B0%E5%BA%A6.png  [《骄傲的印度》 ](https://www.amazon.cn/dp/B00PQDZ542?_encoding=UTF8&ref_=ku_mi_rw_edp) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%96%AF%E9%87%8C%E5%85%B0%E5%8D%A1.png  [《斯里兰卡 》 ](https://www.amazon.cn/dp/B00RXBJNNE?_encoding=UTF8&ref_=ku_mi_rw_edp) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%B6%8A%E7%A6%81%E5%BF%8C%E8%B6%8A%E7%BE%8E%E4%B8%BD.png  [《越禁忌越美丽 》 ](https://www.amazon.cn/dp/B00S9CGUBY?_encoding=UTF8&ref_=ku_mi_rw_edp) %}\n\n{% figure https://img3.doubanio.com/lpic/s28357056.jpg  [《三体 》 ](https://book.douban.com/subject/6518605/) %}\n\n{% figure https://img3.doubanio.com/lpic/s1168991.jpg [《阿甘正传》](https://book.douban.com/subject/1211267/)%}\n\n{% figure https://img3.doubanio.com/lpic/s6384944.jpg [《百年孤独》](https://book.douban.com/subject/6082808/)%}\n\n{% figure https://img3.doubanio.com/lpic/s3278363.jpg [《穆斯林的葬礼》](https://book.douban.com/subject/2244146/)%}\n\n{% figure https://img3.doubanio.com/lpic/s3735710.jpg [《岛》](https://book.douban.com/subject/3673651/)%}\n\n{% figure https://img3.doubanio.com/lpic/s11284102.jpg [《霍乱时期的爱情》](https://book.douban.com/subject/10594787/)%}\n\n{% figure https://img3.doubanio.com/lpic/s6509536.jpg [《悟空传》](https://book.douban.com/subject/6431994/)%}\n\n{% figure https://img3.doubanio.com/lpic/s27988606.jpg [《硅谷之火》](https://book.douban.com/subject/26306584/)%}\n\n{% figure https://img3.doubanio.com/lpic/s9034256.jpg [《千年一叹》](https://book.douban.com/subject/6808159/)%}\n\n{% figure https://img1.doubanio.com/lpic/s27226968.jpg [《文化苦旅》](https://book.douban.com/subject/19940743/)%}\n\n{% figure https://img3.doubanio.com/lpic/s1466042.jpg [《狼图腾》](https://book.douban.com/subject/1022060/)%}\n\n{% figure https://img3.doubanio.com/lpic/s27314106.jpg [《生活的艺术》](https://book.douban.com/subject/7564166/)%}\n\n{% figure https://img1.doubanio.com/lpic/s27595957.jpg [《荆棘鸟》](https://book.douban.com/subject/25887947/)%}\n\n{% endstream %}\n\n## 2.电影\n\n{% stream %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9A%B4%E8%A3%82%E6%97%A0%E5%A3%B0.png\n[《暴裂无声》](https://movie.douban.com/subject/26628329/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8D%97%E6%9E%81%E4%B9%8B%E6%81%8B.png\n[《南极之恋》](https://movie.douban.com/subject/26628329/) %}\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9C%AA%E9%97%BB%E8%8A%B1%E5%90%8D.png\n[《未闻花名》](https://movie.douban.com/subject/5397537/) %}\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%88%BB%E5%88%BB.png\n\n[《刻刻》](https://movie.douban.com/subject/27173361/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%B8%87%E7%89%A9%E7%90%86%E8%AE%BA.png\n[《万物理论》](https://movie.douban.com/subject/24815950/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9D%A5%E8%87%AA%E9%A3%8E%E5%B9%B3%E6%B5%AA%E9%9D%99%E7%9A%84%E6%98%8E%E5%A4%A9.png\n[《来自风平浪静的明天》 ](https://movie.douban.com/subject/11624690/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%94%90%E4%BA%BA%E8%A1%97%E6%8E%A2%E6%A1%882.png\n[《唐人街探案（二）》](https://movie.douban.com/subject/26698897/?from=showing) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%8D%89%E5%A6%96%E8%AE%B02.png\n\n[《捉妖记（二）》 ](https://movie.douban.com/subject/26575103/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E.jpg\n\n[《疯狂动物城》 ](https://movie.douban.com/subject/25662329/?suggest=%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%80%BB%E5%8A%A8%E5%91%98.png\n\n[《机器人总动员》 ](https://movie.douban.com/subject/2131459/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%9B%97%E6%A2%A6%E7%A9%BA%E9%97%B4.png\n\n[《盗梦空间》 ](https://movie.douban.com/subject/3541415/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%91%94%E8%B7%A4%E5%90%A7%EF%BC%81%E7%88%B8%E7%88%B8.png\n\n[《摔跤吧！爸爸》 ](https://movie.douban.com/subject/26387939/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%AF%BB%E6%A2%A6%E7%8E%AF%E6%B8%B8%E8%AE%B0.png\n\n[《寻梦环游记》 ](https://movie.douban.com/subject/20495023/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%98%9F%E9%99%85%E7%A9%BF%E8%B6%8A.png\n\n[《星际穿越》 ](https://movie.douban.com/subject/1889243/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%9C%B8%E7%8E%8B%E5%88%AB%E5%A7%AC.png\n\n[《霸王别姬（1993）》 ](https://movie.douban.com/subject/1291546/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B0%91%E5%B9%B4%E6%B4%BE%E7%9A%84%E5%A5%87%E5%B9%BB%E6%BC%82%E6%B5%81.png\n\n[《少年派的奇幻漂流》 ](https://movie.douban.com/subject/1929463/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%A3%9E%E5%B1%8B%E7%8E%AF%E6%B8%B8%E8%AE%B0.jpg\n\n[《飞屋环游记》 ](https://movie.douban.com/subject/2129039/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%BA%8C%E5%8D%81%E4%BA%8C.png\n\n[《二十二》 ](https://movie.douban.com/subject/26430107/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/V%E5%AD%97%E4%BB%87%E6%9D%80%E9%98%9F.png\n\n[《V字仇杀队》 ](https://movie.douban.com/subject/1309046/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%A9%AF%E9%BE%99%E9%AB%98%E6%89%8B.png\n\n[《驯龙高手》 ](https://movie.douban.com/subject/2353023/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%AE%A9%E5%AD%90%E5%BC%B9%E9%A3%9E.png\n\n[《让子弹飞》 ](https://movie.douban.com/subject/3742360/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%A1%80%E6%88%98%E9%92%A2%E9%94%AF%E5%B2%AD.png\n\n[《血战钢锯岭》 ](https://movie.douban.com/subject/26325320/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%B6%85%E8%83%BD%E9%99%86%E6%88%98%E9%98%9F.png\n\n[《超能陆战队》 ](https://movie.douban.com/subject/11026735/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%97%A0%E6%95%8C%E7%A0%B4%E5%9D%8F%E7%8E%8B.png\n\n[《无敌破坏王》 ](https://movie.douban.com/subject/6534248/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%BD%A0%E5%BE%97%E5%90%8D%E5%AD%97.png\n\n[《你的名字》 ](https://movie.douban.com/subject/26683290/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%A5%9E%E5%81%B7%E5%A5%B6%E7%88%B8.png\n\n[《神偷奶爸》 ](https://movie.douban.com/subject/3287562/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%95%AA%E5%97%92%E5%95%AA%E5%97%92.png\n\n[《啪嗒啪嗒》 ](https://movie.douban.com/subject/10558447/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%BE%8A%E8%82%96%E6%81%A9.png\n\n[《小羊肖恩》 ](https://movie.douban.com/subject/24397586/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E5%BD%93%E5%BD%93%E4%BC%B4%E6%88%91%E5%BF%83.png\n\n[《麦兜当当伴我心》 ](https://movie.douban.com/subject/10772258/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88.png\n\n[《麦兜我和我妈妈》 ](https://movie.douban.com/subject/25884416/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%93%86%E5%95%A6A%E6%A2%A6%EF%BC%9A%E4%BC%B4%E6%88%91%E5%90%8C%E8%A1%8C.png\n\n[《哆啦A梦：伴我同行》 ](https://movie.douban.com/subject/25769362/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%A5%BF%E6%B8%B8%E8%AE%B0%E4%B9%8B%E5%A4%A7%E5%9C%A3%E5%BD%92%E6%9D%A5.png\n\n[《西游记之大圣归来》 ](https://movie.douban.com/subject/26277313/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%98%86%E8%99%AB%E6%80%BB%E5%8A%A8%E5%91%98.png\n\n[《昆虫总动员》 ](https://movie.douban.com/subject/23048775/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%B9%84%E5%85%AC%E6%B2%B3%E8%A1%8C%E5%8A%A8.png\n\n[《湄公河行动》 ](https://movie.douban.com/subject/25815034/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%86%B0%E9%9B%AA%E5%A5%87%E7%BC%98.png\n\n[《冰雪奇缘》 ](https://movie.douban.com/subject/4202982/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%99%BE%E9%B8%9F%E6%9C%9D%E5%87%A4.png\n\n[《百鸟朝凤》 ](https://movie.douban.com/subject/10831445/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%AD%81%E6%8B%94.png\n\n[《魁拔》 ](https://movie.douban.com/subject/10831445/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E7%82%AE%E5%84%BF.png\n\n[《老炮儿》 ](https://movie.douban.com/subject/24751756/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%A4%A7%E6%8A%A4%E6%B3%95.png\n\n[《大护法》 ](https://movie.douban.com/subject/26811587/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%96%8A%E5%B1%B1.png\n\n[《喊山》 ](https://movie.douban.com/subject/26106958/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8A%9F%E5%A4%AB%E7%86%8A%E7%8C%AB.png\n\n[《功夫熊猫》 ](https://movie.douban.com/subject/11589036/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%87%91%E8%9D%89%E8%84%B1%E5%A3%B3.png\n\n[《金蝉脱壳》 ](https://movie.douban.com/subject/3025447/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%BB%A3%E6%98%A5%E5%88%80.png\n\n[《绣春刀》 ](https://movie.douban.com/subject/24745500/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%AF%92%E6%88%98.png\n\n[《寒战》 ](https://movie.douban.com/subject/20505982/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%BA%BA%E5%9C%A8%E5%9B%A7%E9%80%94.png\n\n[《人在囧途》 ](https://movie.douban.com/subject/4237879/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8C%97%E4%BA%AC%E9%81%87%E4%B8%8A%E8%A5%BF%E9%9B%85%E5%9B%BE.png\n\n[《北京遇上西雅图》 ](https://movie.douban.com/subject/10574468/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%AF%BA%E4%BA%9A%E6%96%B9%E8%88%9F%E6%BC%82%E6%B5%81%E8%AE%B0.png\n\n[《诺亚方舟漂流记》 ](https://movie.douban.com/subject/26359269/) %}\n\n{% endstream %}\n\n\n\n\n\n\n\n\n\n","source":"favorite/index.md","raw":"---\ntitle: 喜欢\ndate: 2018-03-15 13:41:17\n---\n\n## 1.书籍\n\n{% stream %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2.png  [《时间简史》 ](https://book.douban.com/subject/1034282/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%9C%8B%E8%A7%81.png  [《看见》 ](https://book.douban.com/subject/20427187/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96.png  [《瓦尔登湖》 ](https://book.douban.com/subject/3522695/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%8E%8B%E5%AD%90.png  [《小王子》 ](https://book.douban.com/subject/1084336/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%9B%B4%E5%9F%8E.png  [《围城》 ](https://book.douban.com/subject/1069848/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%8C%AA%E5%A8%81%E7%9A%84%E6%A3%AE%E6%9E%97.png  [《挪威的森林》 ](https://book.douban.com/subject/1046265/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%91%BC%E5%85%B0%E6%B2%B3%E4%BC%A0.png  [《呼兰河传》 ](https://book.douban.com/subject/4843155/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%BE%B9%E5%9F%8E.png  [《边城》 ](https://book.douban.com/subject/1852117/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%99%BD%E9%B9%BF%E5%8E%9F.png  [《白鹿原》 ](https://book.douban.com/subject/1085799/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C.png  [《平凡的世界》 ](https://book.douban.com/subject/1200840/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7.png  [《老人与海》 ](https://book.douban.com/subject/1880992/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%9B%AA%E5%9B%BD.png  [《雪国》 ](https://book.douban.com/subject/24736899/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8D%83%E5%8F%AA%E9%B9%A4.png  [《千只鹤》 ](https://book.douban.com/subject/24736900/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%BE%8A%E8%84%82%E7%90%83.png  [《羊脂球》 ](https://book.douban.com/subject/3144827/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%A7%A3%E5%AF%86.png  [《解密》 ](https://book.douban.com/subject/1881118/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%AA%84%E5%82%B2%E7%9A%84%E5%8D%B0%E5%BA%A6.png  [《骄傲的印度》 ](https://www.amazon.cn/dp/B00PQDZ542?_encoding=UTF8&ref_=ku_mi_rw_edp) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%96%AF%E9%87%8C%E5%85%B0%E5%8D%A1.png  [《斯里兰卡 》 ](https://www.amazon.cn/dp/B00RXBJNNE?_encoding=UTF8&ref_=ku_mi_rw_edp) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%B6%8A%E7%A6%81%E5%BF%8C%E8%B6%8A%E7%BE%8E%E4%B8%BD.png  [《越禁忌越美丽 》 ](https://www.amazon.cn/dp/B00S9CGUBY?_encoding=UTF8&ref_=ku_mi_rw_edp) %}\n\n{% figure https://img3.doubanio.com/lpic/s28357056.jpg  [《三体 》 ](https://book.douban.com/subject/6518605/) %}\n\n{% figure https://img3.doubanio.com/lpic/s1168991.jpg [《阿甘正传》](https://book.douban.com/subject/1211267/)%}\n\n{% figure https://img3.doubanio.com/lpic/s6384944.jpg [《百年孤独》](https://book.douban.com/subject/6082808/)%}\n\n{% figure https://img3.doubanio.com/lpic/s3278363.jpg [《穆斯林的葬礼》](https://book.douban.com/subject/2244146/)%}\n\n{% figure https://img3.doubanio.com/lpic/s3735710.jpg [《岛》](https://book.douban.com/subject/3673651/)%}\n\n{% figure https://img3.doubanio.com/lpic/s11284102.jpg [《霍乱时期的爱情》](https://book.douban.com/subject/10594787/)%}\n\n{% figure https://img3.doubanio.com/lpic/s6509536.jpg [《悟空传》](https://book.douban.com/subject/6431994/)%}\n\n{% figure https://img3.doubanio.com/lpic/s27988606.jpg [《硅谷之火》](https://book.douban.com/subject/26306584/)%}\n\n{% figure https://img3.doubanio.com/lpic/s9034256.jpg [《千年一叹》](https://book.douban.com/subject/6808159/)%}\n\n{% figure https://img1.doubanio.com/lpic/s27226968.jpg [《文化苦旅》](https://book.douban.com/subject/19940743/)%}\n\n{% figure https://img3.doubanio.com/lpic/s1466042.jpg [《狼图腾》](https://book.douban.com/subject/1022060/)%}\n\n{% figure https://img3.doubanio.com/lpic/s27314106.jpg [《生活的艺术》](https://book.douban.com/subject/7564166/)%}\n\n{% figure https://img1.doubanio.com/lpic/s27595957.jpg [《荆棘鸟》](https://book.douban.com/subject/25887947/)%}\n\n{% endstream %}\n\n## 2.电影\n\n{% stream %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9A%B4%E8%A3%82%E6%97%A0%E5%A3%B0.png\n[《暴裂无声》](https://movie.douban.com/subject/26628329/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8D%97%E6%9E%81%E4%B9%8B%E6%81%8B.png\n[《南极之恋》](https://movie.douban.com/subject/26628329/) %}\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9C%AA%E9%97%BB%E8%8A%B1%E5%90%8D.png\n[《未闻花名》](https://movie.douban.com/subject/5397537/) %}\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%88%BB%E5%88%BB.png\n\n[《刻刻》](https://movie.douban.com/subject/27173361/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%B8%87%E7%89%A9%E7%90%86%E8%AE%BA.png\n[《万物理论》](https://movie.douban.com/subject/24815950/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9D%A5%E8%87%AA%E9%A3%8E%E5%B9%B3%E6%B5%AA%E9%9D%99%E7%9A%84%E6%98%8E%E5%A4%A9.png\n[《来自风平浪静的明天》 ](https://movie.douban.com/subject/11624690/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%94%90%E4%BA%BA%E8%A1%97%E6%8E%A2%E6%A1%882.png\n[《唐人街探案（二）》](https://movie.douban.com/subject/26698897/?from=showing) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%8D%89%E5%A6%96%E8%AE%B02.png\n\n[《捉妖记（二）》 ](https://movie.douban.com/subject/26575103/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E.jpg\n\n[《疯狂动物城》 ](https://movie.douban.com/subject/25662329/?suggest=%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%80%BB%E5%8A%A8%E5%91%98.png\n\n[《机器人总动员》 ](https://movie.douban.com/subject/2131459/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%9B%97%E6%A2%A6%E7%A9%BA%E9%97%B4.png\n\n[《盗梦空间》 ](https://movie.douban.com/subject/3541415/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%91%94%E8%B7%A4%E5%90%A7%EF%BC%81%E7%88%B8%E7%88%B8.png\n\n[《摔跤吧！爸爸》 ](https://movie.douban.com/subject/26387939/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%AF%BB%E6%A2%A6%E7%8E%AF%E6%B8%B8%E8%AE%B0.png\n\n[《寻梦环游记》 ](https://movie.douban.com/subject/20495023/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%98%9F%E9%99%85%E7%A9%BF%E8%B6%8A.png\n\n[《星际穿越》 ](https://movie.douban.com/subject/1889243/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%9C%B8%E7%8E%8B%E5%88%AB%E5%A7%AC.png\n\n[《霸王别姬（1993）》 ](https://movie.douban.com/subject/1291546/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B0%91%E5%B9%B4%E6%B4%BE%E7%9A%84%E5%A5%87%E5%B9%BB%E6%BC%82%E6%B5%81.png\n\n[《少年派的奇幻漂流》 ](https://movie.douban.com/subject/1929463/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%A3%9E%E5%B1%8B%E7%8E%AF%E6%B8%B8%E8%AE%B0.jpg\n\n[《飞屋环游记》 ](https://movie.douban.com/subject/2129039/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%BA%8C%E5%8D%81%E4%BA%8C.png\n\n[《二十二》 ](https://movie.douban.com/subject/26430107/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/V%E5%AD%97%E4%BB%87%E6%9D%80%E9%98%9F.png\n\n[《V字仇杀队》 ](https://movie.douban.com/subject/1309046/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%A9%AF%E9%BE%99%E9%AB%98%E6%89%8B.png\n\n[《驯龙高手》 ](https://movie.douban.com/subject/2353023/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%AE%A9%E5%AD%90%E5%BC%B9%E9%A3%9E.png\n\n[《让子弹飞》 ](https://movie.douban.com/subject/3742360/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%A1%80%E6%88%98%E9%92%A2%E9%94%AF%E5%B2%AD.png\n\n[《血战钢锯岭》 ](https://movie.douban.com/subject/26325320/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%B6%85%E8%83%BD%E9%99%86%E6%88%98%E9%98%9F.png\n\n[《超能陆战队》 ](https://movie.douban.com/subject/11026735/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%97%A0%E6%95%8C%E7%A0%B4%E5%9D%8F%E7%8E%8B.png\n\n[《无敌破坏王》 ](https://movie.douban.com/subject/6534248/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%BD%A0%E5%BE%97%E5%90%8D%E5%AD%97.png\n\n[《你的名字》 ](https://movie.douban.com/subject/26683290/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%A5%9E%E5%81%B7%E5%A5%B6%E7%88%B8.png\n\n[《神偷奶爸》 ](https://movie.douban.com/subject/3287562/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%95%AA%E5%97%92%E5%95%AA%E5%97%92.png\n\n[《啪嗒啪嗒》 ](https://movie.douban.com/subject/10558447/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%BE%8A%E8%82%96%E6%81%A9.png\n\n[《小羊肖恩》 ](https://movie.douban.com/subject/24397586/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E5%BD%93%E5%BD%93%E4%BC%B4%E6%88%91%E5%BF%83.png\n\n[《麦兜当当伴我心》 ](https://movie.douban.com/subject/10772258/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88.png\n\n[《麦兜我和我妈妈》 ](https://movie.douban.com/subject/25884416/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%93%86%E5%95%A6A%E6%A2%A6%EF%BC%9A%E4%BC%B4%E6%88%91%E5%90%8C%E8%A1%8C.png\n\n[《哆啦A梦：伴我同行》 ](https://movie.douban.com/subject/25769362/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%A5%BF%E6%B8%B8%E8%AE%B0%E4%B9%8B%E5%A4%A7%E5%9C%A3%E5%BD%92%E6%9D%A5.png\n\n[《西游记之大圣归来》 ](https://movie.douban.com/subject/26277313/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%98%86%E8%99%AB%E6%80%BB%E5%8A%A8%E5%91%98.png\n\n[《昆虫总动员》 ](https://movie.douban.com/subject/23048775/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E6%B9%84%E5%85%AC%E6%B2%B3%E8%A1%8C%E5%8A%A8.png\n\n[《湄公河行动》 ](https://movie.douban.com/subject/25815034/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%86%B0%E9%9B%AA%E5%A5%87%E7%BC%98.png\n\n[《冰雪奇缘》 ](https://movie.douban.com/subject/4202982/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%99%BE%E9%B8%9F%E6%9C%9D%E5%87%A4.png\n\n[《百鸟朝凤》 ](https://movie.douban.com/subject/10831445/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%AD%81%E6%8B%94.png\n\n[《魁拔》 ](https://movie.douban.com/subject/10831445/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E7%82%AE%E5%84%BF.png\n\n[《老炮儿》 ](https://movie.douban.com/subject/24751756/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%A4%A7%E6%8A%A4%E6%B3%95.png\n\n[《大护法》 ](https://movie.douban.com/subject/26811587/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%96%8A%E5%B1%B1.png\n\n[《喊山》 ](https://movie.douban.com/subject/26106958/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8A%9F%E5%A4%AB%E7%86%8A%E7%8C%AB.png\n\n[《功夫熊猫》 ](https://movie.douban.com/subject/11589036/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E9%87%91%E8%9D%89%E8%84%B1%E5%A3%B3.png\n\n[《金蝉脱壳》 ](https://movie.douban.com/subject/3025447/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E7%BB%A3%E6%98%A5%E5%88%80.png\n\n[《绣春刀》 ](https://movie.douban.com/subject/24745500/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%AF%92%E6%88%98.png\n\n[《寒战》 ](https://movie.douban.com/subject/20505982/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E4%BA%BA%E5%9C%A8%E5%9B%A7%E9%80%94.png\n\n[《人在囧途》 ](https://movie.douban.com/subject/4237879/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E5%8C%97%E4%BA%AC%E9%81%87%E4%B8%8A%E8%A5%BF%E9%9B%85%E5%9B%BE.png\n\n[《北京遇上西雅图》 ](https://movie.douban.com/subject/10574468/) %}\n\n{% figure http://p66yyzg4i.bkt.clouddn.com/%E8%AF%BA%E4%BA%9A%E6%96%B9%E8%88%9F%E6%BC%82%E6%B5%81%E8%AE%B0.png\n\n[《诺亚方舟漂流记》 ](https://movie.douban.com/subject/26359269/) %}\n\n{% endstream %}\n\n\n\n\n\n\n\n\n\n","updated":"2018-04-15T16:24:39.461Z","path":"favorite/index.html","comments":1,"layout":"page","_id":"cjg7s0pq200063201qp1iyp4f","content":"<h2 id=\"1-书籍\"><a href=\"#1-书籍\" class=\"headerlink\" title=\"1.书籍\"></a>1.书籍</h2><script src=\"//cdn.bootcss.com/jquery/2.1.0/jquery.min.js\"></script><script src=\"//cdn.bootcss.com/jquery.lazyload/1.9.1/jquery.lazyload.min.js\"></script><div class=\"hexo-img-stream\"><style type=\"text/css\">.hexo-image-steam-lazy {display:block;}.hexo-img-stream{width:90%;max-width:1100px;margin:3% auto}div.hexo-img-stream figure{background:#fefefe;box-shadow:0 1px 2px rgba(34,25,25,0.4);margin:0 0.05% 3%;padding:3%;padding-bottom:10px;display:inline-block;max-width:25%}div.hexo-img-stream figure img{border-bottom:1px solid #ccc;padding-bottom:15px;margin-bottom:5px}div.hexo-img-stream figure figcaption{font-size:.9rem;color:#444;line-height:1.5;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}div.hexo-img-stream small{font-size:1rem;float:right;text-transform:uppercase;color:#aaa}div.hexo-img-stream small a{color:#666;text-decoration:none;transition:.4s color}@media screen and (max-width:750px){.hexo-img-stream{column-gap:0}}</style>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1034282/\" target=\"_blank\" rel=\"noopener\">《时间简史》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9C%8B%E8%A7%81.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9C%8B%E8%A7%81.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/20427187/\" target=\"_blank\" rel=\"noopener\">《看见》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/3522695/\" target=\"_blank\" rel=\"noopener\">《瓦尔登湖》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%8E%8B%E5%AD%90.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%8E%8B%E5%AD%90.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1084336/\" target=\"_blank\" rel=\"noopener\">《小王子》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%9B%B4%E5%9F%8E.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%9B%B4%E5%9F%8E.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1069848/\" target=\"_blank\" rel=\"noopener\">《围城》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8C%AA%E5%A8%81%E7%9A%84%E6%A3%AE%E6%9E%97.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8C%AA%E5%A8%81%E7%9A%84%E6%A3%AE%E6%9E%97.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1046265/\" target=\"_blank\" rel=\"noopener\">《挪威的森林》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%91%BC%E5%85%B0%E6%B2%B3%E4%BC%A0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%91%BC%E5%85%B0%E6%B2%B3%E4%BC%A0.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/4843155/\" target=\"_blank\" rel=\"noopener\">《呼兰河传》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%BE%B9%E5%9F%8E.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%BE%B9%E5%9F%8E.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1852117/\" target=\"_blank\" rel=\"noopener\">《边城》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BD%E9%B9%BF%E5%8E%9F.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BD%E9%B9%BF%E5%8E%9F.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1085799/\" target=\"_blank\" rel=\"noopener\">《白鹿原》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1200840/\" target=\"_blank\" rel=\"noopener\">《平凡的世界》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1880992/\" target=\"_blank\" rel=\"noopener\">《老人与海》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9B%AA%E5%9B%BD.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9B%AA%E5%9B%BD.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/24736899/\" target=\"_blank\" rel=\"noopener\">《雪国》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%83%E5%8F%AA%E9%B9%A4.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%83%E5%8F%AA%E9%B9%A4.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/24736900/\" target=\"_blank\" rel=\"noopener\">《千只鹤》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BE%8A%E8%84%82%E7%90%83.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BE%8A%E8%84%82%E7%90%83.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/3144827/\" target=\"_blank\" rel=\"noopener\">《羊脂球》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A7%A3%E5%AF%86.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A7%A3%E5%AF%86.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1881118/\" target=\"_blank\" rel=\"noopener\">《解密》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AA%84%E5%82%B2%E7%9A%84%E5%8D%B0%E5%BA%A6.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AA%84%E5%82%B2%E7%9A%84%E5%8D%B0%E5%BA%A6.png\"></noscript><figcaption><a href=\"https://www.amazon.cn/dp/B00PQDZ542?_encoding=UTF8&amp;ref_=ku_mi_rw_edp\" target=\"_blank\" rel=\"noopener\">《骄傲的印度》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%96%AF%E9%87%8C%E5%85%B0%E5%8D%A1.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%96%AF%E9%87%8C%E5%85%B0%E5%8D%A1.png\"></noscript><figcaption><a href=\"https://www.amazon.cn/dp/B00RXBJNNE?_encoding=UTF8&amp;ref_=ku_mi_rw_edp\" target=\"_blank\" rel=\"noopener\">《斯里兰卡 》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%8A%E7%A6%81%E5%BF%8C%E8%B6%8A%E7%BE%8E%E4%B8%BD.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%8A%E7%A6%81%E5%BF%8C%E8%B6%8A%E7%BE%8E%E4%B8%BD.png\"></noscript><figcaption><a href=\"https://www.amazon.cn/dp/B00S9CGUBY?_encoding=UTF8&amp;ref_=ku_mi_rw_edp\" target=\"_blank\" rel=\"noopener\">《越禁忌越美丽 》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s28357056.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s28357056.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6518605/\" target=\"_blank\" rel=\"noopener\">《三体 》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s1168991.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s1168991.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1211267/\" target=\"_blank\" rel=\"noopener\">《阿甘正传》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s6384944.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s6384944.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6082808/\" target=\"_blank\" rel=\"noopener\">《百年孤独》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s3278363.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s3278363.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/2244146/\" target=\"_blank\" rel=\"noopener\">《穆斯林的葬礼》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s3735710.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s3735710.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/3673651/\" target=\"_blank\" rel=\"noopener\">《岛》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s11284102.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s11284102.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/10594787/\" target=\"_blank\" rel=\"noopener\">《霍乱时期的爱情》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s6509536.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s6509536.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6431994/\" target=\"_blank\" rel=\"noopener\">《悟空传》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s27988606.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s27988606.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/26306584/\" target=\"_blank\" rel=\"noopener\">《硅谷之火》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s9034256.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s9034256.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6808159/\" target=\"_blank\" rel=\"noopener\">《千年一叹》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img1.doubanio.com/lpic/s27226968.jpg\"><noscript><img src=\"https://img1.doubanio.com/lpic/s27226968.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/19940743/\" target=\"_blank\" rel=\"noopener\">《文化苦旅》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s1466042.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s1466042.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1022060/\" target=\"_blank\" rel=\"noopener\">《狼图腾》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s27314106.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s27314106.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/7564166/\" target=\"_blank\" rel=\"noopener\">《生活的艺术》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img1.doubanio.com/lpic/s27595957.jpg\"><noscript><img src=\"https://img1.doubanio.com/lpic/s27595957.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/25887947/\" target=\"_blank\" rel=\"noopener\">《荆棘鸟》</a>\n</figcaption></figure>\n</div><script type=\"text/javascript\">$('img.hexo-image-steam-lazy').lazyload({ effect:'fadeIn' });</script>\n<h2 id=\"2-电影\"><a href=\"#2-电影\" class=\"headerlink\" title=\"2.电影\"></a>2.电影</h2><script src=\"//cdn.bootcss.com/jquery/2.1.0/jquery.min.js\"></script><script src=\"//cdn.bootcss.com/jquery.lazyload/1.9.1/jquery.lazyload.min.js\"></script><div class=\"hexo-img-stream\"><style type=\"text/css\">.hexo-image-steam-lazy {display:block;}.hexo-img-stream{width:90%;max-width:1100px;margin:3% auto}div.hexo-img-stream figure{background:#fefefe;box-shadow:0 1px 2px rgba(34,25,25,0.4);margin:0 0.05% 3%;padding:3%;padding-bottom:10px;display:inline-block;max-width:25%}div.hexo-img-stream figure img{border-bottom:1px solid #ccc;padding-bottom:15px;margin-bottom:5px}div.hexo-img-stream figure figcaption{font-size:.9rem;color:#444;line-height:1.5;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}div.hexo-img-stream small{font-size:1rem;float:right;text-transform:uppercase;color:#aaa}div.hexo-img-stream small a{color:#666;text-decoration:none;transition:.4s color}@media screen and (max-width:750px){.hexo-img-stream{column-gap:0}}</style>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9A%B4%E8%A3%82%E6%97%A0%E5%A3%B0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9A%B4%E8%A3%82%E6%97%A0%E5%A3%B0.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26628329/\" target=\"_blank\" rel=\"noopener\">《暴裂无声》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%97%E6%9E%81%E4%B9%8B%E6%81%8B.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%97%E6%9E%81%E4%B9%8B%E6%81%8B.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26628329/\" target=\"_blank\" rel=\"noopener\">《南极之恋》</a>\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%AA%E9%97%BB%E8%8A%B1%E5%90%8D.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%AA%E9%97%BB%E8%8A%B1%E5%90%8D.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/5397537/\" target=\"_blank\" rel=\"noopener\">《未闻花名》</a>\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%88%BB%E5%88%BB.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%88%BB%E5%88%BB.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/27173361/\" target=\"_blank\" rel=\"noopener\">《刻刻》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%B8%87%E7%89%A9%E7%90%86%E8%AE%BA.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%B8%87%E7%89%A9%E7%90%86%E8%AE%BA.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24815950/\" target=\"_blank\" rel=\"noopener\">《万物理论》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9D%A5%E8%87%AA%E9%A3%8E%E5%B9%B3%E6%B5%AA%E9%9D%99%E7%9A%84%E6%98%8E%E5%A4%A9.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9D%A5%E8%87%AA%E9%A3%8E%E5%B9%B3%E6%B5%AA%E9%9D%99%E7%9A%84%E6%98%8E%E5%A4%A9.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/11624690/\" target=\"_blank\" rel=\"noopener\">《来自风平浪静的明天》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%94%90%E4%BA%BA%E8%A1%97%E6%8E%A2%E6%A1%882.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%94%90%E4%BA%BA%E8%A1%97%E6%8E%A2%E6%A1%882.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26698897/?from=showing\" target=\"_blank\" rel=\"noopener\">《唐人街探案（二）》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8D%89%E5%A6%96%E8%AE%B02.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8D%89%E5%A6%96%E8%AE%B02.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26575103/\" target=\"_blank\" rel=\"noopener\">《捉妖记（二）》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E.jpg\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E.jpg\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25662329/?suggest=%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E\" target=\"_blank\" rel=\"noopener\">《疯狂动物城》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%80%BB%E5%8A%A8%E5%91%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%80%BB%E5%8A%A8%E5%91%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/2131459/\" target=\"_blank\" rel=\"noopener\">《机器人总动员》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9B%97%E6%A2%A6%E7%A9%BA%E9%97%B4.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9B%97%E6%A2%A6%E7%A9%BA%E9%97%B4.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3541415/\" target=\"_blank\" rel=\"noopener\">《盗梦空间》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%91%94%E8%B7%A4%E5%90%A7%EF%BC%81%E7%88%B8%E7%88%B8.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%91%94%E8%B7%A4%E5%90%A7%EF%BC%81%E7%88%B8%E7%88%B8.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26387939/\" target=\"_blank\" rel=\"noopener\">《摔跤吧！爸爸》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%BB%E6%A2%A6%E7%8E%AF%E6%B8%B8%E8%AE%B0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%BB%E6%A2%A6%E7%8E%AF%E6%B8%B8%E8%AE%B0.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/20495023/\" target=\"_blank\" rel=\"noopener\">《寻梦环游记》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%9F%E9%99%85%E7%A9%BF%E8%B6%8A.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%9F%E9%99%85%E7%A9%BF%E8%B6%8A.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1889243/\" target=\"_blank\" rel=\"noopener\">《星际穿越》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9C%B8%E7%8E%8B%E5%88%AB%E5%A7%AC.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9C%B8%E7%8E%8B%E5%88%AB%E5%A7%AC.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1291546/\" target=\"_blank\" rel=\"noopener\">《霸王别姬（1993）》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%91%E5%B9%B4%E6%B4%BE%E7%9A%84%E5%A5%87%E5%B9%BB%E6%BC%82%E6%B5%81.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%91%E5%B9%B4%E6%B4%BE%E7%9A%84%E5%A5%87%E5%B9%BB%E6%BC%82%E6%B5%81.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1929463/\" target=\"_blank\" rel=\"noopener\">《少年派的奇幻漂流》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A3%9E%E5%B1%8B%E7%8E%AF%E6%B8%B8%E8%AE%B0.jpg\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A3%9E%E5%B1%8B%E7%8E%AF%E6%B8%B8%E8%AE%B0.jpg\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/2129039/\" target=\"_blank\" rel=\"noopener\">《飞屋环游记》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%8C%E5%8D%81%E4%BA%8C.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%8C%E5%8D%81%E4%BA%8C.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26430107/\" target=\"_blank\" rel=\"noopener\">《二十二》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/V%E5%AD%97%E4%BB%87%E6%9D%80%E9%98%9F.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/V%E5%AD%97%E4%BB%87%E6%9D%80%E9%98%9F.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1309046/\" target=\"_blank\" rel=\"noopener\">《V字仇杀队》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A9%AF%E9%BE%99%E9%AB%98%E6%89%8B.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A9%AF%E9%BE%99%E9%AB%98%E6%89%8B.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/2353023/\" target=\"_blank\" rel=\"noopener\">《驯龙高手》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AE%A9%E5%AD%90%E5%BC%B9%E9%A3%9E.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AE%A9%E5%AD%90%E5%BC%B9%E9%A3%9E.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3742360/\" target=\"_blank\" rel=\"noopener\">《让子弹飞》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A1%80%E6%88%98%E9%92%A2%E9%94%AF%E5%B2%AD.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A1%80%E6%88%98%E9%92%A2%E9%94%AF%E5%B2%AD.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26325320/\" target=\"_blank\" rel=\"noopener\">《血战钢锯岭》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%85%E8%83%BD%E9%99%86%E6%88%98%E9%98%9F.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%85%E8%83%BD%E9%99%86%E6%88%98%E9%98%9F.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/11026735/\" target=\"_blank\" rel=\"noopener\">《超能陆战队》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%A0%E6%95%8C%E7%A0%B4%E5%9D%8F%E7%8E%8B.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%A0%E6%95%8C%E7%A0%B4%E5%9D%8F%E7%8E%8B.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/6534248/\" target=\"_blank\" rel=\"noopener\">《无敌破坏王》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BD%A0%E5%BE%97%E5%90%8D%E5%AD%97.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BD%A0%E5%BE%97%E5%90%8D%E5%AD%97.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26683290/\" target=\"_blank\" rel=\"noopener\">《你的名字》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%A5%9E%E5%81%B7%E5%A5%B6%E7%88%B8.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%A5%9E%E5%81%B7%E5%A5%B6%E7%88%B8.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3287562/\" target=\"_blank\" rel=\"noopener\">《神偷奶爸》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%95%AA%E5%97%92%E5%95%AA%E5%97%92.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%95%AA%E5%97%92%E5%95%AA%E5%97%92.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10558447/\" target=\"_blank\" rel=\"noopener\">《啪嗒啪嗒》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%BE%8A%E8%82%96%E6%81%A9.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%BE%8A%E8%82%96%E6%81%A9.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24397586/\" target=\"_blank\" rel=\"noopener\">《小羊肖恩》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E5%BD%93%E5%BD%93%E4%BC%B4%E6%88%91%E5%BF%83.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E5%BD%93%E5%BD%93%E4%BC%B4%E6%88%91%E5%BF%83.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10772258/\" target=\"_blank\" rel=\"noopener\">《麦兜当当伴我心》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25884416/\" target=\"_blank\" rel=\"noopener\">《麦兜我和我妈妈》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%93%86%E5%95%A6A%E6%A2%A6%EF%BC%9A%E4%BC%B4%E6%88%91%E5%90%8C%E8%A1%8C.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%93%86%E5%95%A6A%E6%A2%A6%EF%BC%9A%E4%BC%B4%E6%88%91%E5%90%8C%E8%A1%8C.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25769362/\" target=\"_blank\" rel=\"noopener\">《哆啦A梦：伴我同行》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A5%BF%E6%B8%B8%E8%AE%B0%E4%B9%8B%E5%A4%A7%E5%9C%A3%E5%BD%92%E6%9D%A5.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A5%BF%E6%B8%B8%E8%AE%B0%E4%B9%8B%E5%A4%A7%E5%9C%A3%E5%BD%92%E6%9D%A5.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26277313/\" target=\"_blank\" rel=\"noopener\">《西游记之大圣归来》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%86%E8%99%AB%E6%80%BB%E5%8A%A8%E5%91%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%86%E8%99%AB%E6%80%BB%E5%8A%A8%E5%91%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/23048775/\" target=\"_blank\" rel=\"noopener\">《昆虫总动员》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%B9%84%E5%85%AC%E6%B2%B3%E8%A1%8C%E5%8A%A8.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%B9%84%E5%85%AC%E6%B2%B3%E8%A1%8C%E5%8A%A8.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25815034/\" target=\"_blank\" rel=\"noopener\">《湄公河行动》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%86%B0%E9%9B%AA%E5%A5%87%E7%BC%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%86%B0%E9%9B%AA%E5%A5%87%E7%BC%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/4202982/\" target=\"_blank\" rel=\"noopener\">《冰雪奇缘》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BE%E9%B8%9F%E6%9C%9D%E5%87%A4.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BE%E9%B8%9F%E6%9C%9D%E5%87%A4.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10831445/\" target=\"_blank\" rel=\"noopener\">《百鸟朝凤》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AD%81%E6%8B%94.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AD%81%E6%8B%94.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10831445/\" target=\"_blank\" rel=\"noopener\">《魁拔》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E7%82%AE%E5%84%BF.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E7%82%AE%E5%84%BF.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24751756/\" target=\"_blank\" rel=\"noopener\">《老炮儿》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%A4%A7%E6%8A%A4%E6%B3%95.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%A4%A7%E6%8A%A4%E6%B3%95.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26811587/\" target=\"_blank\" rel=\"noopener\">《大护法》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%96%8A%E5%B1%B1.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%96%8A%E5%B1%B1.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26106958/\" target=\"_blank\" rel=\"noopener\">《喊山》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8A%9F%E5%A4%AB%E7%86%8A%E7%8C%AB.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8A%9F%E5%A4%AB%E7%86%8A%E7%8C%AB.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/11589036/\" target=\"_blank\" rel=\"noopener\">《功夫熊猫》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%87%91%E8%9D%89%E8%84%B1%E5%A3%B3.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%87%91%E8%9D%89%E8%84%B1%E5%A3%B3.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3025447/\" target=\"_blank\" rel=\"noopener\">《金蝉脱壳》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BB%A3%E6%98%A5%E5%88%80.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BB%A3%E6%98%A5%E5%88%80.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24745500/\" target=\"_blank\" rel=\"noopener\">《绣春刀》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%92%E6%88%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%92%E6%88%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/20505982/\" target=\"_blank\" rel=\"noopener\">《寒战》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%BA%E5%9C%A8%E5%9B%A7%E9%80%94.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%BA%E5%9C%A8%E5%9B%A7%E9%80%94.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/4237879/\" target=\"_blank\" rel=\"noopener\">《人在囧途》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8C%97%E4%BA%AC%E9%81%87%E4%B8%8A%E8%A5%BF%E9%9B%85%E5%9B%BE.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8C%97%E4%BA%AC%E9%81%87%E4%B8%8A%E8%A5%BF%E9%9B%85%E5%9B%BE.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10574468/\" target=\"_blank\" rel=\"noopener\">《北京遇上西雅图》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AF%BA%E4%BA%9A%E6%96%B9%E8%88%9F%E6%BC%82%E6%B5%81%E8%AE%B0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AF%BA%E4%BA%9A%E6%96%B9%E8%88%9F%E6%BC%82%E6%B5%81%E8%AE%B0.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26359269/\" target=\"_blank\" rel=\"noopener\">《诺亚方舟漂流记》 </a>\n</figcaption></figure>\n</div><script type=\"text/javascript\">$('img.hexo-image-steam-lazy').lazyload({ effect:'fadeIn' });</script>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-书籍\"><a href=\"#1-书籍\" class=\"headerlink\" title=\"1.书籍\"></a>1.书籍</h2><script src=\"//cdn.bootcss.com/jquery/2.1.0/jquery.min.js\"></script><script src=\"//cdn.bootcss.com/jquery.lazyload/1.9.1/jquery.lazyload.min.js\"></script><div class=\"hexo-img-stream\"><style type=\"text/css\">.hexo-image-steam-lazy {display:block;}.hexo-img-stream{width:90%;max-width:1100px;margin:3% auto}div.hexo-img-stream figure{background:#fefefe;box-shadow:0 1px 2px rgba(34,25,25,0.4);margin:0 0.05% 3%;padding:3%;padding-bottom:10px;display:inline-block;max-width:25%}div.hexo-img-stream figure img{border-bottom:1px solid #ccc;padding-bottom:15px;margin-bottom:5px}div.hexo-img-stream figure figcaption{font-size:.9rem;color:#444;line-height:1.5;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}div.hexo-img-stream small{font-size:1rem;float:right;text-transform:uppercase;color:#aaa}div.hexo-img-stream small a{color:#666;text-decoration:none;transition:.4s color}@media screen and (max-width:750px){.hexo-img-stream{column-gap:0}}</style>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1034282/\" target=\"_blank\" rel=\"noopener\">《时间简史》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9C%8B%E8%A7%81.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9C%8B%E8%A7%81.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/20427187/\" target=\"_blank\" rel=\"noopener\">《看见》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%93%A6%E5%B0%94%E7%99%BB%E6%B9%96.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/3522695/\" target=\"_blank\" rel=\"noopener\">《瓦尔登湖》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%8E%8B%E5%AD%90.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%8E%8B%E5%AD%90.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1084336/\" target=\"_blank\" rel=\"noopener\">《小王子》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%9B%B4%E5%9F%8E.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%9B%B4%E5%9F%8E.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1069848/\" target=\"_blank\" rel=\"noopener\">《围城》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8C%AA%E5%A8%81%E7%9A%84%E6%A3%AE%E6%9E%97.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8C%AA%E5%A8%81%E7%9A%84%E6%A3%AE%E6%9E%97.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1046265/\" target=\"_blank\" rel=\"noopener\">《挪威的森林》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%91%BC%E5%85%B0%E6%B2%B3%E4%BC%A0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%91%BC%E5%85%B0%E6%B2%B3%E4%BC%A0.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/4843155/\" target=\"_blank\" rel=\"noopener\">《呼兰河传》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%BE%B9%E5%9F%8E.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%BE%B9%E5%9F%8E.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1852117/\" target=\"_blank\" rel=\"noopener\">《边城》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BD%E9%B9%BF%E5%8E%9F.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BD%E9%B9%BF%E5%8E%9F.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1085799/\" target=\"_blank\" rel=\"noopener\">《白鹿原》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1200840/\" target=\"_blank\" rel=\"noopener\">《平凡的世界》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E4%BA%BA%E4%B8%8E%E6%B5%B7.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1880992/\" target=\"_blank\" rel=\"noopener\">《老人与海》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9B%AA%E5%9B%BD.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9B%AA%E5%9B%BD.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/24736899/\" target=\"_blank\" rel=\"noopener\">《雪国》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%83%E5%8F%AA%E9%B9%A4.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%83%E5%8F%AA%E9%B9%A4.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/24736900/\" target=\"_blank\" rel=\"noopener\">《千只鹤》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BE%8A%E8%84%82%E7%90%83.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BE%8A%E8%84%82%E7%90%83.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/3144827/\" target=\"_blank\" rel=\"noopener\">《羊脂球》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A7%A3%E5%AF%86.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A7%A3%E5%AF%86.png\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1881118/\" target=\"_blank\" rel=\"noopener\">《解密》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AA%84%E5%82%B2%E7%9A%84%E5%8D%B0%E5%BA%A6.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AA%84%E5%82%B2%E7%9A%84%E5%8D%B0%E5%BA%A6.png\"></noscript><figcaption><a href=\"https://www.amazon.cn/dp/B00PQDZ542?_encoding=UTF8&amp;ref_=ku_mi_rw_edp\" target=\"_blank\" rel=\"noopener\">《骄傲的印度》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%96%AF%E9%87%8C%E5%85%B0%E5%8D%A1.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%96%AF%E9%87%8C%E5%85%B0%E5%8D%A1.png\"></noscript><figcaption><a href=\"https://www.amazon.cn/dp/B00RXBJNNE?_encoding=UTF8&amp;ref_=ku_mi_rw_edp\" target=\"_blank\" rel=\"noopener\">《斯里兰卡 》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%8A%E7%A6%81%E5%BF%8C%E8%B6%8A%E7%BE%8E%E4%B8%BD.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%8A%E7%A6%81%E5%BF%8C%E8%B6%8A%E7%BE%8E%E4%B8%BD.png\"></noscript><figcaption><a href=\"https://www.amazon.cn/dp/B00S9CGUBY?_encoding=UTF8&amp;ref_=ku_mi_rw_edp\" target=\"_blank\" rel=\"noopener\">《越禁忌越美丽 》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s28357056.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s28357056.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6518605/\" target=\"_blank\" rel=\"noopener\">《三体 》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s1168991.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s1168991.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1211267/\" target=\"_blank\" rel=\"noopener\">《阿甘正传》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s6384944.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s6384944.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6082808/\" target=\"_blank\" rel=\"noopener\">《百年孤独》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s3278363.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s3278363.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/2244146/\" target=\"_blank\" rel=\"noopener\">《穆斯林的葬礼》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s3735710.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s3735710.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/3673651/\" target=\"_blank\" rel=\"noopener\">《岛》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s11284102.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s11284102.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/10594787/\" target=\"_blank\" rel=\"noopener\">《霍乱时期的爱情》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s6509536.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s6509536.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6431994/\" target=\"_blank\" rel=\"noopener\">《悟空传》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s27988606.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s27988606.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/26306584/\" target=\"_blank\" rel=\"noopener\">《硅谷之火》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s9034256.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s9034256.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/6808159/\" target=\"_blank\" rel=\"noopener\">《千年一叹》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img1.doubanio.com/lpic/s27226968.jpg\"><noscript><img src=\"https://img1.doubanio.com/lpic/s27226968.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/19940743/\" target=\"_blank\" rel=\"noopener\">《文化苦旅》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s1466042.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s1466042.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/1022060/\" target=\"_blank\" rel=\"noopener\">《狼图腾》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img3.doubanio.com/lpic/s27314106.jpg\"><noscript><img src=\"https://img3.doubanio.com/lpic/s27314106.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/7564166/\" target=\"_blank\" rel=\"noopener\">《生活的艺术》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"https://img1.doubanio.com/lpic/s27595957.jpg\"><noscript><img src=\"https://img1.doubanio.com/lpic/s27595957.jpg\"></noscript><figcaption><a href=\"https://book.douban.com/subject/25887947/\" target=\"_blank\" rel=\"noopener\">《荆棘鸟》</a>\n</figcaption></figure>\n</div><script type=\"text/javascript\">$('img.hexo-image-steam-lazy').lazyload({ effect:'fadeIn' });</script>\n<h2 id=\"2-电影\"><a href=\"#2-电影\" class=\"headerlink\" title=\"2.电影\"></a>2.电影</h2><script src=\"//cdn.bootcss.com/jquery/2.1.0/jquery.min.js\"></script><script src=\"//cdn.bootcss.com/jquery.lazyload/1.9.1/jquery.lazyload.min.js\"></script><div class=\"hexo-img-stream\"><style type=\"text/css\">.hexo-image-steam-lazy {display:block;}.hexo-img-stream{width:90%;max-width:1100px;margin:3% auto}div.hexo-img-stream figure{background:#fefefe;box-shadow:0 1px 2px rgba(34,25,25,0.4);margin:0 0.05% 3%;padding:3%;padding-bottom:10px;display:inline-block;max-width:25%}div.hexo-img-stream figure img{border-bottom:1px solid #ccc;padding-bottom:15px;margin-bottom:5px}div.hexo-img-stream figure figcaption{font-size:.9rem;color:#444;line-height:1.5;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}div.hexo-img-stream small{font-size:1rem;float:right;text-transform:uppercase;color:#aaa}div.hexo-img-stream small a{color:#666;text-decoration:none;transition:.4s color}@media screen and (max-width:750px){.hexo-img-stream{column-gap:0}}</style>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9A%B4%E8%A3%82%E6%97%A0%E5%A3%B0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9A%B4%E8%A3%82%E6%97%A0%E5%A3%B0.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26628329/\" target=\"_blank\" rel=\"noopener\">《暴裂无声》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%97%E6%9E%81%E4%B9%8B%E6%81%8B.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8D%97%E6%9E%81%E4%B9%8B%E6%81%8B.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26628329/\" target=\"_blank\" rel=\"noopener\">《南极之恋》</a>\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%AA%E9%97%BB%E8%8A%B1%E5%90%8D.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%AA%E9%97%BB%E8%8A%B1%E5%90%8D.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/5397537/\" target=\"_blank\" rel=\"noopener\">《未闻花名》</a>\n</figcaption></figure>\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%88%BB%E5%88%BB.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%88%BB%E5%88%BB.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/27173361/\" target=\"_blank\" rel=\"noopener\">《刻刻》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%B8%87%E7%89%A9%E7%90%86%E8%AE%BA.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%B8%87%E7%89%A9%E7%90%86%E8%AE%BA.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24815950/\" target=\"_blank\" rel=\"noopener\">《万物理论》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9D%A5%E8%87%AA%E9%A3%8E%E5%B9%B3%E6%B5%AA%E9%9D%99%E7%9A%84%E6%98%8E%E5%A4%A9.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9D%A5%E8%87%AA%E9%A3%8E%E5%B9%B3%E6%B5%AA%E9%9D%99%E7%9A%84%E6%98%8E%E5%A4%A9.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/11624690/\" target=\"_blank\" rel=\"noopener\">《来自风平浪静的明天》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%94%90%E4%BA%BA%E8%A1%97%E6%8E%A2%E6%A1%882.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%94%90%E4%BA%BA%E8%A1%97%E6%8E%A2%E6%A1%882.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26698897/?from=showing\" target=\"_blank\" rel=\"noopener\">《唐人街探案（二）》</a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8D%89%E5%A6%96%E8%AE%B02.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%8D%89%E5%A6%96%E8%AE%B02.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26575103/\" target=\"_blank\" rel=\"noopener\">《捉妖记（二）》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E.jpg\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E.jpg\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25662329/?suggest=%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E\" target=\"_blank\" rel=\"noopener\">《疯狂动物城》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%80%BB%E5%8A%A8%E5%91%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%80%BB%E5%8A%A8%E5%91%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/2131459/\" target=\"_blank\" rel=\"noopener\">《机器人总动员》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9B%97%E6%A2%A6%E7%A9%BA%E9%97%B4.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%9B%97%E6%A2%A6%E7%A9%BA%E9%97%B4.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3541415/\" target=\"_blank\" rel=\"noopener\">《盗梦空间》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%91%94%E8%B7%A4%E5%90%A7%EF%BC%81%E7%88%B8%E7%88%B8.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%91%94%E8%B7%A4%E5%90%A7%EF%BC%81%E7%88%B8%E7%88%B8.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26387939/\" target=\"_blank\" rel=\"noopener\">《摔跤吧！爸爸》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%BB%E6%A2%A6%E7%8E%AF%E6%B8%B8%E8%AE%B0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%BB%E6%A2%A6%E7%8E%AF%E6%B8%B8%E8%AE%B0.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/20495023/\" target=\"_blank\" rel=\"noopener\">《寻梦环游记》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%9F%E9%99%85%E7%A9%BF%E8%B6%8A.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%9F%E9%99%85%E7%A9%BF%E8%B6%8A.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1889243/\" target=\"_blank\" rel=\"noopener\">《星际穿越》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9C%B8%E7%8E%8B%E5%88%AB%E5%A7%AC.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%9C%B8%E7%8E%8B%E5%88%AB%E5%A7%AC.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1291546/\" target=\"_blank\" rel=\"noopener\">《霸王别姬（1993）》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%91%E5%B9%B4%E6%B4%BE%E7%9A%84%E5%A5%87%E5%B9%BB%E6%BC%82%E6%B5%81.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%91%E5%B9%B4%E6%B4%BE%E7%9A%84%E5%A5%87%E5%B9%BB%E6%BC%82%E6%B5%81.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1929463/\" target=\"_blank\" rel=\"noopener\">《少年派的奇幻漂流》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A3%9E%E5%B1%8B%E7%8E%AF%E6%B8%B8%E8%AE%B0.jpg\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A3%9E%E5%B1%8B%E7%8E%AF%E6%B8%B8%E8%AE%B0.jpg\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/2129039/\" target=\"_blank\" rel=\"noopener\">《飞屋环游记》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%8C%E5%8D%81%E4%BA%8C.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%8C%E5%8D%81%E4%BA%8C.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26430107/\" target=\"_blank\" rel=\"noopener\">《二十二》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/V%E5%AD%97%E4%BB%87%E6%9D%80%E9%98%9F.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/V%E5%AD%97%E4%BB%87%E6%9D%80%E9%98%9F.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/1309046/\" target=\"_blank\" rel=\"noopener\">《V字仇杀队》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A9%AF%E9%BE%99%E9%AB%98%E6%89%8B.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%A9%AF%E9%BE%99%E9%AB%98%E6%89%8B.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/2353023/\" target=\"_blank\" rel=\"noopener\">《驯龙高手》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AE%A9%E5%AD%90%E5%BC%B9%E9%A3%9E.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AE%A9%E5%AD%90%E5%BC%B9%E9%A3%9E.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3742360/\" target=\"_blank\" rel=\"noopener\">《让子弹飞》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A1%80%E6%88%98%E9%92%A2%E9%94%AF%E5%B2%AD.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A1%80%E6%88%98%E9%92%A2%E9%94%AF%E5%B2%AD.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26325320/\" target=\"_blank\" rel=\"noopener\">《血战钢锯岭》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%85%E8%83%BD%E9%99%86%E6%88%98%E9%98%9F.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%B6%85%E8%83%BD%E9%99%86%E6%88%98%E9%98%9F.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/11026735/\" target=\"_blank\" rel=\"noopener\">《超能陆战队》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%A0%E6%95%8C%E7%A0%B4%E5%9D%8F%E7%8E%8B.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%97%A0%E6%95%8C%E7%A0%B4%E5%9D%8F%E7%8E%8B.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/6534248/\" target=\"_blank\" rel=\"noopener\">《无敌破坏王》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BD%A0%E5%BE%97%E5%90%8D%E5%AD%97.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BD%A0%E5%BE%97%E5%90%8D%E5%AD%97.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26683290/\" target=\"_blank\" rel=\"noopener\">《你的名字》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%A5%9E%E5%81%B7%E5%A5%B6%E7%88%B8.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%A5%9E%E5%81%B7%E5%A5%B6%E7%88%B8.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3287562/\" target=\"_blank\" rel=\"noopener\">《神偷奶爸》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%95%AA%E5%97%92%E5%95%AA%E5%97%92.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%95%AA%E5%97%92%E5%95%AA%E5%97%92.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10558447/\" target=\"_blank\" rel=\"noopener\">《啪嗒啪嗒》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%BE%8A%E8%82%96%E6%81%A9.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%B0%8F%E7%BE%8A%E8%82%96%E6%81%A9.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24397586/\" target=\"_blank\" rel=\"noopener\">《小羊肖恩》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E5%BD%93%E5%BD%93%E4%BC%B4%E6%88%91%E5%BF%83.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E5%BD%93%E5%BD%93%E4%BC%B4%E6%88%91%E5%BF%83.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10772258/\" target=\"_blank\" rel=\"noopener\">《麦兜当当伴我心》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%BA%A6%E5%85%9C%E6%88%91%E5%92%8C%E6%88%91%E5%A6%88%E5%A6%88.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25884416/\" target=\"_blank\" rel=\"noopener\">《麦兜我和我妈妈》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%93%86%E5%95%A6A%E6%A2%A6%EF%BC%9A%E4%BC%B4%E6%88%91%E5%90%8C%E8%A1%8C.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%93%86%E5%95%A6A%E6%A2%A6%EF%BC%9A%E4%BC%B4%E6%88%91%E5%90%8C%E8%A1%8C.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25769362/\" target=\"_blank\" rel=\"noopener\">《哆啦A梦：伴我同行》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A5%BF%E6%B8%B8%E8%AE%B0%E4%B9%8B%E5%A4%A7%E5%9C%A3%E5%BD%92%E6%9D%A5.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%A5%BF%E6%B8%B8%E8%AE%B0%E4%B9%8B%E5%A4%A7%E5%9C%A3%E5%BD%92%E6%9D%A5.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26277313/\" target=\"_blank\" rel=\"noopener\">《西游记之大圣归来》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%86%E8%99%AB%E6%80%BB%E5%8A%A8%E5%91%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%98%86%E8%99%AB%E6%80%BB%E5%8A%A8%E5%91%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/23048775/\" target=\"_blank\" rel=\"noopener\">《昆虫总动员》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E6%B9%84%E5%85%AC%E6%B2%B3%E8%A1%8C%E5%8A%A8.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%B9%84%E5%85%AC%E6%B2%B3%E8%A1%8C%E5%8A%A8.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/25815034/\" target=\"_blank\" rel=\"noopener\">《湄公河行动》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%86%B0%E9%9B%AA%E5%A5%87%E7%BC%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%86%B0%E9%9B%AA%E5%A5%87%E7%BC%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/4202982/\" target=\"_blank\" rel=\"noopener\">《冰雪奇缘》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BE%E9%B8%9F%E6%9C%9D%E5%87%A4.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%99%BE%E9%B8%9F%E6%9C%9D%E5%87%A4.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10831445/\" target=\"_blank\" rel=\"noopener\">《百鸟朝凤》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AD%81%E6%8B%94.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%AD%81%E6%8B%94.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10831445/\" target=\"_blank\" rel=\"noopener\">《魁拔》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E7%82%AE%E5%84%BF.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%80%81%E7%82%AE%E5%84%BF.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24751756/\" target=\"_blank\" rel=\"noopener\">《老炮儿》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%A4%A7%E6%8A%A4%E6%B3%95.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%A4%A7%E6%8A%A4%E6%B3%95.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26811587/\" target=\"_blank\" rel=\"noopener\">《大护法》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%96%8A%E5%B1%B1.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%96%8A%E5%B1%B1.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26106958/\" target=\"_blank\" rel=\"noopener\">《喊山》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8A%9F%E5%A4%AB%E7%86%8A%E7%8C%AB.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8A%9F%E5%A4%AB%E7%86%8A%E7%8C%AB.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/11589036/\" target=\"_blank\" rel=\"noopener\">《功夫熊猫》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E9%87%91%E8%9D%89%E8%84%B1%E5%A3%B3.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E9%87%91%E8%9D%89%E8%84%B1%E5%A3%B3.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/3025447/\" target=\"_blank\" rel=\"noopener\">《金蝉脱壳》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BB%A3%E6%98%A5%E5%88%80.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E7%BB%A3%E6%98%A5%E5%88%80.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/24745500/\" target=\"_blank\" rel=\"noopener\">《绣春刀》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%92%E6%88%98.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%AF%92%E6%88%98.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/20505982/\" target=\"_blank\" rel=\"noopener\">《寒战》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%BA%E5%9C%A8%E5%9B%A7%E9%80%94.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E4%BA%BA%E5%9C%A8%E5%9B%A7%E9%80%94.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/4237879/\" target=\"_blank\" rel=\"noopener\">《人在囧途》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8C%97%E4%BA%AC%E9%81%87%E4%B8%8A%E8%A5%BF%E9%9B%85%E5%9B%BE.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E5%8C%97%E4%BA%AC%E9%81%87%E4%B8%8A%E8%A5%BF%E9%9B%85%E5%9B%BE.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/10574468/\" target=\"_blank\" rel=\"noopener\">《北京遇上西雅图》 </a>\n</figcaption></figure>\n\n<figure><img class=\"hexo-image-steam-lazy nofancy\" src=\"https://ws4.sinaimg.cn/large/e724cbefgw1etyppy7bgwg2001001017.gif\" data-original=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AF%BA%E4%BA%9A%E6%96%B9%E8%88%9F%E6%BC%82%E6%B5%81%E8%AE%B0.png\"><noscript><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E8%AF%BA%E4%BA%9A%E6%96%B9%E8%88%9F%E6%BC%82%E6%B5%81%E8%AE%B0.png\"></noscript><figcaption><a href=\"https://movie.douban.com/subject/26359269/\" target=\"_blank\" rel=\"noopener\">《诺亚方舟漂流记》 </a>\n</figcaption></figure>\n</div><script type=\"text/javascript\">$('img.hexo-image-steam-lazy').lazyload({ effect:'fadeIn' });</script>\n"},{"title":"标签","type":"tags","comments":0,"date":"2018-03-13T15:29:35.000Z","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\ntype: \"tags\"\ncomments: false\ndate: 2018-03-13 23:29:35\n---\n","updated":"2018-03-13T17:26:40.814Z","path":"tags/index.html","layout":"page","_id":"cjg7s0pq700093201d3frgsk1","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Markdown写作教程","date":"2018-03-18T15:29:14.000Z","toc":true,"comments":1,"_content":"\n[博客搭建教程](https://weizhixiaoyi.com/2018/03/16/Mac+Hexo+GitHub%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/)写完之后，很多同学都比较感兴趣，那么在此也写下Markdown写作教程，更快捷、方便的写作博文。当然网上已经有太多人写Markdown教程，那么很多人难免问这个问题，为什么你还要花时间去写如此一篇教程呢？是因为哪怕是同样的内容，写出来之后便有我自己的风格，能让更多人浅显易懂的了解这些知识，同时也能增加我的个人理解，共同学习。\n\n### 1.为什么选择Markdown\n\n首先通过Github搭建博客，我们只能用Markdown文档，然后直接转换成Html网页展现出来。但除了这个原因之外，更吸引我的地方便是其简单、快捷、高效的写作方式，通过轻文本标记语言，利用简洁的语法进行排版，达到所见及所得的效果，书写的过程只考虑内容和文字本身，写作的过程便是享受。目前CSDN、简书、博客园、知乎等平台均支持Markdown写作。当然富文本写作方式也有其迷人之处，比如我用**印象笔记**至此已经写了200+的笔记，有时间给大家写个印象笔记教程，如何高效收集、管理生活中的知识点与信息流。\n\n### 2.标题\n\n标题通过`#`的个数进行区分，Markdown共支持6级标题。\n\n![标题](Markdown写作教程/图片01.png)\n\n### 3.字体设置\n\n#### 3.1粗体\n\n文字前后加`**`来表示粗体。\n\n```markdown\n**粗体**\n```\n\n**粗体**\n\n#### 3.2斜体\n\n文字前后加`*`来表示斜体。\n\n```markdown\n*斜体*\n```\n\n*斜体*\n\n#### 3.3粗斜体\n\n文字前后加`***`来表示粗斜体。\n\n```markdown\n***粗斜体***\n```\n\n***粗斜体***\n\n#### 3.4下划线\n\n文字前后加`<u>` `</u>`来表示下划线。\n\n```markdown\n<u>下滑线</u>\n```\n\n<u>下划线</u>\n\n#### 3.5删除线\n\n文字前后加`~~`来表示删除线。\n\n```markdown\n~~删除线~~\n```\n\n~~删除线~~\n\n#### 3.6标记\n\n文字前后加`` `来表示标记，该符号位于Esc键下面。\n\n```markdown\n`标记`\n```\n\n`标记`\n\n#### 3.7Html标签\n\n```Markdown\n<font face=\"微软雅黑\" color=\"red\" size=\"6\">字体及字体颜色和大小</font>\n```\n\n<font face=\"微软雅黑\" color=\"red\" size=\"3\">字体及字体颜色和大小</font>\n\n### 4.列表\n\n#### 4.1有序列表\n\n采用`1.  ` 后加空格形式表示有序列表。\n\n```markdown\n1. 有序列表1\n2. 有序列表2\n3. 有序列表3\n```\n\n1. 有序列表1\n2. 有序列表2\n3. 有序列表3\n\n#### 4.2无序列表\n\n采用`+` `-` `* ` `=`符号表示无序列表，支持多级嵌套。\n\n```markdown\n+ 有序列表1\n+ + 有序列表1.1\n+ + 有序列表1.2\n+ 有序列表2\n+ 有序列表3\n```\n\n- 无序列表1\n  - 无序列表1.1\n  - 无序列表1.2\n- 无序列表2\n- 无序列表3\n\n#### 4.3未完成列表\n\n采用`- []`表示未完成任务，各符号间均有空格。\n\n```markdown\n- [ ] 未完成任务1\n- [ ] 未完成任务2\n- [ ] 未完成任务3\n```\n\n- [ ] 未完成任务1\n- [ ] 未完成任务2\n- [ ] 未完成任务3\n\n#### 4.4已完成任务\n\n采用`- [x] `表示已完成任务，各符号间均有空格。同时可直接在未完成任务间`打勾`来转换成已完成任务。\n\n```markdown\n- [x] 已完成任务1\n- [x] 已完成任务2\n- [x] 已完成任务3\n```\n\n- [ ] 已完成任务1\n- [ ] 已完成任务2\n- [ ] 已完成任务3\n\n### 5.表格\n\n表格对齐方式\n\n- 居左：:----\n- 居中：:----:或-----\n- 居由：----:\n\n```markdown\n| 标题1           |      标题2      |           标题3 |\n| :-------------- | :-------------: | --------------: |\n| 居左测试文本1.1 | 居中测试文本2.1 | 居右测试文本3.1 |\n| 居左测试文本1.2 | 居中测试文本2.2 | 居右测试文本3.2 |\n```\n\n| 标题1           |      标题2      |           标题3 |\n| :-------------- | :-------------: | --------------: |\n| 居左测试文本1.1 | 居中测试文本2.1 | 居右测试文本3.1 |\n| 居左测试文本1.2 | 居中测试文本2.2 | 居右测试文本3.2 |\n\n### 6.段落和换行\n\n#### 6.1首行缩进方式\n\n+ `&emsp;`中文空格\n+ `&ensp;`半中文空格\n+ `&nbsp;`英文空格\n+ ` `输入法切换到全角双击空格\n\n#### 6.2换行\n\n+ ` ` ` `换行处连续打两个空格\n+ 换行处使用`<br>`进行换行\n\n#### 6.3空行\n\n+ ` ` ` ` 空行处连续打两个空格\n+ 换行处使用`<br>`进行空行\n\n### 6.引用和代码块\n\n#### 6.1引用\n\n若在文章中需要引入一段话等，可以采用引用的方式呈现，支持多级引用。\n\n```Markdown\n> 引用1\n> > 引用1.1\n> > 引用1.2\n> 引用2\n```\n\n> 引用1\n>\n> > 引用1.1\n> >\n> > 引用1.2\n>\n> 引用2\n\n#### 6.2代码块\n\n代码前后添加```` `表示代码块。\n\n```markdown\n​```Python\nprint('代码块')\n​```\n```\n\n```python\nprint（'代码块'）\n```\n\n### 7.链接\n\n#### 7.1图片链接\n\n采用`![]()`来表示图片链接。\n\n```Markdown\n![图片名称](链接地址)\n```\n\n![图片名称](Markdown写作教程/图片02.png)\n\n#### 7.2文字链接\n\n采用`[]()`表示文字链接。\n\n```Markdown\n[链接名称](链接地址)\n```\n\n[文字链接](weizhixiaoyi.com)\n\n#### 7.3参考链接\n\n采用`[ ]: `表示参考链接，注意符号后有空格。\n\n```markdown\n[ ]: url title\n```\n\n[参考链接]: https://weizhixiaoyi.com\t\"谓之小一\"\n\n### 8.分割线\n\n上下文无关时可使用分割符进行分开。\n\n- 连续多个`-`  (>=3)\n- 连续多个`*` （>=3）\n- 连续多个下划线`_` （>=3）\n\n```\n---分割线\n***分割线\n___分割线\n```\n\n------\n\n------\n\n------\n\n### 9.脚注和注释\n\n#### 9.1脚注\n\n采用`[^]:表示脚注，注意空格。\n\n```markdown\n[^]: 脚注\n```\n\n[^]: 脚注\n\n#### 9.2注释\n\n采用`<!---->`表示注释.\n\n```markdown\n<!--注释-->\n```\n\n<!--注释-->\n\n### 11.转义\n\nMarkdown通过反斜杠`\\`来插入在语法中有其他意义的符号，Markdown支持以下符号来进行转义。\n\n```markdown\n\\\\反斜线\n\\`反引号\n\\*星号\n\\_下划线\n\\{}花括号\n\\[]方括号\n\\()括弧\n\\#井字号\n\\+加号\n\\-减号\n\\.英文句点\n\\!感叹号\n```\n\n\\\\反斜线\n\\`反引号\n\\*星号\n\\_下划线\n\\{}花括号\n\\[]方括号\n\\()括弧\n\\#井字号\n\\+加号\n\\-减号\n\\.英文句点\n\\!感叹号\n\n### 12.目录\n\n采用`[TOC]`来生成文章目录。\n\n```Markdown\n[TOC]\n```\n\n![图片03](Markdown写作教程/图片03.png)\n\n-----\n\n### 13.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![推广](Markdown写作教程/推广.png)\n\n","source":"_posts/Markdown写作教程.md","raw":"---\ntitle: Markdown写作教程\ndate: 2018-03-18 23:29:14\ntags: [Markdown,博客,教程]\ntoc: true\ncomments: true\n---\n\n[博客搭建教程](https://weizhixiaoyi.com/2018/03/16/Mac+Hexo+GitHub%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/)写完之后，很多同学都比较感兴趣，那么在此也写下Markdown写作教程，更快捷、方便的写作博文。当然网上已经有太多人写Markdown教程，那么很多人难免问这个问题，为什么你还要花时间去写如此一篇教程呢？是因为哪怕是同样的内容，写出来之后便有我自己的风格，能让更多人浅显易懂的了解这些知识，同时也能增加我的个人理解，共同学习。\n\n### 1.为什么选择Markdown\n\n首先通过Github搭建博客，我们只能用Markdown文档，然后直接转换成Html网页展现出来。但除了这个原因之外，更吸引我的地方便是其简单、快捷、高效的写作方式，通过轻文本标记语言，利用简洁的语法进行排版，达到所见及所得的效果，书写的过程只考虑内容和文字本身，写作的过程便是享受。目前CSDN、简书、博客园、知乎等平台均支持Markdown写作。当然富文本写作方式也有其迷人之处，比如我用**印象笔记**至此已经写了200+的笔记，有时间给大家写个印象笔记教程，如何高效收集、管理生活中的知识点与信息流。\n\n### 2.标题\n\n标题通过`#`的个数进行区分，Markdown共支持6级标题。\n\n![标题](Markdown写作教程/图片01.png)\n\n### 3.字体设置\n\n#### 3.1粗体\n\n文字前后加`**`来表示粗体。\n\n```markdown\n**粗体**\n```\n\n**粗体**\n\n#### 3.2斜体\n\n文字前后加`*`来表示斜体。\n\n```markdown\n*斜体*\n```\n\n*斜体*\n\n#### 3.3粗斜体\n\n文字前后加`***`来表示粗斜体。\n\n```markdown\n***粗斜体***\n```\n\n***粗斜体***\n\n#### 3.4下划线\n\n文字前后加`<u>` `</u>`来表示下划线。\n\n```markdown\n<u>下滑线</u>\n```\n\n<u>下划线</u>\n\n#### 3.5删除线\n\n文字前后加`~~`来表示删除线。\n\n```markdown\n~~删除线~~\n```\n\n~~删除线~~\n\n#### 3.6标记\n\n文字前后加`` `来表示标记，该符号位于Esc键下面。\n\n```markdown\n`标记`\n```\n\n`标记`\n\n#### 3.7Html标签\n\n```Markdown\n<font face=\"微软雅黑\" color=\"red\" size=\"6\">字体及字体颜色和大小</font>\n```\n\n<font face=\"微软雅黑\" color=\"red\" size=\"3\">字体及字体颜色和大小</font>\n\n### 4.列表\n\n#### 4.1有序列表\n\n采用`1.  ` 后加空格形式表示有序列表。\n\n```markdown\n1. 有序列表1\n2. 有序列表2\n3. 有序列表3\n```\n\n1. 有序列表1\n2. 有序列表2\n3. 有序列表3\n\n#### 4.2无序列表\n\n采用`+` `-` `* ` `=`符号表示无序列表，支持多级嵌套。\n\n```markdown\n+ 有序列表1\n+ + 有序列表1.1\n+ + 有序列表1.2\n+ 有序列表2\n+ 有序列表3\n```\n\n- 无序列表1\n  - 无序列表1.1\n  - 无序列表1.2\n- 无序列表2\n- 无序列表3\n\n#### 4.3未完成列表\n\n采用`- []`表示未完成任务，各符号间均有空格。\n\n```markdown\n- [ ] 未完成任务1\n- [ ] 未完成任务2\n- [ ] 未完成任务3\n```\n\n- [ ] 未完成任务1\n- [ ] 未完成任务2\n- [ ] 未完成任务3\n\n#### 4.4已完成任务\n\n采用`- [x] `表示已完成任务，各符号间均有空格。同时可直接在未完成任务间`打勾`来转换成已完成任务。\n\n```markdown\n- [x] 已完成任务1\n- [x] 已完成任务2\n- [x] 已完成任务3\n```\n\n- [ ] 已完成任务1\n- [ ] 已完成任务2\n- [ ] 已完成任务3\n\n### 5.表格\n\n表格对齐方式\n\n- 居左：:----\n- 居中：:----:或-----\n- 居由：----:\n\n```markdown\n| 标题1           |      标题2      |           标题3 |\n| :-------------- | :-------------: | --------------: |\n| 居左测试文本1.1 | 居中测试文本2.1 | 居右测试文本3.1 |\n| 居左测试文本1.2 | 居中测试文本2.2 | 居右测试文本3.2 |\n```\n\n| 标题1           |      标题2      |           标题3 |\n| :-------------- | :-------------: | --------------: |\n| 居左测试文本1.1 | 居中测试文本2.1 | 居右测试文本3.1 |\n| 居左测试文本1.2 | 居中测试文本2.2 | 居右测试文本3.2 |\n\n### 6.段落和换行\n\n#### 6.1首行缩进方式\n\n+ `&emsp;`中文空格\n+ `&ensp;`半中文空格\n+ `&nbsp;`英文空格\n+ ` `输入法切换到全角双击空格\n\n#### 6.2换行\n\n+ ` ` ` `换行处连续打两个空格\n+ 换行处使用`<br>`进行换行\n\n#### 6.3空行\n\n+ ` ` ` ` 空行处连续打两个空格\n+ 换行处使用`<br>`进行空行\n\n### 6.引用和代码块\n\n#### 6.1引用\n\n若在文章中需要引入一段话等，可以采用引用的方式呈现，支持多级引用。\n\n```Markdown\n> 引用1\n> > 引用1.1\n> > 引用1.2\n> 引用2\n```\n\n> 引用1\n>\n> > 引用1.1\n> >\n> > 引用1.2\n>\n> 引用2\n\n#### 6.2代码块\n\n代码前后添加```` `表示代码块。\n\n```markdown\n​```Python\nprint('代码块')\n​```\n```\n\n```python\nprint（'代码块'）\n```\n\n### 7.链接\n\n#### 7.1图片链接\n\n采用`![]()`来表示图片链接。\n\n```Markdown\n![图片名称](链接地址)\n```\n\n![图片名称](Markdown写作教程/图片02.png)\n\n#### 7.2文字链接\n\n采用`[]()`表示文字链接。\n\n```Markdown\n[链接名称](链接地址)\n```\n\n[文字链接](weizhixiaoyi.com)\n\n#### 7.3参考链接\n\n采用`[ ]: `表示参考链接，注意符号后有空格。\n\n```markdown\n[ ]: url title\n```\n\n[参考链接]: https://weizhixiaoyi.com\t\"谓之小一\"\n\n### 8.分割线\n\n上下文无关时可使用分割符进行分开。\n\n- 连续多个`-`  (>=3)\n- 连续多个`*` （>=3）\n- 连续多个下划线`_` （>=3）\n\n```\n---分割线\n***分割线\n___分割线\n```\n\n------\n\n------\n\n------\n\n### 9.脚注和注释\n\n#### 9.1脚注\n\n采用`[^]:表示脚注，注意空格。\n\n```markdown\n[^]: 脚注\n```\n\n[^]: 脚注\n\n#### 9.2注释\n\n采用`<!---->`表示注释.\n\n```markdown\n<!--注释-->\n```\n\n<!--注释-->\n\n### 11.转义\n\nMarkdown通过反斜杠`\\`来插入在语法中有其他意义的符号，Markdown支持以下符号来进行转义。\n\n```markdown\n\\\\反斜线\n\\`反引号\n\\*星号\n\\_下划线\n\\{}花括号\n\\[]方括号\n\\()括弧\n\\#井字号\n\\+加号\n\\-减号\n\\.英文句点\n\\!感叹号\n```\n\n\\\\反斜线\n\\`反引号\n\\*星号\n\\_下划线\n\\{}花括号\n\\[]方括号\n\\()括弧\n\\#井字号\n\\+加号\n\\-减号\n\\.英文句点\n\\!感叹号\n\n### 12.目录\n\n采用`[TOC]`来生成文章目录。\n\n```Markdown\n[TOC]\n```\n\n![图片03](Markdown写作教程/图片03.png)\n\n-----\n\n### 13.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![推广](Markdown写作教程/推广.png)\n\n","slug":"Markdown写作教程","published":1,"updated":"2018-03-26T16:37:15.932Z","layout":"post","photos":[],"link":"","_id":"cjg7s0ppk000032016o409b0k","content":"<p><a href=\"https://weizhixiaoyi.com/2018/03/16/Mac+Hexo+GitHub%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/\">博客搭建教程</a>写完之后，很多同学都比较感兴趣，那么在此也写下Markdown写作教程，更快捷、方便的写作博文。当然网上已经有太多人写Markdown教程，那么很多人难免问这个问题，为什么你还要花时间去写如此一篇教程呢？是因为哪怕是同样的内容，写出来之后便有我自己的风格，能让更多人浅显易懂的了解这些知识，同时也能增加我的个人理解，共同学习。</p>\n<h3 id=\"1-为什么选择Markdown\"><a href=\"#1-为什么选择Markdown\" class=\"headerlink\" title=\"1.为什么选择Markdown\"></a>1.为什么选择Markdown</h3><p>首先通过Github搭建博客，我们只能用Markdown文档，然后直接转换成Html网页展现出来。但除了这个原因之外，更吸引我的地方便是其简单、快捷、高效的写作方式，通过轻文本标记语言，利用简洁的语法进行排版，达到所见及所得的效果，书写的过程只考虑内容和文字本身，写作的过程便是享受。目前CSDN、简书、博客园、知乎等平台均支持Markdown写作。当然富文本写作方式也有其迷人之处，比如我用<strong>印象笔记</strong>至此已经写了200+的笔记，有时间给大家写个印象笔记教程，如何高效收集、管理生活中的知识点与信息流。</p>\n<h3 id=\"2-标题\"><a href=\"#2-标题\" class=\"headerlink\" title=\"2.标题\"></a>2.标题</h3><p>标题通过<code>#</code>的个数进行区分，Markdown共支持6级标题。</p>\n<p><img src=\"/2018/03/18/Markdown写作教程/图片01.png\" alt=\"标题\"></p>\n<h3 id=\"3-字体设置\"><a href=\"#3-字体设置\" class=\"headerlink\" title=\"3.字体设置\"></a>3.字体设置</h3><h4 id=\"3-1粗体\"><a href=\"#3-1粗体\" class=\"headerlink\" title=\"3.1粗体\"></a>3.1粗体</h4><p>文字前后加<code>**</code>来表示粗体。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"strong\">**粗体**</span></span><br></pre></td></tr></table></figure>\n<p><strong>粗体</strong></p>\n<h4 id=\"3-2斜体\"><a href=\"#3-2斜体\" class=\"headerlink\" title=\"3.2斜体\"></a>3.2斜体</h4><p>文字前后加<code>*</code>来表示斜体。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"emphasis\">*斜体*</span></span><br></pre></td></tr></table></figure>\n<p><em>斜体</em></p>\n<h4 id=\"3-3粗斜体\"><a href=\"#3-3粗斜体\" class=\"headerlink\" title=\"3.3粗斜体\"></a>3.3粗斜体</h4><p>文字前后加<code>***</code>来表示粗斜体。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"strong\">***粗斜体**</span>*</span><br></pre></td></tr></table></figure>\n<p><strong><em>粗斜体</em></strong></p>\n<h4 id=\"3-4下划线\"><a href=\"#3-4下划线\" class=\"headerlink\" title=\"3.4下划线\"></a>3.4下划线</h4><p>文字前后加<code>&lt;u&gt;</code> <code>&lt;/u&gt;</code>来表示下划线。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;u&gt;下滑线&lt;/u&gt;</span><br></pre></td></tr></table></figure>\n<p><u>下划线</u></p>\n<h4 id=\"3-5删除线\"><a href=\"#3-5删除线\" class=\"headerlink\" title=\"3.5删除线\"></a>3.5删除线</h4><p>文字前后加<code>~~</code>来表示删除线。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~~删除线~~</span><br></pre></td></tr></table></figure>\n<p><del>删除线</del></p>\n<h4 id=\"3-6标记\"><a href=\"#3-6标记\" class=\"headerlink\" title=\"3.6标记\"></a>3.6标记</h4><p>文字前后加<code>` </code>来表示标记，该符号位于Esc键下面。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"code\">`标记`</span></span><br></pre></td></tr></table></figure>\n<p><code>标记</code></p>\n<h4 id=\"3-7Html标签\"><a href=\"#3-7Html标签\" class=\"headerlink\" title=\"3.7Html标签\"></a>3.7Html标签</h4><figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;font face=\"微软雅黑\" color=\"red\" size=\"6\"&gt;字体及字体颜色和大小&lt;/font&gt;</span><br></pre></td></tr></table></figure>\n<font face=\"微软雅黑\" color=\"red\" size=\"3\">字体及字体颜色和大小</font>\n\n<h3 id=\"4-列表\"><a href=\"#4-列表\" class=\"headerlink\" title=\"4.列表\"></a>4.列表</h3><h4 id=\"4-1有序列表\"><a href=\"#4-1有序列表\" class=\"headerlink\" title=\"4.1有序列表\"></a>4.1有序列表</h4><p>采用<code>1.</code> 后加空格形式表示有序列表。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">1. </span>有序列表1</span><br><span class=\"line\"><span class=\"bullet\">2. </span>有序列表2</span><br><span class=\"line\"><span class=\"bullet\">3. </span>有序列表3</span><br></pre></td></tr></table></figure>\n<ol>\n<li>有序列表1</li>\n<li>有序列表2</li>\n<li>有序列表3</li>\n</ol>\n<h4 id=\"4-2无序列表\"><a href=\"#4-2无序列表\" class=\"headerlink\" title=\"4.2无序列表\"></a>4.2无序列表</h4><p>采用<code>+</code> <code>-</code> <code>*</code> <code>=</code>符号表示无序列表，支持多级嵌套。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">+ </span>有序列表1</span><br><span class=\"line\"><span class=\"bullet\">+ </span>+ 有序列表1.1</span><br><span class=\"line\"><span class=\"bullet\">+ </span>+ 有序列表1.2</span><br><span class=\"line\"><span class=\"bullet\">+ </span>有序列表2</span><br><span class=\"line\"><span class=\"bullet\">+ </span>有序列表3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>无序列表1<ul>\n<li>无序列表1.1</li>\n<li>无序列表1.2</li>\n</ul>\n</li>\n<li>无序列表2</li>\n<li>无序列表3</li>\n</ul>\n<h4 id=\"4-3未完成列表\"><a href=\"#4-3未完成列表\" class=\"headerlink\" title=\"4.3未完成列表\"></a>4.3未完成列表</h4><p>采用<code>- []</code>表示未完成任务，各符号间均有空格。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">- </span>[ ] 未完成任务1</span><br><span class=\"line\"><span class=\"bullet\">- </span>[ ] 未完成任务2</span><br><span class=\"line\"><span class=\"bullet\">- </span>[ ] 未完成任务3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>[ ] 未完成任务1</li>\n<li>[ ] 未完成任务2</li>\n<li>[ ] 未完成任务3</li>\n</ul>\n<h4 id=\"4-4已完成任务\"><a href=\"#4-4已完成任务\" class=\"headerlink\" title=\"4.4已完成任务\"></a>4.4已完成任务</h4><p>采用<code>- [x]</code>表示已完成任务，各符号间均有空格。同时可直接在未完成任务间<code>打勾</code>来转换成已完成任务。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">- </span>[x] 已完成任务1</span><br><span class=\"line\"><span class=\"bullet\">- </span>[x] 已完成任务2</span><br><span class=\"line\"><span class=\"bullet\">- </span>[x] 已完成任务3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>[ ] 已完成任务1</li>\n<li>[ ] 已完成任务2</li>\n<li>[ ] 已完成任务3</li>\n</ul>\n<h3 id=\"5-表格\"><a href=\"#5-表格\" class=\"headerlink\" title=\"5.表格\"></a>5.表格</h3><p>表格对齐方式</p>\n<ul>\n<li>居左：:——</li>\n<li>居中：:——:或——-</li>\n<li>居由：——:</li>\n</ul>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">| 标题1           |      标题2      |           标题3 |</span><br><span class=\"line\">| :-------------- | :-------------: | --------------: |</span><br><span class=\"line\">| 居左测试文本1.1 | 居中测试文本2.1 | 居右测试文本3.1 |</span><br><span class=\"line\">| 居左测试文本1.2 | 居中测试文本2.2 | 居右测试文本3.2 |</span><br></pre></td></tr></table></figure>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">标题1</th>\n<th style=\"text-align:center\">标题2</th>\n<th style=\"text-align:right\">标题3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">居左测试文本1.1</td>\n<td style=\"text-align:center\">居中测试文本2.1</td>\n<td style=\"text-align:right\">居右测试文本3.1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">居左测试文本1.2</td>\n<td style=\"text-align:center\">居中测试文本2.2</td>\n<td style=\"text-align:right\">居右测试文本3.2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"6-段落和换行\"><a href=\"#6-段落和换行\" class=\"headerlink\" title=\"6.段落和换行\"></a>6.段落和换行</h3><h4 id=\"6-1首行缩进方式\"><a href=\"#6-1首行缩进方式\" class=\"headerlink\" title=\"6.1首行缩进方式\"></a>6.1首行缩进方式</h4><ul>\n<li><code>&amp;emsp;</code>中文空格</li>\n<li><code>&amp;ensp;</code>半中文空格</li>\n<li><code>&amp;nbsp;</code>英文空格</li>\n<li><code> </code>输入法切换到全角双击空格</li>\n</ul>\n<h4 id=\"6-2换行\"><a href=\"#6-2换行\" class=\"headerlink\" title=\"6.2换行\"></a>6.2换行</h4><ul>\n<li><code>` </code> `换行处连续打两个空格</li>\n<li>换行处使用<code>&lt;br&gt;</code>进行换行</li>\n</ul>\n<h4 id=\"6-3空行\"><a href=\"#6-3空行\" class=\"headerlink\" title=\"6.3空行\"></a>6.3空行</h4><ul>\n<li><code>` </code> ` 空行处连续打两个空格</li>\n<li>换行处使用<code>&lt;br&gt;</code>进行空行</li>\n</ul>\n<h3 id=\"6-引用和代码块\"><a href=\"#6-引用和代码块\" class=\"headerlink\" title=\"6.引用和代码块\"></a>6.引用和代码块</h3><h4 id=\"6-1引用\"><a href=\"#6-1引用\" class=\"headerlink\" title=\"6.1引用\"></a>6.1引用</h4><p>若在文章中需要引入一段话等，可以采用引用的方式呈现，支持多级引用。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"quote\">&gt; 引用1</span></span><br><span class=\"line\"><span class=\"quote\">&gt; &gt; 引用1.1</span></span><br><span class=\"line\"><span class=\"quote\">&gt; &gt; 引用1.2</span></span><br><span class=\"line\"><span class=\"quote\">&gt; 引用2</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>引用1</p>\n<blockquote>\n<p>引用1.1</p>\n<p>引用1.2</p>\n</blockquote>\n<p>引用2</p>\n</blockquote>\n<h4 id=\"6-2代码块\"><a href=\"#6-2代码块\" class=\"headerlink\" title=\"6.2代码块\"></a>6.2代码块</h4><p>代码前后添加<figure class=\"highlight plain\"><figcaption><span>`表示代码块。</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">```markdown</span><br><span class=\"line\">​```Python</span><br><span class=\"line\">print(&apos;代码块&apos;)</span><br><span class=\"line\">​</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">```python</span><br><span class=\"line\">print（<span class=\"string\">'代码块'</span>）</span><br></pre></td></tr></table></figure>\n<h3 id=\"7-链接\"><a href=\"#7-链接\" class=\"headerlink\" title=\"7.链接\"></a>7.链接</h3><h4 id=\"7-1图片链接\"><a href=\"#7-1图片链接\" class=\"headerlink\" title=\"7.1图片链接\"></a>7.1图片链接</h4><p>采用<code>![]()</code>来表示图片链接。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">![<span class=\"string\">图片名称</span>](<span class=\"link\">链接地址</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/18/Markdown写作教程/图片02.png\" alt=\"图片名称\"></p>\n<h4 id=\"7-2文字链接\"><a href=\"#7-2文字链接\" class=\"headerlink\" title=\"7.2文字链接\"></a>7.2文字链接</h4><p>采用<code>[]()</code>表示文字链接。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[<span class=\"string\">链接名称</span>](<span class=\"link\">链接地址</span>)</span><br></pre></td></tr></table></figure>\n<p><a href=\"weizhixiaoyi.com\">文字链接</a></p>\n<h4 id=\"7-3参考链接\"><a href=\"#7-3参考链接\" class=\"headerlink\" title=\"7.3参考链接\"></a>7.3参考链接</h4><p>采用<code>[ ]:</code>表示参考链接，注意符号后有空格。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[<span class=\"symbol\"> </span>]: <span class=\"link\">url title</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"8-分割线\"><a href=\"#8-分割线\" class=\"headerlink\" title=\"8.分割线\"></a>8.分割线</h3><p>上下文无关时可使用分割符进行分开。</p>\n<ul>\n<li>连续多个<code>-</code>  (&gt;=3)</li>\n<li>连续多个<code>*</code> （&gt;=3）</li>\n<li>连续多个下划线<code>_</code> （&gt;=3）</li>\n</ul>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---分割线</span><br><span class=\"line\"><span class=\"emphasis\">***</span>分割线</span><br><span class=\"line\"><span class=\"emphasis\">___</span>分割线</span><br></pre></td></tr></table></figure>\n<hr>\n<hr>\n<hr>\n<h3 id=\"9-脚注和注释\"><a href=\"#9-脚注和注释\" class=\"headerlink\" title=\"9.脚注和注释\"></a>9.脚注和注释</h3><h4 id=\"9-1脚注\"><a href=\"#9-1脚注\" class=\"headerlink\" title=\"9.1脚注\"></a>9.1脚注</h4><p>采用`<sup><a href=\"#fn_\" id=\"reffn_\"></a></sup>:表示脚注，注意空格。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[<span class=\"symbol\">^</span>]: <span class=\"link\">脚注</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"9-2注释\"><a href=\"#9-2注释\" class=\"headerlink\" title=\"9.2注释\"></a>9.2注释</h4><p>采用<code>&lt;!----&gt;</code>表示注释.</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"xml\"><span class=\"comment\">&lt;!--注释--&gt;</span></span></span><br></pre></td></tr></table></figure>\n<!--注释-->\n<h3 id=\"11-转义\"><a href=\"#11-转义\" class=\"headerlink\" title=\"11.转义\"></a>11.转义</h3><p>Markdown通过反斜杠<code>\\</code>来插入在语法中有其他意义的符号，Markdown支持以下符号来进行转义。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\\\反斜线</span><br><span class=\"line\">\\`反引号</span><br><span class=\"line\">\\*星号</span><br><span class=\"line\">\\_下划线</span><br><span class=\"line\">\\&#123;&#125;花括号</span><br><span class=\"line\">\\[]方括号</span><br><span class=\"line\">\\()括弧</span><br><span class=\"line\">\\#井字号</span><br><span class=\"line\">\\+加号</span><br><span class=\"line\">\\-减号</span><br><span class=\"line\">\\.英文句点</span><br><span class=\"line\">\\!感叹号</span><br></pre></td></tr></table></figure>\n<p>\\\\反斜线<br>`反引号<br>*星号<br>_下划线<br>\\{}花括号<br>[]方括号<br>()括弧<br>#井字号<br>+加号<br>-减号<br>.英文句点<br>!感叹号</p>\n<h3 id=\"12-目录\"><a href=\"#12-目录\" class=\"headerlink\" title=\"12.目录\"></a>12.目录</h3><p>采用<code>[TOC]</code>来生成文章目录。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[TOC]</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/18/Markdown写作教程/图片03.png\" alt=\"图片03\"></p>\n<hr>\n<h3 id=\"13-推广\"><a href=\"#13-推广\" class=\"headerlink\" title=\"13.推广\"></a>13.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/18/Markdown写作教程/推广.png\" alt=\"推广\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://weizhixiaoyi.com/2018/03/16/Mac+Hexo+GitHub%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/\">博客搭建教程</a>写完之后，很多同学都比较感兴趣，那么在此也写下Markdown写作教程，更快捷、方便的写作博文。当然网上已经有太多人写Markdown教程，那么很多人难免问这个问题，为什么你还要花时间去写如此一篇教程呢？是因为哪怕是同样的内容，写出来之后便有我自己的风格，能让更多人浅显易懂的了解这些知识，同时也能增加我的个人理解，共同学习。</p>\n<h3 id=\"1-为什么选择Markdown\"><a href=\"#1-为什么选择Markdown\" class=\"headerlink\" title=\"1.为什么选择Markdown\"></a>1.为什么选择Markdown</h3><p>首先通过Github搭建博客，我们只能用Markdown文档，然后直接转换成Html网页展现出来。但除了这个原因之外，更吸引我的地方便是其简单、快捷、高效的写作方式，通过轻文本标记语言，利用简洁的语法进行排版，达到所见及所得的效果，书写的过程只考虑内容和文字本身，写作的过程便是享受。目前CSDN、简书、博客园、知乎等平台均支持Markdown写作。当然富文本写作方式也有其迷人之处，比如我用<strong>印象笔记</strong>至此已经写了200+的笔记，有时间给大家写个印象笔记教程，如何高效收集、管理生活中的知识点与信息流。</p>\n<h3 id=\"2-标题\"><a href=\"#2-标题\" class=\"headerlink\" title=\"2.标题\"></a>2.标题</h3><p>标题通过<code>#</code>的个数进行区分，Markdown共支持6级标题。</p>\n<p><img src=\"/2018/03/18/Markdown写作教程/图片01.png\" alt=\"标题\"></p>\n<h3 id=\"3-字体设置\"><a href=\"#3-字体设置\" class=\"headerlink\" title=\"3.字体设置\"></a>3.字体设置</h3><h4 id=\"3-1粗体\"><a href=\"#3-1粗体\" class=\"headerlink\" title=\"3.1粗体\"></a>3.1粗体</h4><p>文字前后加<code>**</code>来表示粗体。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"strong\">**粗体**</span></span><br></pre></td></tr></table></figure>\n<p><strong>粗体</strong></p>\n<h4 id=\"3-2斜体\"><a href=\"#3-2斜体\" class=\"headerlink\" title=\"3.2斜体\"></a>3.2斜体</h4><p>文字前后加<code>*</code>来表示斜体。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"emphasis\">*斜体*</span></span><br></pre></td></tr></table></figure>\n<p><em>斜体</em></p>\n<h4 id=\"3-3粗斜体\"><a href=\"#3-3粗斜体\" class=\"headerlink\" title=\"3.3粗斜体\"></a>3.3粗斜体</h4><p>文字前后加<code>***</code>来表示粗斜体。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"strong\">***粗斜体**</span>*</span><br></pre></td></tr></table></figure>\n<p><strong><em>粗斜体</em></strong></p>\n<h4 id=\"3-4下划线\"><a href=\"#3-4下划线\" class=\"headerlink\" title=\"3.4下划线\"></a>3.4下划线</h4><p>文字前后加<code>&lt;u&gt;</code> <code>&lt;/u&gt;</code>来表示下划线。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;u&gt;下滑线&lt;/u&gt;</span><br></pre></td></tr></table></figure>\n<p><u>下划线</u></p>\n<h4 id=\"3-5删除线\"><a href=\"#3-5删除线\" class=\"headerlink\" title=\"3.5删除线\"></a>3.5删除线</h4><p>文字前后加<code>~~</code>来表示删除线。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~~删除线~~</span><br></pre></td></tr></table></figure>\n<p><del>删除线</del></p>\n<h4 id=\"3-6标记\"><a href=\"#3-6标记\" class=\"headerlink\" title=\"3.6标记\"></a>3.6标记</h4><p>文字前后加<code>` </code>来表示标记，该符号位于Esc键下面。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"code\">`标记`</span></span><br></pre></td></tr></table></figure>\n<p><code>标记</code></p>\n<h4 id=\"3-7Html标签\"><a href=\"#3-7Html标签\" class=\"headerlink\" title=\"3.7Html标签\"></a>3.7Html标签</h4><figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;font face=\"微软雅黑\" color=\"red\" size=\"6\"&gt;字体及字体颜色和大小&lt;/font&gt;</span><br></pre></td></tr></table></figure>\n<font face=\"微软雅黑\" color=\"red\" size=\"3\">字体及字体颜色和大小</font>\n\n<h3 id=\"4-列表\"><a href=\"#4-列表\" class=\"headerlink\" title=\"4.列表\"></a>4.列表</h3><h4 id=\"4-1有序列表\"><a href=\"#4-1有序列表\" class=\"headerlink\" title=\"4.1有序列表\"></a>4.1有序列表</h4><p>采用<code>1.</code> 后加空格形式表示有序列表。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">1. </span>有序列表1</span><br><span class=\"line\"><span class=\"bullet\">2. </span>有序列表2</span><br><span class=\"line\"><span class=\"bullet\">3. </span>有序列表3</span><br></pre></td></tr></table></figure>\n<ol>\n<li>有序列表1</li>\n<li>有序列表2</li>\n<li>有序列表3</li>\n</ol>\n<h4 id=\"4-2无序列表\"><a href=\"#4-2无序列表\" class=\"headerlink\" title=\"4.2无序列表\"></a>4.2无序列表</h4><p>采用<code>+</code> <code>-</code> <code>*</code> <code>=</code>符号表示无序列表，支持多级嵌套。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">+ </span>有序列表1</span><br><span class=\"line\"><span class=\"bullet\">+ </span>+ 有序列表1.1</span><br><span class=\"line\"><span class=\"bullet\">+ </span>+ 有序列表1.2</span><br><span class=\"line\"><span class=\"bullet\">+ </span>有序列表2</span><br><span class=\"line\"><span class=\"bullet\">+ </span>有序列表3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>无序列表1<ul>\n<li>无序列表1.1</li>\n<li>无序列表1.2</li>\n</ul>\n</li>\n<li>无序列表2</li>\n<li>无序列表3</li>\n</ul>\n<h4 id=\"4-3未完成列表\"><a href=\"#4-3未完成列表\" class=\"headerlink\" title=\"4.3未完成列表\"></a>4.3未完成列表</h4><p>采用<code>- []</code>表示未完成任务，各符号间均有空格。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">- </span>[ ] 未完成任务1</span><br><span class=\"line\"><span class=\"bullet\">- </span>[ ] 未完成任务2</span><br><span class=\"line\"><span class=\"bullet\">- </span>[ ] 未完成任务3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>[ ] 未完成任务1</li>\n<li>[ ] 未完成任务2</li>\n<li>[ ] 未完成任务3</li>\n</ul>\n<h4 id=\"4-4已完成任务\"><a href=\"#4-4已完成任务\" class=\"headerlink\" title=\"4.4已完成任务\"></a>4.4已完成任务</h4><p>采用<code>- [x]</code>表示已完成任务，各符号间均有空格。同时可直接在未完成任务间<code>打勾</code>来转换成已完成任务。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"bullet\">- </span>[x] 已完成任务1</span><br><span class=\"line\"><span class=\"bullet\">- </span>[x] 已完成任务2</span><br><span class=\"line\"><span class=\"bullet\">- </span>[x] 已完成任务3</span><br></pre></td></tr></table></figure>\n<ul>\n<li>[ ] 已完成任务1</li>\n<li>[ ] 已完成任务2</li>\n<li>[ ] 已完成任务3</li>\n</ul>\n<h3 id=\"5-表格\"><a href=\"#5-表格\" class=\"headerlink\" title=\"5.表格\"></a>5.表格</h3><p>表格对齐方式</p>\n<ul>\n<li>居左：:——</li>\n<li>居中：:——:或——-</li>\n<li>居由：——:</li>\n</ul>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">| 标题1           |      标题2      |           标题3 |</span><br><span class=\"line\">| :-------------- | :-------------: | --------------: |</span><br><span class=\"line\">| 居左测试文本1.1 | 居中测试文本2.1 | 居右测试文本3.1 |</span><br><span class=\"line\">| 居左测试文本1.2 | 居中测试文本2.2 | 居右测试文本3.2 |</span><br></pre></td></tr></table></figure>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">标题1</th>\n<th style=\"text-align:center\">标题2</th>\n<th style=\"text-align:right\">标题3</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">居左测试文本1.1</td>\n<td style=\"text-align:center\">居中测试文本2.1</td>\n<td style=\"text-align:right\">居右测试文本3.1</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">居左测试文本1.2</td>\n<td style=\"text-align:center\">居中测试文本2.2</td>\n<td style=\"text-align:right\">居右测试文本3.2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"6-段落和换行\"><a href=\"#6-段落和换行\" class=\"headerlink\" title=\"6.段落和换行\"></a>6.段落和换行</h3><h4 id=\"6-1首行缩进方式\"><a href=\"#6-1首行缩进方式\" class=\"headerlink\" title=\"6.1首行缩进方式\"></a>6.1首行缩进方式</h4><ul>\n<li><code>&amp;emsp;</code>中文空格</li>\n<li><code>&amp;ensp;</code>半中文空格</li>\n<li><code>&amp;nbsp;</code>英文空格</li>\n<li><code> </code>输入法切换到全角双击空格</li>\n</ul>\n<h4 id=\"6-2换行\"><a href=\"#6-2换行\" class=\"headerlink\" title=\"6.2换行\"></a>6.2换行</h4><ul>\n<li><code>` </code> `换行处连续打两个空格</li>\n<li>换行处使用<code>&lt;br&gt;</code>进行换行</li>\n</ul>\n<h4 id=\"6-3空行\"><a href=\"#6-3空行\" class=\"headerlink\" title=\"6.3空行\"></a>6.3空行</h4><ul>\n<li><code>` </code> ` 空行处连续打两个空格</li>\n<li>换行处使用<code>&lt;br&gt;</code>进行空行</li>\n</ul>\n<h3 id=\"6-引用和代码块\"><a href=\"#6-引用和代码块\" class=\"headerlink\" title=\"6.引用和代码块\"></a>6.引用和代码块</h3><h4 id=\"6-1引用\"><a href=\"#6-1引用\" class=\"headerlink\" title=\"6.1引用\"></a>6.1引用</h4><p>若在文章中需要引入一段话等，可以采用引用的方式呈现，支持多级引用。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"quote\">&gt; 引用1</span></span><br><span class=\"line\"><span class=\"quote\">&gt; &gt; 引用1.1</span></span><br><span class=\"line\"><span class=\"quote\">&gt; &gt; 引用1.2</span></span><br><span class=\"line\"><span class=\"quote\">&gt; 引用2</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>引用1</p>\n<blockquote>\n<p>引用1.1</p>\n<p>引用1.2</p>\n</blockquote>\n<p>引用2</p>\n</blockquote>\n<h4 id=\"6-2代码块\"><a href=\"#6-2代码块\" class=\"headerlink\" title=\"6.2代码块\"></a>6.2代码块</h4><p>代码前后添加<figure class=\"highlight plain\"><figcaption><span>`表示代码块。</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">```markdown</span><br><span class=\"line\">​```Python</span><br><span class=\"line\">print(&apos;代码块&apos;)</span><br><span class=\"line\">​</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">```python</span><br><span class=\"line\">print（<span class=\"string\">'代码块'</span>）</span><br></pre></td></tr></table></figure>\n<h3 id=\"7-链接\"><a href=\"#7-链接\" class=\"headerlink\" title=\"7.链接\"></a>7.链接</h3><h4 id=\"7-1图片链接\"><a href=\"#7-1图片链接\" class=\"headerlink\" title=\"7.1图片链接\"></a>7.1图片链接</h4><p>采用<code>![]()</code>来表示图片链接。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">![<span class=\"string\">图片名称</span>](<span class=\"link\">链接地址</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/18/Markdown写作教程/图片02.png\" alt=\"图片名称\"></p>\n<h4 id=\"7-2文字链接\"><a href=\"#7-2文字链接\" class=\"headerlink\" title=\"7.2文字链接\"></a>7.2文字链接</h4><p>采用<code>[]()</code>表示文字链接。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[<span class=\"string\">链接名称</span>](<span class=\"link\">链接地址</span>)</span><br></pre></td></tr></table></figure>\n<p><a href=\"weizhixiaoyi.com\">文字链接</a></p>\n<h4 id=\"7-3参考链接\"><a href=\"#7-3参考链接\" class=\"headerlink\" title=\"7.3参考链接\"></a>7.3参考链接</h4><p>采用<code>[ ]:</code>表示参考链接，注意符号后有空格。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[<span class=\"symbol\"> </span>]: <span class=\"link\">url title</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"8-分割线\"><a href=\"#8-分割线\" class=\"headerlink\" title=\"8.分割线\"></a>8.分割线</h3><p>上下文无关时可使用分割符进行分开。</p>\n<ul>\n<li>连续多个<code>-</code>  (&gt;=3)</li>\n<li>连续多个<code>*</code> （&gt;=3）</li>\n<li>连续多个下划线<code>_</code> （&gt;=3）</li>\n</ul>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---分割线</span><br><span class=\"line\"><span class=\"emphasis\">***</span>分割线</span><br><span class=\"line\"><span class=\"emphasis\">___</span>分割线</span><br></pre></td></tr></table></figure>\n<hr>\n<hr>\n<hr>\n<h3 id=\"9-脚注和注释\"><a href=\"#9-脚注和注释\" class=\"headerlink\" title=\"9.脚注和注释\"></a>9.脚注和注释</h3><h4 id=\"9-1脚注\"><a href=\"#9-1脚注\" class=\"headerlink\" title=\"9.1脚注\"></a>9.1脚注</h4><p>采用`<sup><a href=\"#fn_\" id=\"reffn_\"></a></sup>:表示脚注，注意空格。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[<span class=\"symbol\">^</span>]: <span class=\"link\">脚注</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"9-2注释\"><a href=\"#9-2注释\" class=\"headerlink\" title=\"9.2注释\"></a>9.2注释</h4><p>采用<code>&lt;!----&gt;</code>表示注释.</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"xml\"><span class=\"comment\">&lt;!--注释--&gt;</span></span></span><br></pre></td></tr></table></figure>\n<!--注释-->\n<h3 id=\"11-转义\"><a href=\"#11-转义\" class=\"headerlink\" title=\"11.转义\"></a>11.转义</h3><p>Markdown通过反斜杠<code>\\</code>来插入在语法中有其他意义的符号，Markdown支持以下符号来进行转义。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">\\\\反斜线</span><br><span class=\"line\">\\`反引号</span><br><span class=\"line\">\\*星号</span><br><span class=\"line\">\\_下划线</span><br><span class=\"line\">\\&#123;&#125;花括号</span><br><span class=\"line\">\\[]方括号</span><br><span class=\"line\">\\()括弧</span><br><span class=\"line\">\\#井字号</span><br><span class=\"line\">\\+加号</span><br><span class=\"line\">\\-减号</span><br><span class=\"line\">\\.英文句点</span><br><span class=\"line\">\\!感叹号</span><br></pre></td></tr></table></figure>\n<p>\\\\反斜线<br>`反引号<br>*星号<br>_下划线<br>\\{}花括号<br>[]方括号<br>()括弧<br>#井字号<br>+加号<br>-减号<br>.英文句点<br>!感叹号</p>\n<h3 id=\"12-目录\"><a href=\"#12-目录\" class=\"headerlink\" title=\"12.目录\"></a>12.目录</h3><p>采用<code>[TOC]</code>来生成文章目录。</p>\n<figure class=\"highlight markdown\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[TOC]</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/18/Markdown写作教程/图片03.png\" alt=\"图片03\"></p>\n<hr>\n<h3 id=\"13-推广\"><a href=\"#13-推广\" class=\"headerlink\" title=\"13.推广\"></a>13.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/18/Markdown写作教程/推广.png\" alt=\"推广\"></p>\n"},{"title":"Python之NumPy使用教程","date":"2018-03-13T09:35:25.000Z","toc":true,"comments":1,"_content":"### 1.NumPy概述\nNumPy(Numerical Python)是用Python进行科学计算的基础软件包。包含以下特点：\n 1. 强大的N维数组对象Array\n 2. 成熟的函数库\n 3. 用于集成C/C++和Fortran代码的工具\n 4. 实用的线性代数、傅立叶变换和随机生成函数\n\n### 2.NumPy安装\n```\npip install numpy或pip3 install numpy\n```\n### 3.NumPy引入\n```\nimport numpy as np#为了方便实用numpy 采用np简写\n```\n### 4.NumPy方法\n```\narray=np.array([[1,2,3],[4,5,6]])#将列表转换为矩阵 并转换为int类型\nprint(array)\n'''\n[[1 2 3]\n [4 5 6]]\n '''\n```\n#### 4.1NumPy属性\n```\nprint('array of dim:',array.ndim)#矩阵的维度\n#array of dim:2\nprint('array of shape',array.shape)#矩阵的行数和列数\n#array of shape:(2,3)\nprint('number of size:',array.size)#元素的个数\n#number of size:6\n```\n#### 4.2NumPy创建Array\n\n - array:创建数组\n - dtype:指定数据类型\n - zeros:创建数据全为0\n - ones:创建数据全为1\n - empty:创建数据接近0\n - arange:指定范围内创建数据\n - linspace创建线段\n\n创建数组\n```\na=np.array([1,2,3])\nprint(a)\n#[1,2,3]\n```\n指定数据dtype\n```\na=np.array([1,2,3],dtype=np.int)#指定为int类型\nprint(a.dtype)\n#int 64\nb=np.array([1,2,3],dtype=np.float)#指定为float类型\nprint(b.dtype)\n#float 64\n```\n创建特定数据\n```\na=np.array([[1,2,3],[4,5,6]])#矩阵 2行3列\nprint(a)\n'''\n[[1 2 3]\n [4 5 6]]\n '''\n```\n创建全0数组\n```\na=np.zeros((2,3))#数据全0 2行3列\nprint(a)\n'''\n[[0 0 0]\n [0 0 0]]\n '''\n```\n创建全1数组 指定特定类型dtype\n```\na=np.zeros((2,3),dtype=np.int)#数据全1 2行3列 同时指定类型\nprint(a)\n'''\n[[1 1 1]\n [1 1 1]]\n '''\n```\n创建全空数组 每个值接近0\n```\na=np.empty(2,3)#数据全为empty 3行4列\nprint(a)\n'''\n[[  0.00000000e+000   0.00000000e+000   2.12704693e-314]\n [  2.12706024e-314   2.12706024e-314   2.12706024e-314]]\n '''\n```\n用array创建连续数组\n```\na=np.arange(1,10,2)#1到10的数据 2步长\nprint(a)\n#[1 3 5 7 9]\n```\n用reshape改变数据形状\n```\na=np.arange(6).reshape(2,3)\nprint(a)\n'''\n[[0 1 2]\n [3 4 5]]\n '''\n```\n用linspace创建线段形数据\n```\na=np.linspace(1,10,20)#开始端1 结束端5 分割成10个数据 生成线段\nprint(a)\n'''\n[ 1.          1.44444444  1.88888889  2.33333333  2.77777778  3.22222222\n  3.66666667  4.11111111  4.55555556  5.        ]\n  '''\n```\n#### 4.3NumPy基础运算\n基础运算之加、减、三角函数等\n```\na=np.array([10,20,30,40])\nb=np.arange(4) #array[0,1,2,3]\n\nc=a+b#加法运算\nprint(c)\n#[10,21,32,43]\n\nc=a-b#减法运算\nprint(c)\n#[10.19,28,37]\n\nc=10*np.sin(a)#三角函数运算\n#[-5.44021111,  9.12945251, -9.88031624,  7.4511316 ]\n\nprint(b<3)#逻辑判断\n#[ True  True  True False]\n\nd=np.random.random((2,3))#随机生成2行3列的矩阵\nprint(d)\n'''\n[[ 0.21116981  0.0804489   0.51855475]\n [ 0.38359164  0.55852973  0.73218811]]\n'''\nprint(np.sum(d))#元素求和\n#2.48448292958\nprint(np.max(d))#元素求最大值\n#0.732188108709\nprint(np.min(d))#元素求最小值\n#0.0804488978886\n```\n多维矩阵运算\n```\na=np.array([[1,1],[0,1]])\nb=np.arange(4).reshape((2,2))\n\nc=np.dot(a,b)#或c=a.dot(b)矩阵运算\nprint(c)\n'''\n[[2 4]\n [2 3]]\n '''\n```\n对行或列执行查找运算\n```\na=np.array([[1,2],[3,4]])\nprint(a)\n'''\n[[1,2]\n [3,4]]\n '''\nprint(np.max(a,axis=0))#axis=0时是对列进行操作\n#[3,4]\nprint(np.min(a,axis=1))#axis=1是对行进行操作\n#[1,3]\n```\n矩阵索引操作\n```\nA=np.arange(2,14).reshape(3,4)\nprint(A)\n'''\n[[2,3,4,5]\n [6,7,8,9]\n [10,11,12,13]]\n '''\nprint(np.argmax(A))#矩阵中最大元素的索引\n#11\nprint(np.argmin(A))#矩阵中最小元素的索引\n#0\nprint(np.mean(A))#或者np.average(A)求解矩阵均值\n#7.5\nprint(np.cumsum(A))#矩阵累加函数\n#[2 5 9 14 20 27 35 44 54 65 77 90]\nprint(np.diff(A))#矩阵累差函数\n'''\n[[1 1 1]\n [1 1 1]\n [1 1 1]]\n '''\nprint(np.nonzero(A))#将非0元素的行与列坐标分割开来\n#(array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]), array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]))\n```\n矩阵排序、转置、替换操作\n```\nA=np.arange(14,2,-1).reshape((3,4))\nprint(A)\n'''\n[[14 13 12 11]\n [10  9  8  7]\n [ 6  5  4  3]]\n '''\nprint(np.sort(A))#排序\n'''\n[[11 12 13 14]\n [ 7  8  9 10]\n [ 3  4  5  6]]\n '''\n\nprint(np.transpose(A))\n'''\n[[14 10  6]\n [13  9  5]\n [12  8  4]\n [11  7  3]]\n '''\n\nprint(np.clip(A,5,9))#替换 判断当前矩阵元素是否比最小值小或比最大值大 若是则替换\n'''\n[[9 9 9 9]\n [9 9 8 7]\n [6 5 5 5]]\n '''\n```\n### 5.索引\n一维索引\n```\nA=np.arange(0,12)\nprint(A)\n#[ 0  1  2  3  4  5  6  7  8  9 10 11]\nprint(A[1])#一维索引\n#1\n\nA=np.arange(0,12).reshape((3,4))\nprint(A[0])\n#[0,1,2,3]\n```\n二维索引\n```\nA=np.arange(0,12).reshape((3,4))\nprint(A)\n'''\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n '''\nprint(A[1][1])#或者A[1,1]\n#5\nprint(A[1,1:3])#切片处理\n#[5,6]\n\nfor row in A:\n    print(A)\n'''\n[0 1 2 3]\n[4 5 6 7]\n[ 8  9 10 11]\n '''\nfor col in A:\n    print(col)\n'''\n[0 4 8]\n[1 5 9]\n[ 2  6 10]\n[ 3  7 11]\n '''\n\nfor item in A.flat:\n    print(item)\n'''\n0\n1\n...\n10\n11\n'''\n```\n### 6.NumPy之Array合并\n```\nA=np.array([1,1,1])\nB=np.array([2,2,2])\nprint(np.vstack((A,B)))#上下合并\n'''\n[[1 1 1]\n [2 2 2]]\n '''\nprint(np.hstack((A,B)))#左右合并\n#[1 1 1 2 2 2]\n```\n增加维度\n```\nA=np.array([1,1,1])\nprint(A.shape)\n#(3,)\nprint(A[np.newaxis,:])\n#[[1 1 1]]\nprint(A[np.newaxis,:].shape)#newaxis增加维度\n#(1,3)\n\nprint(A[:,np.newaxis])\n'''\n[[1]\n [1]\n [1]]\n '''\nprint(A[:,np.newaxis].shape)\n#（3,1）\n```\n多矩阵合并\n```\nA = np.array([1,1,1])[:,np.newaxis]\nB = np.array([2,2,2])[:,np.newaxis]\nprint(np.concatenate((A,B,B,A),axis=0))#0表示上下合并\n'''\n[[1]\n [1]\n [1]\n [2]\n [2]\n [2]\n [2]\n [2]\n [2]\n [1]\n [1]\n [1]]\n '''\nprint(np.concatenate((A,B,B,A),axis=1))#1表示左右合并\n'''\n[[1 2 2 1]\n [1 2 2 1]\n [1 2 2 1]]\n '''\n```\n### 7.NumPy分割\n```\nA=np.arange(12).reshape((3,4))\nprint(A)\n'''\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n '''\nprint(np.split(A,3,axis=0))#横向分割成3部分 或者np.vsplit(A,3)\n#[array([[0, 1, 2, 3]]), array([[4, 5, 6, 7]]), array([[ 8,  9, 10, 11]])]\n\nprint(np.split(A,2,axis=1))#竖向分割成2部分 或者np.hsplit(A,2)\n'''\n[array([[0, 1],\n       [4, 5],\n       [8, 9]]), array([[ 2,  3],\n       [ 6,  7],\n       [10, 11]])]\n '''\n \nprint(np.array_split(A,3,axis=1))#不等量分割成3部分\n'''\n[array([[0, 1],\n       [4, 5],\n       [8, 9]]), array([[ 2],\n       [ 6],\n       [10]]), array([[ 3],\n       [ 7],\n       [11]])]\n'''  \n```\n### 8.NumPy中copy和deep copy\n'='赋值方式会带有关联性\n```\na=np.arange(4)\nprint(a)\n#[1 2 3 4]\nb=a\nc=a\nd=b\nprint(b is a)\n#True\nprint(c is a)\n#True\nprint(d is a)\n#True\n\nb[0]=5#改变b的值，a,c,d同样会进行改变\nprint(a)\n#[5 2 3 4]\n```\n'copy()'赋值方式没有关联性\n```\na=np.arange(4)#deep copy\nprint(a)\n#[0 1 2 3]\nb=a.copy()\na[0]=5\nprint(b)#值并不发生改变\n#[0 1 2 3]\n```\n----------\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。如果感觉不错的话，可以资助1元钱当作鼓励，Thank you谢谢!\n<img src=\"http://img.blog.csdn.net/20180309135000807?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width = \"400\" height = \"400\" alt=\"公众号\" align=center/> <img src=\"http://img.blog.csdn.net/20180308203132669?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width = \"400\" height = \"400\" alt=\"赞赏码\" align=center/>","source":"_posts/Python之NumPy使用教程.md","raw":"---\ntitle: Python之NumPy使用教程\ndate: 2018-03-13 17:35:25\ntags: python\ntoc: true\ncategories: Python库\ncomments: true\n---\n### 1.NumPy概述\nNumPy(Numerical Python)是用Python进行科学计算的基础软件包。包含以下特点：\n 1. 强大的N维数组对象Array\n 2. 成熟的函数库\n 3. 用于集成C/C++和Fortran代码的工具\n 4. 实用的线性代数、傅立叶变换和随机生成函数\n\n### 2.NumPy安装\n```\npip install numpy或pip3 install numpy\n```\n### 3.NumPy引入\n```\nimport numpy as np#为了方便实用numpy 采用np简写\n```\n### 4.NumPy方法\n```\narray=np.array([[1,2,3],[4,5,6]])#将列表转换为矩阵 并转换为int类型\nprint(array)\n'''\n[[1 2 3]\n [4 5 6]]\n '''\n```\n#### 4.1NumPy属性\n```\nprint('array of dim:',array.ndim)#矩阵的维度\n#array of dim:2\nprint('array of shape',array.shape)#矩阵的行数和列数\n#array of shape:(2,3)\nprint('number of size:',array.size)#元素的个数\n#number of size:6\n```\n#### 4.2NumPy创建Array\n\n - array:创建数组\n - dtype:指定数据类型\n - zeros:创建数据全为0\n - ones:创建数据全为1\n - empty:创建数据接近0\n - arange:指定范围内创建数据\n - linspace创建线段\n\n创建数组\n```\na=np.array([1,2,3])\nprint(a)\n#[1,2,3]\n```\n指定数据dtype\n```\na=np.array([1,2,3],dtype=np.int)#指定为int类型\nprint(a.dtype)\n#int 64\nb=np.array([1,2,3],dtype=np.float)#指定为float类型\nprint(b.dtype)\n#float 64\n```\n创建特定数据\n```\na=np.array([[1,2,3],[4,5,6]])#矩阵 2行3列\nprint(a)\n'''\n[[1 2 3]\n [4 5 6]]\n '''\n```\n创建全0数组\n```\na=np.zeros((2,3))#数据全0 2行3列\nprint(a)\n'''\n[[0 0 0]\n [0 0 0]]\n '''\n```\n创建全1数组 指定特定类型dtype\n```\na=np.zeros((2,3),dtype=np.int)#数据全1 2行3列 同时指定类型\nprint(a)\n'''\n[[1 1 1]\n [1 1 1]]\n '''\n```\n创建全空数组 每个值接近0\n```\na=np.empty(2,3)#数据全为empty 3行4列\nprint(a)\n'''\n[[  0.00000000e+000   0.00000000e+000   2.12704693e-314]\n [  2.12706024e-314   2.12706024e-314   2.12706024e-314]]\n '''\n```\n用array创建连续数组\n```\na=np.arange(1,10,2)#1到10的数据 2步长\nprint(a)\n#[1 3 5 7 9]\n```\n用reshape改变数据形状\n```\na=np.arange(6).reshape(2,3)\nprint(a)\n'''\n[[0 1 2]\n [3 4 5]]\n '''\n```\n用linspace创建线段形数据\n```\na=np.linspace(1,10,20)#开始端1 结束端5 分割成10个数据 生成线段\nprint(a)\n'''\n[ 1.          1.44444444  1.88888889  2.33333333  2.77777778  3.22222222\n  3.66666667  4.11111111  4.55555556  5.        ]\n  '''\n```\n#### 4.3NumPy基础运算\n基础运算之加、减、三角函数等\n```\na=np.array([10,20,30,40])\nb=np.arange(4) #array[0,1,2,3]\n\nc=a+b#加法运算\nprint(c)\n#[10,21,32,43]\n\nc=a-b#减法运算\nprint(c)\n#[10.19,28,37]\n\nc=10*np.sin(a)#三角函数运算\n#[-5.44021111,  9.12945251, -9.88031624,  7.4511316 ]\n\nprint(b<3)#逻辑判断\n#[ True  True  True False]\n\nd=np.random.random((2,3))#随机生成2行3列的矩阵\nprint(d)\n'''\n[[ 0.21116981  0.0804489   0.51855475]\n [ 0.38359164  0.55852973  0.73218811]]\n'''\nprint(np.sum(d))#元素求和\n#2.48448292958\nprint(np.max(d))#元素求最大值\n#0.732188108709\nprint(np.min(d))#元素求最小值\n#0.0804488978886\n```\n多维矩阵运算\n```\na=np.array([[1,1],[0,1]])\nb=np.arange(4).reshape((2,2))\n\nc=np.dot(a,b)#或c=a.dot(b)矩阵运算\nprint(c)\n'''\n[[2 4]\n [2 3]]\n '''\n```\n对行或列执行查找运算\n```\na=np.array([[1,2],[3,4]])\nprint(a)\n'''\n[[1,2]\n [3,4]]\n '''\nprint(np.max(a,axis=0))#axis=0时是对列进行操作\n#[3,4]\nprint(np.min(a,axis=1))#axis=1是对行进行操作\n#[1,3]\n```\n矩阵索引操作\n```\nA=np.arange(2,14).reshape(3,4)\nprint(A)\n'''\n[[2,3,4,5]\n [6,7,8,9]\n [10,11,12,13]]\n '''\nprint(np.argmax(A))#矩阵中最大元素的索引\n#11\nprint(np.argmin(A))#矩阵中最小元素的索引\n#0\nprint(np.mean(A))#或者np.average(A)求解矩阵均值\n#7.5\nprint(np.cumsum(A))#矩阵累加函数\n#[2 5 9 14 20 27 35 44 54 65 77 90]\nprint(np.diff(A))#矩阵累差函数\n'''\n[[1 1 1]\n [1 1 1]\n [1 1 1]]\n '''\nprint(np.nonzero(A))#将非0元素的行与列坐标分割开来\n#(array([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]), array([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]))\n```\n矩阵排序、转置、替换操作\n```\nA=np.arange(14,2,-1).reshape((3,4))\nprint(A)\n'''\n[[14 13 12 11]\n [10  9  8  7]\n [ 6  5  4  3]]\n '''\nprint(np.sort(A))#排序\n'''\n[[11 12 13 14]\n [ 7  8  9 10]\n [ 3  4  5  6]]\n '''\n\nprint(np.transpose(A))\n'''\n[[14 10  6]\n [13  9  5]\n [12  8  4]\n [11  7  3]]\n '''\n\nprint(np.clip(A,5,9))#替换 判断当前矩阵元素是否比最小值小或比最大值大 若是则替换\n'''\n[[9 9 9 9]\n [9 9 8 7]\n [6 5 5 5]]\n '''\n```\n### 5.索引\n一维索引\n```\nA=np.arange(0,12)\nprint(A)\n#[ 0  1  2  3  4  5  6  7  8  9 10 11]\nprint(A[1])#一维索引\n#1\n\nA=np.arange(0,12).reshape((3,4))\nprint(A[0])\n#[0,1,2,3]\n```\n二维索引\n```\nA=np.arange(0,12).reshape((3,4))\nprint(A)\n'''\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n '''\nprint(A[1][1])#或者A[1,1]\n#5\nprint(A[1,1:3])#切片处理\n#[5,6]\n\nfor row in A:\n    print(A)\n'''\n[0 1 2 3]\n[4 5 6 7]\n[ 8  9 10 11]\n '''\nfor col in A:\n    print(col)\n'''\n[0 4 8]\n[1 5 9]\n[ 2  6 10]\n[ 3  7 11]\n '''\n\nfor item in A.flat:\n    print(item)\n'''\n0\n1\n...\n10\n11\n'''\n```\n### 6.NumPy之Array合并\n```\nA=np.array([1,1,1])\nB=np.array([2,2,2])\nprint(np.vstack((A,B)))#上下合并\n'''\n[[1 1 1]\n [2 2 2]]\n '''\nprint(np.hstack((A,B)))#左右合并\n#[1 1 1 2 2 2]\n```\n增加维度\n```\nA=np.array([1,1,1])\nprint(A.shape)\n#(3,)\nprint(A[np.newaxis,:])\n#[[1 1 1]]\nprint(A[np.newaxis,:].shape)#newaxis增加维度\n#(1,3)\n\nprint(A[:,np.newaxis])\n'''\n[[1]\n [1]\n [1]]\n '''\nprint(A[:,np.newaxis].shape)\n#（3,1）\n```\n多矩阵合并\n```\nA = np.array([1,1,1])[:,np.newaxis]\nB = np.array([2,2,2])[:,np.newaxis]\nprint(np.concatenate((A,B,B,A),axis=0))#0表示上下合并\n'''\n[[1]\n [1]\n [1]\n [2]\n [2]\n [2]\n [2]\n [2]\n [2]\n [1]\n [1]\n [1]]\n '''\nprint(np.concatenate((A,B,B,A),axis=1))#1表示左右合并\n'''\n[[1 2 2 1]\n [1 2 2 1]\n [1 2 2 1]]\n '''\n```\n### 7.NumPy分割\n```\nA=np.arange(12).reshape((3,4))\nprint(A)\n'''\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n '''\nprint(np.split(A,3,axis=0))#横向分割成3部分 或者np.vsplit(A,3)\n#[array([[0, 1, 2, 3]]), array([[4, 5, 6, 7]]), array([[ 8,  9, 10, 11]])]\n\nprint(np.split(A,2,axis=1))#竖向分割成2部分 或者np.hsplit(A,2)\n'''\n[array([[0, 1],\n       [4, 5],\n       [8, 9]]), array([[ 2,  3],\n       [ 6,  7],\n       [10, 11]])]\n '''\n \nprint(np.array_split(A,3,axis=1))#不等量分割成3部分\n'''\n[array([[0, 1],\n       [4, 5],\n       [8, 9]]), array([[ 2],\n       [ 6],\n       [10]]), array([[ 3],\n       [ 7],\n       [11]])]\n'''  \n```\n### 8.NumPy中copy和deep copy\n'='赋值方式会带有关联性\n```\na=np.arange(4)\nprint(a)\n#[1 2 3 4]\nb=a\nc=a\nd=b\nprint(b is a)\n#True\nprint(c is a)\n#True\nprint(d is a)\n#True\n\nb[0]=5#改变b的值，a,c,d同样会进行改变\nprint(a)\n#[5 2 3 4]\n```\n'copy()'赋值方式没有关联性\n```\na=np.arange(4)#deep copy\nprint(a)\n#[0 1 2 3]\nb=a.copy()\na[0]=5\nprint(b)#值并不发生改变\n#[0 1 2 3]\n```\n----------\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。如果感觉不错的话，可以资助1元钱当作鼓励，Thank you谢谢!\n<img src=\"http://img.blog.csdn.net/20180309135000807?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width = \"400\" height = \"400\" alt=\"公众号\" align=center/> <img src=\"http://img.blog.csdn.net/20180308203132669?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width = \"400\" height = \"400\" alt=\"赞赏码\" align=center/>","slug":"Python之NumPy使用教程","published":1,"updated":"2018-03-14T03:16:53.604Z","layout":"post","photos":[],"link":"","_id":"cjg7s0ppr000232011xydtxw6","content":"<h3 id=\"1-NumPy概述\"><a href=\"#1-NumPy概述\" class=\"headerlink\" title=\"1.NumPy概述\"></a>1.NumPy概述</h3><p>NumPy(Numerical Python)是用Python进行科学计算的基础软件包。包含以下特点：</p>\n<ol>\n<li>强大的N维数组对象Array</li>\n<li>成熟的函数库</li>\n<li>用于集成C/C++和Fortran代码的工具</li>\n<li>实用的线性代数、傅立叶变换和随机生成函数</li>\n</ol>\n<h3 id=\"2-NumPy安装\"><a href=\"#2-NumPy安装\" class=\"headerlink\" title=\"2.NumPy安装\"></a>2.NumPy安装</h3><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip <span class=\"keyword\">install</span> numpy或pip3 <span class=\"keyword\">install</span> numpy</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-NumPy引入\"><a href=\"#3-NumPy引入\" class=\"headerlink\" title=\"3.NumPy引入\"></a>3.NumPy引入</h3><figure class=\"highlight capnproto\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np<span class=\"comment\">#为了方便实用numpy 采用np简写</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-NumPy方法\"><a href=\"#4-NumPy方法\" class=\"headerlink\" title=\"4.NumPy方法\"></a>4.NumPy方法</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array=np.array([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])#将列表转换为矩阵 并转换为int类型</span><br><span class=\"line\">print(array)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br><span class=\"line\"> [<span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span>]]</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure>\n<h4 id=\"4-1NumPy属性\"><a href=\"#4-1NumPy属性\" class=\"headerlink\" title=\"4.1NumPy属性\"></a>4.1NumPy属性</h4><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(<span class=\"string\">'array of dim:'</span>,array.ndim)</span></span>#矩阵的维度</span><br><span class=\"line\"><span class=\"selector-id\">#array</span> of dim:<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(<span class=\"string\">'array of shape'</span>,array.shape)</span></span>#矩阵的行数和列数</span><br><span class=\"line\"><span class=\"selector-id\">#array</span> of shape:(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(<span class=\"string\">'number of size:'</span>,array.size)</span></span>#元素的个数</span><br><span class=\"line\"><span class=\"selector-id\">#number</span> of size:<span class=\"number\">6</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"4-2NumPy创建Array\"><a href=\"#4-2NumPy创建Array\" class=\"headerlink\" title=\"4.2NumPy创建Array\"></a>4.2NumPy创建Array</h4><ul>\n<li>array:创建数组</li>\n<li>dtype:指定数据类型</li>\n<li>zeros:创建数据全为0</li>\n<li>ones:创建数据全为1</li>\n<li>empty:创建数据接近0</li>\n<li>arange:指定范围内创建数据</li>\n<li>linspace创建线段</li>\n</ul>\n<p>创建数组<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">#[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure></p>\n<p>指定数据dtype<br><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">a</span>=np.array([1,2,3],<span class=\"attribute\">dtype</span>=np.int)#指定为int类型</span><br><span class=\"line\"><span class=\"builtin-name\">print</span>(a.dtype)</span><br><span class=\"line\"><span class=\"comment\">#int 64</span></span><br><span class=\"line\"><span class=\"attribute\">b</span>=np.array([1,2,3],<span class=\"attribute\">dtype</span>=np.float)#指定为float类型</span><br><span class=\"line\"><span class=\"builtin-name\">print</span>(b.dtype)</span><br><span class=\"line\"><span class=\"comment\">#float 64</span></span><br></pre></td></tr></table></figure></p>\n<p>创建特定数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])#矩阵 <span class=\"number\">2</span>行<span class=\"number\">3</span>列</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br><span class=\"line\"> [<span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span>]]</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>创建全0数组<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.zeros((<span class=\"number\">2</span>,<span class=\"number\">3</span>))<span class=\"comment\">#数据全0 2行3列</span></span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[0 0 0]</span></span><br><span class=\"line\"><span class=\"string\"> [0 0 0]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>创建全1数组 指定特定类型dtype<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.zeros((<span class=\"number\">2</span>,<span class=\"number\">3</span>),dtype=np.int)<span class=\"comment\">#数据全1 2行3列 同时指定类型</span></span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1 1 1]</span></span><br><span class=\"line\"><span class=\"string\"> [1 1 1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>创建全空数组 每个值接近0<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.empty(<span class=\"number\">2</span>,<span class=\"number\">3</span>)<span class=\"comment\">#数据全为empty 3行4列</span></span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[  0.00000000e+000   0.00000000e+000   2.12704693e-314]</span></span><br><span class=\"line\"><span class=\"string\"> [  2.12706024e-314   2.12706024e-314   2.12706024e-314]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>用array创建连续数组<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">1</span>,<span class=\"number\">10</span>,<span class=\"number\">2</span>)#<span class=\"number\">1</span>到<span class=\"number\">10</span>的数据 <span class=\"number\">2</span>步长</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">#[<span class=\"number\">1</span> <span class=\"number\">3</span> <span class=\"number\">5</span> <span class=\"number\">7</span> <span class=\"number\">9</span>]</span><br></pre></td></tr></table></figure></p>\n<p>用reshape改变数据形状<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">6</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[0 1 2]</span></span><br><span class=\"line\"><span class=\"string\"> [3 4 5]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>用linspace创建线段形数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.linspace(<span class=\"number\">1</span>,<span class=\"number\">10</span>,<span class=\"number\">20</span>)#开始端<span class=\"number\">1</span> 结束端<span class=\"number\">5</span> 分割成<span class=\"number\">10</span>个数据 生成线段</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[ <span class=\"number\">1.</span>          <span class=\"number\">1.44444444</span>  <span class=\"number\">1.88888889</span>  <span class=\"number\">2.33333333</span>  <span class=\"number\">2.77777778</span>  <span class=\"number\">3.22222222</span></span><br><span class=\"line\">  <span class=\"number\">3.66666667</span>  <span class=\"number\">4.11111111</span>  <span class=\"number\">4.55555556</span>  <span class=\"number\">5.</span>        ]</span><br><span class=\"line\">  '''</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"4-3NumPy基础运算\"><a href=\"#4-3NumPy基础运算\" class=\"headerlink\" title=\"4.3NumPy基础运算\"></a>4.3NumPy基础运算</h4><p>基础运算之加、减、三角函数等<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>,<span class=\"number\">40</span>])</span><br><span class=\"line\">b=np.arange(<span class=\"number\">4</span>) #array[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">c=a+b#加法运算</span><br><span class=\"line\">print(c)</span><br><span class=\"line\">#[<span class=\"number\">10</span>,<span class=\"number\">21</span>,<span class=\"number\">32</span>,<span class=\"number\">43</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">c=a-b#减法运算</span><br><span class=\"line\">print(c)</span><br><span class=\"line\">#[<span class=\"number\">10.19</span>,<span class=\"number\">28</span>,<span class=\"number\">37</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">c=<span class=\"number\">10</span>*np.sin(a)#三角函数运算</span><br><span class=\"line\">#[<span class=\"number\">-5.44021111</span>,  <span class=\"number\">9.12945251</span>, <span class=\"number\">-9.88031624</span>,  <span class=\"number\">7.4511316</span> ]</span><br><span class=\"line\"></span><br><span class=\"line\">print(b&lt;<span class=\"number\">3</span>)#逻辑判断</span><br><span class=\"line\">#[ True  True  True False]</span><br><span class=\"line\"></span><br><span class=\"line\">d=np.random.random((<span class=\"number\">2</span>,<span class=\"number\">3</span>))#随机生成<span class=\"number\">2</span>行<span class=\"number\">3</span>列的矩阵</span><br><span class=\"line\">print(d)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[ <span class=\"number\">0.21116981</span>  <span class=\"number\">0.0804489</span>   <span class=\"number\">0.51855475</span>]</span><br><span class=\"line\"> [ <span class=\"number\">0.38359164</span>  <span class=\"number\">0.55852973</span>  <span class=\"number\">0.73218811</span>]]</span><br><span class=\"line\">'''</span><br><span class=\"line\">print(np.sum(d))#元素求和</span><br><span class=\"line\">#<span class=\"number\">2.48448292958</span></span><br><span class=\"line\">print(np.max(d))#元素求最大值</span><br><span class=\"line\">#<span class=\"number\">0.732188108709</span></span><br><span class=\"line\">print(np.min(d))#元素求最小值</span><br><span class=\"line\">#<span class=\"number\">0.0804488978886</span></span><br></pre></td></tr></table></figure></p>\n<p>多维矩阵运算<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([[<span class=\"number\">1</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>]])</span><br><span class=\"line\">b=np.arange(<span class=\"number\">4</span>).reshape((<span class=\"number\">2</span>,<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">c=np.dot(a,b)<span class=\"comment\">#或c=a.dot(b)矩阵运算</span></span><br><span class=\"line\">print(c)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[2 4]</span></span><br><span class=\"line\"><span class=\"string\"> [2 3]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>对行或列执行查找运算<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([[<span class=\"number\">1</span>,<span class=\"number\">2</span>],[<span class=\"number\">3</span>,<span class=\"number\">4</span>]])</span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1,2]</span></span><br><span class=\"line\"><span class=\"string\"> [3,4]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(np.max(a,axis=<span class=\"number\">0</span>))<span class=\"comment\">#axis=0时是对列进行操作</span></span><br><span class=\"line\"><span class=\"comment\">#[3,4]</span></span><br><span class=\"line\">print(np.min(a,axis=<span class=\"number\">1</span>))<span class=\"comment\">#axis=1是对行进行操作</span></span><br><span class=\"line\"><span class=\"comment\">#[1,3]</span></span><br></pre></td></tr></table></figure></p>\n<p>矩阵索引操作<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">2</span>,<span class=\"number\">14</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\"> [<span class=\"number\">6</span>,<span class=\"number\">7</span>,<span class=\"number\">8</span>,<span class=\"number\">9</span>]</span><br><span class=\"line\"> [<span class=\"number\">10</span>,<span class=\"number\">11</span>,<span class=\"number\">12</span>,<span class=\"number\">13</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.argmax(A))#矩阵中最大元素的索引</span><br><span class=\"line\">#<span class=\"number\">11</span></span><br><span class=\"line\">print(np.argmin(A))#矩阵中最小元素的索引</span><br><span class=\"line\">#<span class=\"number\">0</span></span><br><span class=\"line\">print(np.mean(A))#或者np.average(A)求解矩阵均值</span><br><span class=\"line\">#<span class=\"number\">7.5</span></span><br><span class=\"line\">print(np.cumsum(A))#矩阵累加函数</span><br><span class=\"line\">#[<span class=\"number\">2</span> <span class=\"number\">5</span> <span class=\"number\">9</span> <span class=\"number\">14</span> <span class=\"number\">20</span> <span class=\"number\">27</span> <span class=\"number\">35</span> <span class=\"number\">44</span> <span class=\"number\">54</span> <span class=\"number\">65</span> <span class=\"number\">77</span> <span class=\"number\">90</span>]</span><br><span class=\"line\">print(np.diff(A))#矩阵累差函数</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]</span><br><span class=\"line\"> [<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]</span><br><span class=\"line\"> [<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.nonzero(A))#将非<span class=\"number\">0</span>元素的行与列坐标分割开来</span><br><span class=\"line\">#(array([<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>]), array([<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]))</span><br></pre></td></tr></table></figure></p>\n<p>矩阵排序、转置、替换操作<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">14</span>,<span class=\"number\">2</span>,<span class=\"number\">-1</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">14</span> <span class=\"number\">13</span> <span class=\"number\">12</span> <span class=\"number\">11</span>]</span><br><span class=\"line\"> [<span class=\"number\">10</span>  <span class=\"number\">9</span>  <span class=\"number\">8</span>  <span class=\"number\">7</span>]</span><br><span class=\"line\"> [ <span class=\"number\">6</span>  <span class=\"number\">5</span>  <span class=\"number\">4</span>  <span class=\"number\">3</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.sort(A))#排序</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">11</span> <span class=\"number\">12</span> <span class=\"number\">13</span> <span class=\"number\">14</span>]</span><br><span class=\"line\"> [ <span class=\"number\">7</span>  <span class=\"number\">8</span>  <span class=\"number\">9</span> <span class=\"number\">10</span>]</span><br><span class=\"line\"> [ <span class=\"number\">3</span>  <span class=\"number\">4</span>  <span class=\"number\">5</span>  <span class=\"number\">6</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\"></span><br><span class=\"line\">print(np.transpose(A))</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">14</span> <span class=\"number\">10</span>  <span class=\"number\">6</span>]</span><br><span class=\"line\"> [<span class=\"number\">13</span>  <span class=\"number\">9</span>  <span class=\"number\">5</span>]</span><br><span class=\"line\"> [<span class=\"number\">12</span>  <span class=\"number\">8</span>  <span class=\"number\">4</span>]</span><br><span class=\"line\"> [<span class=\"number\">11</span>  <span class=\"number\">7</span>  <span class=\"number\">3</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\"></span><br><span class=\"line\">print(np.clip(A,<span class=\"number\">5</span>,<span class=\"number\">9</span>))#替换 判断当前矩阵元素是否比最小值小或比最大值大 若是则替换</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">9</span> <span class=\"number\">9</span> <span class=\"number\">9</span> <span class=\"number\">9</span>]</span><br><span class=\"line\"> [<span class=\"number\">9</span> <span class=\"number\">9</span> <span class=\"number\">8</span> <span class=\"number\">7</span>]</span><br><span class=\"line\"> [<span class=\"number\">6</span> <span class=\"number\">5</span> <span class=\"number\">5</span> <span class=\"number\">5</span>]]</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"5-索引\"><a href=\"#5-索引\" class=\"headerlink\" title=\"5.索引\"></a>5.索引</h3><p>一维索引<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">0</span>,<span class=\"number\">12</span>)</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">#[ <span class=\"number\">0</span>  <span class=\"number\">1</span>  <span class=\"number\">2</span>  <span class=\"number\">3</span>  <span class=\"number\">4</span>  <span class=\"number\">5</span>  <span class=\"number\">6</span>  <span class=\"number\">7</span>  <span class=\"number\">8</span>  <span class=\"number\">9</span> <span class=\"number\">10</span> <span class=\"number\">11</span>]</span><br><span class=\"line\">print(A[<span class=\"number\">1</span>])#一维索引</span><br><span class=\"line\">#<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">A=np.arange(<span class=\"number\">0</span>,<span class=\"number\">12</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A[<span class=\"number\">0</span>])</span><br><span class=\"line\">#[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure></p>\n<p>二维索引<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">0</span>,<span class=\"number\">12</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[ 0  1  2  3]</span></span><br><span class=\"line\"><span class=\"string\"> [ 4  5  6  7]</span></span><br><span class=\"line\"><span class=\"string\"> [ 8  9 10 11]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(A[<span class=\"number\">1</span>][<span class=\"number\">1</span>])<span class=\"comment\">#或者A[1,1]</span></span><br><span class=\"line\"><span class=\"comment\">#5</span></span><br><span class=\"line\">print(A[<span class=\"number\">1</span>,<span class=\"number\">1</span>:<span class=\"number\">3</span>])<span class=\"comment\">#切片处理</span></span><br><span class=\"line\"><span class=\"comment\">#[5,6]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> A:</span><br><span class=\"line\">    print(A)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[0 1 2 3]</span></span><br><span class=\"line\"><span class=\"string\">[4 5 6 7]</span></span><br><span class=\"line\"><span class=\"string\">[ 8  9 10 11]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> A:</span><br><span class=\"line\">    print(col)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[0 4 8]</span></span><br><span class=\"line\"><span class=\"string\">[1 5 9]</span></span><br><span class=\"line\"><span class=\"string\">[ 2  6 10]</span></span><br><span class=\"line\"><span class=\"string\">[ 3  7 11]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> A.flat:</span><br><span class=\"line\">    print(item)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">0</span></span><br><span class=\"line\"><span class=\"string\">1</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"string\">10</span></span><br><span class=\"line\"><span class=\"string\">11</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"6-NumPy之Array合并\"><a href=\"#6-NumPy之Array合并\" class=\"headerlink\" title=\"6.NumPy之Array合并\"></a>6.NumPy之Array合并</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.array([<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\">B=np.array([<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>])</span><br><span class=\"line\">print(np.vstack((A,B)))#上下合并</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]</span><br><span class=\"line\"> [<span class=\"number\">2</span> <span class=\"number\">2</span> <span class=\"number\">2</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.hstack((A,B)))#左右合并</span><br><span class=\"line\">#[<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">2</span> <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n<p>增加维度<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.array([<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\">print(A.shape)</span><br><span class=\"line\"><span class=\"comment\">#(3,)</span></span><br><span class=\"line\">print(A[np.newaxis,:])</span><br><span class=\"line\"><span class=\"comment\">#[[1 1 1]]</span></span><br><span class=\"line\">print(A[np.newaxis,:].shape)<span class=\"comment\">#newaxis增加维度</span></span><br><span class=\"line\"><span class=\"comment\">#(1,3)</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(A[:,np.newaxis])</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(A[:,np.newaxis].shape)</span><br><span class=\"line\"><span class=\"comment\">#（3,1）</span></span><br></pre></td></tr></table></figure></p>\n<p>多矩阵合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A = np.array([<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>])[:,np.newaxis]</span><br><span class=\"line\">B = np.array([<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>])[:,np.newaxis]</span><br><span class=\"line\">print(np.concatenate((A,B,B,A),axis=<span class=\"number\">0</span>))<span class=\"comment\">#0表示上下合并</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(np.concatenate((A,B,B,A),axis=<span class=\"number\">1</span>))<span class=\"comment\">#1表示左右合并</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1 2 2 1]</span></span><br><span class=\"line\"><span class=\"string\"> [1 2 2 1]</span></span><br><span class=\"line\"><span class=\"string\"> [1 2 2 1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"7-NumPy分割\"><a href=\"#7-NumPy分割\" class=\"headerlink\" title=\"7.NumPy分割\"></a>7.NumPy分割</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">12</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[ <span class=\"number\">0</span>  <span class=\"number\">1</span>  <span class=\"number\">2</span>  <span class=\"number\">3</span>]</span><br><span class=\"line\"> [ <span class=\"number\">4</span>  <span class=\"number\">5</span>  <span class=\"number\">6</span>  <span class=\"number\">7</span>]</span><br><span class=\"line\"> [ <span class=\"number\">8</span>  <span class=\"number\">9</span> <span class=\"number\">10</span> <span class=\"number\">11</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.split(A,<span class=\"number\">3</span>,axis=<span class=\"number\">0</span>))#横向分割成<span class=\"number\">3</span>部分 或者np.vsplit(A,<span class=\"number\">3</span>)</span><br><span class=\"line\">#[array([[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]]), array([[<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>]]), array([[ <span class=\"number\">8</span>,  <span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>]])]</span><br><span class=\"line\"></span><br><span class=\"line\">print(np.split(A,<span class=\"number\">2</span>,axis=<span class=\"number\">1</span>))#竖向分割成<span class=\"number\">2</span>部分 或者np.hsplit(A,<span class=\"number\">2</span>)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[array([[<span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">       [<span class=\"number\">4</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">       [<span class=\"number\">8</span>, <span class=\"number\">9</span>]]), array([[ <span class=\"number\">2</span>,  <span class=\"number\">3</span>],</span><br><span class=\"line\">       [ <span class=\"number\">6</span>,  <span class=\"number\">7</span>],</span><br><span class=\"line\">       [<span class=\"number\">10</span>, <span class=\"number\">11</span>]])]</span><br><span class=\"line\"> '''</span><br><span class=\"line\"> </span><br><span class=\"line\">print(np.array_split(A,<span class=\"number\">3</span>,axis=<span class=\"number\">1</span>))#不等量分割成<span class=\"number\">3</span>部分</span><br><span class=\"line\">'''</span><br><span class=\"line\">[array([[<span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">       [<span class=\"number\">4</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">       [<span class=\"number\">8</span>, <span class=\"number\">9</span>]]), array([[ <span class=\"number\">2</span>],</span><br><span class=\"line\">       [ <span class=\"number\">6</span>],</span><br><span class=\"line\">       [<span class=\"number\">10</span>]]), array([[ <span class=\"number\">3</span>],</span><br><span class=\"line\">       [ <span class=\"number\">7</span>],</span><br><span class=\"line\">       [<span class=\"number\">11</span>]])]</span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure>\n<h3 id=\"8-NumPy中copy和deep-copy\"><a href=\"#8-NumPy中copy和deep-copy\" class=\"headerlink\" title=\"8.NumPy中copy和deep copy\"></a>8.NumPy中copy和deep copy</h3><p>‘=’赋值方式会带有关联性<br><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(a)</span></span></span><br><span class=\"line\">#[<span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span>]</span><br><span class=\"line\">b=a</span><br><span class=\"line\">c=a</span><br><span class=\"line\">d=b</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(b is a)</span></span></span><br><span class=\"line\">#True</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(c is a)</span></span></span><br><span class=\"line\">#True</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(d is a)</span></span></span><br><span class=\"line\">#True</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"selector-tag\">b</span>[<span class=\"number\">0</span>]=<span class=\"number\">5</span>#改变b的值，<span class=\"selector-tag\">a</span>,c,d同样会进行改变</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(a)</span></span></span><br><span class=\"line\">#[<span class=\"number\">5</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span>]</span><br></pre></td></tr></table></figure></p>\n<p>‘copy()’赋值方式没有关联性<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">4</span>)#deep copy</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">#[<span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br><span class=\"line\">b=a.copy()</span><br><span class=\"line\">a[<span class=\"number\">0</span>]=<span class=\"number\">5</span></span><br><span class=\"line\">print(b)#值并不发生改变</span><br><span class=\"line\">#[<span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。如果感觉不错的话，可以资助1元钱当作鼓励，Thank you谢谢!<br><img src=\"http://img.blog.csdn.net/20180309135000807?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width=\"400\" height=\"400\" alt=\"公众号\" align=\"center/\"> <img src=\"http://img.blog.csdn.net/20180308203132669?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width=\"400\" height=\"400\" alt=\"赞赏码\" align=\"center/\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-NumPy概述\"><a href=\"#1-NumPy概述\" class=\"headerlink\" title=\"1.NumPy概述\"></a>1.NumPy概述</h3><p>NumPy(Numerical Python)是用Python进行科学计算的基础软件包。包含以下特点：</p>\n<ol>\n<li>强大的N维数组对象Array</li>\n<li>成熟的函数库</li>\n<li>用于集成C/C++和Fortran代码的工具</li>\n<li>实用的线性代数、傅立叶变换和随机生成函数</li>\n</ol>\n<h3 id=\"2-NumPy安装\"><a href=\"#2-NumPy安装\" class=\"headerlink\" title=\"2.NumPy安装\"></a>2.NumPy安装</h3><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip <span class=\"keyword\">install</span> numpy或pip3 <span class=\"keyword\">install</span> numpy</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-NumPy引入\"><a href=\"#3-NumPy引入\" class=\"headerlink\" title=\"3.NumPy引入\"></a>3.NumPy引入</h3><figure class=\"highlight capnproto\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np<span class=\"comment\">#为了方便实用numpy 采用np简写</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-NumPy方法\"><a href=\"#4-NumPy方法\" class=\"headerlink\" title=\"4.NumPy方法\"></a>4.NumPy方法</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">array=np.array([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])#将列表转换为矩阵 并转换为int类型</span><br><span class=\"line\">print(array)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br><span class=\"line\"> [<span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span>]]</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure>\n<h4 id=\"4-1NumPy属性\"><a href=\"#4-1NumPy属性\" class=\"headerlink\" title=\"4.1NumPy属性\"></a>4.1NumPy属性</h4><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(<span class=\"string\">'array of dim:'</span>,array.ndim)</span></span>#矩阵的维度</span><br><span class=\"line\"><span class=\"selector-id\">#array</span> of dim:<span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(<span class=\"string\">'array of shape'</span>,array.shape)</span></span>#矩阵的行数和列数</span><br><span class=\"line\"><span class=\"selector-id\">#array</span> of shape:(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(<span class=\"string\">'number of size:'</span>,array.size)</span></span>#元素的个数</span><br><span class=\"line\"><span class=\"selector-id\">#number</span> of size:<span class=\"number\">6</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"4-2NumPy创建Array\"><a href=\"#4-2NumPy创建Array\" class=\"headerlink\" title=\"4.2NumPy创建Array\"></a>4.2NumPy创建Array</h4><ul>\n<li>array:创建数组</li>\n<li>dtype:指定数据类型</li>\n<li>zeros:创建数据全为0</li>\n<li>ones:创建数据全为1</li>\n<li>empty:创建数据接近0</li>\n<li>arange:指定范围内创建数据</li>\n<li>linspace创建线段</li>\n</ul>\n<p>创建数组<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">#[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure></p>\n<p>指定数据dtype<br><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">a</span>=np.array([1,2,3],<span class=\"attribute\">dtype</span>=np.int)#指定为int类型</span><br><span class=\"line\"><span class=\"builtin-name\">print</span>(a.dtype)</span><br><span class=\"line\"><span class=\"comment\">#int 64</span></span><br><span class=\"line\"><span class=\"attribute\">b</span>=np.array([1,2,3],<span class=\"attribute\">dtype</span>=np.float)#指定为float类型</span><br><span class=\"line\"><span class=\"builtin-name\">print</span>(b.dtype)</span><br><span class=\"line\"><span class=\"comment\">#float 64</span></span><br></pre></td></tr></table></figure></p>\n<p>创建特定数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>],[<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>]])#矩阵 <span class=\"number\">2</span>行<span class=\"number\">3</span>列</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br><span class=\"line\"> [<span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span>]]</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>创建全0数组<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.zeros((<span class=\"number\">2</span>,<span class=\"number\">3</span>))<span class=\"comment\">#数据全0 2行3列</span></span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[0 0 0]</span></span><br><span class=\"line\"><span class=\"string\"> [0 0 0]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>创建全1数组 指定特定类型dtype<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.zeros((<span class=\"number\">2</span>,<span class=\"number\">3</span>),dtype=np.int)<span class=\"comment\">#数据全1 2行3列 同时指定类型</span></span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1 1 1]</span></span><br><span class=\"line\"><span class=\"string\"> [1 1 1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>创建全空数组 每个值接近0<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.empty(<span class=\"number\">2</span>,<span class=\"number\">3</span>)<span class=\"comment\">#数据全为empty 3行4列</span></span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[  0.00000000e+000   0.00000000e+000   2.12704693e-314]</span></span><br><span class=\"line\"><span class=\"string\"> [  2.12706024e-314   2.12706024e-314   2.12706024e-314]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>用array创建连续数组<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">1</span>,<span class=\"number\">10</span>,<span class=\"number\">2</span>)#<span class=\"number\">1</span>到<span class=\"number\">10</span>的数据 <span class=\"number\">2</span>步长</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">#[<span class=\"number\">1</span> <span class=\"number\">3</span> <span class=\"number\">5</span> <span class=\"number\">7</span> <span class=\"number\">9</span>]</span><br></pre></td></tr></table></figure></p>\n<p>用reshape改变数据形状<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">6</span>).reshape(<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[0 1 2]</span></span><br><span class=\"line\"><span class=\"string\"> [3 4 5]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>用linspace创建线段形数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.linspace(<span class=\"number\">1</span>,<span class=\"number\">10</span>,<span class=\"number\">20</span>)#开始端<span class=\"number\">1</span> 结束端<span class=\"number\">5</span> 分割成<span class=\"number\">10</span>个数据 生成线段</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[ <span class=\"number\">1.</span>          <span class=\"number\">1.44444444</span>  <span class=\"number\">1.88888889</span>  <span class=\"number\">2.33333333</span>  <span class=\"number\">2.77777778</span>  <span class=\"number\">3.22222222</span></span><br><span class=\"line\">  <span class=\"number\">3.66666667</span>  <span class=\"number\">4.11111111</span>  <span class=\"number\">4.55555556</span>  <span class=\"number\">5.</span>        ]</span><br><span class=\"line\">  '''</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"4-3NumPy基础运算\"><a href=\"#4-3NumPy基础运算\" class=\"headerlink\" title=\"4.3NumPy基础运算\"></a>4.3NumPy基础运算</h4><p>基础运算之加、减、三角函数等<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([<span class=\"number\">10</span>,<span class=\"number\">20</span>,<span class=\"number\">30</span>,<span class=\"number\">40</span>])</span><br><span class=\"line\">b=np.arange(<span class=\"number\">4</span>) #array[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">c=a+b#加法运算</span><br><span class=\"line\">print(c)</span><br><span class=\"line\">#[<span class=\"number\">10</span>,<span class=\"number\">21</span>,<span class=\"number\">32</span>,<span class=\"number\">43</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">c=a-b#减法运算</span><br><span class=\"line\">print(c)</span><br><span class=\"line\">#[<span class=\"number\">10.19</span>,<span class=\"number\">28</span>,<span class=\"number\">37</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">c=<span class=\"number\">10</span>*np.sin(a)#三角函数运算</span><br><span class=\"line\">#[<span class=\"number\">-5.44021111</span>,  <span class=\"number\">9.12945251</span>, <span class=\"number\">-9.88031624</span>,  <span class=\"number\">7.4511316</span> ]</span><br><span class=\"line\"></span><br><span class=\"line\">print(b&lt;<span class=\"number\">3</span>)#逻辑判断</span><br><span class=\"line\">#[ True  True  True False]</span><br><span class=\"line\"></span><br><span class=\"line\">d=np.random.random((<span class=\"number\">2</span>,<span class=\"number\">3</span>))#随机生成<span class=\"number\">2</span>行<span class=\"number\">3</span>列的矩阵</span><br><span class=\"line\">print(d)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[ <span class=\"number\">0.21116981</span>  <span class=\"number\">0.0804489</span>   <span class=\"number\">0.51855475</span>]</span><br><span class=\"line\"> [ <span class=\"number\">0.38359164</span>  <span class=\"number\">0.55852973</span>  <span class=\"number\">0.73218811</span>]]</span><br><span class=\"line\">'''</span><br><span class=\"line\">print(np.sum(d))#元素求和</span><br><span class=\"line\">#<span class=\"number\">2.48448292958</span></span><br><span class=\"line\">print(np.max(d))#元素求最大值</span><br><span class=\"line\">#<span class=\"number\">0.732188108709</span></span><br><span class=\"line\">print(np.min(d))#元素求最小值</span><br><span class=\"line\">#<span class=\"number\">0.0804488978886</span></span><br></pre></td></tr></table></figure></p>\n<p>多维矩阵运算<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([[<span class=\"number\">1</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>]])</span><br><span class=\"line\">b=np.arange(<span class=\"number\">4</span>).reshape((<span class=\"number\">2</span>,<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">c=np.dot(a,b)<span class=\"comment\">#或c=a.dot(b)矩阵运算</span></span><br><span class=\"line\">print(c)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[2 4]</span></span><br><span class=\"line\"><span class=\"string\"> [2 3]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>对行或列执行查找运算<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.array([[<span class=\"number\">1</span>,<span class=\"number\">2</span>],[<span class=\"number\">3</span>,<span class=\"number\">4</span>]])</span><br><span class=\"line\">print(a)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1,2]</span></span><br><span class=\"line\"><span class=\"string\"> [3,4]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(np.max(a,axis=<span class=\"number\">0</span>))<span class=\"comment\">#axis=0时是对列进行操作</span></span><br><span class=\"line\"><span class=\"comment\">#[3,4]</span></span><br><span class=\"line\">print(np.min(a,axis=<span class=\"number\">1</span>))<span class=\"comment\">#axis=1是对行进行操作</span></span><br><span class=\"line\"><span class=\"comment\">#[1,3]</span></span><br></pre></td></tr></table></figure></p>\n<p>矩阵索引操作<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">2</span>,<span class=\"number\">14</span>).reshape(<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>]</span><br><span class=\"line\"> [<span class=\"number\">6</span>,<span class=\"number\">7</span>,<span class=\"number\">8</span>,<span class=\"number\">9</span>]</span><br><span class=\"line\"> [<span class=\"number\">10</span>,<span class=\"number\">11</span>,<span class=\"number\">12</span>,<span class=\"number\">13</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.argmax(A))#矩阵中最大元素的索引</span><br><span class=\"line\">#<span class=\"number\">11</span></span><br><span class=\"line\">print(np.argmin(A))#矩阵中最小元素的索引</span><br><span class=\"line\">#<span class=\"number\">0</span></span><br><span class=\"line\">print(np.mean(A))#或者np.average(A)求解矩阵均值</span><br><span class=\"line\">#<span class=\"number\">7.5</span></span><br><span class=\"line\">print(np.cumsum(A))#矩阵累加函数</span><br><span class=\"line\">#[<span class=\"number\">2</span> <span class=\"number\">5</span> <span class=\"number\">9</span> <span class=\"number\">14</span> <span class=\"number\">20</span> <span class=\"number\">27</span> <span class=\"number\">35</span> <span class=\"number\">44</span> <span class=\"number\">54</span> <span class=\"number\">65</span> <span class=\"number\">77</span> <span class=\"number\">90</span>]</span><br><span class=\"line\">print(np.diff(A))#矩阵累差函数</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]</span><br><span class=\"line\"> [<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]</span><br><span class=\"line\"> [<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.nonzero(A))#将非<span class=\"number\">0</span>元素的行与列坐标分割开来</span><br><span class=\"line\">#(array([<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>]), array([<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]))</span><br></pre></td></tr></table></figure></p>\n<p>矩阵排序、转置、替换操作<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">14</span>,<span class=\"number\">2</span>,<span class=\"number\">-1</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">14</span> <span class=\"number\">13</span> <span class=\"number\">12</span> <span class=\"number\">11</span>]</span><br><span class=\"line\"> [<span class=\"number\">10</span>  <span class=\"number\">9</span>  <span class=\"number\">8</span>  <span class=\"number\">7</span>]</span><br><span class=\"line\"> [ <span class=\"number\">6</span>  <span class=\"number\">5</span>  <span class=\"number\">4</span>  <span class=\"number\">3</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.sort(A))#排序</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">11</span> <span class=\"number\">12</span> <span class=\"number\">13</span> <span class=\"number\">14</span>]</span><br><span class=\"line\"> [ <span class=\"number\">7</span>  <span class=\"number\">8</span>  <span class=\"number\">9</span> <span class=\"number\">10</span>]</span><br><span class=\"line\"> [ <span class=\"number\">3</span>  <span class=\"number\">4</span>  <span class=\"number\">5</span>  <span class=\"number\">6</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\"></span><br><span class=\"line\">print(np.transpose(A))</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">14</span> <span class=\"number\">10</span>  <span class=\"number\">6</span>]</span><br><span class=\"line\"> [<span class=\"number\">13</span>  <span class=\"number\">9</span>  <span class=\"number\">5</span>]</span><br><span class=\"line\"> [<span class=\"number\">12</span>  <span class=\"number\">8</span>  <span class=\"number\">4</span>]</span><br><span class=\"line\"> [<span class=\"number\">11</span>  <span class=\"number\">7</span>  <span class=\"number\">3</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\"></span><br><span class=\"line\">print(np.clip(A,<span class=\"number\">5</span>,<span class=\"number\">9</span>))#替换 判断当前矩阵元素是否比最小值小或比最大值大 若是则替换</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">9</span> <span class=\"number\">9</span> <span class=\"number\">9</span> <span class=\"number\">9</span>]</span><br><span class=\"line\"> [<span class=\"number\">9</span> <span class=\"number\">9</span> <span class=\"number\">8</span> <span class=\"number\">7</span>]</span><br><span class=\"line\"> [<span class=\"number\">6</span> <span class=\"number\">5</span> <span class=\"number\">5</span> <span class=\"number\">5</span>]]</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"5-索引\"><a href=\"#5-索引\" class=\"headerlink\" title=\"5.索引\"></a>5.索引</h3><p>一维索引<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">0</span>,<span class=\"number\">12</span>)</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">#[ <span class=\"number\">0</span>  <span class=\"number\">1</span>  <span class=\"number\">2</span>  <span class=\"number\">3</span>  <span class=\"number\">4</span>  <span class=\"number\">5</span>  <span class=\"number\">6</span>  <span class=\"number\">7</span>  <span class=\"number\">8</span>  <span class=\"number\">9</span> <span class=\"number\">10</span> <span class=\"number\">11</span>]</span><br><span class=\"line\">print(A[<span class=\"number\">1</span>])#一维索引</span><br><span class=\"line\">#<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">A=np.arange(<span class=\"number\">0</span>,<span class=\"number\">12</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A[<span class=\"number\">0</span>])</span><br><span class=\"line\">#[<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure></p>\n<p>二维索引<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">0</span>,<span class=\"number\">12</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[ 0  1  2  3]</span></span><br><span class=\"line\"><span class=\"string\"> [ 4  5  6  7]</span></span><br><span class=\"line\"><span class=\"string\"> [ 8  9 10 11]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(A[<span class=\"number\">1</span>][<span class=\"number\">1</span>])<span class=\"comment\">#或者A[1,1]</span></span><br><span class=\"line\"><span class=\"comment\">#5</span></span><br><span class=\"line\">print(A[<span class=\"number\">1</span>,<span class=\"number\">1</span>:<span class=\"number\">3</span>])<span class=\"comment\">#切片处理</span></span><br><span class=\"line\"><span class=\"comment\">#[5,6]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> A:</span><br><span class=\"line\">    print(A)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[0 1 2 3]</span></span><br><span class=\"line\"><span class=\"string\">[4 5 6 7]</span></span><br><span class=\"line\"><span class=\"string\">[ 8  9 10 11]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> col <span class=\"keyword\">in</span> A:</span><br><span class=\"line\">    print(col)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[0 4 8]</span></span><br><span class=\"line\"><span class=\"string\">[1 5 9]</span></span><br><span class=\"line\"><span class=\"string\">[ 2  6 10]</span></span><br><span class=\"line\"><span class=\"string\">[ 3  7 11]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> A.flat:</span><br><span class=\"line\">    print(item)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">0</span></span><br><span class=\"line\"><span class=\"string\">1</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"string\">10</span></span><br><span class=\"line\"><span class=\"string\">11</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"6-NumPy之Array合并\"><a href=\"#6-NumPy之Array合并\" class=\"headerlink\" title=\"6.NumPy之Array合并\"></a>6.NumPy之Array合并</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.array([<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\">B=np.array([<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>])</span><br><span class=\"line\">print(np.vstack((A,B)))#上下合并</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span>]</span><br><span class=\"line\"> [<span class=\"number\">2</span> <span class=\"number\">2</span> <span class=\"number\">2</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.hstack((A,B)))#左右合并</span><br><span class=\"line\">#[<span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">2</span> <span class=\"number\">2</span>]</span><br></pre></td></tr></table></figure>\n<p>增加维度<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.array([<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>])</span><br><span class=\"line\">print(A.shape)</span><br><span class=\"line\"><span class=\"comment\">#(3,)</span></span><br><span class=\"line\">print(A[np.newaxis,:])</span><br><span class=\"line\"><span class=\"comment\">#[[1 1 1]]</span></span><br><span class=\"line\">print(A[np.newaxis,:].shape)<span class=\"comment\">#newaxis增加维度</span></span><br><span class=\"line\"><span class=\"comment\">#(1,3)</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(A[:,np.newaxis])</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(A[:,np.newaxis].shape)</span><br><span class=\"line\"><span class=\"comment\">#（3,1）</span></span><br></pre></td></tr></table></figure></p>\n<p>多矩阵合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A = np.array([<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>])[:,np.newaxis]</span><br><span class=\"line\">B = np.array([<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>])[:,np.newaxis]</span><br><span class=\"line\">print(np.concatenate((A,B,B,A),axis=<span class=\"number\">0</span>))<span class=\"comment\">#0表示上下合并</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [2]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]</span></span><br><span class=\"line\"><span class=\"string\"> [1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(np.concatenate((A,B,B,A),axis=<span class=\"number\">1</span>))<span class=\"comment\">#1表示左右合并</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1 2 2 1]</span></span><br><span class=\"line\"><span class=\"string\"> [1 2 2 1]</span></span><br><span class=\"line\"><span class=\"string\"> [1 2 2 1]]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"7-NumPy分割\"><a href=\"#7-NumPy分割\" class=\"headerlink\" title=\"7.NumPy分割\"></a>7.NumPy分割</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A=np.arange(<span class=\"number\">12</span>).reshape((<span class=\"number\">3</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">print(A)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[[ <span class=\"number\">0</span>  <span class=\"number\">1</span>  <span class=\"number\">2</span>  <span class=\"number\">3</span>]</span><br><span class=\"line\"> [ <span class=\"number\">4</span>  <span class=\"number\">5</span>  <span class=\"number\">6</span>  <span class=\"number\">7</span>]</span><br><span class=\"line\"> [ <span class=\"number\">8</span>  <span class=\"number\">9</span> <span class=\"number\">10</span> <span class=\"number\">11</span>]]</span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(np.split(A,<span class=\"number\">3</span>,axis=<span class=\"number\">0</span>))#横向分割成<span class=\"number\">3</span>部分 或者np.vsplit(A,<span class=\"number\">3</span>)</span><br><span class=\"line\">#[array([[<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>]]), array([[<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>, <span class=\"number\">7</span>]]), array([[ <span class=\"number\">8</span>,  <span class=\"number\">9</span>, <span class=\"number\">10</span>, <span class=\"number\">11</span>]])]</span><br><span class=\"line\"></span><br><span class=\"line\">print(np.split(A,<span class=\"number\">2</span>,axis=<span class=\"number\">1</span>))#竖向分割成<span class=\"number\">2</span>部分 或者np.hsplit(A,<span class=\"number\">2</span>)</span><br><span class=\"line\">'''</span><br><span class=\"line\">[array([[<span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">       [<span class=\"number\">4</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">       [<span class=\"number\">8</span>, <span class=\"number\">9</span>]]), array([[ <span class=\"number\">2</span>,  <span class=\"number\">3</span>],</span><br><span class=\"line\">       [ <span class=\"number\">6</span>,  <span class=\"number\">7</span>],</span><br><span class=\"line\">       [<span class=\"number\">10</span>, <span class=\"number\">11</span>]])]</span><br><span class=\"line\"> '''</span><br><span class=\"line\"> </span><br><span class=\"line\">print(np.array_split(A,<span class=\"number\">3</span>,axis=<span class=\"number\">1</span>))#不等量分割成<span class=\"number\">3</span>部分</span><br><span class=\"line\">'''</span><br><span class=\"line\">[array([[<span class=\"number\">0</span>, <span class=\"number\">1</span>],</span><br><span class=\"line\">       [<span class=\"number\">4</span>, <span class=\"number\">5</span>],</span><br><span class=\"line\">       [<span class=\"number\">8</span>, <span class=\"number\">9</span>]]), array([[ <span class=\"number\">2</span>],</span><br><span class=\"line\">       [ <span class=\"number\">6</span>],</span><br><span class=\"line\">       [<span class=\"number\">10</span>]]), array([[ <span class=\"number\">3</span>],</span><br><span class=\"line\">       [ <span class=\"number\">7</span>],</span><br><span class=\"line\">       [<span class=\"number\">11</span>]])]</span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure>\n<h3 id=\"8-NumPy中copy和deep-copy\"><a href=\"#8-NumPy中copy和deep-copy\" class=\"headerlink\" title=\"8.NumPy中copy和deep copy\"></a>8.NumPy中copy和deep copy</h3><p>‘=’赋值方式会带有关联性<br><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(a)</span></span></span><br><span class=\"line\">#[<span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span>]</span><br><span class=\"line\">b=a</span><br><span class=\"line\">c=a</span><br><span class=\"line\">d=b</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(b is a)</span></span></span><br><span class=\"line\">#True</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(c is a)</span></span></span><br><span class=\"line\">#True</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(d is a)</span></span></span><br><span class=\"line\">#True</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"selector-tag\">b</span>[<span class=\"number\">0</span>]=<span class=\"number\">5</span>#改变b的值，<span class=\"selector-tag\">a</span>,c,d同样会进行改变</span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">print</span><span class=\"params\">(a)</span></span></span><br><span class=\"line\">#[<span class=\"number\">5</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span>]</span><br></pre></td></tr></table></figure></p>\n<p>‘copy()’赋值方式没有关联性<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=np.arange(<span class=\"number\">4</span>)#deep copy</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">#[<span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br><span class=\"line\">b=a.copy()</span><br><span class=\"line\">a[<span class=\"number\">0</span>]=<span class=\"number\">5</span></span><br><span class=\"line\">print(b)#值并不发生改变</span><br><span class=\"line\">#[<span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span>]</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。如果感觉不错的话，可以资助1元钱当作鼓励，Thank you谢谢!<br><img src=\"http://img.blog.csdn.net/20180309135000807?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width=\"400\" height=\"400\" alt=\"公众号\" align=\"center/\"> <img src=\"http://img.blog.csdn.net/20180308203132669?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" width=\"400\" height=\"400\" alt=\"赞赏码\" align=\"center/\"></p>\n"},{"title":"Python之MatPlotLib使用教程","date":"2018-03-14T03:43:07.000Z","toc":true,"comments":1,"_content":"### 1.Matplotlib简介\n\n 1. Matplotlib是非常强大的python画图工具\n 2. Matplotlib可以画图线图、散点图、等高线图、条形图、柱形图、3D图形、图形动画等。 \n\n### 2.Matplotlib安装\n```\npip3 install matplotlib#python3\n```\n### 3.Matplotlib引入\n```\nimport matplotlib.pyplot as plt#为方便简介为plt\nimport numpy as np#画图过程中会使用numpy\nimport pandas as pd#画图过程中会使用pandas\n```\n### 4.Matplotlib基本应用\n```\nx=np.linspace(-1,1,50)#定义x数据范围\ny1=2*x+1#定义y数据范围\ny2=x**2\nplt.figure()#定义一个图像窗口\nplt.plot(x,y)#plot()画出曲线\nplt.show()#显示图像\n```\n![图片01](http://img.blog.csdn.net/20180311144537863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.1figure图像\nmatplotlib的figure为单独图像窗口，小窗口内还可以有更多的小图片。\n```\nx=np.linspace(-3,3,50)#50为生成的样本数\ny1=2*x+1\ny2=x**2\nplt.figure(num=1,figsize=(8,5))#定义编号为1 大小为(8,5)\nplt.plot(x,y1,color='red',linewidth=2,linestyle='--')#颜色为红色，线宽度为2，线风格为--\nplt.plot(x,y2)#进行画图\nplt.show()#显示图\n```\n![图片02](http://img.blog.csdn.net/20180311145427674?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.2设置坐标轴\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='-')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nplt.xlabel(\"I'm x\")\nplt.ylabel(\"I'm y\")\nplt.show()\n```\n![图片03](http://img.blog.csdn.net/20180311151115803?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n自定义坐标轴\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='-')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nplt.xlabel(\"I'm x\")\nplt.ylabel(\"I'm y\")\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nprint(new_ticks)\n#[-1.   -0.25  0.5   1.25  2.  ]\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\nplt.show()\n```\n![图片04](http://img.blog.csdn.net/2018031115185255?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n设置边框属性\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='--')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\nax=plt.gca()#gca=get current axis\nax.spines['right'].set_color('none')#边框属性设置为none 不显示\nax.spines['top'].set_color('none')\nplt.show()\n```\n![图片05](http://img.blog.csdn.net/20180311152822953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n调整移动坐标轴\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='--')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\nax=plt.gca()#gca=get current axis\nax.spines['right'].set_color('none')#边框属性设置为none 不显示\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')#使用xaxis.set_ticks_position设置x坐标刻度数字或名称的位置 所有属性为top、bottom、both、default、none\nax.spines['bottom'].set_position(('data', 0))#使用.spines设置边框x轴；使用.set_position设置边框位置，y=0位置 位置所有属性有outward、axes、data\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data',0))#坐标中心点在(0,0)位置\nplt.show()\n```\n![这里写图片描述](http://img.blog.csdn.net/20180311153109404?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.3添加图例\nmatplotlib中legend图例帮助我们展示数据对应的图像名称。\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\n\nl1,=plt.plot(x,y1,color='red',linewidth=2,linestyle='--',label='linear line')\nl2,=plt.plot(x,y2,label='square line')#进行画图\nplt.legend(loc='best')#显示在最好的位置\nplt.show()#显示图\n```\n![图片07](http://img.blog.csdn.net/20180311163819992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n调整位置和名称，单独修改label信息，我们可以在plt.legend输入更多参数\n```\nplt.legend(handles=[l1, l2], labels=['up', 'down'],  loc='best')\n#loc有很多参数 其中best自分配最佳位置\n'''\n 'best' : 0,          \n 'upper right'  : 1,\n 'upper left'   : 2,\n 'lower left'   : 3,\n 'lower right'  : 4,\n 'right'        : 5,\n 'center left'  : 6,\n 'center right' : 7,\n 'lower center' : 8,\n 'upper center' : 9,\n 'center'       : 10,\n '''\n```\n#### 4.4标注\n\n```\nx=np.linspace(-3,3,50)\ny = 2*x + 1\nplt.figure(num=1, figsize=(8, 5))\nplt.plot(x, y,)\n\n#移动坐标轴\nax = plt.gca()\nax.spines['right'].set_color('none')\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\n\n#标注信息\nx0=1\ny0=2*x0+1\nplt.scatter(x0,y0,s=50,color='b')\nplt.plot([x0,x0],[y0,0],'k--',lw=2.5)#连接(x0,y0)(x0,0) k表示黑色 lw=2.5表示线粗细\n#xycoords='data'是基于数据的值来选位置，xytext=(+30,-30)和textcoords='offset points'对于标注位置描述和xy偏差值，arrowprops对图中箭头类型设置\nplt.annotate(r'$2x0+1=%s$' % y0, xy=(x0, y0), xycoords='data', xytext=(+30, -30),\n             textcoords='offset points', fontsize=16,\n             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n#添加注视text（-3.7,3）表示选取text位置 空格需要用\\进行转译 fontdict设置文本字体             \nplt.text(-3.7, 3, r'$This\\ is\\ the\\ some\\ text. \\mu\\ \\sigma_i\\ \\alpha_t$',\n         fontdict={'size': 16, 'color': 'r'})\nplt.show()\n```\n![图片08](http://img.blog.csdn.net/2018031116474811?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.5能见度调整\n```\nx=np.linspace(-3, 3, 50)\ny=0.1*x\nplt.figure()\nplt.plot(x, y, linewidth=10, zorder=1)\nplt.ylim(-2, 2)\n\n#移动坐标轴\nax = plt.gca()\nax.spines['right'].set_color('none')\nax.spines['top'].set_color('none')\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\n\n#label.set_fontsize(12)重新调整字体大小 bbox设置目的内容的透明度相关参数 facecolor调节box前景色 edgecolor设置边框 alpha设置透明度 zorder设置图层顺序\nfor label in ax.get_xticklabels() + ax.get_yticklabels():\n    label.set_fontsize(12)\n    label.set_bbox(dict(facecolor='red', edgecolor='None', alpha=0.7, zorder=2))\nplt.show()\n```\n![图片09](http://img.blog.csdn.net/20180311172352949?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n### 5.画图种类\n#### 5.1Scatter散点图\n```\nn=1024\nX=np.random.normal(0,1,n)#每一个点的X值\nY=np.random.normal(0,1,n)#每一个点的Y值\nT=np.arctan2(Y,X)#arctan2返回给定的X和Y值的反正切值\n#scatter画散点图 size=75 颜色为T 透明度为50% 利用xticks函数来隐藏x坐标轴\nplt.scatter(X,Y,s=75,c=T,alpha=0.5)\nplt.xlim(-1.5,1.5)\nplt.xticks(())#忽略xticks\nplt.ylim(-1.5,1.5)\nplt.yticks(())#忽略yticks\nplt.show()\n```\n\n![图片10](http://img.blog.csdn.net/20180311174847167?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.2条形图\n```\n#基本图形\nn=12\nX=np.arange(n)\nY1=(1-X/float(n))*np.random.uniform(0.5,1,n)\nY2=(1-X/float(n))*np.random.uniform(0.5,1,n)\nplt.bar(X,+Y1,facecolor='#9999ff',edgecolor='white')\nplt.bar(X,-Y2,facecolor='#ff9999',edgecolor='white')\n\n#标记值\nfor x,y in zip(X,Y1):#zip表示可以传递两个值\n    plt.text(x+0.4,y+0.05,'%.2f'%y,ha='center',va='bottom')#ha表示横向对齐 bottom表示向下对齐\nfor x,y in zip(X,Y2):\n    plt.text(x+0.4,-y-0.05,'%.2f'%y,ha='center',va='top')\nplt.xlim(-0.5,n)\nplt.xticks(())#忽略xticks\nplt.ylim(-1.25,1.25)\nplt.yticks(())#忽略yticks\nplt.show()\n```\n![图片11](http://img.blog.csdn.net/20180311181815729?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.3等高线图\n\n```\nn=256\nx=np.linspace(-3,3,n)\ny=np.linspace(-3,3,n)\nX,Y=np.meshgrid(x,y)#meshgrid从坐标向量返回坐标矩阵\n#f函数用来计算高度值 利用contour函数把颜色加进去 位置参数依次为x,y,f(x,y)，透明度为0.75，并将f(x,y)的值对应到camp之中\ndef f(x,y):\n    return (1 - x / 2 + x ** 5 + y ** 3) * np.exp(-x ** 2 - y ** 2)\nplt.contourf(X,Y,f(X,Y),8,alpha=0.75,cmap=plt.cm.hot)#8表示等高线分成多少份 alpha表示透明度 cmap表示color map\n#使用plt.contour函数进行等高线绘制 参数依次为x,y,f(x,y)，颜色选择黑色，线条宽度为0.5\nC=plt.contour(X,Y,f(X,Y),8,colors='black',linewidth=0.5)\n#使用plt.clabel添加高度数值 inline控制是否将label画在线里面，字体大小为10\nplt.clabel(C,inline=True,fontsize=10)\nplt.xticks(())#隐藏坐标轴\nplt.yticks(())\nplt.show()\n```\n![图片12](http://img.blog.csdn.net/20180311182506284?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.4Image图片\n利用matplotlib打印出图像\n```\na = np.array([0.313660827978, 0.365348418405, 0.423733120134,\n              0.365348418405, 0.439599930621, 0.525083754405,\n              0.423733120134, 0.525083754405, 0.651536351379]).reshape(3,3)\n#origin='lower'代表的就是选择的原点位置\nplt.imshow(a,interpolation='nearest',cmap='bone',origin='lower')#cmap为color map\nplt.colorbar(shrink=.92)#右边颜色说明 shrink参数是将图片长度变为原来的92%\nplt.xticks(())\nplt.yticks(())\nplt.show()              \n```\n![图片13](http://img.blog.csdn.net/20180311192757270?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n出图方式 此处采用内插法中的nearest-neighbor\n![图片14](http://img.blog.csdn.net/20180311193343476?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.53D图像\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D#需另外导入模块Axes 3D\nfig=plt.figure()#定义图像窗口\nax=Axes3D(fig)#在窗口上添加3D坐标轴\n#将X和Y值编织成栅格\nX=np.arange(-4,4,0.25)\nY=np.arange(-4,4,0.25)\nX,Y=np.meshgrid(X,Y)\nR=np.sqrt(X**2+Y**2)\nZ=np.sin(R)#高度值\n#将colormap rainbow填充颜色，之后将三维图像投影到XY平面做等高线图，其中ratride和cstride表示row和column的宽度\nax.plot_surface(X,Y,Z,rstride=1,cstride=1,cmap=plt.get_cmap('rainbow'))#rstride表示图像中分割线的跨图\n#添加XY平面等高线 投影到z平面\nax.contourf(X,Y,Z,zdir='z',offset=-2,cmap=plt.get_cmap('rainbow'))#把图像进行投影的图形 offset表示比0坐标轴低两个位置\nax.set_zlim(-2,2)\nplt.show()\n```\n![图片15](http://img.blog.csdn.net/20180311194735746?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n### 6.多图合并显示\n\n#### 6.1Subplot多合一显示\n\n均匀图中图：MatPlotLib可以组合许多的小图在大图中显示，使用的方法叫做subplot。\n\n```python\nplt.figure()\nplt.subplot(2,1,1)#表示整个图像分割成2行2列，当前位置为1\nplt.plot([0,1],[0,1])#横坐标变化为[0,1] 竖坐标变化为[0,2]\n\nplt.subplot(2,3,4)\nplt.plot([0,1],[0,2])\n\nplt.subplot(2,3,5)\nplt.plot([0,1],[0,3])\n\nplt.subplot(2,3,6)\nplt.plot([0,1],[0,4])\nplt.show()\n```\n\n![图片16](Python之MatPlotLib使用教程/图片16.png)\n\n不均匀图中图\n\n```python\nplt.figure()\nplt.subplot(2,1,1)#将整个窗口分割成2行1列，当前位置表示第一个图\nplt.plot([0,1],[0,1])#横坐标变化为[0,1],竖坐标变化为[0,1]\n\nplt.subplot(2,3,4)#将整个窗口分割成2行3列，当前位置为4\nplt.plot([0,1],[0,2])\n\nplt.subplot(2,3,5)\nplt.plot([0,1],[0,3])\n\nplt.subplot(2,3,6)\nplt.plot([0,1],[0,4])\nplt.show()\n```\n\n![图片17](Python之MatPlotLib使用教程/图片17.png)\n\n#### 6.2SubPlot分格显示\n\n方法一\n\n```python\nimport matplotlib.gridspec as gridspec#引入新模块\nplt.figure()\n'''\n使用plt.subplot2grid创建第一个小图，(3,3)表示将整个图像分割成3行3列，(0,0)表示从第0行0列开始作图，colspan=3表示列的跨度为3。colspan和rowspan缺省时默认跨度为1\n'''\nax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)  # stands for axes\nax1.plot([1, 2], [1, 2])\nax1.set_title('ax1_title')#设置图的标题\n\n#将图像分割成3行3列，从第1行0列开始做图，列的跨度为2\nax2 = plt.subplot2grid((3, 3), (1, 0), colspan=2)\n\n#将图像分割成3行3列，从第1行2列开始做图，行的跨度为2\nax3 = plt.subplot2grid((3, 3), (1, 2), rowspan=2)\n\n#将图像分割成3行3列，从第2行0列开始做图，行与列的跨度默认为1\nax4 = plt.subplot2grid((3, 3), (2, 0))\nax4.scatter([1, 2], [2, 2])\nax4.set_xlabel('ax4_x')\nax4.set_ylabel('ax4_y')\nax5 = plt.subplot2grid((3, 3), (2, 1))\n```\n\n![图像18](Python之MatPlotLib使用教程/图像18.png)\n\n方法二\n\n```Python\nplt.figure()\ngs = gridspec.GridSpec(3, 3)#将图像分割成3行3列\nax6 = plt.subplot(gs[0, :])#gs[0:1]表示图占第0行和所有列\nax7 = plt.subplot(gs[1, :2])#gs[1,:2]表示图占第1行和第二列前的所有列\nax8 = plt.subplot(gs[1:, 2])\nax9 = plt.subplot(gs[-1, 0])\nax10 = plt.subplot(gs[-1, -2])#gs[-1.-2]表示这个图占倒数第1行和倒数第2行\nplt.show()\n```\n\n![图像19](Python之MatPlotLib使用教程/图像19.png)\n\n方法三\n\n```Python\n'''\n建立一个2行2列的图像窗口，sharex=True表示共享x轴坐标，sharey=True表示共享y轴坐标，((ax11,ax12),(ax13,1x14))表示从到至右一次存放ax11,ax12,ax13,ax114\n'''\nf, ((ax11, ax12), (ax13, ax14)) = plt.subplots(2, 2, sharex=True, sharey=True)\nax11.scatter([1,2], [1,2])ax11.scatter 坐标范围x为[1,2]，y为[1,2]\nplt.tight_layout()#表示紧凑显示图像\nplt.show()\n```\n\n![图像21](Python之MatPlotLib使用教程/图像20.png)\n\n#### 6.3图中图\n\n```Python\nfig=plt.figure()\n#创建数据\nx=[1,2,3,4,5,6,7]\ny=[1,3,4,2,5,8,6]\n\n#绘制大图：假设大图的大小为10，那么大图被包含在由(1,1)开始，宽8高8的坐标系之中。\nleft, bottom, width, height = 0.1, 0.1, 0.8, 0.8\nax1 = fig.add_axes([left, bottom, width, height])  # main axes\nax1.plot(x, y, 'r')#绘制大图，颜色为red\nax1.set_xlabel('x')#横坐标名称为x\nax1.set_ylabel('y')\nax1.set_title('title')#图名称为title\n\n#绘制小图，注意坐标系位置和大小的改变\nax2 = fig.add_axes([0.2, 0.6, 0.25, 0.25])\nax2.plot(y, x, 'b')#颜色为buue\nax2.set_xlabel('x')\nax2.set_ylabel('y')\nax2.set_title('title inside 1')\n\n#绘制第二个小兔\nplt.axes([0.6, 0.2, 0.25, 0.25])\nplt.plot(y[::-1], x, 'g')#将y进行逆序\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('title inside 2')\nplt.show()\n```\n\n![图像21](Python之MatPlotLib使用教程/图像21.png)\n\n#### 6.4次坐标轴\n\n```Python\nx=np.arange(0,10,0.1)\ny1=0.5*x**2\ny2=-1*y1\nfig, ax1 = plt.subplots()\n\nax2 = ax1.twinx()#镜像显示\nax1.plot(x, y1, 'g-')\nax2.plot(x, y2, 'b-')\n\nax1.set_xlabel('X data')\nax1.set_ylabel('Y1 data', color='g')#第一个y坐标轴\nax2.set_ylabel('Y2 data', color='b')#第二个y坐标轴\nplt.show()\n```\n\n![图像22](Python之MatPlotLib使用教程/图像22.png)\n\n### 7.动画\n\n```Python\nfrom matplotlib import animation#引入新模块\nfig,ax=plt.subplots()\nx=np.arange(0,2*np.pi,0.01)#数据为0~2PI范围内的正弦曲线\nline,=ax.plot(x,np.sin(x))# line表示列表\n\n#构造自定义动画函数animate，用来更新每一帧上x和y坐标值，参数表示第i帧\ndef animate(i):\n    line.set_ydata(np.sin(x+i/100))\n    return line,\n\n#构造开始帧函数init\ndef init():\n    line.set_ydata(np.sin(x))\n    return line,\n\n# frame表示动画长度，一次循环所包含的帧数；interval表示更新频率 \n# blit选择更新所有点，还是仅更新新变化产生的点。应该选True，但mac用户选择False。\nani=animation.FuncAnimation(fig=fig,func=animate,frames=200,init_func=init,interval=20,blit=False)\nplt.show()\n```\n\n![图像23](Python之MatPlotLib使用教程/图像23.png)\n\n**MatPlotLib之中还有很多画图方法，由于篇幅有限不再赘述，更多内容参考MatPlotLib Tutorials。**\n\n----------\n\n\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。\n\n","source":"_posts/Python之MatPlotLib使用教程.md","raw":"---\ntitle: Python之MatPlotLib使用教程\ndate: 2018-03-14 11:43:07\ntags: python\ntoc: true\ncategories: Python库\ncomments: true\n---\n### 1.Matplotlib简介\n\n 1. Matplotlib是非常强大的python画图工具\n 2. Matplotlib可以画图线图、散点图、等高线图、条形图、柱形图、3D图形、图形动画等。 \n\n### 2.Matplotlib安装\n```\npip3 install matplotlib#python3\n```\n### 3.Matplotlib引入\n```\nimport matplotlib.pyplot as plt#为方便简介为plt\nimport numpy as np#画图过程中会使用numpy\nimport pandas as pd#画图过程中会使用pandas\n```\n### 4.Matplotlib基本应用\n```\nx=np.linspace(-1,1,50)#定义x数据范围\ny1=2*x+1#定义y数据范围\ny2=x**2\nplt.figure()#定义一个图像窗口\nplt.plot(x,y)#plot()画出曲线\nplt.show()#显示图像\n```\n![图片01](http://img.blog.csdn.net/20180311144537863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.1figure图像\nmatplotlib的figure为单独图像窗口，小窗口内还可以有更多的小图片。\n```\nx=np.linspace(-3,3,50)#50为生成的样本数\ny1=2*x+1\ny2=x**2\nplt.figure(num=1,figsize=(8,5))#定义编号为1 大小为(8,5)\nplt.plot(x,y1,color='red',linewidth=2,linestyle='--')#颜色为红色，线宽度为2，线风格为--\nplt.plot(x,y2)#进行画图\nplt.show()#显示图\n```\n![图片02](http://img.blog.csdn.net/20180311145427674?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.2设置坐标轴\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='-')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nplt.xlabel(\"I'm x\")\nplt.ylabel(\"I'm y\")\nplt.show()\n```\n![图片03](http://img.blog.csdn.net/20180311151115803?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n自定义坐标轴\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='-')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nplt.xlabel(\"I'm x\")\nplt.ylabel(\"I'm y\")\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nprint(new_ticks)\n#[-1.   -0.25  0.5   1.25  2.  ]\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\nplt.show()\n```\n![图片04](http://img.blog.csdn.net/2018031115185255?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n设置边框属性\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='--')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\nax=plt.gca()#gca=get current axis\nax.spines['right'].set_color('none')#边框属性设置为none 不显示\nax.spines['top'].set_color('none')\nplt.show()\n```\n![图片05](http://img.blog.csdn.net/20180311152822953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n调整移动坐标轴\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.plot(x,y1,color='red',linewidth=2,linestyle='--')\nplt.plot(x,y2)#进行画图\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\nax=plt.gca()#gca=get current axis\nax.spines['right'].set_color('none')#边框属性设置为none 不显示\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')#使用xaxis.set_ticks_position设置x坐标刻度数字或名称的位置 所有属性为top、bottom、both、default、none\nax.spines['bottom'].set_position(('data', 0))#使用.spines设置边框x轴；使用.set_position设置边框位置，y=0位置 位置所有属性有outward、axes、data\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data',0))#坐标中心点在(0,0)位置\nplt.show()\n```\n![这里写图片描述](http://img.blog.csdn.net/20180311153109404?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.3添加图例\nmatplotlib中legend图例帮助我们展示数据对应的图像名称。\n```\nx=np.linspace(-3,3,50)\ny1=2*x+1\ny2=x**2\nplt.figure(num=2,figsize=(8,5))\nplt.xlim(-1,2)\nplt.ylim(-2,3)\nnew_ticks=np.linspace(-1,2,5)#小标从-1到2分为5个单位\nplt.xticks(new_ticks)#进行替换新下标\nplt.yticks([-2,-1,1,2,],\n           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])\n\nl1,=plt.plot(x,y1,color='red',linewidth=2,linestyle='--',label='linear line')\nl2,=plt.plot(x,y2,label='square line')#进行画图\nplt.legend(loc='best')#显示在最好的位置\nplt.show()#显示图\n```\n![图片07](http://img.blog.csdn.net/20180311163819992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n调整位置和名称，单独修改label信息，我们可以在plt.legend输入更多参数\n```\nplt.legend(handles=[l1, l2], labels=['up', 'down'],  loc='best')\n#loc有很多参数 其中best自分配最佳位置\n'''\n 'best' : 0,          \n 'upper right'  : 1,\n 'upper left'   : 2,\n 'lower left'   : 3,\n 'lower right'  : 4,\n 'right'        : 5,\n 'center left'  : 6,\n 'center right' : 7,\n 'lower center' : 8,\n 'upper center' : 9,\n 'center'       : 10,\n '''\n```\n#### 4.4标注\n\n```\nx=np.linspace(-3,3,50)\ny = 2*x + 1\nplt.figure(num=1, figsize=(8, 5))\nplt.plot(x, y,)\n\n#移动坐标轴\nax = plt.gca()\nax.spines['right'].set_color('none')\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\n\n#标注信息\nx0=1\ny0=2*x0+1\nplt.scatter(x0,y0,s=50,color='b')\nplt.plot([x0,x0],[y0,0],'k--',lw=2.5)#连接(x0,y0)(x0,0) k表示黑色 lw=2.5表示线粗细\n#xycoords='data'是基于数据的值来选位置，xytext=(+30,-30)和textcoords='offset points'对于标注位置描述和xy偏差值，arrowprops对图中箭头类型设置\nplt.annotate(r'$2x0+1=%s$' % y0, xy=(x0, y0), xycoords='data', xytext=(+30, -30),\n             textcoords='offset points', fontsize=16,\n             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n#添加注视text（-3.7,3）表示选取text位置 空格需要用\\进行转译 fontdict设置文本字体             \nplt.text(-3.7, 3, r'$This\\ is\\ the\\ some\\ text. \\mu\\ \\sigma_i\\ \\alpha_t$',\n         fontdict={'size': 16, 'color': 'r'})\nplt.show()\n```\n![图片08](http://img.blog.csdn.net/2018031116474811?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 4.5能见度调整\n```\nx=np.linspace(-3, 3, 50)\ny=0.1*x\nplt.figure()\nplt.plot(x, y, linewidth=10, zorder=1)\nplt.ylim(-2, 2)\n\n#移动坐标轴\nax = plt.gca()\nax.spines['right'].set_color('none')\nax.spines['top'].set_color('none')\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\n\n#label.set_fontsize(12)重新调整字体大小 bbox设置目的内容的透明度相关参数 facecolor调节box前景色 edgecolor设置边框 alpha设置透明度 zorder设置图层顺序\nfor label in ax.get_xticklabels() + ax.get_yticklabels():\n    label.set_fontsize(12)\n    label.set_bbox(dict(facecolor='red', edgecolor='None', alpha=0.7, zorder=2))\nplt.show()\n```\n![图片09](http://img.blog.csdn.net/20180311172352949?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n### 5.画图种类\n#### 5.1Scatter散点图\n```\nn=1024\nX=np.random.normal(0,1,n)#每一个点的X值\nY=np.random.normal(0,1,n)#每一个点的Y值\nT=np.arctan2(Y,X)#arctan2返回给定的X和Y值的反正切值\n#scatter画散点图 size=75 颜色为T 透明度为50% 利用xticks函数来隐藏x坐标轴\nplt.scatter(X,Y,s=75,c=T,alpha=0.5)\nplt.xlim(-1.5,1.5)\nplt.xticks(())#忽略xticks\nplt.ylim(-1.5,1.5)\nplt.yticks(())#忽略yticks\nplt.show()\n```\n\n![图片10](http://img.blog.csdn.net/20180311174847167?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.2条形图\n```\n#基本图形\nn=12\nX=np.arange(n)\nY1=(1-X/float(n))*np.random.uniform(0.5,1,n)\nY2=(1-X/float(n))*np.random.uniform(0.5,1,n)\nplt.bar(X,+Y1,facecolor='#9999ff',edgecolor='white')\nplt.bar(X,-Y2,facecolor='#ff9999',edgecolor='white')\n\n#标记值\nfor x,y in zip(X,Y1):#zip表示可以传递两个值\n    plt.text(x+0.4,y+0.05,'%.2f'%y,ha='center',va='bottom')#ha表示横向对齐 bottom表示向下对齐\nfor x,y in zip(X,Y2):\n    plt.text(x+0.4,-y-0.05,'%.2f'%y,ha='center',va='top')\nplt.xlim(-0.5,n)\nplt.xticks(())#忽略xticks\nplt.ylim(-1.25,1.25)\nplt.yticks(())#忽略yticks\nplt.show()\n```\n![图片11](http://img.blog.csdn.net/20180311181815729?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.3等高线图\n\n```\nn=256\nx=np.linspace(-3,3,n)\ny=np.linspace(-3,3,n)\nX,Y=np.meshgrid(x,y)#meshgrid从坐标向量返回坐标矩阵\n#f函数用来计算高度值 利用contour函数把颜色加进去 位置参数依次为x,y,f(x,y)，透明度为0.75，并将f(x,y)的值对应到camp之中\ndef f(x,y):\n    return (1 - x / 2 + x ** 5 + y ** 3) * np.exp(-x ** 2 - y ** 2)\nplt.contourf(X,Y,f(X,Y),8,alpha=0.75,cmap=plt.cm.hot)#8表示等高线分成多少份 alpha表示透明度 cmap表示color map\n#使用plt.contour函数进行等高线绘制 参数依次为x,y,f(x,y)，颜色选择黑色，线条宽度为0.5\nC=plt.contour(X,Y,f(X,Y),8,colors='black',linewidth=0.5)\n#使用plt.clabel添加高度数值 inline控制是否将label画在线里面，字体大小为10\nplt.clabel(C,inline=True,fontsize=10)\nplt.xticks(())#隐藏坐标轴\nplt.yticks(())\nplt.show()\n```\n![图片12](http://img.blog.csdn.net/20180311182506284?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.4Image图片\n利用matplotlib打印出图像\n```\na = np.array([0.313660827978, 0.365348418405, 0.423733120134,\n              0.365348418405, 0.439599930621, 0.525083754405,\n              0.423733120134, 0.525083754405, 0.651536351379]).reshape(3,3)\n#origin='lower'代表的就是选择的原点位置\nplt.imshow(a,interpolation='nearest',cmap='bone',origin='lower')#cmap为color map\nplt.colorbar(shrink=.92)#右边颜色说明 shrink参数是将图片长度变为原来的92%\nplt.xticks(())\nplt.yticks(())\nplt.show()              \n```\n![图片13](http://img.blog.csdn.net/20180311192757270?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n出图方式 此处采用内插法中的nearest-neighbor\n![图片14](http://img.blog.csdn.net/20180311193343476?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n#### 5.53D图像\n```\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D#需另外导入模块Axes 3D\nfig=plt.figure()#定义图像窗口\nax=Axes3D(fig)#在窗口上添加3D坐标轴\n#将X和Y值编织成栅格\nX=np.arange(-4,4,0.25)\nY=np.arange(-4,4,0.25)\nX,Y=np.meshgrid(X,Y)\nR=np.sqrt(X**2+Y**2)\nZ=np.sin(R)#高度值\n#将colormap rainbow填充颜色，之后将三维图像投影到XY平面做等高线图，其中ratride和cstride表示row和column的宽度\nax.plot_surface(X,Y,Z,rstride=1,cstride=1,cmap=plt.get_cmap('rainbow'))#rstride表示图像中分割线的跨图\n#添加XY平面等高线 投影到z平面\nax.contourf(X,Y,Z,zdir='z',offset=-2,cmap=plt.get_cmap('rainbow'))#把图像进行投影的图形 offset表示比0坐标轴低两个位置\nax.set_zlim(-2,2)\nplt.show()\n```\n![图片15](http://img.blog.csdn.net/20180311194735746?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n### 6.多图合并显示\n\n#### 6.1Subplot多合一显示\n\n均匀图中图：MatPlotLib可以组合许多的小图在大图中显示，使用的方法叫做subplot。\n\n```python\nplt.figure()\nplt.subplot(2,1,1)#表示整个图像分割成2行2列，当前位置为1\nplt.plot([0,1],[0,1])#横坐标变化为[0,1] 竖坐标变化为[0,2]\n\nplt.subplot(2,3,4)\nplt.plot([0,1],[0,2])\n\nplt.subplot(2,3,5)\nplt.plot([0,1],[0,3])\n\nplt.subplot(2,3,6)\nplt.plot([0,1],[0,4])\nplt.show()\n```\n\n![图片16](Python之MatPlotLib使用教程/图片16.png)\n\n不均匀图中图\n\n```python\nplt.figure()\nplt.subplot(2,1,1)#将整个窗口分割成2行1列，当前位置表示第一个图\nplt.plot([0,1],[0,1])#横坐标变化为[0,1],竖坐标变化为[0,1]\n\nplt.subplot(2,3,4)#将整个窗口分割成2行3列，当前位置为4\nplt.plot([0,1],[0,2])\n\nplt.subplot(2,3,5)\nplt.plot([0,1],[0,3])\n\nplt.subplot(2,3,6)\nplt.plot([0,1],[0,4])\nplt.show()\n```\n\n![图片17](Python之MatPlotLib使用教程/图片17.png)\n\n#### 6.2SubPlot分格显示\n\n方法一\n\n```python\nimport matplotlib.gridspec as gridspec#引入新模块\nplt.figure()\n'''\n使用plt.subplot2grid创建第一个小图，(3,3)表示将整个图像分割成3行3列，(0,0)表示从第0行0列开始作图，colspan=3表示列的跨度为3。colspan和rowspan缺省时默认跨度为1\n'''\nax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)  # stands for axes\nax1.plot([1, 2], [1, 2])\nax1.set_title('ax1_title')#设置图的标题\n\n#将图像分割成3行3列，从第1行0列开始做图，列的跨度为2\nax2 = plt.subplot2grid((3, 3), (1, 0), colspan=2)\n\n#将图像分割成3行3列，从第1行2列开始做图，行的跨度为2\nax3 = plt.subplot2grid((3, 3), (1, 2), rowspan=2)\n\n#将图像分割成3行3列，从第2行0列开始做图，行与列的跨度默认为1\nax4 = plt.subplot2grid((3, 3), (2, 0))\nax4.scatter([1, 2], [2, 2])\nax4.set_xlabel('ax4_x')\nax4.set_ylabel('ax4_y')\nax5 = plt.subplot2grid((3, 3), (2, 1))\n```\n\n![图像18](Python之MatPlotLib使用教程/图像18.png)\n\n方法二\n\n```Python\nplt.figure()\ngs = gridspec.GridSpec(3, 3)#将图像分割成3行3列\nax6 = plt.subplot(gs[0, :])#gs[0:1]表示图占第0行和所有列\nax7 = plt.subplot(gs[1, :2])#gs[1,:2]表示图占第1行和第二列前的所有列\nax8 = plt.subplot(gs[1:, 2])\nax9 = plt.subplot(gs[-1, 0])\nax10 = plt.subplot(gs[-1, -2])#gs[-1.-2]表示这个图占倒数第1行和倒数第2行\nplt.show()\n```\n\n![图像19](Python之MatPlotLib使用教程/图像19.png)\n\n方法三\n\n```Python\n'''\n建立一个2行2列的图像窗口，sharex=True表示共享x轴坐标，sharey=True表示共享y轴坐标，((ax11,ax12),(ax13,1x14))表示从到至右一次存放ax11,ax12,ax13,ax114\n'''\nf, ((ax11, ax12), (ax13, ax14)) = plt.subplots(2, 2, sharex=True, sharey=True)\nax11.scatter([1,2], [1,2])ax11.scatter 坐标范围x为[1,2]，y为[1,2]\nplt.tight_layout()#表示紧凑显示图像\nplt.show()\n```\n\n![图像21](Python之MatPlotLib使用教程/图像20.png)\n\n#### 6.3图中图\n\n```Python\nfig=plt.figure()\n#创建数据\nx=[1,2,3,4,5,6,7]\ny=[1,3,4,2,5,8,6]\n\n#绘制大图：假设大图的大小为10，那么大图被包含在由(1,1)开始，宽8高8的坐标系之中。\nleft, bottom, width, height = 0.1, 0.1, 0.8, 0.8\nax1 = fig.add_axes([left, bottom, width, height])  # main axes\nax1.plot(x, y, 'r')#绘制大图，颜色为red\nax1.set_xlabel('x')#横坐标名称为x\nax1.set_ylabel('y')\nax1.set_title('title')#图名称为title\n\n#绘制小图，注意坐标系位置和大小的改变\nax2 = fig.add_axes([0.2, 0.6, 0.25, 0.25])\nax2.plot(y, x, 'b')#颜色为buue\nax2.set_xlabel('x')\nax2.set_ylabel('y')\nax2.set_title('title inside 1')\n\n#绘制第二个小兔\nplt.axes([0.6, 0.2, 0.25, 0.25])\nplt.plot(y[::-1], x, 'g')#将y进行逆序\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('title inside 2')\nplt.show()\n```\n\n![图像21](Python之MatPlotLib使用教程/图像21.png)\n\n#### 6.4次坐标轴\n\n```Python\nx=np.arange(0,10,0.1)\ny1=0.5*x**2\ny2=-1*y1\nfig, ax1 = plt.subplots()\n\nax2 = ax1.twinx()#镜像显示\nax1.plot(x, y1, 'g-')\nax2.plot(x, y2, 'b-')\n\nax1.set_xlabel('X data')\nax1.set_ylabel('Y1 data', color='g')#第一个y坐标轴\nax2.set_ylabel('Y2 data', color='b')#第二个y坐标轴\nplt.show()\n```\n\n![图像22](Python之MatPlotLib使用教程/图像22.png)\n\n### 7.动画\n\n```Python\nfrom matplotlib import animation#引入新模块\nfig,ax=plt.subplots()\nx=np.arange(0,2*np.pi,0.01)#数据为0~2PI范围内的正弦曲线\nline,=ax.plot(x,np.sin(x))# line表示列表\n\n#构造自定义动画函数animate，用来更新每一帧上x和y坐标值，参数表示第i帧\ndef animate(i):\n    line.set_ydata(np.sin(x+i/100))\n    return line,\n\n#构造开始帧函数init\ndef init():\n    line.set_ydata(np.sin(x))\n    return line,\n\n# frame表示动画长度，一次循环所包含的帧数；interval表示更新频率 \n# blit选择更新所有点，还是仅更新新变化产生的点。应该选True，但mac用户选择False。\nani=animation.FuncAnimation(fig=fig,func=animate,frames=200,init_func=init,interval=20,blit=False)\nplt.show()\n```\n\n![图像23](Python之MatPlotLib使用教程/图像23.png)\n\n**MatPlotLib之中还有很多画图方法，由于篇幅有限不再赘述，更多内容参考MatPlotLib Tutorials。**\n\n----------\n\n\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。\n\n","slug":"Python之MatPlotLib使用教程","published":1,"updated":"2018-03-25T11:59:25.077Z","layout":"post","photos":[],"link":"","_id":"cjg7s0pq000053201miuj4u8b","content":"<h3 id=\"1-Matplotlib简介\"><a href=\"#1-Matplotlib简介\" class=\"headerlink\" title=\"1.Matplotlib简介\"></a>1.Matplotlib简介</h3><ol>\n<li>Matplotlib是非常强大的python画图工具</li>\n<li>Matplotlib可以画图线图、散点图、等高线图、条形图、柱形图、3D图形、图形动画等。 </li>\n</ol>\n<h3 id=\"2-Matplotlib安装\"><a href=\"#2-Matplotlib安装\" class=\"headerlink\" title=\"2.Matplotlib安装\"></a>2.Matplotlib安装</h3><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip3 <span class=\"keyword\">install</span> matplotlib<span class=\"comment\">#python3</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"3-Matplotlib引入\"><a href=\"#3-Matplotlib引入\" class=\"headerlink\" title=\"3.Matplotlib引入\"></a>3.Matplotlib引入</h3><figure class=\"highlight capnproto\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt<span class=\"comment\">#为方便简介为plt</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np<span class=\"comment\">#画图过程中会使用numpy</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd<span class=\"comment\">#画图过程中会使用pandas</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-Matplotlib基本应用\"><a href=\"#4-Matplotlib基本应用\" class=\"headerlink\" title=\"4.Matplotlib基本应用\"></a>4.Matplotlib基本应用</h3><figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-1,1,50)<span class=\"comment\">#定义x数据范围</span></span><br><span class=\"line\">y1=2*x+1<span class=\"comment\">#定义y数据范围</span></span><br><span class=\"line\">y2=x**2</span><br><span class=\"line\">plt.figure()<span class=\"comment\">#定义一个图像窗口</span></span><br><span class=\"line\">plt.plot(x,y)<span class=\"comment\">#plot()画出曲线</span></span><br><span class=\"line\">plt.show()<span class=\"comment\">#显示图像</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311144537863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片01\"></p>\n<h4 id=\"4-1figure图像\"><a href=\"#4-1figure图像\" class=\"headerlink\" title=\"4.1figure图像\"></a>4.1figure图像</h4><p>matplotlib的figure为单独图像窗口，小窗口内还可以有更多的小图片。<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)#<span class=\"number\">50</span>为生成的样本数</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">1</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))#定义编号为<span class=\"number\">1</span> 大小为(<span class=\"number\">8</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='--')#颜色为红色，线宽度为<span class=\"number\">2</span>，线风格为--</span><br><span class=\"line\">plt.plot(x,y2)#进行画图</span><br><span class=\"line\">plt.show()#显示图</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311145427674?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片02\"></p>\n<h4 id=\"4-2设置坐标轴\"><a href=\"#4-2设置坐标轴\" class=\"headerlink\" title=\"4.2设置坐标轴\"></a>4.2设置坐标轴</h4><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='-')</span><br><span class=\"line\">plt.plot(x,y2)#进行画图</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">\"I'm x\"</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">\"I'm y\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311151115803?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片03\"><br>自定义坐标轴<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='-')</span><br><span class=\"line\">plt.plot(x,y2)#进行画图</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">\"I'm x\"</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">\"I'm y\"</span>)</span><br><span class=\"line\">new_ticks=np.linspace(<span class=\"number\">-1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)#小标从<span class=\"number\">-1</span>到<span class=\"number\">2</span>分为<span class=\"number\">5</span>个单位</span><br><span class=\"line\">print(new_ticks)</span><br><span class=\"line\">#[<span class=\"number\">-1.</span>   <span class=\"number\">-0.25</span>  <span class=\"number\">0.5</span>   <span class=\"number\">1.25</span>  <span class=\"number\">2.</span>  ]</span><br><span class=\"line\">plt.xticks(new_ticks)#进行替换新下标</span><br><span class=\"line\">plt.yticks([<span class=\"number\">-2</span>,<span class=\"number\">-1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/2018031115185255?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片04\"><br>设置边框属性<br><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color=<span class=\"string\">'red'</span>,linewidth=<span class=\"number\">2</span>,linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\">plt.plot(x,y2)<span class=\"comment\">#进行画图</span></span><br><span class=\"line\">plt.xlim(-<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(-<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">new_ticks=np.linspace(-<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)<span class=\"comment\">#小标从-1到2分为5个单位</span></span><br><span class=\"line\">plt.xticks(new_ticks)<span class=\"comment\">#进行替换新下标</span></span><br><span class=\"line\">plt.yticks([-<span class=\"number\">2</span>,-<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [<span class=\"string\">r'$really\\ bad$'</span>,<span class=\"string\">'$bad$'</span>,<span class=\"string\">'$well$'</span>,<span class=\"string\">'$really\\ well$'</span>])</span><br><span class=\"line\">ax=plt.gca()<span class=\"comment\">#gca=get current axis</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)<span class=\"comment\">#边框属性设置为none 不显示</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311152822953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片05\"><br>调整移动坐标轴<br><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color=<span class=\"string\">'red'</span>,linewidth=<span class=\"number\">2</span>,linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\">plt.plot(x,y2)<span class=\"comment\">#进行画图</span></span><br><span class=\"line\">plt.xlim(-<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(-<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">new_ticks=np.linspace(-<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)<span class=\"comment\">#小标从-1到2分为5个单位</span></span><br><span class=\"line\">plt.xticks(new_ticks)<span class=\"comment\">#进行替换新下标</span></span><br><span class=\"line\">plt.yticks([-<span class=\"number\">2</span>,-<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [<span class=\"string\">r'$really\\ bad$'</span>,<span class=\"string\">'$bad$'</span>,<span class=\"string\">'$well$'</span>,<span class=\"string\">'$really\\ well$'</span>])</span><br><span class=\"line\">ax=plt.gca()<span class=\"comment\">#gca=get current axis</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)<span class=\"comment\">#边框属性设置为none 不显示</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.xaxis.set_ticks_position(<span class=\"string\">'bottom'</span>)<span class=\"comment\">#使用xaxis.set_ticks_position设置x坐标刻度数字或名称的位置 所有属性为top、bottom、both、default、none</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))<span class=\"comment\">#使用.spines设置边框x轴；使用.set_position设置边框位置，y=0位置 位置所有属性有outward、axes、data</span></span><br><span class=\"line\">ax.yaxis.set_ticks_position(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>,<span class=\"number\">0</span>))<span class=\"comment\">#坐标中心点在(0,0)位置</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311153109404?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<h4 id=\"4-3添加图例\"><a href=\"#4-3添加图例\" class=\"headerlink\" title=\"4.3添加图例\"></a>4.3添加图例</h4><p>matplotlib中legend图例帮助我们展示数据对应的图像名称。<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">new_ticks=np.linspace(<span class=\"number\">-1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)#小标从<span class=\"number\">-1</span>到<span class=\"number\">2</span>分为<span class=\"number\">5</span>个单位</span><br><span class=\"line\">plt.xticks(new_ticks)#进行替换新下标</span><br><span class=\"line\">plt.yticks([<span class=\"number\">-2</span>,<span class=\"number\">-1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])</span><br><span class=\"line\"></span><br><span class=\"line\">l1,=plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='--',label='linear line')</span><br><span class=\"line\">l2,=plt.plot(x,y2,label='square line')#进行画图</span><br><span class=\"line\">plt.legend(loc='best')#显示在最好的位置</span><br><span class=\"line\">plt.show()#显示图</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311163819992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片07\"><br>调整位置和名称，单独修改label信息，我们可以在plt.legend输入更多参数<br><figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.legend(handles=[l1, l2], labels=[<span class=\"symbol\">'up</span>', <span class=\"symbol\">'down</span>'],  loc=<span class=\"symbol\">'best</span>')</span><br><span class=\"line\">#loc有很多参数 其中best自分配最佳位置</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"> <span class=\"symbol\">'best</span>' : 0,          </span><br><span class=\"line\"> <span class=\"symbol\">'upper</span> right'  : 1,</span><br><span class=\"line\"> <span class=\"symbol\">'upper</span> left'   : 2,</span><br><span class=\"line\"> <span class=\"symbol\">'lower</span> left'   : 3,</span><br><span class=\"line\"> <span class=\"symbol\">'lower</span> right'  : 4,</span><br><span class=\"line\"> <span class=\"symbol\">'right</span>'        : 5,</span><br><span class=\"line\"> <span class=\"symbol\">'center</span> left'  : 6,</span><br><span class=\"line\"> <span class=\"symbol\">'center</span> right' : 7,</span><br><span class=\"line\"> <span class=\"symbol\">'lower</span> center' : 8,</span><br><span class=\"line\"> <span class=\"symbol\">'upper</span> center' : 9,</span><br><span class=\"line\"> <span class=\"symbol\">'center</span>'       : 10,</span><br><span class=\"line\"> <span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"4-4标注\"><a href=\"#4-4标注\" class=\"headerlink\" title=\"4.4标注\"></a>4.4标注</h4><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y = <span class=\"number\">2</span>*x + <span class=\"number\">1</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">1</span>, figsize=(<span class=\"number\">8</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x, y,)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#移动坐标轴</span></span><br><span class=\"line\">ax = plt.gca()</span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.xaxis.set_ticks_position(<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">ax.yaxis.set_ticks_position(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#标注信息</span></span><br><span class=\"line\">x0=<span class=\"number\">1</span></span><br><span class=\"line\">y0=<span class=\"number\">2</span>*x0+<span class=\"number\">1</span></span><br><span class=\"line\">plt.scatter(x0,y0,s=<span class=\"number\">50</span>,color=<span class=\"string\">'b'</span>)</span><br><span class=\"line\">plt.plot([x0,x0],[y0,<span class=\"number\">0</span>],<span class=\"string\">'k--'</span>,lw=<span class=\"number\">2.5</span>)<span class=\"comment\">#连接(x0,y0)(x0,0) k表示黑色 lw=2.5表示线粗细</span></span><br><span class=\"line\"><span class=\"comment\">#xycoords='data'是基于数据的值来选位置，xytext=(+30,-30)和textcoords='offset points'对于标注位置描述和xy偏差值，arrowprops对图中箭头类型设置</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">r'$2x0+1=%s$'</span> % y0, xy=(x0, y0), xycoords=<span class=\"string\">'data'</span>, xytext=(+<span class=\"number\">30</span>, -<span class=\"number\">30</span>),</span><br><span class=\"line\">             textcoords=<span class=\"string\">'offset points'</span>, fontsize=<span class=\"number\">16</span>,</span><br><span class=\"line\">             arrowprops=dict(arrowstyle=<span class=\"string\">'-&gt;'</span>, connectionstyle=<span class=\"string\">\"arc3,rad=.2\"</span>))</span><br><span class=\"line\"><span class=\"comment\">#添加注视text（-3.7,3）表示选取text位置 空格需要用\\进行转译 fontdict设置文本字体             </span></span><br><span class=\"line\">plt.text(-<span class=\"number\">3.7</span>, <span class=\"number\">3</span>, <span class=\"string\">r'$This\\ is\\ the\\ some\\ text. \\mu\\ \\sigma_i\\ \\alpha_t$'</span>,</span><br><span class=\"line\">         fontdict=&#123;<span class=\"string\">'size'</span>: <span class=\"number\">16</span>, <span class=\"string\">'color'</span>: <span class=\"string\">'r'</span>&#125;)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/2018031116474811?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片08\"></p>\n<h4 id=\"4-5能见度调整\"><a href=\"#4-5能见度调整\" class=\"headerlink\" title=\"4.5能见度调整\"></a>4.5能见度调整</h4><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">50</span>)</span><br><span class=\"line\">y=<span class=\"number\">0.1</span>*x</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(x, y, linewidth=<span class=\"number\">10</span>, zorder=<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.ylim(-<span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">#移动坐标轴</span><br><span class=\"line\">ax = plt.gca()</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.xaxis</span><span class=\"selector-class\">.set_ticks_position</span>(<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">ax<span class=\"selector-class\">.yaxis</span><span class=\"selector-class\">.set_ticks_position</span>(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"selector-id\">#label</span>.set_fontsize(<span class=\"number\">12</span>)重新调整字体大小 bbox设置目的内容的透明度相关参数 facecolor调节box前景色 edgecolor设置边框 alpha设置透明度 zorder设置图层顺序</span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"selector-tag\">label</span> <span class=\"keyword\">in</span> ax.get_xticklabels() + ax.get_yticklabels():</span><br><span class=\"line\">    <span class=\"selector-tag\">label</span>.set_fontsize(<span class=\"number\">12</span>)</span><br><span class=\"line\">    <span class=\"selector-tag\">label</span>.set_bbox(dict(facecolor=<span class=\"string\">'red'</span>, edgecolor=<span class=\"string\">'None'</span>, alpha=<span class=\"number\">0.7</span>, zorder=<span class=\"number\">2</span>))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311172352949?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片09\"></p>\n<h3 id=\"5-画图种类\"><a href=\"#5-画图种类\" class=\"headerlink\" title=\"5.画图种类\"></a>5.画图种类</h3><h4 id=\"5-1Scatter散点图\"><a href=\"#5-1Scatter散点图\" class=\"headerlink\" title=\"5.1Scatter散点图\"></a>5.1Scatter散点图</h4><figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">n=1024</span><br><span class=\"line\">X=np.random.normal(0,1,n)<span class=\"comment\">#每一个点的X值</span></span><br><span class=\"line\">Y=np.random.normal(0,1,n)<span class=\"comment\">#每一个点的Y值</span></span><br><span class=\"line\">T=np.arctan2(Y,X)<span class=\"comment\">#arctan2返回给定的X和Y值的反正切值</span></span><br><span class=\"line\"><span class=\"comment\">#scatter画散点图 size=75 颜色为T 透明度为50% 利用xticks函数来隐藏x坐标轴</span></span><br><span class=\"line\">plt.scatter(X,Y,s=75,c=T,alpha=0.5)</span><br><span class=\"line\">plt.xlim(-1.5,1.5)</span><br><span class=\"line\">plt.xticks(())<span class=\"comment\">#忽略xticks</span></span><br><span class=\"line\">plt.ylim(-1.5,1.5)</span><br><span class=\"line\">plt.yticks(())<span class=\"comment\">#忽略yticks</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311174847167?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片10\"></p>\n<h4 id=\"5-2条形图\"><a href=\"#5-2条形图\" class=\"headerlink\" title=\"5.2条形图\"></a>5.2条形图</h4><figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#基本图形</span></span><br><span class=\"line\">n=<span class=\"number\">12</span></span><br><span class=\"line\">X=np.arange(n)</span><br><span class=\"line\">Y1=(<span class=\"number\">1</span>-X/float(n))*np.<span class=\"built_in\">random</span>.uniform(<span class=\"number\">0.5</span>,<span class=\"number\">1</span>,n)</span><br><span class=\"line\">Y2=(<span class=\"number\">1</span>-X/float(n))*np.<span class=\"built_in\">random</span>.uniform(<span class=\"number\">0.5</span>,<span class=\"number\">1</span>,n)</span><br><span class=\"line\">plt.bar(X,+Y1,facecolor=<span class=\"string\">'#9999ff'</span>,edgecolor=<span class=\"string\">'white'</span>)</span><br><span class=\"line\">plt.bar(X,-Y2,facecolor=<span class=\"string\">'#ff9999'</span>,edgecolor=<span class=\"string\">'white'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#标记值</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> x,y <span class=\"keyword\">in</span> zip(X,Y1):<span class=\"comment\">#zip表示可以传递两个值</span></span><br><span class=\"line\">    plt.<span class=\"keyword\">text</span>(x+<span class=\"number\">0.4</span>,y+<span class=\"number\">0.05</span>,<span class=\"string\">'%.2f'</span>%y,ha=<span class=\"string\">'center'</span>,va=<span class=\"string\">'bottom'</span>)<span class=\"comment\">#ha表示横向对齐 bottom表示向下对齐</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> x,y <span class=\"keyword\">in</span> zip(X,Y2):</span><br><span class=\"line\">    plt.<span class=\"keyword\">text</span>(x+<span class=\"number\">0.4</span>,-y<span class=\"number\">-0.05</span>,<span class=\"string\">'%.2f'</span>%y,ha=<span class=\"string\">'center'</span>,va=<span class=\"string\">'top'</span>)</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-0.5</span>,n)</span><br><span class=\"line\">plt.xticks(())<span class=\"comment\">#忽略xticks</span></span><br><span class=\"line\">plt.ylim(<span class=\"number\">-1.25</span>,<span class=\"number\">1.25</span>)</span><br><span class=\"line\">plt.yticks(())<span class=\"comment\">#忽略yticks</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311181815729?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片11\"></p>\n<h4 id=\"5-3等高线图\"><a href=\"#5-3等高线图\" class=\"headerlink\" title=\"5.3等高线图\"></a>5.3等高线图</h4><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">n</span>=256</span><br><span class=\"line\"><span class=\"attribute\">x</span>=np.linspace(-3,3,n)</span><br><span class=\"line\"><span class=\"attribute\">y</span>=np.linspace(-3,3,n)</span><br><span class=\"line\">X,<span class=\"attribute\">Y</span>=np.meshgrid(x,y)#meshgrid从坐标向量返回坐标矩阵</span><br><span class=\"line\"><span class=\"comment\">#f函数用来计算高度值 利用contour函数把颜色加进去 位置参数依次为x,y,f(x,y)，透明度为0.75，并将f(x,y)的值对应到camp之中</span></span><br><span class=\"line\">def f(x,y):</span><br><span class=\"line\">    return (1 - x / 2 + x ** 5 + y ** 3) * np.exp(-x ** 2 - y ** 2)</span><br><span class=\"line\">plt.contourf(X,Y,f(X,Y),8,<span class=\"attribute\">alpha</span>=0.75,cmap=plt.cm.hot)#8表示等高线分成多少份 alpha表示透明度 cmap表示color map</span><br><span class=\"line\"><span class=\"comment\">#使用plt.contour函数进行等高线绘制 参数依次为x,y,f(x,y)，颜色选择黑色，线条宽度为0.5</span></span><br><span class=\"line\"><span class=\"attribute\">C</span>=plt.contour(X,Y,f(X,Y),8,colors='black',linewidth=0.5)</span><br><span class=\"line\"><span class=\"comment\">#使用plt.clabel添加高度数值 inline控制是否将label画在线里面，字体大小为10</span></span><br><span class=\"line\">plt.clabel(C,<span class=\"attribute\">inline</span>=<span class=\"literal\">True</span>,fontsize=10)</span><br><span class=\"line\">plt.xticks(())#隐藏坐标轴</span><br><span class=\"line\">plt.yticks(())</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311182506284?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片12\"></p>\n<h4 id=\"5-4Image图片\"><a href=\"#5-4Image图片\" class=\"headerlink\" title=\"5.4Image图片\"></a>5.4Image图片</h4><p>利用matplotlib打印出图像<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.array([<span class=\"number\">0.313660827978</span>, <span class=\"number\">0.365348418405</span>, <span class=\"number\">0.423733120134</span>,</span><br><span class=\"line\">              <span class=\"number\">0.365348418405</span>, <span class=\"number\">0.439599930621</span>, <span class=\"number\">0.525083754405</span>,</span><br><span class=\"line\">              <span class=\"number\">0.423733120134</span>, <span class=\"number\">0.525083754405</span>, <span class=\"number\">0.651536351379</span>]).reshape(<span class=\"number\">3</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">#origin='lower'代表的就是选择的原点位置</span><br><span class=\"line\">plt.imshow(a,interpolation='nearest',cmap='bone',origin='lower')#cmap为color map</span><br><span class=\"line\">plt.colorbar(shrink=<span class=\"number\">.92</span>)#右边颜色说明 shrink参数是将图片长度变为原来的<span class=\"number\">92</span>%</span><br><span class=\"line\">plt.xticks(())</span><br><span class=\"line\">plt.yticks(())</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311192757270?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片13\"><br>出图方式 此处采用内插法中的nearest-neighbor<br><img src=\"http://img.blog.csdn.net/20180311193343476?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片14\"></p>\n<h4 id=\"5-53D图像\"><a href=\"#5-53D图像\" class=\"headerlink\" title=\"5.53D图像\"></a>5.53D图像</h4><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d import Axes3D#需另外导入模块Axes 3D</span><br><span class=\"line\"><span class=\"attribute\">fig</span>=plt.figure()#定义图像窗口</span><br><span class=\"line\"><span class=\"attribute\">ax</span>=Axes3D(fig)#在窗口上添加3D坐标轴</span><br><span class=\"line\"><span class=\"comment\">#将X和Y值编织成栅格</span></span><br><span class=\"line\"><span class=\"attribute\">X</span>=np.arange(-4,4,0.25)</span><br><span class=\"line\"><span class=\"attribute\">Y</span>=np.arange(-4,4,0.25)</span><br><span class=\"line\">X,<span class=\"attribute\">Y</span>=np.meshgrid(X,Y)</span><br><span class=\"line\"><span class=\"attribute\">R</span>=np.sqrt(X**2+Y**2)</span><br><span class=\"line\"><span class=\"attribute\">Z</span>=np.sin(R)#高度值</span><br><span class=\"line\"><span class=\"comment\">#将colormap rainbow填充颜色，之后将三维图像投影到XY平面做等高线图，其中ratride和cstride表示row和column的宽度</span></span><br><span class=\"line\">ax.plot_surface(X,Y,Z,<span class=\"attribute\">rstride</span>=1,cstride=1,cmap=plt.get_cmap('rainbow'))#rstride表示图像中分割线的跨图</span><br><span class=\"line\"><span class=\"comment\">#添加XY平面等高线 投影到z平面</span></span><br><span class=\"line\">ax.contourf(X,Y,Z,<span class=\"attribute\">zdir</span>=<span class=\"string\">'z'</span>,offset=-2,cmap=plt.get_cmap('rainbow'))#把图像进行投影的图形 offset表示比0坐标轴低两个位置</span><br><span class=\"line\">ax.set_zlim(-2,2)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311194735746?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片15\"></p>\n<h3 id=\"6-多图合并显示\"><a href=\"#6-多图合并显示\" class=\"headerlink\" title=\"6.多图合并显示\"></a>6.多图合并显示</h3><h4 id=\"6-1Subplot多合一显示\"><a href=\"#6-1Subplot多合一显示\" class=\"headerlink\" title=\"6.1Subplot多合一显示\"></a>6.1Subplot多合一显示</h4><p>均匀图中图：MatPlotLib可以组合许多的小图在大图中显示，使用的方法叫做subplot。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>)<span class=\"comment\">#表示整个图像分割成2行2列，当前位置为1</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>])<span class=\"comment\">#横坐标变化为[0,1] 竖坐标变化为[0,2]</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">6</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">4</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图片16.png\" alt=\"图片16\"></p>\n<p>不均匀图中图</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>)<span class=\"comment\">#将整个窗口分割成2行1列，当前位置表示第一个图</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>])<span class=\"comment\">#横坐标变化为[0,1],竖坐标变化为[0,1]</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)<span class=\"comment\">#将整个窗口分割成2行3列，当前位置为4</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">6</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">4</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图片17.png\" alt=\"图片17\"></p>\n<h4 id=\"6-2SubPlot分格显示\"><a href=\"#6-2SubPlot分格显示\" class=\"headerlink\" title=\"6.2SubPlot分格显示\"></a>6.2SubPlot分格显示</h4><p>方法一</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.gridspec <span class=\"keyword\">as</span> gridspec<span class=\"comment\">#引入新模块</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">使用plt.subplot2grid创建第一个小图，(3,3)表示将整个图像分割成3行3列，(0,0)表示从第0行0列开始作图，colspan=3表示列的跨度为3。colspan和rowspan缺省时默认跨度为1</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">ax1 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">0</span>, <span class=\"number\">0</span>), colspan=<span class=\"number\">3</span>)  <span class=\"comment\"># stands for axes</span></span><br><span class=\"line\">ax1.plot([<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'ax1_title'</span>)<span class=\"comment\">#设置图的标题</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将图像分割成3行3列，从第1行0列开始做图，列的跨度为2</span></span><br><span class=\"line\">ax2 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">1</span>, <span class=\"number\">0</span>), colspan=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将图像分割成3行3列，从第1行2列开始做图，行的跨度为2</span></span><br><span class=\"line\">ax3 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">1</span>, <span class=\"number\">2</span>), rowspan=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将图像分割成3行3列，从第2行0列开始做图，行与列的跨度默认为1</span></span><br><span class=\"line\">ax4 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">2</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">ax4.scatter([<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">2</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">ax4.set_xlabel(<span class=\"string\">'ax4_x'</span>)</span><br><span class=\"line\">ax4.set_ylabel(<span class=\"string\">'ax4_y'</span>)</span><br><span class=\"line\">ax5 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">2</span>, <span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像18.png\" alt=\"图像18\"></p>\n<p>方法二</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure()</span><br><span class=\"line\">gs = gridspec.GridSpec(<span class=\"number\">3</span>, <span class=\"number\">3</span>)<span class=\"comment\">#将图像分割成3行3列</span></span><br><span class=\"line\">ax6 = plt.subplot(gs[<span class=\"number\">0</span>, :])<span class=\"comment\">#gs[0:1]表示图占第0行和所有列</span></span><br><span class=\"line\">ax7 = plt.subplot(gs[<span class=\"number\">1</span>, :<span class=\"number\">2</span>])<span class=\"comment\">#gs[1,:2]表示图占第1行和第二列前的所有列</span></span><br><span class=\"line\">ax8 = plt.subplot(gs[<span class=\"number\">1</span>:, <span class=\"number\">2</span>])</span><br><span class=\"line\">ax9 = plt.subplot(gs[<span class=\"number\">-1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\">ax10 = plt.subplot(gs[<span class=\"number\">-1</span>, <span class=\"number\">-2</span>])<span class=\"comment\">#gs[-1.-2]表示这个图占倒数第1行和倒数第2行</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像19.png\" alt=\"图像19\"></p>\n<p>方法三</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">建立一个2行2列的图像窗口，sharex=True表示共享x轴坐标，sharey=True表示共享y轴坐标，((ax11,ax12),(ax13,1x14))表示从到至右一次存放ax11,ax12,ax13,ax114</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">f, ((ax11, ax12), (ax13, ax14)) = plt.subplots(<span class=\"number\">2</span>, <span class=\"number\">2</span>, sharex=<span class=\"keyword\">True</span>, sharey=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">ax11.scatter([<span class=\"number\">1</span>,<span class=\"number\">2</span>], [<span class=\"number\">1</span>,<span class=\"number\">2</span>])ax11.scatter 坐标范围x为[<span class=\"number\">1</span>,<span class=\"number\">2</span>]，y为[<span class=\"number\">1</span>,<span class=\"number\">2</span>]</span><br><span class=\"line\">plt.tight_layout()<span class=\"comment\">#表示紧凑显示图像</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像20.png\" alt=\"图像21\"></p>\n<h4 id=\"6-3图中图\"><a href=\"#6-3图中图\" class=\"headerlink\" title=\"6.3图中图\"></a>6.3图中图</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fig=plt.figure()</span><br><span class=\"line\"><span class=\"comment\">#创建数据</span></span><br><span class=\"line\">x=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>,<span class=\"number\">7</span>]</span><br><span class=\"line\">y=[<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>,<span class=\"number\">8</span>,<span class=\"number\">6</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘制大图：假设大图的大小为10，那么大图被包含在由(1,1)开始，宽8高8的坐标系之中。</span></span><br><span class=\"line\">left, bottom, width, height = <span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.8</span>, <span class=\"number\">0.8</span></span><br><span class=\"line\">ax1 = fig.add_axes([left, bottom, width, height])  <span class=\"comment\"># main axes</span></span><br><span class=\"line\">ax1.plot(x, y, <span class=\"string\">'r'</span>)<span class=\"comment\">#绘制大图，颜色为red</span></span><br><span class=\"line\">ax1.set_xlabel(<span class=\"string\">'x'</span>)<span class=\"comment\">#横坐标名称为x</span></span><br><span class=\"line\">ax1.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'title'</span>)<span class=\"comment\">#图名称为title</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘制小图，注意坐标系位置和大小的改变</span></span><br><span class=\"line\">ax2 = fig.add_axes([<span class=\"number\">0.2</span>, <span class=\"number\">0.6</span>, <span class=\"number\">0.25</span>, <span class=\"number\">0.25</span>])</span><br><span class=\"line\">ax2.plot(y, x, <span class=\"string\">'b'</span>)<span class=\"comment\">#颜色为buue</span></span><br><span class=\"line\">ax2.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax2.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'title inside 1'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘制第二个小兔</span></span><br><span class=\"line\">plt.axes([<span class=\"number\">0.6</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.25</span>, <span class=\"number\">0.25</span>])</span><br><span class=\"line\">plt.plot(y[::<span class=\"number\">-1</span>], x, <span class=\"string\">'g'</span>)<span class=\"comment\">#将y进行逆序</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'title inside 2'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像21.png\" alt=\"图像21\"></p>\n<h4 id=\"6-4次坐标轴\"><a href=\"#6-4次坐标轴\" class=\"headerlink\" title=\"6.4次坐标轴\"></a>6.4次坐标轴</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.arange(<span class=\"number\">0</span>,<span class=\"number\">10</span>,<span class=\"number\">0.1</span>)</span><br><span class=\"line\">y1=<span class=\"number\">0.5</span>*x**<span class=\"number\">2</span></span><br><span class=\"line\">y2=<span class=\"number\">-1</span>*y1</span><br><span class=\"line\">fig, ax1 = plt.subplots()</span><br><span class=\"line\"></span><br><span class=\"line\">ax2 = ax1.twinx()<span class=\"comment\">#镜像显示</span></span><br><span class=\"line\">ax1.plot(x, y1, <span class=\"string\">'g-'</span>)</span><br><span class=\"line\">ax2.plot(x, y2, <span class=\"string\">'b-'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax1.set_xlabel(<span class=\"string\">'X data'</span>)</span><br><span class=\"line\">ax1.set_ylabel(<span class=\"string\">'Y1 data'</span>, color=<span class=\"string\">'g'</span>)<span class=\"comment\">#第一个y坐标轴</span></span><br><span class=\"line\">ax2.set_ylabel(<span class=\"string\">'Y2 data'</span>, color=<span class=\"string\">'b'</span>)<span class=\"comment\">#第二个y坐标轴</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像22.png\" alt=\"图像22\"></p>\n<h3 id=\"7-动画\"><a href=\"#7-动画\" class=\"headerlink\" title=\"7.动画\"></a>7.动画</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> animation<span class=\"comment\">#引入新模块</span></span><br><span class=\"line\">fig,ax=plt.subplots()</span><br><span class=\"line\">x=np.arange(<span class=\"number\">0</span>,<span class=\"number\">2</span>*np.pi,<span class=\"number\">0.01</span>)<span class=\"comment\">#数据为0~2PI范围内的正弦曲线</span></span><br><span class=\"line\">line,=ax.plot(x,np.sin(x))<span class=\"comment\"># line表示列表</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造自定义动画函数animate，用来更新每一帧上x和y坐标值，参数表示第i帧</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">animate</span><span class=\"params\">(i)</span>:</span></span><br><span class=\"line\">    line.set_ydata(np.sin(x+i/<span class=\"number\">100</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> line,</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造开始帧函数init</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">init</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    line.set_ydata(np.sin(x))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> line,</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># frame表示动画长度，一次循环所包含的帧数；interval表示更新频率 </span></span><br><span class=\"line\"><span class=\"comment\"># blit选择更新所有点，还是仅更新新变化产生的点。应该选True，但mac用户选择False。</span></span><br><span class=\"line\">ani=animation.FuncAnimation(fig=fig,func=animate,frames=<span class=\"number\">200</span>,init_func=init,interval=<span class=\"number\">20</span>,blit=<span class=\"keyword\">False</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像23.png\" alt=\"图像23\"></p>\n<p><strong>MatPlotLib之中还有很多画图方法，由于篇幅有限不再赘述，更多内容参考MatPlotLib Tutorials。</strong></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-Matplotlib简介\"><a href=\"#1-Matplotlib简介\" class=\"headerlink\" title=\"1.Matplotlib简介\"></a>1.Matplotlib简介</h3><ol>\n<li>Matplotlib是非常强大的python画图工具</li>\n<li>Matplotlib可以画图线图、散点图、等高线图、条形图、柱形图、3D图形、图形动画等。 </li>\n</ol>\n<h3 id=\"2-Matplotlib安装\"><a href=\"#2-Matplotlib安装\" class=\"headerlink\" title=\"2.Matplotlib安装\"></a>2.Matplotlib安装</h3><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip3 <span class=\"keyword\">install</span> matplotlib<span class=\"comment\">#python3</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"3-Matplotlib引入\"><a href=\"#3-Matplotlib引入\" class=\"headerlink\" title=\"3.Matplotlib引入\"></a>3.Matplotlib引入</h3><figure class=\"highlight capnproto\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt<span class=\"comment\">#为方便简介为plt</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np<span class=\"comment\">#画图过程中会使用numpy</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd<span class=\"comment\">#画图过程中会使用pandas</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-Matplotlib基本应用\"><a href=\"#4-Matplotlib基本应用\" class=\"headerlink\" title=\"4.Matplotlib基本应用\"></a>4.Matplotlib基本应用</h3><figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-1,1,50)<span class=\"comment\">#定义x数据范围</span></span><br><span class=\"line\">y1=2*x+1<span class=\"comment\">#定义y数据范围</span></span><br><span class=\"line\">y2=x**2</span><br><span class=\"line\">plt.figure()<span class=\"comment\">#定义一个图像窗口</span></span><br><span class=\"line\">plt.plot(x,y)<span class=\"comment\">#plot()画出曲线</span></span><br><span class=\"line\">plt.show()<span class=\"comment\">#显示图像</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311144537863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片01\"></p>\n<h4 id=\"4-1figure图像\"><a href=\"#4-1figure图像\" class=\"headerlink\" title=\"4.1figure图像\"></a>4.1figure图像</h4><p>matplotlib的figure为单独图像窗口，小窗口内还可以有更多的小图片。<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)#<span class=\"number\">50</span>为生成的样本数</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">1</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))#定义编号为<span class=\"number\">1</span> 大小为(<span class=\"number\">8</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='--')#颜色为红色，线宽度为<span class=\"number\">2</span>，线风格为--</span><br><span class=\"line\">plt.plot(x,y2)#进行画图</span><br><span class=\"line\">plt.show()#显示图</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311145427674?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片02\"></p>\n<h4 id=\"4-2设置坐标轴\"><a href=\"#4-2设置坐标轴\" class=\"headerlink\" title=\"4.2设置坐标轴\"></a>4.2设置坐标轴</h4><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='-')</span><br><span class=\"line\">plt.plot(x,y2)#进行画图</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">\"I'm x\"</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">\"I'm y\"</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311151115803?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片03\"><br>自定义坐标轴<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='-')</span><br><span class=\"line\">plt.plot(x,y2)#进行画图</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">\"I'm x\"</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">\"I'm y\"</span>)</span><br><span class=\"line\">new_ticks=np.linspace(<span class=\"number\">-1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)#小标从<span class=\"number\">-1</span>到<span class=\"number\">2</span>分为<span class=\"number\">5</span>个单位</span><br><span class=\"line\">print(new_ticks)</span><br><span class=\"line\">#[<span class=\"number\">-1.</span>   <span class=\"number\">-0.25</span>  <span class=\"number\">0.5</span>   <span class=\"number\">1.25</span>  <span class=\"number\">2.</span>  ]</span><br><span class=\"line\">plt.xticks(new_ticks)#进行替换新下标</span><br><span class=\"line\">plt.yticks([<span class=\"number\">-2</span>,<span class=\"number\">-1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/2018031115185255?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片04\"><br>设置边框属性<br><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color=<span class=\"string\">'red'</span>,linewidth=<span class=\"number\">2</span>,linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\">plt.plot(x,y2)<span class=\"comment\">#进行画图</span></span><br><span class=\"line\">plt.xlim(-<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(-<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">new_ticks=np.linspace(-<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)<span class=\"comment\">#小标从-1到2分为5个单位</span></span><br><span class=\"line\">plt.xticks(new_ticks)<span class=\"comment\">#进行替换新下标</span></span><br><span class=\"line\">plt.yticks([-<span class=\"number\">2</span>,-<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [<span class=\"string\">r'$really\\ bad$'</span>,<span class=\"string\">'$bad$'</span>,<span class=\"string\">'$well$'</span>,<span class=\"string\">'$really\\ well$'</span>])</span><br><span class=\"line\">ax=plt.gca()<span class=\"comment\">#gca=get current axis</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)<span class=\"comment\">#边框属性设置为none 不显示</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311152822953?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片05\"><br>调整移动坐标轴<br><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x,y1,color=<span class=\"string\">'red'</span>,linewidth=<span class=\"number\">2</span>,linestyle=<span class=\"string\">'--'</span>)</span><br><span class=\"line\">plt.plot(x,y2)<span class=\"comment\">#进行画图</span></span><br><span class=\"line\">plt.xlim(-<span class=\"number\">1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(-<span class=\"number\">2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">new_ticks=np.linspace(-<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)<span class=\"comment\">#小标从-1到2分为5个单位</span></span><br><span class=\"line\">plt.xticks(new_ticks)<span class=\"comment\">#进行替换新下标</span></span><br><span class=\"line\">plt.yticks([-<span class=\"number\">2</span>,-<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [<span class=\"string\">r'$really\\ bad$'</span>,<span class=\"string\">'$bad$'</span>,<span class=\"string\">'$well$'</span>,<span class=\"string\">'$really\\ well$'</span>])</span><br><span class=\"line\">ax=plt.gca()<span class=\"comment\">#gca=get current axis</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)<span class=\"comment\">#边框属性设置为none 不显示</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.xaxis.set_ticks_position(<span class=\"string\">'bottom'</span>)<span class=\"comment\">#使用xaxis.set_ticks_position设置x坐标刻度数字或名称的位置 所有属性为top、bottom、both、default、none</span></span><br><span class=\"line\">ax.spines[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))<span class=\"comment\">#使用.spines设置边框x轴；使用.set_position设置边框位置，y=0位置 位置所有属性有outward、axes、data</span></span><br><span class=\"line\">ax.yaxis.set_ticks_position(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>,<span class=\"number\">0</span>))<span class=\"comment\">#坐标中心点在(0,0)位置</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311153109404?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"这里写图片描述\"></p>\n<h4 id=\"4-3添加图例\"><a href=\"#4-3添加图例\" class=\"headerlink\" title=\"4.3添加图例\"></a>4.3添加图例</h4><p>matplotlib中legend图例帮助我们展示数据对应的图像名称。<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(<span class=\"number\">-3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y1=<span class=\"number\">2</span>*x+<span class=\"number\">1</span></span><br><span class=\"line\">y2=x**<span class=\"number\">2</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">2</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-1</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.ylim(<span class=\"number\">-2</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">new_ticks=np.linspace(<span class=\"number\">-1</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>)#小标从<span class=\"number\">-1</span>到<span class=\"number\">2</span>分为<span class=\"number\">5</span>个单位</span><br><span class=\"line\">plt.xticks(new_ticks)#进行替换新下标</span><br><span class=\"line\">plt.yticks([<span class=\"number\">-2</span>,<span class=\"number\">-1</span>,<span class=\"number\">1</span>,<span class=\"number\">2</span>,],</span><br><span class=\"line\">           [r'$really\\ bad$','$bad$','$well$','$really\\ well$'])</span><br><span class=\"line\"></span><br><span class=\"line\">l1,=plt.plot(x,y1,color='red',linewidth=<span class=\"number\">2</span>,linestyle='--',label='linear line')</span><br><span class=\"line\">l2,=plt.plot(x,y2,label='square line')#进行画图</span><br><span class=\"line\">plt.legend(loc='best')#显示在最好的位置</span><br><span class=\"line\">plt.show()#显示图</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311163819992?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片07\"><br>调整位置和名称，单独修改label信息，我们可以在plt.legend输入更多参数<br><figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.legend(handles=[l1, l2], labels=[<span class=\"symbol\">'up</span>', <span class=\"symbol\">'down</span>'],  loc=<span class=\"symbol\">'best</span>')</span><br><span class=\"line\">#loc有很多参数 其中best自分配最佳位置</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"> <span class=\"symbol\">'best</span>' : 0,          </span><br><span class=\"line\"> <span class=\"symbol\">'upper</span> right'  : 1,</span><br><span class=\"line\"> <span class=\"symbol\">'upper</span> left'   : 2,</span><br><span class=\"line\"> <span class=\"symbol\">'lower</span> left'   : 3,</span><br><span class=\"line\"> <span class=\"symbol\">'lower</span> right'  : 4,</span><br><span class=\"line\"> <span class=\"symbol\">'right</span>'        : 5,</span><br><span class=\"line\"> <span class=\"symbol\">'center</span> left'  : 6,</span><br><span class=\"line\"> <span class=\"symbol\">'center</span> right' : 7,</span><br><span class=\"line\"> <span class=\"symbol\">'lower</span> center' : 8,</span><br><span class=\"line\"> <span class=\"symbol\">'upper</span> center' : 9,</span><br><span class=\"line\"> <span class=\"symbol\">'center</span>'       : 10,</span><br><span class=\"line\"> <span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"4-4标注\"><a href=\"#4-4标注\" class=\"headerlink\" title=\"4.4标注\"></a>4.4标注</h4><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>,<span class=\"number\">3</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">y = <span class=\"number\">2</span>*x + <span class=\"number\">1</span></span><br><span class=\"line\">plt.figure(num=<span class=\"number\">1</span>, figsize=(<span class=\"number\">8</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">plt.plot(x, y,)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#移动坐标轴</span></span><br><span class=\"line\">ax = plt.gca()</span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.xaxis.set_ticks_position(<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">ax.yaxis.set_ticks_position(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#标注信息</span></span><br><span class=\"line\">x0=<span class=\"number\">1</span></span><br><span class=\"line\">y0=<span class=\"number\">2</span>*x0+<span class=\"number\">1</span></span><br><span class=\"line\">plt.scatter(x0,y0,s=<span class=\"number\">50</span>,color=<span class=\"string\">'b'</span>)</span><br><span class=\"line\">plt.plot([x0,x0],[y0,<span class=\"number\">0</span>],<span class=\"string\">'k--'</span>,lw=<span class=\"number\">2.5</span>)<span class=\"comment\">#连接(x0,y0)(x0,0) k表示黑色 lw=2.5表示线粗细</span></span><br><span class=\"line\"><span class=\"comment\">#xycoords='data'是基于数据的值来选位置，xytext=(+30,-30)和textcoords='offset points'对于标注位置描述和xy偏差值，arrowprops对图中箭头类型设置</span></span><br><span class=\"line\">plt.annotate(<span class=\"string\">r'$2x0+1=%s$'</span> % y0, xy=(x0, y0), xycoords=<span class=\"string\">'data'</span>, xytext=(+<span class=\"number\">30</span>, -<span class=\"number\">30</span>),</span><br><span class=\"line\">             textcoords=<span class=\"string\">'offset points'</span>, fontsize=<span class=\"number\">16</span>,</span><br><span class=\"line\">             arrowprops=dict(arrowstyle=<span class=\"string\">'-&gt;'</span>, connectionstyle=<span class=\"string\">\"arc3,rad=.2\"</span>))</span><br><span class=\"line\"><span class=\"comment\">#添加注视text（-3.7,3）表示选取text位置 空格需要用\\进行转译 fontdict设置文本字体             </span></span><br><span class=\"line\">plt.text(-<span class=\"number\">3.7</span>, <span class=\"number\">3</span>, <span class=\"string\">r'$This\\ is\\ the\\ some\\ text. \\mu\\ \\sigma_i\\ \\alpha_t$'</span>,</span><br><span class=\"line\">         fontdict=&#123;<span class=\"string\">'size'</span>: <span class=\"number\">16</span>, <span class=\"string\">'color'</span>: <span class=\"string\">'r'</span>&#125;)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/2018031116474811?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片08\"></p>\n<h4 id=\"4-5能见度调整\"><a href=\"#4-5能见度调整\" class=\"headerlink\" title=\"4.5能见度调整\"></a>4.5能见度调整</h4><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.linspace(-<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">50</span>)</span><br><span class=\"line\">y=<span class=\"number\">0.1</span>*x</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(x, y, linewidth=<span class=\"number\">10</span>, zorder=<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.ylim(-<span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">#移动坐标轴</span><br><span class=\"line\">ax = plt.gca()</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.xaxis</span><span class=\"selector-class\">.set_ticks_position</span>(<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">ax<span class=\"selector-class\">.yaxis</span><span class=\"selector-class\">.set_ticks_position</span>(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax<span class=\"selector-class\">.spines</span>[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"selector-id\">#label</span>.set_fontsize(<span class=\"number\">12</span>)重新调整字体大小 bbox设置目的内容的透明度相关参数 facecolor调节box前景色 edgecolor设置边框 alpha设置透明度 zorder设置图层顺序</span><br><span class=\"line\"><span class=\"keyword\">for</span> <span class=\"selector-tag\">label</span> <span class=\"keyword\">in</span> ax.get_xticklabels() + ax.get_yticklabels():</span><br><span class=\"line\">    <span class=\"selector-tag\">label</span>.set_fontsize(<span class=\"number\">12</span>)</span><br><span class=\"line\">    <span class=\"selector-tag\">label</span>.set_bbox(dict(facecolor=<span class=\"string\">'red'</span>, edgecolor=<span class=\"string\">'None'</span>, alpha=<span class=\"number\">0.7</span>, zorder=<span class=\"number\">2</span>))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311172352949?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片09\"></p>\n<h3 id=\"5-画图种类\"><a href=\"#5-画图种类\" class=\"headerlink\" title=\"5.画图种类\"></a>5.画图种类</h3><h4 id=\"5-1Scatter散点图\"><a href=\"#5-1Scatter散点图\" class=\"headerlink\" title=\"5.1Scatter散点图\"></a>5.1Scatter散点图</h4><figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">n=1024</span><br><span class=\"line\">X=np.random.normal(0,1,n)<span class=\"comment\">#每一个点的X值</span></span><br><span class=\"line\">Y=np.random.normal(0,1,n)<span class=\"comment\">#每一个点的Y值</span></span><br><span class=\"line\">T=np.arctan2(Y,X)<span class=\"comment\">#arctan2返回给定的X和Y值的反正切值</span></span><br><span class=\"line\"><span class=\"comment\">#scatter画散点图 size=75 颜色为T 透明度为50% 利用xticks函数来隐藏x坐标轴</span></span><br><span class=\"line\">plt.scatter(X,Y,s=75,c=T,alpha=0.5)</span><br><span class=\"line\">plt.xlim(-1.5,1.5)</span><br><span class=\"line\">plt.xticks(())<span class=\"comment\">#忽略xticks</span></span><br><span class=\"line\">plt.ylim(-1.5,1.5)</span><br><span class=\"line\">plt.yticks(())<span class=\"comment\">#忽略yticks</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311174847167?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片10\"></p>\n<h4 id=\"5-2条形图\"><a href=\"#5-2条形图\" class=\"headerlink\" title=\"5.2条形图\"></a>5.2条形图</h4><figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#基本图形</span></span><br><span class=\"line\">n=<span class=\"number\">12</span></span><br><span class=\"line\">X=np.arange(n)</span><br><span class=\"line\">Y1=(<span class=\"number\">1</span>-X/float(n))*np.<span class=\"built_in\">random</span>.uniform(<span class=\"number\">0.5</span>,<span class=\"number\">1</span>,n)</span><br><span class=\"line\">Y2=(<span class=\"number\">1</span>-X/float(n))*np.<span class=\"built_in\">random</span>.uniform(<span class=\"number\">0.5</span>,<span class=\"number\">1</span>,n)</span><br><span class=\"line\">plt.bar(X,+Y1,facecolor=<span class=\"string\">'#9999ff'</span>,edgecolor=<span class=\"string\">'white'</span>)</span><br><span class=\"line\">plt.bar(X,-Y2,facecolor=<span class=\"string\">'#ff9999'</span>,edgecolor=<span class=\"string\">'white'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#标记值</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> x,y <span class=\"keyword\">in</span> zip(X,Y1):<span class=\"comment\">#zip表示可以传递两个值</span></span><br><span class=\"line\">    plt.<span class=\"keyword\">text</span>(x+<span class=\"number\">0.4</span>,y+<span class=\"number\">0.05</span>,<span class=\"string\">'%.2f'</span>%y,ha=<span class=\"string\">'center'</span>,va=<span class=\"string\">'bottom'</span>)<span class=\"comment\">#ha表示横向对齐 bottom表示向下对齐</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> x,y <span class=\"keyword\">in</span> zip(X,Y2):</span><br><span class=\"line\">    plt.<span class=\"keyword\">text</span>(x+<span class=\"number\">0.4</span>,-y<span class=\"number\">-0.05</span>,<span class=\"string\">'%.2f'</span>%y,ha=<span class=\"string\">'center'</span>,va=<span class=\"string\">'top'</span>)</span><br><span class=\"line\">plt.xlim(<span class=\"number\">-0.5</span>,n)</span><br><span class=\"line\">plt.xticks(())<span class=\"comment\">#忽略xticks</span></span><br><span class=\"line\">plt.ylim(<span class=\"number\">-1.25</span>,<span class=\"number\">1.25</span>)</span><br><span class=\"line\">plt.yticks(())<span class=\"comment\">#忽略yticks</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311181815729?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片11\"></p>\n<h4 id=\"5-3等高线图\"><a href=\"#5-3等高线图\" class=\"headerlink\" title=\"5.3等高线图\"></a>5.3等高线图</h4><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">n</span>=256</span><br><span class=\"line\"><span class=\"attribute\">x</span>=np.linspace(-3,3,n)</span><br><span class=\"line\"><span class=\"attribute\">y</span>=np.linspace(-3,3,n)</span><br><span class=\"line\">X,<span class=\"attribute\">Y</span>=np.meshgrid(x,y)#meshgrid从坐标向量返回坐标矩阵</span><br><span class=\"line\"><span class=\"comment\">#f函数用来计算高度值 利用contour函数把颜色加进去 位置参数依次为x,y,f(x,y)，透明度为0.75，并将f(x,y)的值对应到camp之中</span></span><br><span class=\"line\">def f(x,y):</span><br><span class=\"line\">    return (1 - x / 2 + x ** 5 + y ** 3) * np.exp(-x ** 2 - y ** 2)</span><br><span class=\"line\">plt.contourf(X,Y,f(X,Y),8,<span class=\"attribute\">alpha</span>=0.75,cmap=plt.cm.hot)#8表示等高线分成多少份 alpha表示透明度 cmap表示color map</span><br><span class=\"line\"><span class=\"comment\">#使用plt.contour函数进行等高线绘制 参数依次为x,y,f(x,y)，颜色选择黑色，线条宽度为0.5</span></span><br><span class=\"line\"><span class=\"attribute\">C</span>=plt.contour(X,Y,f(X,Y),8,colors='black',linewidth=0.5)</span><br><span class=\"line\"><span class=\"comment\">#使用plt.clabel添加高度数值 inline控制是否将label画在线里面，字体大小为10</span></span><br><span class=\"line\">plt.clabel(C,<span class=\"attribute\">inline</span>=<span class=\"literal\">True</span>,fontsize=10)</span><br><span class=\"line\">plt.xticks(())#隐藏坐标轴</span><br><span class=\"line\">plt.yticks(())</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311182506284?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片12\"></p>\n<h4 id=\"5-4Image图片\"><a href=\"#5-4Image图片\" class=\"headerlink\" title=\"5.4Image图片\"></a>5.4Image图片</h4><p>利用matplotlib打印出图像<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = np.array([<span class=\"number\">0.313660827978</span>, <span class=\"number\">0.365348418405</span>, <span class=\"number\">0.423733120134</span>,</span><br><span class=\"line\">              <span class=\"number\">0.365348418405</span>, <span class=\"number\">0.439599930621</span>, <span class=\"number\">0.525083754405</span>,</span><br><span class=\"line\">              <span class=\"number\">0.423733120134</span>, <span class=\"number\">0.525083754405</span>, <span class=\"number\">0.651536351379</span>]).reshape(<span class=\"number\">3</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">#origin='lower'代表的就是选择的原点位置</span><br><span class=\"line\">plt.imshow(a,interpolation='nearest',cmap='bone',origin='lower')#cmap为color map</span><br><span class=\"line\">plt.colorbar(shrink=<span class=\"number\">.92</span>)#右边颜色说明 shrink参数是将图片长度变为原来的<span class=\"number\">92</span>%</span><br><span class=\"line\">plt.xticks(())</span><br><span class=\"line\">plt.yticks(())</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://img.blog.csdn.net/20180311192757270?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片13\"><br>出图方式 此处采用内插法中的nearest-neighbor<br><img src=\"http://img.blog.csdn.net/20180311193343476?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片14\"></p>\n<h4 id=\"5-53D图像\"><a href=\"#5-53D图像\" class=\"headerlink\" title=\"5.53D图像\"></a>5.53D图像</h4><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">import matplotlib.pyplot as plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d import Axes3D#需另外导入模块Axes 3D</span><br><span class=\"line\"><span class=\"attribute\">fig</span>=plt.figure()#定义图像窗口</span><br><span class=\"line\"><span class=\"attribute\">ax</span>=Axes3D(fig)#在窗口上添加3D坐标轴</span><br><span class=\"line\"><span class=\"comment\">#将X和Y值编织成栅格</span></span><br><span class=\"line\"><span class=\"attribute\">X</span>=np.arange(-4,4,0.25)</span><br><span class=\"line\"><span class=\"attribute\">Y</span>=np.arange(-4,4,0.25)</span><br><span class=\"line\">X,<span class=\"attribute\">Y</span>=np.meshgrid(X,Y)</span><br><span class=\"line\"><span class=\"attribute\">R</span>=np.sqrt(X**2+Y**2)</span><br><span class=\"line\"><span class=\"attribute\">Z</span>=np.sin(R)#高度值</span><br><span class=\"line\"><span class=\"comment\">#将colormap rainbow填充颜色，之后将三维图像投影到XY平面做等高线图，其中ratride和cstride表示row和column的宽度</span></span><br><span class=\"line\">ax.plot_surface(X,Y,Z,<span class=\"attribute\">rstride</span>=1,cstride=1,cmap=plt.get_cmap('rainbow'))#rstride表示图像中分割线的跨图</span><br><span class=\"line\"><span class=\"comment\">#添加XY平面等高线 投影到z平面</span></span><br><span class=\"line\">ax.contourf(X,Y,Z,<span class=\"attribute\">zdir</span>=<span class=\"string\">'z'</span>,offset=-2,cmap=plt.get_cmap('rainbow'))#把图像进行投影的图形 offset表示比0坐标轴低两个位置</span><br><span class=\"line\">ax.set_zlim(-2,2)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://img.blog.csdn.net/20180311194735746?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"图片15\"></p>\n<h3 id=\"6-多图合并显示\"><a href=\"#6-多图合并显示\" class=\"headerlink\" title=\"6.多图合并显示\"></a>6.多图合并显示</h3><h4 id=\"6-1Subplot多合一显示\"><a href=\"#6-1Subplot多合一显示\" class=\"headerlink\" title=\"6.1Subplot多合一显示\"></a>6.1Subplot多合一显示</h4><p>均匀图中图：MatPlotLib可以组合许多的小图在大图中显示，使用的方法叫做subplot。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>)<span class=\"comment\">#表示整个图像分割成2行2列，当前位置为1</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>])<span class=\"comment\">#横坐标变化为[0,1] 竖坐标变化为[0,2]</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">6</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">4</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图片16.png\" alt=\"图片16\"></p>\n<p>不均匀图中图</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>)<span class=\"comment\">#将整个窗口分割成2行1列，当前位置表示第一个图</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">1</span>])<span class=\"comment\">#横坐标变化为[0,1],竖坐标变化为[0,1]</span></span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>)<span class=\"comment\">#将整个窗口分割成2行3列，当前位置为4</span></span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">2</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">6</span>)</span><br><span class=\"line\">plt.plot([<span class=\"number\">0</span>,<span class=\"number\">1</span>],[<span class=\"number\">0</span>,<span class=\"number\">4</span>])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图片17.png\" alt=\"图片17\"></p>\n<h4 id=\"6-2SubPlot分格显示\"><a href=\"#6-2SubPlot分格显示\" class=\"headerlink\" title=\"6.2SubPlot分格显示\"></a>6.2SubPlot分格显示</h4><p>方法一</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.gridspec <span class=\"keyword\">as</span> gridspec<span class=\"comment\">#引入新模块</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">使用plt.subplot2grid创建第一个小图，(3,3)表示将整个图像分割成3行3列，(0,0)表示从第0行0列开始作图，colspan=3表示列的跨度为3。colspan和rowspan缺省时默认跨度为1</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">ax1 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">0</span>, <span class=\"number\">0</span>), colspan=<span class=\"number\">3</span>)  <span class=\"comment\"># stands for axes</span></span><br><span class=\"line\">ax1.plot([<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">1</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'ax1_title'</span>)<span class=\"comment\">#设置图的标题</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将图像分割成3行3列，从第1行0列开始做图，列的跨度为2</span></span><br><span class=\"line\">ax2 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">1</span>, <span class=\"number\">0</span>), colspan=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将图像分割成3行3列，从第1行2列开始做图，行的跨度为2</span></span><br><span class=\"line\">ax3 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">1</span>, <span class=\"number\">2</span>), rowspan=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将图像分割成3行3列，从第2行0列开始做图，行与列的跨度默认为1</span></span><br><span class=\"line\">ax4 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">2</span>, <span class=\"number\">0</span>))</span><br><span class=\"line\">ax4.scatter([<span class=\"number\">1</span>, <span class=\"number\">2</span>], [<span class=\"number\">2</span>, <span class=\"number\">2</span>])</span><br><span class=\"line\">ax4.set_xlabel(<span class=\"string\">'ax4_x'</span>)</span><br><span class=\"line\">ax4.set_ylabel(<span class=\"string\">'ax4_y'</span>)</span><br><span class=\"line\">ax5 = plt.subplot2grid((<span class=\"number\">3</span>, <span class=\"number\">3</span>), (<span class=\"number\">2</span>, <span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像18.png\" alt=\"图像18\"></p>\n<p>方法二</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.figure()</span><br><span class=\"line\">gs = gridspec.GridSpec(<span class=\"number\">3</span>, <span class=\"number\">3</span>)<span class=\"comment\">#将图像分割成3行3列</span></span><br><span class=\"line\">ax6 = plt.subplot(gs[<span class=\"number\">0</span>, :])<span class=\"comment\">#gs[0:1]表示图占第0行和所有列</span></span><br><span class=\"line\">ax7 = plt.subplot(gs[<span class=\"number\">1</span>, :<span class=\"number\">2</span>])<span class=\"comment\">#gs[1,:2]表示图占第1行和第二列前的所有列</span></span><br><span class=\"line\">ax8 = plt.subplot(gs[<span class=\"number\">1</span>:, <span class=\"number\">2</span>])</span><br><span class=\"line\">ax9 = plt.subplot(gs[<span class=\"number\">-1</span>, <span class=\"number\">0</span>])</span><br><span class=\"line\">ax10 = plt.subplot(gs[<span class=\"number\">-1</span>, <span class=\"number\">-2</span>])<span class=\"comment\">#gs[-1.-2]表示这个图占倒数第1行和倒数第2行</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像19.png\" alt=\"图像19\"></p>\n<p>方法三</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">建立一个2行2列的图像窗口，sharex=True表示共享x轴坐标，sharey=True表示共享y轴坐标，((ax11,ax12),(ax13,1x14))表示从到至右一次存放ax11,ax12,ax13,ax114</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">f, ((ax11, ax12), (ax13, ax14)) = plt.subplots(<span class=\"number\">2</span>, <span class=\"number\">2</span>, sharex=<span class=\"keyword\">True</span>, sharey=<span class=\"keyword\">True</span>)</span><br><span class=\"line\">ax11.scatter([<span class=\"number\">1</span>,<span class=\"number\">2</span>], [<span class=\"number\">1</span>,<span class=\"number\">2</span>])ax11.scatter 坐标范围x为[<span class=\"number\">1</span>,<span class=\"number\">2</span>]，y为[<span class=\"number\">1</span>,<span class=\"number\">2</span>]</span><br><span class=\"line\">plt.tight_layout()<span class=\"comment\">#表示紧凑显示图像</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像20.png\" alt=\"图像21\"></p>\n<h4 id=\"6-3图中图\"><a href=\"#6-3图中图\" class=\"headerlink\" title=\"6.3图中图\"></a>6.3图中图</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fig=plt.figure()</span><br><span class=\"line\"><span class=\"comment\">#创建数据</span></span><br><span class=\"line\">x=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>,<span class=\"number\">7</span>]</span><br><span class=\"line\">y=[<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">5</span>,<span class=\"number\">8</span>,<span class=\"number\">6</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘制大图：假设大图的大小为10，那么大图被包含在由(1,1)开始，宽8高8的坐标系之中。</span></span><br><span class=\"line\">left, bottom, width, height = <span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.8</span>, <span class=\"number\">0.8</span></span><br><span class=\"line\">ax1 = fig.add_axes([left, bottom, width, height])  <span class=\"comment\"># main axes</span></span><br><span class=\"line\">ax1.plot(x, y, <span class=\"string\">'r'</span>)<span class=\"comment\">#绘制大图，颜色为red</span></span><br><span class=\"line\">ax1.set_xlabel(<span class=\"string\">'x'</span>)<span class=\"comment\">#横坐标名称为x</span></span><br><span class=\"line\">ax1.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax1.set_title(<span class=\"string\">'title'</span>)<span class=\"comment\">#图名称为title</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘制小图，注意坐标系位置和大小的改变</span></span><br><span class=\"line\">ax2 = fig.add_axes([<span class=\"number\">0.2</span>, <span class=\"number\">0.6</span>, <span class=\"number\">0.25</span>, <span class=\"number\">0.25</span>])</span><br><span class=\"line\">ax2.plot(y, x, <span class=\"string\">'b'</span>)<span class=\"comment\">#颜色为buue</span></span><br><span class=\"line\">ax2.set_xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">ax2.set_ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">ax2.set_title(<span class=\"string\">'title inside 1'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘制第二个小兔</span></span><br><span class=\"line\">plt.axes([<span class=\"number\">0.6</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.25</span>, <span class=\"number\">0.25</span>])</span><br><span class=\"line\">plt.plot(y[::<span class=\"number\">-1</span>], x, <span class=\"string\">'g'</span>)<span class=\"comment\">#将y进行逆序</span></span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'x'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'y'</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">'title inside 2'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像21.png\" alt=\"图像21\"></p>\n<h4 id=\"6-4次坐标轴\"><a href=\"#6-4次坐标轴\" class=\"headerlink\" title=\"6.4次坐标轴\"></a>6.4次坐标轴</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x=np.arange(<span class=\"number\">0</span>,<span class=\"number\">10</span>,<span class=\"number\">0.1</span>)</span><br><span class=\"line\">y1=<span class=\"number\">0.5</span>*x**<span class=\"number\">2</span></span><br><span class=\"line\">y2=<span class=\"number\">-1</span>*y1</span><br><span class=\"line\">fig, ax1 = plt.subplots()</span><br><span class=\"line\"></span><br><span class=\"line\">ax2 = ax1.twinx()<span class=\"comment\">#镜像显示</span></span><br><span class=\"line\">ax1.plot(x, y1, <span class=\"string\">'g-'</span>)</span><br><span class=\"line\">ax2.plot(x, y2, <span class=\"string\">'b-'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">ax1.set_xlabel(<span class=\"string\">'X data'</span>)</span><br><span class=\"line\">ax1.set_ylabel(<span class=\"string\">'Y1 data'</span>, color=<span class=\"string\">'g'</span>)<span class=\"comment\">#第一个y坐标轴</span></span><br><span class=\"line\">ax2.set_ylabel(<span class=\"string\">'Y2 data'</span>, color=<span class=\"string\">'b'</span>)<span class=\"comment\">#第二个y坐标轴</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像22.png\" alt=\"图像22\"></p>\n<h3 id=\"7-动画\"><a href=\"#7-动画\" class=\"headerlink\" title=\"7.动画\"></a>7.动画</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> animation<span class=\"comment\">#引入新模块</span></span><br><span class=\"line\">fig,ax=plt.subplots()</span><br><span class=\"line\">x=np.arange(<span class=\"number\">0</span>,<span class=\"number\">2</span>*np.pi,<span class=\"number\">0.01</span>)<span class=\"comment\">#数据为0~2PI范围内的正弦曲线</span></span><br><span class=\"line\">line,=ax.plot(x,np.sin(x))<span class=\"comment\"># line表示列表</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造自定义动画函数animate，用来更新每一帧上x和y坐标值，参数表示第i帧</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">animate</span><span class=\"params\">(i)</span>:</span></span><br><span class=\"line\">    line.set_ydata(np.sin(x+i/<span class=\"number\">100</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> line,</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造开始帧函数init</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">init</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    line.set_ydata(np.sin(x))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> line,</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># frame表示动画长度，一次循环所包含的帧数；interval表示更新频率 </span></span><br><span class=\"line\"><span class=\"comment\"># blit选择更新所有点，还是仅更新新变化产生的点。应该选True，但mac用户选择False。</span></span><br><span class=\"line\">ani=animation.FuncAnimation(fig=fig,func=animate,frames=<span class=\"number\">200</span>,init_func=init,interval=<span class=\"number\">20</span>,blit=<span class=\"keyword\">False</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/14/Python之MatPlotLib使用教程/图像23.png\" alt=\"图像23\"></p>\n<p><strong>MatPlotLib之中还有很多画图方法，由于篇幅有限不再赘述，更多内容参考MatPlotLib Tutorials。</strong></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。</p>\n"},{"title":"Mac+Hexo+GitHub博客搭建教程","date":"2018-03-16T03:41:35.000Z","toc":true,"comments":1,"_content":"\n### 1.为什么写博客\n\n以前利用Jekyll+Github搭建博客，但每次博客搭建完成后都没有继续坚持写博文，直到最近找实习才认识到技术博客的重要性。以前学习的很多知识点都已经忘记啦，所以下定决心这次认真总结以前学习的知识点，认真写点技术文章。\n\n### 2.Mac+Hexo+GitHub博客\n\n现在博客主流的就是Jekyll和Hexo两种格式，选择Jekyll还是Hexo就根据个人喜好啦，但个人更推荐使用Hexo，选择Hexo的主要原因。\n\n+ Jekyll没有本地服务器，无法实现本地文章预览，需要上传到WEB容器中才能预览功能，而Hexo可以通过简单的命令实现本地预览功能，并直接发布到WEB容器中实现同步。\n+ Jekyll主题和Hexo主题对比而言，Hexo主题更加简洁美观(个人审美原因)。\n\n选择GitHub的原因不用多说，程序员的乐园，更是支持pages功能，虽然很多其他社区也支持，比如GitLab、coding、码云等，但GitHub更加活跃，自己的项目就是放在上面，所以更加方便。但GitHub有最大一点不好之处便是*百度爬虫无法爬去博客内容*，自己也找了好久解决方法，比如利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，所以暂时没什么太好的解决方法。\n\n### 3.博客本地环境搭建\n\n#### 3.1安装Node.js和Git\n\nMac上安装可以选择图形化方式和终端安装，此处直接使用客户端方式安装。Node.js官网下载文件，根据提示安装即可，安装成功后在目录*/usr/local/bin*目录下。测试Node.js和npm，出现下述信息则安装成功。\n\n```\nnode -v\nv8.10.0\n```\n\n```\nnpm -v\n5.6.0\n```\n\nGit官网下载相应文件根据提示直接进行安装，检查git是否安装成功，直接查看git版本即可。\n\n> Git --version \n>\n> git version 2.15.0\n\n#### 3.2安装Hexo\n\nNode.js和Git都安装成功后开始安装Hexo。安装时注意权限问题，加上sudo，其中-g表示全局安装。\n\n```mac\nsudo npm install -g hexo\n```\n\n#### 3.3博客初始化\n\n创建存储博客的文件，比如命名为myblog，然后进入到myblog之中。\n\n```\ncd myblog\n```\n\n执行下述命令初始化本地博客，下载一些列文件。\n\n```\nhexo init\n```\n\n执行下述命令安装npm。\n\n```\nsudo npm install\n```\n\n执行下述命令生成本地html文件并开启服务器，然后通过http://localhost:4000查看本地博客。\n\n```\nhexo g\nhexo s\n```\n\n![图片3.3](Mac+Hexo+GitHub博客搭建教程/图片3.3.png)\n\n### 4.本地博客关联GitHub\n\n#### 4.1本地博客代码上传GitHub\n\n注册并登陆GitHub账号后，新建仓库，名称必须为`user.github.io`，如`weizhixiaoyi.github.io`。\n\n![图片01](Mac+Hexo+GitHub博客搭建教程/图片4.1.png)\n\n终端cd到myblog文件夹下，打开_config.yml文件。或者用其他文本编辑器打开可以，推荐sublime。\n\n```Vim\nvim _config.yml\n```\n\n打开后至文档最后部分，将deploy配置如下。\n\n```Python\ndeploy:\n  type: git\n  repository: https://github.com/weizhixiaoyi/weizhixiaoyi.github.io.git\n  branch: master\n```\n\n其中将repository中`weizhixiaoyi`改为自己的用户名，注意type、repository、branch后均有空格。通过如下命令在myblog下生成静态文件并上传到服务器。\n\n```\nhexo g\nhexo d\n```\n\n若执行`hexo g`出错则执行`npm install hexo --save`，若执行`hexo d`出错则执行`npm install hexo-deployer-git --save `。错误修正后再次执行`hexo g`和`hexo d`。\n\n若未关联GitHub，执行`hexo d`时会提示输入GitHub账号用户名和密码，即:\n\n```\nusername for 'https://github.com':\npassword for 'https://github.com':\n```\n\n`hexo d`执行成功后便可通过https://weizhixiaoyi.github.io访问博客，看到的内容和http://localhost:4000相同。\n\n#### 4.2添加ssh keys到GitHub\n\n添加ssh key后不需要每次更新博客再输入用户名和密码。首先检查本地是否包含ssh keys。如果存在则直接将ssh key添加到GitHub之中，否则进入新生成ssh key。\n\n执行下述命令生成新的ssh key，将`your_email@example.com`改成自己以注册的GitHub邮箱地址。默认会在`~/.ssh/id_rsa.pub`中生成`id_rsa`和`id_rsa.pub`文件。\n\n```\nssh-keygen -t rsa -C \"your_email@exampl\"\t\t\n```\n\nMac下利用`open ~/.ssh  `打开文件夹，打开id_rsa.pub文件，里面的信息即为ssh key，将此信息复制到GitHub的Add ssh key`路径GitHub->Setting->SSH keys->add SSH key`界面即可。Title里填写任意标题，将复制的内容粘贴到key中，点击Add key完成添加。\n\n此时本地博客内容便已关联到GitHub之中，本地博客改变之后，通过`hexo g`和`hexo d`便可更新到GitHub之中，通过https://weizhixiaoyi.github.io访问便可看到更新内容。\n\n### 5.更换Hexo主题\n\n可以选择Hexo主题官网页面搜索喜欢的theme，这里我选择hexo-theme-next当作自己主题，hex-theme-next主题是GitHub中hexo主题star最高的项目，非常推荐使用。\n\n终端cd到myblog目录下执行如下所示命令。\n\n```\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n将blog目录下_config.yml里的theme的名称`landscape`更改为`next`。\n\n执行如下命令（每次部署文章的步骤）\n\n```\nhexo g  //生成缓存和静态文件\nhexo d  //重新部署到服务器\n```\n\n当本地博客部署到服务器后，网页端无变化时可以采用下述命令。\n\n```\nhexo clean  //清楚缓存文件(db.json)和已生成的静态文件(public)\n```\n\n### 6.配置Hexo-theme-next主题\n\nHexo-theme-next主题便为精于心、简于形，简介的界面下能够呈现丰富的内容，访问[next官网](http://theme-next.iissnan.com/)查看配置内容。配置文件主要修改next中_config.yml文件，next有三种主题选择，分别为Muse、Mist、Pisces三种，个人选择的是Pisces主题。主题增加标签、分类、归档、喜欢（书籍和电影信息流）、文章阅读统计、访问人数统计、评论等功能，博客界面如下所示。\n\n![图片6.1](Mac+Hexo+GitHub博客搭建教程/图片6.1.png)\n\n![图片6.1](Mac+Hexo+GitHub博客搭建教程/图片6.2.png)\n\n![图片6.1](Mac+Hexo+GitHub博客搭建教程/图片6.3.png)\n\n#### 6.1增加标签、分类、归档页\n\n首先将next/config.yml文件中将`menu`中`tags` ` catagories` `archive`前面的`#`。例如增加标签页，通过`hexo new page 'tags'`增加新界面，在myblog/sources中发现多了tags文件夹，修改index.md中内容，将type更改为`tags`。利用`hexo g`和`hexo d`将界面重新上传到服务器便可看到新增加的标签页，分类和归档页同理。\n\n#### 6.2增加喜欢界面\n\n喜欢界面用于展现自己看过的书籍和电影，通过图片流的形式进行安装。\n\n从GitHub上https://github.com/weizhixiaoyi 中的themes/next/scripts下载image-stream.js，放到你的主题/scripts目录中。如果博客主题已经默认引入了jQuery，建议在配置中将image_stream.jquery设置为false。\n\n```Query\nimage_stream:\n\tjquery: false\n```\n\n在Hexo博客的本地目录中创建一个favorite页面目录，同6.1步骤。并在Next主题中配置config.yml，配置如下所示，其中heart表示图标为心形。\n\n```\nmenu:\n  home: / || home\n  about: /about/ || user\n  favorite: /favorite/ || heart\n  tags: /tags/ || tags\n  categories: /categories/ || th\n  archives: /archives/ || archive\n```\n\n然后在source/favorite/index.md中使用插件自定义的两个模版来生成页面，index.md内容格式如下所示。\n\n```\n{% stream %}\n\n{% figure https://img3.doubanio.com/view/photo/raw/public/p2203001610.jpg\n[《万物理论》]（https://movie.douban.com/subject/24815950/）%}\n\n{% endstream %}\n```\n#### 6.3文章阅读统计\n\n文章阅读统计采用LeanCloud，能够提供直观的文章被访问次数，方便作者了解文章写作的质量。Next主题支持leancloud统计，但需要提供app_id和app_key，因此我们需另外注册leancloud账号，注册过程在此便不再赘述。\n\n注册成功之后进行创建新应用，设置相应用户名便创建成功。进入用户界面创建Class，在此需要注意的是Class名称必须为Counter，之后此表便是文章数量统计表。然后我们进入设置中的应用key模块便可获得app_id和app_key，进入next主题的config.yml中，找到leancloud位置复制即可，同时将enable设置为true。另外我们也可以在后台人为修改文章访问量，比如将Python之NumPy使用教程访问量增加。\n\n```\nleancloud_visitors:\n  enable: true \n  app_id: Sj2lCA09ErubMSsa2v9oFU9Y-gzGzoHsz #<app_id>\n  app_key: qJejurdHKM06N75OQedX4SDK #<app_key>\n```\n\n![图片6.4](Mac+Hexo+GitHub博客搭建教程/图片6.4.png)\n\n#### 6.4增加百度统计\n\n百度统计能够清晰看出网站访问数据。在百度官网注册账号后，添加绑定个人网站，在管理页面中找到`代码获取`。\n\n```javascript\n<script>\nvar _hmt = _hmt || [];\n(function() {\n  var hm = document.createElement(\"script\");\n  hm.src = \"https://hm.baidu.com/hm.js?b54e835b3551fd0696954b3aedf5d645\";\n  var s = document.getElementsByTagName(\"script\")[0]; \n  s.parentNode.insertBefore(hm, s);\n})();\n</script>\n```\n\n将代码中`b54e835b3551fd0696954b3aedf5d645`复制到next主题_config.yml的`baidu_analytics`中。接下来通过`代码安装检查`来检查代码是否安装成功，安装成功后便可查看网站详细统计信息。\n\n![图片6.5](Mac+Hexo+GitHub博客搭建教程/图片6.5.png)\n\n#### 6.4增加评论功能\n\n多说、网易云跟帖关闭，畅言需要备案，disqus被墙而且界面不是太美观。新出来的来必力倒是挺不错，支持QQ、微信、微博、百度、人人账号登陆，可以选择常用表情和gif动画，并支持自定义搜索表情。\n\n![图片6.6](Mac+Hexo+GitHub博客搭建教程/图片6.6.png)进入来必力官网注册账号，填写网站域名，进入代码管理界面获得data-uid，复制到next主题_config.yml中的livere_uid处便可，重新提交网站便可看到评论专区。`编写文章时应在头部添加comments: true`\n\n### 7.绑定个人域名\n\n现在使用的域名`weizhixiaoyi.github.io`是github提供的二级域名，也可绑定自己的个性域名`weizhixiaoyi.com`。域名是在阿里云购买，年费为55元，也可以在狗爹`https://sg.godaddy.com`购买，购买好域名之后便可以直接解析。\n\n#### 7.1GitHub端\n\n在next主题中source文件夹中创建`CNAME`文件，没有后缀名，然后将个人域名`weizhixiaoyi.com`添加进`CNAME`文件即可，然后通过`hexo g` `hexo d`重新部署网站。\n\n#### 7.2域名解析\n\n如果将域名指向另外一个域名，需要增加CNAME记录。登陆阿里云官网，进入控制台中域名设置，添加解析。\n\n+ 记录类型：CNAME\n+ 主机记录：@\n+ 解析线路：默认\n+ 记录值：weizhixiaoyi.github.io\n\n解析成功后，等待几分钟便可登陆weizhixiaoyi.com查看网站内容。\n\n### 7.博客SEO优化\n\nSEO优化也就是搜索引擎优化，搜索引擎优化即为增加博客内容被搜索引擎爬取次数，以此增加博客的点击率和曝光度。如果想让自己博客更加容易被搜索到，便是让百度爬虫、谷歌爬虫主动去爬取自己博客内容，但由于Github博客屏蔽百度爬虫，所以只能将自己的博客收录到谷歌，当然这种方法适合于墙外用户。\n\n#### 7.1确认收录情况\n\n在谷歌上搜索`site:weizhixiaoyi.com`，如果能搜索内容就已经被谷歌收录，否则就没有被谷歌收录。\n\n![图片7.1](Mac+Hexo+GitHub博客搭建教程/图片7.1.png)\n\n#### 7.1网站身份验证\n\n验证网站的目的就是证明你是网站的所有者，这里使用站长平台功能进行验证，另外没有梯子的朋友可以通过`shadowsock`+`搬瓦工`自行搭建。\n\n进入谷歌站长平台中的搜索引擎提交入口，添加域名，选择验证方式。个人选择的是在网页中添加标签，进入next主题文件夹，然后找到layout/_partials/，打开head.swig文件，在theme_google_site_verification处添加如下信息。\n\n```\n{% if theme.google_site_verification %}\n  <meta name=\"google-site-verification\" content=\"E1Oy09IV-Rsypa8wpY-yrplcH8RMIHLCzj3m91nX1Eo\" />\n{% endif %}\n```\n\n然后回到`myblog`文件夹下将_config.yml中google_site_vertification设置为`true`。当然你也可以选择其他验证方式，比如添加html文档。信息添加成功之后便可利用`hexo g`和`hexo d`更新博客内容，至此网站身份验证结束。\n\n#### 7.2添加Sitemap\n\nsitemap站点地图是一种文件格式，可以通过该文件列出您网站上的链接，从而将您网站内容告知谷歌和其他搜索引擎。\n\n首先安装针对谷歌的插件`npm install hexo-generator-sitemap --save`，然后进入`myblog`文件夹下将`sitemap`设置如下。\n\n```\n# sitemap\nsitemap:\n  path: sitemap.xml\n```\n\n#### 7.3谷歌收录博客\n\n谷歌收录操作比较简单，就是向Google站长工具提交sitemap，成功登陆Google账号后，添加站点验证。站点验证通过后找到站点地图界面，然后进行添加站点地图地址就行啦。等待1天后通过`site:weizhixiaoyi.com`能够搜索到博客内容，便证明谷歌搜索引擎已收录网站内容。\n\n![图片7.2](Mac+Hexo+GitHub博客搭建教程/图片7.2.png)\n\n另外也可通过bing站长管理工具进行收录网站内容，将网站内容呈现给更多需要帮助的人。针对百度爬虫不能爬取Github博客内容问题，我尝试过利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，但感觉效果都不是太好，所以问题亟待解决，等找到合适的解决办法之后再告知大家。\n\n### 8.ToDoList\n\n+ 寻找更好的方法解决百度爬虫无法爬取博客内容的问题\n+ 博客增加转发功能\n\n------\n\n### 9.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![推广](Mac+Hexo+GitHub博客搭建教程/推广.png)","source":"_posts/Mac+Hexo+GitHub博客搭建教程.md","raw":"---\ntitle: Mac+Hexo+GitHub博客搭建教程\ndate: 2018-03-16 11:41:35\ntags: [Mac,Hexo,GitHub,博客]\ncategories: 教程\ntoc: true\ncomments: true\n---\n\n### 1.为什么写博客\n\n以前利用Jekyll+Github搭建博客，但每次博客搭建完成后都没有继续坚持写博文，直到最近找实习才认识到技术博客的重要性。以前学习的很多知识点都已经忘记啦，所以下定决心这次认真总结以前学习的知识点，认真写点技术文章。\n\n### 2.Mac+Hexo+GitHub博客\n\n现在博客主流的就是Jekyll和Hexo两种格式，选择Jekyll还是Hexo就根据个人喜好啦，但个人更推荐使用Hexo，选择Hexo的主要原因。\n\n+ Jekyll没有本地服务器，无法实现本地文章预览，需要上传到WEB容器中才能预览功能，而Hexo可以通过简单的命令实现本地预览功能，并直接发布到WEB容器中实现同步。\n+ Jekyll主题和Hexo主题对比而言，Hexo主题更加简洁美观(个人审美原因)。\n\n选择GitHub的原因不用多说，程序员的乐园，更是支持pages功能，虽然很多其他社区也支持，比如GitLab、coding、码云等，但GitHub更加活跃，自己的项目就是放在上面，所以更加方便。但GitHub有最大一点不好之处便是*百度爬虫无法爬去博客内容*，自己也找了好久解决方法，比如利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，所以暂时没什么太好的解决方法。\n\n### 3.博客本地环境搭建\n\n#### 3.1安装Node.js和Git\n\nMac上安装可以选择图形化方式和终端安装，此处直接使用客户端方式安装。Node.js官网下载文件，根据提示安装即可，安装成功后在目录*/usr/local/bin*目录下。测试Node.js和npm，出现下述信息则安装成功。\n\n```\nnode -v\nv8.10.0\n```\n\n```\nnpm -v\n5.6.0\n```\n\nGit官网下载相应文件根据提示直接进行安装，检查git是否安装成功，直接查看git版本即可。\n\n> Git --version \n>\n> git version 2.15.0\n\n#### 3.2安装Hexo\n\nNode.js和Git都安装成功后开始安装Hexo。安装时注意权限问题，加上sudo，其中-g表示全局安装。\n\n```mac\nsudo npm install -g hexo\n```\n\n#### 3.3博客初始化\n\n创建存储博客的文件，比如命名为myblog，然后进入到myblog之中。\n\n```\ncd myblog\n```\n\n执行下述命令初始化本地博客，下载一些列文件。\n\n```\nhexo init\n```\n\n执行下述命令安装npm。\n\n```\nsudo npm install\n```\n\n执行下述命令生成本地html文件并开启服务器，然后通过http://localhost:4000查看本地博客。\n\n```\nhexo g\nhexo s\n```\n\n![图片3.3](Mac+Hexo+GitHub博客搭建教程/图片3.3.png)\n\n### 4.本地博客关联GitHub\n\n#### 4.1本地博客代码上传GitHub\n\n注册并登陆GitHub账号后，新建仓库，名称必须为`user.github.io`，如`weizhixiaoyi.github.io`。\n\n![图片01](Mac+Hexo+GitHub博客搭建教程/图片4.1.png)\n\n终端cd到myblog文件夹下，打开_config.yml文件。或者用其他文本编辑器打开可以，推荐sublime。\n\n```Vim\nvim _config.yml\n```\n\n打开后至文档最后部分，将deploy配置如下。\n\n```Python\ndeploy:\n  type: git\n  repository: https://github.com/weizhixiaoyi/weizhixiaoyi.github.io.git\n  branch: master\n```\n\n其中将repository中`weizhixiaoyi`改为自己的用户名，注意type、repository、branch后均有空格。通过如下命令在myblog下生成静态文件并上传到服务器。\n\n```\nhexo g\nhexo d\n```\n\n若执行`hexo g`出错则执行`npm install hexo --save`，若执行`hexo d`出错则执行`npm install hexo-deployer-git --save `。错误修正后再次执行`hexo g`和`hexo d`。\n\n若未关联GitHub，执行`hexo d`时会提示输入GitHub账号用户名和密码，即:\n\n```\nusername for 'https://github.com':\npassword for 'https://github.com':\n```\n\n`hexo d`执行成功后便可通过https://weizhixiaoyi.github.io访问博客，看到的内容和http://localhost:4000相同。\n\n#### 4.2添加ssh keys到GitHub\n\n添加ssh key后不需要每次更新博客再输入用户名和密码。首先检查本地是否包含ssh keys。如果存在则直接将ssh key添加到GitHub之中，否则进入新生成ssh key。\n\n执行下述命令生成新的ssh key，将`your_email@example.com`改成自己以注册的GitHub邮箱地址。默认会在`~/.ssh/id_rsa.pub`中生成`id_rsa`和`id_rsa.pub`文件。\n\n```\nssh-keygen -t rsa -C \"your_email@exampl\"\t\t\n```\n\nMac下利用`open ~/.ssh  `打开文件夹，打开id_rsa.pub文件，里面的信息即为ssh key，将此信息复制到GitHub的Add ssh key`路径GitHub->Setting->SSH keys->add SSH key`界面即可。Title里填写任意标题，将复制的内容粘贴到key中，点击Add key完成添加。\n\n此时本地博客内容便已关联到GitHub之中，本地博客改变之后，通过`hexo g`和`hexo d`便可更新到GitHub之中，通过https://weizhixiaoyi.github.io访问便可看到更新内容。\n\n### 5.更换Hexo主题\n\n可以选择Hexo主题官网页面搜索喜欢的theme，这里我选择hexo-theme-next当作自己主题，hex-theme-next主题是GitHub中hexo主题star最高的项目，非常推荐使用。\n\n终端cd到myblog目录下执行如下所示命令。\n\n```\ngit clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n将blog目录下_config.yml里的theme的名称`landscape`更改为`next`。\n\n执行如下命令（每次部署文章的步骤）\n\n```\nhexo g  //生成缓存和静态文件\nhexo d  //重新部署到服务器\n```\n\n当本地博客部署到服务器后，网页端无变化时可以采用下述命令。\n\n```\nhexo clean  //清楚缓存文件(db.json)和已生成的静态文件(public)\n```\n\n### 6.配置Hexo-theme-next主题\n\nHexo-theme-next主题便为精于心、简于形，简介的界面下能够呈现丰富的内容，访问[next官网](http://theme-next.iissnan.com/)查看配置内容。配置文件主要修改next中_config.yml文件，next有三种主题选择，分别为Muse、Mist、Pisces三种，个人选择的是Pisces主题。主题增加标签、分类、归档、喜欢（书籍和电影信息流）、文章阅读统计、访问人数统计、评论等功能，博客界面如下所示。\n\n![图片6.1](Mac+Hexo+GitHub博客搭建教程/图片6.1.png)\n\n![图片6.1](Mac+Hexo+GitHub博客搭建教程/图片6.2.png)\n\n![图片6.1](Mac+Hexo+GitHub博客搭建教程/图片6.3.png)\n\n#### 6.1增加标签、分类、归档页\n\n首先将next/config.yml文件中将`menu`中`tags` ` catagories` `archive`前面的`#`。例如增加标签页，通过`hexo new page 'tags'`增加新界面，在myblog/sources中发现多了tags文件夹，修改index.md中内容，将type更改为`tags`。利用`hexo g`和`hexo d`将界面重新上传到服务器便可看到新增加的标签页，分类和归档页同理。\n\n#### 6.2增加喜欢界面\n\n喜欢界面用于展现自己看过的书籍和电影，通过图片流的形式进行安装。\n\n从GitHub上https://github.com/weizhixiaoyi 中的themes/next/scripts下载image-stream.js，放到你的主题/scripts目录中。如果博客主题已经默认引入了jQuery，建议在配置中将image_stream.jquery设置为false。\n\n```Query\nimage_stream:\n\tjquery: false\n```\n\n在Hexo博客的本地目录中创建一个favorite页面目录，同6.1步骤。并在Next主题中配置config.yml，配置如下所示，其中heart表示图标为心形。\n\n```\nmenu:\n  home: / || home\n  about: /about/ || user\n  favorite: /favorite/ || heart\n  tags: /tags/ || tags\n  categories: /categories/ || th\n  archives: /archives/ || archive\n```\n\n然后在source/favorite/index.md中使用插件自定义的两个模版来生成页面，index.md内容格式如下所示。\n\n```\n{% stream %}\n\n{% figure https://img3.doubanio.com/view/photo/raw/public/p2203001610.jpg\n[《万物理论》]（https://movie.douban.com/subject/24815950/）%}\n\n{% endstream %}\n```\n#### 6.3文章阅读统计\n\n文章阅读统计采用LeanCloud，能够提供直观的文章被访问次数，方便作者了解文章写作的质量。Next主题支持leancloud统计，但需要提供app_id和app_key，因此我们需另外注册leancloud账号，注册过程在此便不再赘述。\n\n注册成功之后进行创建新应用，设置相应用户名便创建成功。进入用户界面创建Class，在此需要注意的是Class名称必须为Counter，之后此表便是文章数量统计表。然后我们进入设置中的应用key模块便可获得app_id和app_key，进入next主题的config.yml中，找到leancloud位置复制即可，同时将enable设置为true。另外我们也可以在后台人为修改文章访问量，比如将Python之NumPy使用教程访问量增加。\n\n```\nleancloud_visitors:\n  enable: true \n  app_id: Sj2lCA09ErubMSsa2v9oFU9Y-gzGzoHsz #<app_id>\n  app_key: qJejurdHKM06N75OQedX4SDK #<app_key>\n```\n\n![图片6.4](Mac+Hexo+GitHub博客搭建教程/图片6.4.png)\n\n#### 6.4增加百度统计\n\n百度统计能够清晰看出网站访问数据。在百度官网注册账号后，添加绑定个人网站，在管理页面中找到`代码获取`。\n\n```javascript\n<script>\nvar _hmt = _hmt || [];\n(function() {\n  var hm = document.createElement(\"script\");\n  hm.src = \"https://hm.baidu.com/hm.js?b54e835b3551fd0696954b3aedf5d645\";\n  var s = document.getElementsByTagName(\"script\")[0]; \n  s.parentNode.insertBefore(hm, s);\n})();\n</script>\n```\n\n将代码中`b54e835b3551fd0696954b3aedf5d645`复制到next主题_config.yml的`baidu_analytics`中。接下来通过`代码安装检查`来检查代码是否安装成功，安装成功后便可查看网站详细统计信息。\n\n![图片6.5](Mac+Hexo+GitHub博客搭建教程/图片6.5.png)\n\n#### 6.4增加评论功能\n\n多说、网易云跟帖关闭，畅言需要备案，disqus被墙而且界面不是太美观。新出来的来必力倒是挺不错，支持QQ、微信、微博、百度、人人账号登陆，可以选择常用表情和gif动画，并支持自定义搜索表情。\n\n![图片6.6](Mac+Hexo+GitHub博客搭建教程/图片6.6.png)进入来必力官网注册账号，填写网站域名，进入代码管理界面获得data-uid，复制到next主题_config.yml中的livere_uid处便可，重新提交网站便可看到评论专区。`编写文章时应在头部添加comments: true`\n\n### 7.绑定个人域名\n\n现在使用的域名`weizhixiaoyi.github.io`是github提供的二级域名，也可绑定自己的个性域名`weizhixiaoyi.com`。域名是在阿里云购买，年费为55元，也可以在狗爹`https://sg.godaddy.com`购买，购买好域名之后便可以直接解析。\n\n#### 7.1GitHub端\n\n在next主题中source文件夹中创建`CNAME`文件，没有后缀名，然后将个人域名`weizhixiaoyi.com`添加进`CNAME`文件即可，然后通过`hexo g` `hexo d`重新部署网站。\n\n#### 7.2域名解析\n\n如果将域名指向另外一个域名，需要增加CNAME记录。登陆阿里云官网，进入控制台中域名设置，添加解析。\n\n+ 记录类型：CNAME\n+ 主机记录：@\n+ 解析线路：默认\n+ 记录值：weizhixiaoyi.github.io\n\n解析成功后，等待几分钟便可登陆weizhixiaoyi.com查看网站内容。\n\n### 7.博客SEO优化\n\nSEO优化也就是搜索引擎优化，搜索引擎优化即为增加博客内容被搜索引擎爬取次数，以此增加博客的点击率和曝光度。如果想让自己博客更加容易被搜索到，便是让百度爬虫、谷歌爬虫主动去爬取自己博客内容，但由于Github博客屏蔽百度爬虫，所以只能将自己的博客收录到谷歌，当然这种方法适合于墙外用户。\n\n#### 7.1确认收录情况\n\n在谷歌上搜索`site:weizhixiaoyi.com`，如果能搜索内容就已经被谷歌收录，否则就没有被谷歌收录。\n\n![图片7.1](Mac+Hexo+GitHub博客搭建教程/图片7.1.png)\n\n#### 7.1网站身份验证\n\n验证网站的目的就是证明你是网站的所有者，这里使用站长平台功能进行验证，另外没有梯子的朋友可以通过`shadowsock`+`搬瓦工`自行搭建。\n\n进入谷歌站长平台中的搜索引擎提交入口，添加域名，选择验证方式。个人选择的是在网页中添加标签，进入next主题文件夹，然后找到layout/_partials/，打开head.swig文件，在theme_google_site_verification处添加如下信息。\n\n```\n{% if theme.google_site_verification %}\n  <meta name=\"google-site-verification\" content=\"E1Oy09IV-Rsypa8wpY-yrplcH8RMIHLCzj3m91nX1Eo\" />\n{% endif %}\n```\n\n然后回到`myblog`文件夹下将_config.yml中google_site_vertification设置为`true`。当然你也可以选择其他验证方式，比如添加html文档。信息添加成功之后便可利用`hexo g`和`hexo d`更新博客内容，至此网站身份验证结束。\n\n#### 7.2添加Sitemap\n\nsitemap站点地图是一种文件格式，可以通过该文件列出您网站上的链接，从而将您网站内容告知谷歌和其他搜索引擎。\n\n首先安装针对谷歌的插件`npm install hexo-generator-sitemap --save`，然后进入`myblog`文件夹下将`sitemap`设置如下。\n\n```\n# sitemap\nsitemap:\n  path: sitemap.xml\n```\n\n#### 7.3谷歌收录博客\n\n谷歌收录操作比较简单，就是向Google站长工具提交sitemap，成功登陆Google账号后，添加站点验证。站点验证通过后找到站点地图界面，然后进行添加站点地图地址就行啦。等待1天后通过`site:weizhixiaoyi.com`能够搜索到博客内容，便证明谷歌搜索引擎已收录网站内容。\n\n![图片7.2](Mac+Hexo+GitHub博客搭建教程/图片7.2.png)\n\n另外也可通过bing站长管理工具进行收录网站内容，将网站内容呈现给更多需要帮助的人。针对百度爬虫不能爬取Github博客内容问题，我尝试过利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，但感觉效果都不是太好，所以问题亟待解决，等找到合适的解决办法之后再告知大家。\n\n### 8.ToDoList\n\n+ 寻找更好的方法解决百度爬虫无法爬取博客内容的问题\n+ 博客增加转发功能\n\n------\n\n### 9.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![推广](Mac+Hexo+GitHub博客搭建教程/推广.png)","slug":"Mac+Hexo+GitHub博客搭建教程","published":1,"updated":"2018-03-17T10:23:04.618Z","layout":"post","photos":[],"link":"","_id":"cjg7s0pq5000832011gewnfmc","content":"<h3 id=\"1-为什么写博客\"><a href=\"#1-为什么写博客\" class=\"headerlink\" title=\"1.为什么写博客\"></a>1.为什么写博客</h3><p>以前利用Jekyll+Github搭建博客，但每次博客搭建完成后都没有继续坚持写博文，直到最近找实习才认识到技术博客的重要性。以前学习的很多知识点都已经忘记啦，所以下定决心这次认真总结以前学习的知识点，认真写点技术文章。</p>\n<h3 id=\"2-Mac-Hexo-GitHub博客\"><a href=\"#2-Mac-Hexo-GitHub博客\" class=\"headerlink\" title=\"2.Mac+Hexo+GitHub博客\"></a>2.Mac+Hexo+GitHub博客</h3><p>现在博客主流的就是Jekyll和Hexo两种格式，选择Jekyll还是Hexo就根据个人喜好啦，但个人更推荐使用Hexo，选择Hexo的主要原因。</p>\n<ul>\n<li>Jekyll没有本地服务器，无法实现本地文章预览，需要上传到WEB容器中才能预览功能，而Hexo可以通过简单的命令实现本地预览功能，并直接发布到WEB容器中实现同步。</li>\n<li>Jekyll主题和Hexo主题对比而言，Hexo主题更加简洁美观(个人审美原因)。</li>\n</ul>\n<p>选择GitHub的原因不用多说，程序员的乐园，更是支持pages功能，虽然很多其他社区也支持，比如GitLab、coding、码云等，但GitHub更加活跃，自己的项目就是放在上面，所以更加方便。但GitHub有最大一点不好之处便是<em>百度爬虫无法爬去博客内容</em>，自己也找了好久解决方法，比如利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，所以暂时没什么太好的解决方法。</p>\n<h3 id=\"3-博客本地环境搭建\"><a href=\"#3-博客本地环境搭建\" class=\"headerlink\" title=\"3.博客本地环境搭建\"></a>3.博客本地环境搭建</h3><h4 id=\"3-1安装Node-js和Git\"><a href=\"#3-1安装Node-js和Git\" class=\"headerlink\" title=\"3.1安装Node.js和Git\"></a>3.1安装Node.js和Git</h4><p>Mac上安装可以选择图形化方式和终端安装，此处直接使用客户端方式安装。Node.js官网下载文件，根据提示安装即可，安装成功后在目录<em>/usr/local/bin</em>目录下。测试Node.js和npm，出现下述信息则安装成功。</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">node</span> <span class=\"title\">-v</span></span><br><span class=\"line\">v8.<span class=\"number\">10.0</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"selector-tag\">npm</span> <span class=\"selector-tag\">-v</span></span><br><span class=\"line\">5<span class=\"selector-class\">.6</span><span class=\"selector-class\">.0</span></span><br></pre></td></tr></table></figure>\n<p>Git官网下载相应文件根据提示直接进行安装，检查git是否安装成功，直接查看git版本即可。</p>\n<blockquote>\n<p>Git —version </p>\n<p>git version 2.15.0</p>\n</blockquote>\n<h4 id=\"3-2安装Hexo\"><a href=\"#3-2安装Hexo\" class=\"headerlink\" title=\"3.2安装Hexo\"></a>3.2安装Hexo</h4><p>Node.js和Git都安装成功后开始安装Hexo。安装时注意权限问题，加上sudo，其中-g表示全局安装。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo npm install -g hexo</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3博客初始化\"><a href=\"#3-3博客初始化\" class=\"headerlink\" title=\"3.3博客初始化\"></a>3.3博客初始化</h4><p>创建存储博客的文件，比如命名为myblog，然后进入到myblog之中。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> myblog</span><br></pre></td></tr></table></figure>\n<p>执行下述命令初始化本地博客，下载一些列文件。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo init</span></span><br></pre></td></tr></table></figure>\n<p>执行下述命令安装npm。</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo npm <span class=\"keyword\">install</span></span><br></pre></td></tr></table></figure>\n<p>执行下述命令生成本地html文件并开启服务器，然后通过<a href=\"http://localhost:4000查看本地博客。\" target=\"_blank\" rel=\"noopener\">http://localhost:4000查看本地博客。</a></p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo g</span></span><br><span class=\"line\"><span class=\"attribute\">hexo s</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片3.3.png\" alt=\"图片3.3\"></p>\n<h3 id=\"4-本地博客关联GitHub\"><a href=\"#4-本地博客关联GitHub\" class=\"headerlink\" title=\"4.本地博客关联GitHub\"></a>4.本地博客关联GitHub</h3><h4 id=\"4-1本地博客代码上传GitHub\"><a href=\"#4-1本地博客代码上传GitHub\" class=\"headerlink\" title=\"4.1本地博客代码上传GitHub\"></a>4.1本地博客代码上传GitHub</h4><p>注册并登陆GitHub账号后，新建仓库，名称必须为<code>user.github.io</code>，如<code>weizhixiaoyi.github.io</code>。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片4.1.png\" alt=\"图片01\"></p>\n<p>终端cd到myblog文件夹下，打开_config.yml文件。或者用其他文本编辑器打开可以，推荐sublime。</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">vim</span> _config.yml</span><br></pre></td></tr></table></figure>\n<p>打开后至文档最后部分，将deploy配置如下。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repository: https://github.com/weizhixiaoyi/weizhixiaoyi.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p>其中将repository中<code>weizhixiaoyi</code>改为自己的用户名，注意type、repository、branch后均有空格。通过如下命令在myblog下生成静态文件并上传到服务器。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo g</span></span><br><span class=\"line\"><span class=\"attribute\">hexo d</span></span><br></pre></td></tr></table></figure>\n<p>若执行<code>hexo g</code>出错则执行<code>npm install hexo --save</code>，若执行<code>hexo d</code>出错则执行<code>npm install hexo-deployer-git --save</code>。错误修正后再次执行<code>hexo g</code>和<code>hexo d</code>。</p>\n<p>若未关联GitHub，执行<code>hexo d</code>时会提示输入GitHub账号用户名和密码，即:</p>\n<figure class=\"highlight rust\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">username <span class=\"keyword\">for</span> <span class=\"symbol\">'https</span>:<span class=\"comment\">//github.com':</span></span><br><span class=\"line\">password <span class=\"keyword\">for</span> <span class=\"symbol\">'https</span>:<span class=\"comment\">//github.com':</span></span><br></pre></td></tr></table></figure>\n<p><code>hexo d</code>执行成功后便可通过<a href=\"https://weizhixiaoyi.github.io访问博客，看到的内容和http://localhost:4000相同。\" target=\"_blank\" rel=\"noopener\">https://weizhixiaoyi.github.io访问博客，看到的内容和http://localhost:4000相同。</a></p>\n<h4 id=\"4-2添加ssh-keys到GitHub\"><a href=\"#4-2添加ssh-keys到GitHub\" class=\"headerlink\" title=\"4.2添加ssh keys到GitHub\"></a>4.2添加ssh keys到GitHub</h4><p>添加ssh key后不需要每次更新博客再输入用户名和密码。首先检查本地是否包含ssh keys。如果存在则直接将ssh key添加到GitHub之中，否则进入新生成ssh key。</p>\n<p>执行下述命令生成新的ssh key，将<code>your_email@example.com</code>改成自己以注册的GitHub邮箱地址。默认会在<code>~/.ssh/id_rsa.pub</code>中生成<code>id_rsa</code>和<code>id_rsa.pub</code>文件。</p>\n<figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen -<span class=\"built_in\">t</span> rsa -C <span class=\"string\">\"your_email@exampl\"</span></span><br></pre></td></tr></table></figure>\n<p>Mac下利用<code>open ~/.ssh</code>打开文件夹，打开id_rsa.pub文件，里面的信息即为ssh key，将此信息复制到GitHub的Add ssh key<code>路径GitHub-&gt;Setting-&gt;SSH keys-&gt;add SSH key</code>界面即可。Title里填写任意标题，将复制的内容粘贴到key中，点击Add key完成添加。</p>\n<p>此时本地博客内容便已关联到GitHub之中，本地博客改变之后，通过<code>hexo g</code>和<code>hexo d</code>便可更新到GitHub之中，通过<a href=\"https://weizhixiaoyi.github.io访问便可看到更新内容。\" target=\"_blank\" rel=\"noopener\">https://weizhixiaoyi.github.io访问便可看到更新内容。</a></p>\n<h3 id=\"5-更换Hexo主题\"><a href=\"#5-更换Hexo主题\" class=\"headerlink\" title=\"5.更换Hexo主题\"></a>5.更换Hexo主题</h3><p>可以选择Hexo主题官网页面搜索喜欢的theme，这里我选择hexo-theme-next当作自己主题，hex-theme-next主题是GitHub中hexo主题star最高的项目，非常推荐使用。</p>\n<p>终端cd到myblog目录下执行如下所示命令。</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone http<span class=\"variable\">s:</span>//github.<span class=\"keyword\">com</span>/iissnan/hexo-theme-<span class=\"keyword\">next</span> themes/<span class=\"keyword\">next</span></span><br></pre></td></tr></table></figure>\n<p>将blog目录下_config.yml里的theme的名称<code>landscape</code>更改为<code>next</code>。</p>\n<p>执行如下命令（每次部署文章的步骤）</p>\n<figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g  <span class=\"comment\">//生成缓存和静态文件</span></span><br><span class=\"line\">hexo d  <span class=\"comment\">//重新部署到服务器</span></span><br></pre></td></tr></table></figure>\n<p>当本地博客部署到服务器后，网页端无变化时可以采用下述命令。</p>\n<figure class=\"highlight x86asm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean  //清楚缓存文件(<span class=\"built_in\">db</span>.json)和已生成的静态文件(<span class=\"meta\">public</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"6-配置Hexo-theme-next主题\"><a href=\"#6-配置Hexo-theme-next主题\" class=\"headerlink\" title=\"6.配置Hexo-theme-next主题\"></a>6.配置Hexo-theme-next主题</h3><p>Hexo-theme-next主题便为精于心、简于形，简介的界面下能够呈现丰富的内容，访问<a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">next官网</a>查看配置内容。配置文件主要修改next中_config.yml文件，next有三种主题选择，分别为Muse、Mist、Pisces三种，个人选择的是Pisces主题。主题增加标签、分类、归档、喜欢（书籍和电影信息流）、文章阅读统计、访问人数统计、评论等功能，博客界面如下所示。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.1.png\" alt=\"图片6.1\"></p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.2.png\" alt=\"图片6.1\"></p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.3.png\" alt=\"图片6.1\"></p>\n<h4 id=\"6-1增加标签、分类、归档页\"><a href=\"#6-1增加标签、分类、归档页\" class=\"headerlink\" title=\"6.1增加标签、分类、归档页\"></a>6.1增加标签、分类、归档页</h4><p>首先将next/config.yml文件中将<code>menu</code>中<code>tags</code> <code>catagories</code> <code>archive</code>前面的<code>#</code>。例如增加标签页，通过<code>hexo new page &#39;tags&#39;</code>增加新界面，在myblog/sources中发现多了tags文件夹，修改index.md中内容，将type更改为<code>tags</code>。利用<code>hexo g</code>和<code>hexo d</code>将界面重新上传到服务器便可看到新增加的标签页，分类和归档页同理。</p>\n<h4 id=\"6-2增加喜欢界面\"><a href=\"#6-2增加喜欢界面\" class=\"headerlink\" title=\"6.2增加喜欢界面\"></a>6.2增加喜欢界面</h4><p>喜欢界面用于展现自己看过的书籍和电影，通过图片流的形式进行安装。</p>\n<p>从GitHub上<a href=\"https://github.com/weizhixiaoyi\" target=\"_blank\" rel=\"noopener\">https://github.com/weizhixiaoyi</a> 中的themes/next/scripts下载image-stream.js，放到你的主题/scripts目录中。如果博客主题已经默认引入了jQuery，建议在配置中将image_stream.jquery设置为false。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">image_stream:</span><br><span class=\"line\">\tjquery: false</span><br></pre></td></tr></table></figure>\n<p>在Hexo博客的本地目录中创建一个favorite页面目录，同6.1步骤。并在Next主题中配置config.yml，配置如下所示，其中heart表示图标为心形。</p>\n<figure class=\"highlight dts\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"symbol\">menu:</span></span><br><span class=\"line\"><span class=\"symbol\">  home:</span> / || home</span><br><span class=\"line\"><span class=\"symbol\">  about:</span> <span class=\"meta-keyword\">/about/</span> || user</span><br><span class=\"line\"><span class=\"symbol\">  favorite:</span> <span class=\"meta-keyword\">/favorite/</span> || heart</span><br><span class=\"line\"><span class=\"symbol\">  tags:</span> <span class=\"meta-keyword\">/tags/</span> || tags</span><br><span class=\"line\"><span class=\"symbol\">  categories:</span> <span class=\"meta-keyword\">/categories/</span> || th</span><br><span class=\"line\"><span class=\"symbol\">  archives:</span> <span class=\"meta-keyword\">/archives/</span> || archive</span><br></pre></td></tr></table></figure>\n<p>然后在source/favorite/index.md中使用插件自定义的两个模版来生成页面，index.md内容格式如下所示。</p>\n<figure class=\"highlight django\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\">stream</span> %&#125;</span><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\">figure</span> https://img3.doubanio.com/view/photo/raw/public/p2203001610.jpg</span></span><br><span class=\"line\"><span class=\"template-tag\">[《万物理论》]（https://movie.douban.com/subject/24815950/）%&#125;</span><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\">endstream</span> %&#125;</span><span class=\"xml\"></span></span><br></pre></td></tr></table></figure>\n<h4 id=\"6-3文章阅读统计\"><a href=\"#6-3文章阅读统计\" class=\"headerlink\" title=\"6.3文章阅读统计\"></a>6.3文章阅读统计</h4><p>文章阅读统计采用LeanCloud，能够提供直观的文章被访问次数，方便作者了解文章写作的质量。Next主题支持leancloud统计，但需要提供app_id和app_key，因此我们需另外注册leancloud账号，注册过程在此便不再赘述。</p>\n<p>注册成功之后进行创建新应用，设置相应用户名便创建成功。进入用户界面创建Class，在此需要注意的是Class名称必须为Counter，之后此表便是文章数量统计表。然后我们进入设置中的应用key模块便可获得app_id和app_key，进入next主题的config.yml中，找到leancloud位置复制即可，同时将enable设置为true。另外我们也可以在后台人为修改文章访问量，比如将Python之NumPy使用教程访问量增加。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">leancloud_visitors:</span></span><br><span class=\"line\"><span class=\"attr\">  enable:</span> <span class=\"literal\">true</span> </span><br><span class=\"line\"><span class=\"attr\">  app_id:</span> <span class=\"string\">Sj2lCA09ErubMSsa2v9oFU9Y-gzGzoHsz</span> <span class=\"comment\">#&lt;app_id&gt;</span></span><br><span class=\"line\"><span class=\"attr\">  app_key:</span> <span class=\"string\">qJejurdHKM06N75OQedX4SDK</span> <span class=\"comment\">#&lt;app_key&gt;</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.4.png\" alt=\"图片6.4\"></p>\n<h4 id=\"6-4增加百度统计\"><a href=\"#6-4增加百度统计\" class=\"headerlink\" title=\"6.4增加百度统计\"></a>6.4增加百度统计</h4><p>百度统计能够清晰看出网站访问数据。在百度官网注册账号后，添加绑定个人网站，在管理页面中找到<code>代码获取</code>。</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;script&gt;</span><br><span class=\"line\"><span class=\"keyword\">var</span> _hmt = _hmt || [];</span><br><span class=\"line\">(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>) </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">var</span> hm = <span class=\"built_in\">document</span>.createElement(<span class=\"string\">\"script\"</span>);</span><br><span class=\"line\">  hm.src = <span class=\"string\">\"https://hm.baidu.com/hm.js?b54e835b3551fd0696954b3aedf5d645\"</span>;</span><br><span class=\"line\">  <span class=\"keyword\">var</span> s = <span class=\"built_in\">document</span>.getElementsByTagName(<span class=\"string\">\"script\"</span>)[<span class=\"number\">0</span>]; </span><br><span class=\"line\">  s.parentNode.insertBefore(hm, s);</span><br><span class=\"line\">&#125;)();</span><br><span class=\"line\">&lt;<span class=\"regexp\">/script&gt;</span></span><br></pre></td></tr></table></figure>\n<p>将代码中<code>b54e835b3551fd0696954b3aedf5d645</code>复制到next主题_config.yml的<code>baidu_analytics</code>中。接下来通过<code>代码安装检查</code>来检查代码是否安装成功，安装成功后便可查看网站详细统计信息。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.5.png\" alt=\"图片6.5\"></p>\n<h4 id=\"6-4增加评论功能\"><a href=\"#6-4增加评论功能\" class=\"headerlink\" title=\"6.4增加评论功能\"></a>6.4增加评论功能</h4><p>多说、网易云跟帖关闭，畅言需要备案，disqus被墙而且界面不是太美观。新出来的来必力倒是挺不错，支持QQ、微信、微博、百度、人人账号登陆，可以选择常用表情和gif动画，并支持自定义搜索表情。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.6.png\" alt=\"图片6.6\">进入来必力官网注册账号，填写网站域名，进入代码管理界面获得data-uid，复制到next主题_config.yml中的livere_uid处便可，重新提交网站便可看到评论专区。<code>编写文章时应在头部添加comments: true</code></p>\n<h3 id=\"7-绑定个人域名\"><a href=\"#7-绑定个人域名\" class=\"headerlink\" title=\"7.绑定个人域名\"></a>7.绑定个人域名</h3><p>现在使用的域名<code>weizhixiaoyi.github.io</code>是github提供的二级域名，也可绑定自己的个性域名<code>weizhixiaoyi.com</code>。域名是在阿里云购买，年费为55元，也可以在狗爹<code>https://sg.godaddy.com</code>购买，购买好域名之后便可以直接解析。</p>\n<h4 id=\"7-1GitHub端\"><a href=\"#7-1GitHub端\" class=\"headerlink\" title=\"7.1GitHub端\"></a>7.1GitHub端</h4><p>在next主题中source文件夹中创建<code>CNAME</code>文件，没有后缀名，然后将个人域名<code>weizhixiaoyi.com</code>添加进<code>CNAME</code>文件即可，然后通过<code>hexo g</code> <code>hexo d</code>重新部署网站。</p>\n<h4 id=\"7-2域名解析\"><a href=\"#7-2域名解析\" class=\"headerlink\" title=\"7.2域名解析\"></a>7.2域名解析</h4><p>如果将域名指向另外一个域名，需要增加CNAME记录。登陆阿里云官网，进入控制台中域名设置，添加解析。</p>\n<ul>\n<li>记录类型：CNAME</li>\n<li>主机记录：@</li>\n<li>解析线路：默认</li>\n<li>记录值：weizhixiaoyi.github.io</li>\n</ul>\n<p>解析成功后，等待几分钟便可登陆weizhixiaoyi.com查看网站内容。</p>\n<h3 id=\"7-博客SEO优化\"><a href=\"#7-博客SEO优化\" class=\"headerlink\" title=\"7.博客SEO优化\"></a>7.博客SEO优化</h3><p>SEO优化也就是搜索引擎优化，搜索引擎优化即为增加博客内容被搜索引擎爬取次数，以此增加博客的点击率和曝光度。如果想让自己博客更加容易被搜索到，便是让百度爬虫、谷歌爬虫主动去爬取自己博客内容，但由于Github博客屏蔽百度爬虫，所以只能将自己的博客收录到谷歌，当然这种方法适合于墙外用户。</p>\n<h4 id=\"7-1确认收录情况\"><a href=\"#7-1确认收录情况\" class=\"headerlink\" title=\"7.1确认收录情况\"></a>7.1确认收录情况</h4><p>在谷歌上搜索<code>site:weizhixiaoyi.com</code>，如果能搜索内容就已经被谷歌收录，否则就没有被谷歌收录。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片7.1.png\" alt=\"图片7.1\"></p>\n<h4 id=\"7-1网站身份验证\"><a href=\"#7-1网站身份验证\" class=\"headerlink\" title=\"7.1网站身份验证\"></a>7.1网站身份验证</h4><p>验证网站的目的就是证明你是网站的所有者，这里使用站长平台功能进行验证，另外没有梯子的朋友可以通过<code>shadowsock</code>+<code>搬瓦工</code>自行搭建。</p>\n<p>进入谷歌站长平台中的搜索引擎提交入口，添加域名，选择验证方式。个人选择的是在网页中添加标签，进入next主题文件夹，然后找到layout/_partials/，打开head.swig文件，在theme_google_site_verification处添加如下信息。</p>\n<figure class=\"highlight django\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">if</span></span> theme.google_site_verification %&#125;</span><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\">  <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">name</span>=<span class=\"string\">\"google-site-verification\"</span> <span class=\"attr\">content</span>=<span class=\"string\">\"E1Oy09IV-Rsypa8wpY-yrplcH8RMIHLCzj3m91nX1Eo\"</span> /&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">endif</span></span> %&#125;</span><span class=\"xml\"></span></span><br></pre></td></tr></table></figure>\n<p>然后回到<code>myblog</code>文件夹下将_config.yml中google_site_vertification设置为<code>true</code>。当然你也可以选择其他验证方式，比如添加html文档。信息添加成功之后便可利用<code>hexo g</code>和<code>hexo d</code>更新博客内容，至此网站身份验证结束。</p>\n<h4 id=\"7-2添加Sitemap\"><a href=\"#7-2添加Sitemap\" class=\"headerlink\" title=\"7.2添加Sitemap\"></a>7.2添加Sitemap</h4><p>sitemap站点地图是一种文件格式，可以通过该文件列出您网站上的链接，从而将您网站内容告知谷歌和其他搜索引擎。</p>\n<p>首先安装针对谷歌的插件<code>npm install hexo-generator-sitemap --save</code>，然后进入<code>myblog</code>文件夹下将<code>sitemap</code>设置如下。</p>\n<figure class=\"highlight dts\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\"># sitemap</span></span><br><span class=\"line\"><span class=\"symbol\">sitemap:</span></span><br><span class=\"line\"><span class=\"symbol\">  path:</span> sitemap.xml</span><br></pre></td></tr></table></figure>\n<h4 id=\"7-3谷歌收录博客\"><a href=\"#7-3谷歌收录博客\" class=\"headerlink\" title=\"7.3谷歌收录博客\"></a>7.3谷歌收录博客</h4><p>谷歌收录操作比较简单，就是向Google站长工具提交sitemap，成功登陆Google账号后，添加站点验证。站点验证通过后找到站点地图界面，然后进行添加站点地图地址就行啦。等待1天后通过<code>site:weizhixiaoyi.com</code>能够搜索到博客内容，便证明谷歌搜索引擎已收录网站内容。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片7.2.png\" alt=\"图片7.2\"></p>\n<p>另外也可通过bing站长管理工具进行收录网站内容，将网站内容呈现给更多需要帮助的人。针对百度爬虫不能爬取Github博客内容问题，我尝试过利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，但感觉效果都不是太好，所以问题亟待解决，等找到合适的解决办法之后再告知大家。</p>\n<h3 id=\"8-ToDoList\"><a href=\"#8-ToDoList\" class=\"headerlink\" title=\"8.ToDoList\"></a>8.ToDoList</h3><ul>\n<li>寻找更好的方法解决百度爬虫无法爬取博客内容的问题</li>\n<li>博客增加转发功能</li>\n</ul>\n<hr>\n<h3 id=\"9-推广\"><a href=\"#9-推广\" class=\"headerlink\" title=\"9.推广\"></a>9.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/推广.png\" alt=\"推广\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-为什么写博客\"><a href=\"#1-为什么写博客\" class=\"headerlink\" title=\"1.为什么写博客\"></a>1.为什么写博客</h3><p>以前利用Jekyll+Github搭建博客，但每次博客搭建完成后都没有继续坚持写博文，直到最近找实习才认识到技术博客的重要性。以前学习的很多知识点都已经忘记啦，所以下定决心这次认真总结以前学习的知识点，认真写点技术文章。</p>\n<h3 id=\"2-Mac-Hexo-GitHub博客\"><a href=\"#2-Mac-Hexo-GitHub博客\" class=\"headerlink\" title=\"2.Mac+Hexo+GitHub博客\"></a>2.Mac+Hexo+GitHub博客</h3><p>现在博客主流的就是Jekyll和Hexo两种格式，选择Jekyll还是Hexo就根据个人喜好啦，但个人更推荐使用Hexo，选择Hexo的主要原因。</p>\n<ul>\n<li>Jekyll没有本地服务器，无法实现本地文章预览，需要上传到WEB容器中才能预览功能，而Hexo可以通过简单的命令实现本地预览功能，并直接发布到WEB容器中实现同步。</li>\n<li>Jekyll主题和Hexo主题对比而言，Hexo主题更加简洁美观(个人审美原因)。</li>\n</ul>\n<p>选择GitHub的原因不用多说，程序员的乐园，更是支持pages功能，虽然很多其他社区也支持，比如GitLab、coding、码云等，但GitHub更加活跃，自己的项目就是放在上面，所以更加方便。但GitHub有最大一点不好之处便是<em>百度爬虫无法爬去博客内容</em>，自己也找了好久解决方法，比如利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，所以暂时没什么太好的解决方法。</p>\n<h3 id=\"3-博客本地环境搭建\"><a href=\"#3-博客本地环境搭建\" class=\"headerlink\" title=\"3.博客本地环境搭建\"></a>3.博客本地环境搭建</h3><h4 id=\"3-1安装Node-js和Git\"><a href=\"#3-1安装Node-js和Git\" class=\"headerlink\" title=\"3.1安装Node.js和Git\"></a>3.1安装Node.js和Git</h4><p>Mac上安装可以选择图形化方式和终端安装，此处直接使用客户端方式安装。Node.js官网下载文件，根据提示安装即可，安装成功后在目录<em>/usr/local/bin</em>目录下。测试Node.js和npm，出现下述信息则安装成功。</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">node</span> <span class=\"title\">-v</span></span><br><span class=\"line\">v8.<span class=\"number\">10.0</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"selector-tag\">npm</span> <span class=\"selector-tag\">-v</span></span><br><span class=\"line\">5<span class=\"selector-class\">.6</span><span class=\"selector-class\">.0</span></span><br></pre></td></tr></table></figure>\n<p>Git官网下载相应文件根据提示直接进行安装，检查git是否安装成功，直接查看git版本即可。</p>\n<blockquote>\n<p>Git —version </p>\n<p>git version 2.15.0</p>\n</blockquote>\n<h4 id=\"3-2安装Hexo\"><a href=\"#3-2安装Hexo\" class=\"headerlink\" title=\"3.2安装Hexo\"></a>3.2安装Hexo</h4><p>Node.js和Git都安装成功后开始安装Hexo。安装时注意权限问题，加上sudo，其中-g表示全局安装。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo npm install -g hexo</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3博客初始化\"><a href=\"#3-3博客初始化\" class=\"headerlink\" title=\"3.3博客初始化\"></a>3.3博客初始化</h4><p>创建存储博客的文件，比如命名为myblog，然后进入到myblog之中。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> myblog</span><br></pre></td></tr></table></figure>\n<p>执行下述命令初始化本地博客，下载一些列文件。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo init</span></span><br></pre></td></tr></table></figure>\n<p>执行下述命令安装npm。</p>\n<figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo npm <span class=\"keyword\">install</span></span><br></pre></td></tr></table></figure>\n<p>执行下述命令生成本地html文件并开启服务器，然后通过<a href=\"http://localhost:4000查看本地博客。\" target=\"_blank\" rel=\"noopener\">http://localhost:4000查看本地博客。</a></p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo g</span></span><br><span class=\"line\"><span class=\"attribute\">hexo s</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片3.3.png\" alt=\"图片3.3\"></p>\n<h3 id=\"4-本地博客关联GitHub\"><a href=\"#4-本地博客关联GitHub\" class=\"headerlink\" title=\"4.本地博客关联GitHub\"></a>4.本地博客关联GitHub</h3><h4 id=\"4-1本地博客代码上传GitHub\"><a href=\"#4-1本地博客代码上传GitHub\" class=\"headerlink\" title=\"4.1本地博客代码上传GitHub\"></a>4.1本地博客代码上传GitHub</h4><p>注册并登陆GitHub账号后，新建仓库，名称必须为<code>user.github.io</code>，如<code>weizhixiaoyi.github.io</code>。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片4.1.png\" alt=\"图片01\"></p>\n<p>终端cd到myblog文件夹下，打开_config.yml文件。或者用其他文本编辑器打开可以，推荐sublime。</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">vim</span> _config.yml</span><br></pre></td></tr></table></figure>\n<p>打开后至文档最后部分，将deploy配置如下。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deploy:</span><br><span class=\"line\">  type: git</span><br><span class=\"line\">  repository: https://github.com/weizhixiaoyi/weizhixiaoyi.github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<p>其中将repository中<code>weizhixiaoyi</code>改为自己的用户名，注意type、repository、branch后均有空格。通过如下命令在myblog下生成静态文件并上传到服务器。</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo g</span></span><br><span class=\"line\"><span class=\"attribute\">hexo d</span></span><br></pre></td></tr></table></figure>\n<p>若执行<code>hexo g</code>出错则执行<code>npm install hexo --save</code>，若执行<code>hexo d</code>出错则执行<code>npm install hexo-deployer-git --save</code>。错误修正后再次执行<code>hexo g</code>和<code>hexo d</code>。</p>\n<p>若未关联GitHub，执行<code>hexo d</code>时会提示输入GitHub账号用户名和密码，即:</p>\n<figure class=\"highlight rust\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">username <span class=\"keyword\">for</span> <span class=\"symbol\">'https</span>:<span class=\"comment\">//github.com':</span></span><br><span class=\"line\">password <span class=\"keyword\">for</span> <span class=\"symbol\">'https</span>:<span class=\"comment\">//github.com':</span></span><br></pre></td></tr></table></figure>\n<p><code>hexo d</code>执行成功后便可通过<a href=\"https://weizhixiaoyi.github.io访问博客，看到的内容和http://localhost:4000相同。\" target=\"_blank\" rel=\"noopener\">https://weizhixiaoyi.github.io访问博客，看到的内容和http://localhost:4000相同。</a></p>\n<h4 id=\"4-2添加ssh-keys到GitHub\"><a href=\"#4-2添加ssh-keys到GitHub\" class=\"headerlink\" title=\"4.2添加ssh keys到GitHub\"></a>4.2添加ssh keys到GitHub</h4><p>添加ssh key后不需要每次更新博客再输入用户名和密码。首先检查本地是否包含ssh keys。如果存在则直接将ssh key添加到GitHub之中，否则进入新生成ssh key。</p>\n<p>执行下述命令生成新的ssh key，将<code>your_email@example.com</code>改成自己以注册的GitHub邮箱地址。默认会在<code>~/.ssh/id_rsa.pub</code>中生成<code>id_rsa</code>和<code>id_rsa.pub</code>文件。</p>\n<figure class=\"highlight excel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-keygen -<span class=\"built_in\">t</span> rsa -C <span class=\"string\">\"your_email@exampl\"</span></span><br></pre></td></tr></table></figure>\n<p>Mac下利用<code>open ~/.ssh</code>打开文件夹，打开id_rsa.pub文件，里面的信息即为ssh key，将此信息复制到GitHub的Add ssh key<code>路径GitHub-&gt;Setting-&gt;SSH keys-&gt;add SSH key</code>界面即可。Title里填写任意标题，将复制的内容粘贴到key中，点击Add key完成添加。</p>\n<p>此时本地博客内容便已关联到GitHub之中，本地博客改变之后，通过<code>hexo g</code>和<code>hexo d</code>便可更新到GitHub之中，通过<a href=\"https://weizhixiaoyi.github.io访问便可看到更新内容。\" target=\"_blank\" rel=\"noopener\">https://weizhixiaoyi.github.io访问便可看到更新内容。</a></p>\n<h3 id=\"5-更换Hexo主题\"><a href=\"#5-更换Hexo主题\" class=\"headerlink\" title=\"5.更换Hexo主题\"></a>5.更换Hexo主题</h3><p>可以选择Hexo主题官网页面搜索喜欢的theme，这里我选择hexo-theme-next当作自己主题，hex-theme-next主题是GitHub中hexo主题star最高的项目，非常推荐使用。</p>\n<p>终端cd到myblog目录下执行如下所示命令。</p>\n<figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone http<span class=\"variable\">s:</span>//github.<span class=\"keyword\">com</span>/iissnan/hexo-theme-<span class=\"keyword\">next</span> themes/<span class=\"keyword\">next</span></span><br></pre></td></tr></table></figure>\n<p>将blog目录下_config.yml里的theme的名称<code>landscape</code>更改为<code>next</code>。</p>\n<p>执行如下命令（每次部署文章的步骤）</p>\n<figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g  <span class=\"comment\">//生成缓存和静态文件</span></span><br><span class=\"line\">hexo d  <span class=\"comment\">//重新部署到服务器</span></span><br></pre></td></tr></table></figure>\n<p>当本地博客部署到服务器后，网页端无变化时可以采用下述命令。</p>\n<figure class=\"highlight x86asm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo clean  //清楚缓存文件(<span class=\"built_in\">db</span>.json)和已生成的静态文件(<span class=\"meta\">public</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"6-配置Hexo-theme-next主题\"><a href=\"#6-配置Hexo-theme-next主题\" class=\"headerlink\" title=\"6.配置Hexo-theme-next主题\"></a>6.配置Hexo-theme-next主题</h3><p>Hexo-theme-next主题便为精于心、简于形，简介的界面下能够呈现丰富的内容，访问<a href=\"http://theme-next.iissnan.com/\" target=\"_blank\" rel=\"noopener\">next官网</a>查看配置内容。配置文件主要修改next中_config.yml文件，next有三种主题选择，分别为Muse、Mist、Pisces三种，个人选择的是Pisces主题。主题增加标签、分类、归档、喜欢（书籍和电影信息流）、文章阅读统计、访问人数统计、评论等功能，博客界面如下所示。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.1.png\" alt=\"图片6.1\"></p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.2.png\" alt=\"图片6.1\"></p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.3.png\" alt=\"图片6.1\"></p>\n<h4 id=\"6-1增加标签、分类、归档页\"><a href=\"#6-1增加标签、分类、归档页\" class=\"headerlink\" title=\"6.1增加标签、分类、归档页\"></a>6.1增加标签、分类、归档页</h4><p>首先将next/config.yml文件中将<code>menu</code>中<code>tags</code> <code>catagories</code> <code>archive</code>前面的<code>#</code>。例如增加标签页，通过<code>hexo new page &#39;tags&#39;</code>增加新界面，在myblog/sources中发现多了tags文件夹，修改index.md中内容，将type更改为<code>tags</code>。利用<code>hexo g</code>和<code>hexo d</code>将界面重新上传到服务器便可看到新增加的标签页，分类和归档页同理。</p>\n<h4 id=\"6-2增加喜欢界面\"><a href=\"#6-2增加喜欢界面\" class=\"headerlink\" title=\"6.2增加喜欢界面\"></a>6.2增加喜欢界面</h4><p>喜欢界面用于展现自己看过的书籍和电影，通过图片流的形式进行安装。</p>\n<p>从GitHub上<a href=\"https://github.com/weizhixiaoyi\" target=\"_blank\" rel=\"noopener\">https://github.com/weizhixiaoyi</a> 中的themes/next/scripts下载image-stream.js，放到你的主题/scripts目录中。如果博客主题已经默认引入了jQuery，建议在配置中将image_stream.jquery设置为false。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">image_stream:</span><br><span class=\"line\">\tjquery: false</span><br></pre></td></tr></table></figure>\n<p>在Hexo博客的本地目录中创建一个favorite页面目录，同6.1步骤。并在Next主题中配置config.yml，配置如下所示，其中heart表示图标为心形。</p>\n<figure class=\"highlight dts\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"symbol\">menu:</span></span><br><span class=\"line\"><span class=\"symbol\">  home:</span> / || home</span><br><span class=\"line\"><span class=\"symbol\">  about:</span> <span class=\"meta-keyword\">/about/</span> || user</span><br><span class=\"line\"><span class=\"symbol\">  favorite:</span> <span class=\"meta-keyword\">/favorite/</span> || heart</span><br><span class=\"line\"><span class=\"symbol\">  tags:</span> <span class=\"meta-keyword\">/tags/</span> || tags</span><br><span class=\"line\"><span class=\"symbol\">  categories:</span> <span class=\"meta-keyword\">/categories/</span> || th</span><br><span class=\"line\"><span class=\"symbol\">  archives:</span> <span class=\"meta-keyword\">/archives/</span> || archive</span><br></pre></td></tr></table></figure>\n<p>然后在source/favorite/index.md中使用插件自定义的两个模版来生成页面，index.md内容格式如下所示。</p>\n<figure class=\"highlight django\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\">stream</span> %&#125;</span><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\">figure</span> https://img3.doubanio.com/view/photo/raw/public/p2203001610.jpg</span></span><br><span class=\"line\"><span class=\"template-tag\">[《万物理论》]（https://movie.douban.com/subject/24815950/）%&#125;</span><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\">endstream</span> %&#125;</span><span class=\"xml\"></span></span><br></pre></td></tr></table></figure>\n<h4 id=\"6-3文章阅读统计\"><a href=\"#6-3文章阅读统计\" class=\"headerlink\" title=\"6.3文章阅读统计\"></a>6.3文章阅读统计</h4><p>文章阅读统计采用LeanCloud，能够提供直观的文章被访问次数，方便作者了解文章写作的质量。Next主题支持leancloud统计，但需要提供app_id和app_key，因此我们需另外注册leancloud账号，注册过程在此便不再赘述。</p>\n<p>注册成功之后进行创建新应用，设置相应用户名便创建成功。进入用户界面创建Class，在此需要注意的是Class名称必须为Counter，之后此表便是文章数量统计表。然后我们进入设置中的应用key模块便可获得app_id和app_key，进入next主题的config.yml中，找到leancloud位置复制即可，同时将enable设置为true。另外我们也可以在后台人为修改文章访问量，比如将Python之NumPy使用教程访问量增加。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">leancloud_visitors:</span></span><br><span class=\"line\"><span class=\"attr\">  enable:</span> <span class=\"literal\">true</span> </span><br><span class=\"line\"><span class=\"attr\">  app_id:</span> <span class=\"string\">Sj2lCA09ErubMSsa2v9oFU9Y-gzGzoHsz</span> <span class=\"comment\">#&lt;app_id&gt;</span></span><br><span class=\"line\"><span class=\"attr\">  app_key:</span> <span class=\"string\">qJejurdHKM06N75OQedX4SDK</span> <span class=\"comment\">#&lt;app_key&gt;</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.4.png\" alt=\"图片6.4\"></p>\n<h4 id=\"6-4增加百度统计\"><a href=\"#6-4增加百度统计\" class=\"headerlink\" title=\"6.4增加百度统计\"></a>6.4增加百度统计</h4><p>百度统计能够清晰看出网站访问数据。在百度官网注册账号后，添加绑定个人网站，在管理页面中找到<code>代码获取</code>。</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;script&gt;</span><br><span class=\"line\"><span class=\"keyword\">var</span> _hmt = _hmt || [];</span><br><span class=\"line\">(<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>) </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">var</span> hm = <span class=\"built_in\">document</span>.createElement(<span class=\"string\">\"script\"</span>);</span><br><span class=\"line\">  hm.src = <span class=\"string\">\"https://hm.baidu.com/hm.js?b54e835b3551fd0696954b3aedf5d645\"</span>;</span><br><span class=\"line\">  <span class=\"keyword\">var</span> s = <span class=\"built_in\">document</span>.getElementsByTagName(<span class=\"string\">\"script\"</span>)[<span class=\"number\">0</span>]; </span><br><span class=\"line\">  s.parentNode.insertBefore(hm, s);</span><br><span class=\"line\">&#125;)();</span><br><span class=\"line\">&lt;<span class=\"regexp\">/script&gt;</span></span><br></pre></td></tr></table></figure>\n<p>将代码中<code>b54e835b3551fd0696954b3aedf5d645</code>复制到next主题_config.yml的<code>baidu_analytics</code>中。接下来通过<code>代码安装检查</code>来检查代码是否安装成功，安装成功后便可查看网站详细统计信息。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.5.png\" alt=\"图片6.5\"></p>\n<h4 id=\"6-4增加评论功能\"><a href=\"#6-4增加评论功能\" class=\"headerlink\" title=\"6.4增加评论功能\"></a>6.4增加评论功能</h4><p>多说、网易云跟帖关闭，畅言需要备案，disqus被墙而且界面不是太美观。新出来的来必力倒是挺不错，支持QQ、微信、微博、百度、人人账号登陆，可以选择常用表情和gif动画，并支持自定义搜索表情。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片6.6.png\" alt=\"图片6.6\">进入来必力官网注册账号，填写网站域名，进入代码管理界面获得data-uid，复制到next主题_config.yml中的livere_uid处便可，重新提交网站便可看到评论专区。<code>编写文章时应在头部添加comments: true</code></p>\n<h3 id=\"7-绑定个人域名\"><a href=\"#7-绑定个人域名\" class=\"headerlink\" title=\"7.绑定个人域名\"></a>7.绑定个人域名</h3><p>现在使用的域名<code>weizhixiaoyi.github.io</code>是github提供的二级域名，也可绑定自己的个性域名<code>weizhixiaoyi.com</code>。域名是在阿里云购买，年费为55元，也可以在狗爹<code>https://sg.godaddy.com</code>购买，购买好域名之后便可以直接解析。</p>\n<h4 id=\"7-1GitHub端\"><a href=\"#7-1GitHub端\" class=\"headerlink\" title=\"7.1GitHub端\"></a>7.1GitHub端</h4><p>在next主题中source文件夹中创建<code>CNAME</code>文件，没有后缀名，然后将个人域名<code>weizhixiaoyi.com</code>添加进<code>CNAME</code>文件即可，然后通过<code>hexo g</code> <code>hexo d</code>重新部署网站。</p>\n<h4 id=\"7-2域名解析\"><a href=\"#7-2域名解析\" class=\"headerlink\" title=\"7.2域名解析\"></a>7.2域名解析</h4><p>如果将域名指向另外一个域名，需要增加CNAME记录。登陆阿里云官网，进入控制台中域名设置，添加解析。</p>\n<ul>\n<li>记录类型：CNAME</li>\n<li>主机记录：@</li>\n<li>解析线路：默认</li>\n<li>记录值：weizhixiaoyi.github.io</li>\n</ul>\n<p>解析成功后，等待几分钟便可登陆weizhixiaoyi.com查看网站内容。</p>\n<h3 id=\"7-博客SEO优化\"><a href=\"#7-博客SEO优化\" class=\"headerlink\" title=\"7.博客SEO优化\"></a>7.博客SEO优化</h3><p>SEO优化也就是搜索引擎优化，搜索引擎优化即为增加博客内容被搜索引擎爬取次数，以此增加博客的点击率和曝光度。如果想让自己博客更加容易被搜索到，便是让百度爬虫、谷歌爬虫主动去爬取自己博客内容，但由于Github博客屏蔽百度爬虫，所以只能将自己的博客收录到谷歌，当然这种方法适合于墙外用户。</p>\n<h4 id=\"7-1确认收录情况\"><a href=\"#7-1确认收录情况\" class=\"headerlink\" title=\"7.1确认收录情况\"></a>7.1确认收录情况</h4><p>在谷歌上搜索<code>site:weizhixiaoyi.com</code>，如果能搜索内容就已经被谷歌收录，否则就没有被谷歌收录。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片7.1.png\" alt=\"图片7.1\"></p>\n<h4 id=\"7-1网站身份验证\"><a href=\"#7-1网站身份验证\" class=\"headerlink\" title=\"7.1网站身份验证\"></a>7.1网站身份验证</h4><p>验证网站的目的就是证明你是网站的所有者，这里使用站长平台功能进行验证，另外没有梯子的朋友可以通过<code>shadowsock</code>+<code>搬瓦工</code>自行搭建。</p>\n<p>进入谷歌站长平台中的搜索引擎提交入口，添加域名，选择验证方式。个人选择的是在网页中添加标签，进入next主题文件夹，然后找到layout/_partials/，打开head.swig文件，在theme_google_site_verification处添加如下信息。</p>\n<figure class=\"highlight django\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">if</span></span> theme.google_site_verification %&#125;</span><span class=\"xml\"></span></span><br><span class=\"line\"><span class=\"xml\">  <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">name</span>=<span class=\"string\">\"google-site-verification\"</span> <span class=\"attr\">content</span>=<span class=\"string\">\"E1Oy09IV-Rsypa8wpY-yrplcH8RMIHLCzj3m91nX1Eo\"</span> /&gt;</span></span></span><br><span class=\"line\"><span class=\"xml\"></span><span class=\"template-tag\">&#123;% <span class=\"name\"><span class=\"name\">endif</span></span> %&#125;</span><span class=\"xml\"></span></span><br></pre></td></tr></table></figure>\n<p>然后回到<code>myblog</code>文件夹下将_config.yml中google_site_vertification设置为<code>true</code>。当然你也可以选择其他验证方式，比如添加html文档。信息添加成功之后便可利用<code>hexo g</code>和<code>hexo d</code>更新博客内容，至此网站身份验证结束。</p>\n<h4 id=\"7-2添加Sitemap\"><a href=\"#7-2添加Sitemap\" class=\"headerlink\" title=\"7.2添加Sitemap\"></a>7.2添加Sitemap</h4><p>sitemap站点地图是一种文件格式，可以通过该文件列出您网站上的链接，从而将您网站内容告知谷歌和其他搜索引擎。</p>\n<p>首先安装针对谷歌的插件<code>npm install hexo-generator-sitemap --save</code>，然后进入<code>myblog</code>文件夹下将<code>sitemap</code>设置如下。</p>\n<figure class=\"highlight dts\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\"># sitemap</span></span><br><span class=\"line\"><span class=\"symbol\">sitemap:</span></span><br><span class=\"line\"><span class=\"symbol\">  path:</span> sitemap.xml</span><br></pre></td></tr></table></figure>\n<h4 id=\"7-3谷歌收录博客\"><a href=\"#7-3谷歌收录博客\" class=\"headerlink\" title=\"7.3谷歌收录博客\"></a>7.3谷歌收录博客</h4><p>谷歌收录操作比较简单，就是向Google站长工具提交sitemap，成功登陆Google账号后，添加站点验证。站点验证通过后找到站点地图界面，然后进行添加站点地图地址就行啦。等待1天后通过<code>site:weizhixiaoyi.com</code>能够搜索到博客内容，便证明谷歌搜索引擎已收录网站内容。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/图片7.2.png\" alt=\"图片7.2\"></p>\n<p>另外也可通过bing站长管理工具进行收录网站内容，将网站内容呈现给更多需要帮助的人。针对百度爬虫不能爬取Github博客内容问题，我尝试过利用coding托管(免费版绑定域名有广告)、CDN加速(对于流量太小的网站没什么用)，但感觉效果都不是太好，所以问题亟待解决，等找到合适的解决办法之后再告知大家。</p>\n<h3 id=\"8-ToDoList\"><a href=\"#8-ToDoList\" class=\"headerlink\" title=\"8.ToDoList\"></a>8.ToDoList</h3><ul>\n<li>寻找更好的方法解决百度爬虫无法爬取博客内容的问题</li>\n<li>博客增加转发功能</li>\n</ul>\n<hr>\n<h3 id=\"9-推广\"><a href=\"#9-推广\" class=\"headerlink\" title=\"9.推广\"></a>9.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/16/Mac+Hexo+GitHub博客搭建教程/推广.png\" alt=\"推广\"></p>\n"},{"title":"Python之Pandas使用教程","date":"2018-03-12T05:18:48.000Z","toc":true,"comments":1,"_content":"### 1.Pandas概述\n\n 1. Pandas是Python的一个数据分析包，该工具为解决数据分析任务而创建。\n 2. Pandas纳入大量库和标准数据模型，提供高效的操作数据集所需的工具。\n 3. Pandas提供大量能使我们快速便捷地处理数据的函数和方法。\n 4. Pandas是字典形式，基于NumPy创建，让NumPy为中心的应用变得更加简单。   \n### 2.Pandas安装\n```\npip3 install pandas\n```\n### 3.Pandas引入\n```\nimport pandas as pd#为了方便实用pandas 采用pd简写\n```\n### 4.Pandas数据结构\n#### 4.1Series\n```\nimport numpy as np\nimport pandas as pd\ns=pd.Series([1,2,3,np.nan,5,6])\nprint(s)#索引在左边 值在右边\n'''\n0    1.0\n1    2.0\n2    3.0\n3    NaN\n4    5.0\n5    6.0\ndtype: float64\n '''\n```\n#### 4.2DataFrame\nDataFrame是表格型数据结构，包含一组有序的列，每列可以是不同的值类型。DataFrame有行索引和列索引，可以看成由Series组成的字典。\n```\ndates=pd.date_range('20180310',periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=['A','B','C','D'])#生成6行4列位置\nprint(df)#输出6行4列的表格\n'''\n                   A         B         C         D\n2018-03-10 -0.092889 -0.503172  0.692763 -1.261313\n2018-03-11 -0.895628 -2.300249 -1.098069  0.468986\n2018-03-12  0.084732 -1.275078  1.638007 -0.291145\n2018-03-13 -0.561528  0.431088  0.430414  1.065939\n2018-03-14  1.485434 -0.341404  0.267613 -1.493366\n2018-03-15 -1.671474  0.110933  1.688264 -0.910599\n  '''\nprint(df['B'])\n'''\n2018-03-10   -0.927291\n2018-03-11   -0.406842\n2018-03-12   -0.088316\n2018-03-13   -1.631055\n2018-03-14   -0.929926\n2018-03-15   -0.010904\nFreq: D, Name: B, dtype: float64\n '''\n\n#创建特定数据的DataFrame\ndf_1=pd.DataFrame({'A' : 1.,\n                    'B' : pd.Timestamp('20180310'),\n                    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n                    'D' : np.array([3] * 4,dtype='int32'),\n                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n                    'F' : 'foo'\n                    })\nprint(df_1)\n'''\n     A          B    C  D      E    F\n0  1.0 2018-03-10  1.0  3   test  foo\n1  1.0 2018-03-10  1.0  3  train  foo\n2  1.0 2018-03-10  1.0  3   test  foo\n3  1.0 2018-03-10  1.0  3  train  foo\n'''\nprint(df_1.dtypes)\n'''\nA           float64\nB    datetime64[ns]\nC           float32\nD             int32\nE          category\nF            object\ndtype: object\n'''\nprint(df_1.index)#行的序号\n#Int64Index([0, 1, 2, 3], dtype='int64')\nprint(df_1.columns)#列的序号名字\n#Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')\nprint(df_1.values)#把每个值进行打印出来\n'''\n[[1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']]\n '''\nprint(df_1.describe())#数字总结\n'''\n         A    C    D\ncount  4.0  4.0  4.0\nmean   1.0  1.0  3.0\nstd    0.0  0.0  0.0\nmin    1.0  1.0  3.0\n25%    1.0  1.0  3.0\n50%    1.0  1.0  3.0\n75%    1.0  1.0  3.0\nmax    1.0  1.0  3.0\n'''\nprint(df_1.T)#翻转数据\n'''\n                     0                    1                    2  \\\nA                    1                    1                    1   \nB  2018-03-10 00:00:00  2018-03-10 00:00:00  2018-03-10 00:00:00   \nC                    1                    1                    1   \nD                    3                    3                    3   \nE                 test                train                 test   \nF                  foo                  foo                  foo   \n\n                     3  \nA                    1  \nB  2018-03-10 00:00:00  \nC                    1  \nD                    3  \nE                train  \nF                  foo  \n'''\nprint(df_1.sort_index(axis=1, ascending=False))#axis等于1按列进行排序 如ABCDEFG 然后ascending倒叙进行显示\n'''\n     F      E  D    C          B    A\n0  foo   test  3  1.0 2018-03-10  1.0\n1  foo  train  3  1.0 2018-03-10  1.0\n2  foo   test  3  1.0 2018-03-10  1.0\n3  foo  train  3  1.0 2018-03-10  1.0\n'''\nprint(df_1.sort_values(by='E'))#按值进行排序\n'''\n     A          B    C  D      E    F\n0  1.0 2018-03-10  1.0  3   test  foo\n2  1.0 2018-03-10  1.0  3   test  foo\n1  1.0 2018-03-10  1.0  3  train  foo\n3  1.0 2018-03-10  1.0  3  train  foo\n'''\n```\n###5.Pandas选择数据\n```\ndates=pd.date_range('20180310',periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=['A','B','C','D'])#生成6行4列位置\nprint(df)\n'''\n                   A         B         C         D\n2018-03-10 -0.520509 -0.136602 -0.516984  1.357505\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465\n2018-03-13  0.540385  0.427337 -0.591381  0.126503\n2018-03-14  0.191962  1.237843  1.903370  2.155366\n2018-03-15 -0.188331 -0.578581 -0.845854 -0.056373\n '''\nprint(df['A'])#或者df.A 选择某列\n'''\n2018-03-10   -0.520509\n2018-03-11    0.332656\n2018-03-12    0.499960\n2018-03-13    0.540385\n2018-03-14    0.191962\n2018-03-15   -0.188331\n'''\n```\n切片选择\n```\nprint(df[0:3], df['20180310':'20180314'])#两次进行选择 第一次切片选择 第二次按照筛选条件进行选择\n'''\n                   A         B         C         D\n2018-03-10 -0.520509 -0.136602 -0.516984  1.357505\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465                    \n                  A         B         C         D\n2018-03-10 -0.520509 -0.136602 -0.516984  1.357505\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465\n2018-03-13  0.540385  0.427337 -0.591381  0.126503\n2018-03-14  0.191962  1.237843  1.903370  2.155366\n '''\n```\n根据标签loc-行标签进行选择数据\n```\nprint(df.loc['20180312', ['A','B']])#按照行标签进行选择 精确选择\n '''\nA    0.499960\nB    1.576897\nName: 2018-03-12 00:00:00, dtype: float64\n'''\n```\n根据序列iloc-行号进行选择数据\n```\nprint(df.iloc[3, 1])#输出第三行第一列的数据\n#0.427336827399\n\nprint(df.iloc[3:5,0:2])#进行切片选择\n '''\n                   A         B\n2018-03-13  0.540385  0.427337\n2018-03-14  0.191962  1.237843\n '''\n\nprint(df.iloc[[1,2,4],[0,2]])#进行不连续筛选\n'''\n                   A         C\n2018-03-11  0.332656  0.382384\n2018-03-12  0.499960  2.128730\n2018-03-14  0.191962  1.903370\n '''\n```\n根据混合的两种ix\n```\nprint(df.ix[:3, ['A', 'C']])\n'''\n                   A         C\n2018-03-10 -0.919275 -1.356037\n2018-03-11  0.010171 -0.380010\n2018-03-12  0.285251 -1.174265\n '''\n```\n\n根据判断筛选\n```\nprint(df[df.A > 0])#筛选出df.A大于0的元素 布尔条件筛选\n'''\n                   A         B         C         D\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465\n2018-03-13  0.540385  0.427337 -0.591381  0.126503\n2018-03-14  0.191962  1.237843  1.903370  2.155366\n '''\n```\n### 6.Pandas设置数据\n根据loc和iloc设置\n```\ndates = pd.date_range('20180310', periods=6)\ndf = pd.DataFrame(np.arange(24).reshape((6,4)), index=dates, columns=['A', 'B', 'C', 'D'])\nprint(df)\n'''\n             A   B     C   D\n2018-03-10   0   1     2   3\n2018-03-11   4   5     6   7\n2018-03-12   8   9  1111  11\n2018-03-13  12  13    14  15\n2018-03-14  16  17    18  19\n2018-03-15  20  21    22  23\n'''\n\ndf.iloc[2,2] = 999#单点设置\ndf.loc['2018-03-13', 'D'] = 999\nprint(df)\n'''\n            A   B    C    D\n2018-03-10  0   1    2    3\n2018-03-11  0   5    6    7\n2018-03-12  0   9  999   11\n2018-03-13  0  13   14  999\n2018-03-14  0  17   18   19\n2018-03-15  0  21   22   23\n'''\n```\n根据条件设置\n```\ndf[df.A>0]=999#将df.A大于0的值改变\nprint(df)\n'''\n              A   B    C    D\n2018-03-10    0   1    2    3\n2018-03-11  999   5    6    7\n2018-03-12  999   9  999   11\n2018-03-13  999  13   14  999\n2018-03-14  999  17   18   19\n2018-03-15  999  21   22   23\n '''\n```\n根据行或列设置\n```\ndf['F']=np.nan\nprint(df)\n'''\n              A   B    C   D\n2018-03-10    0   1    2 NaN\n2018-03-11  999   5    6 NaN\n2018-03-12  999   9  999 NaN\n2018-03-13  999  13   14 NaN\n2018-03-14  999  17   18 NaN\n2018-03-15  999  21   22 NaN\n '''\n```\n添加数据\n```\ndf['E']  = pd.Series([1,2,3,4,5,6], index=pd.date_range('20180313', periods=6))#增加一列\nprint(df)\n'''\n              A   B    C   D    E\n2018-03-10    0   1    2 NaN  NaN\n2018-03-11  999   5    6 NaN  NaN\n2018-03-12  999   9  999 NaN  NaN\n2018-03-13  999  13   14 NaN  1.0\n2018-03-14  999  17   18 NaN  2.0\n2018-03-15  999  21   22 NaN  3.0\n'''\n```\n### 7.Pandas处理丢失数据\n处理数据中NaN数据\n```\ndates = pd.date_range('20180310', periods=6)\ndf = pd.DataFrame(np.arange(24).reshape((6,4)), index=dates, columns=['A', 'B', 'C', 'D'])\ndf.iloc[0,1]=np.nan\ndf.iloc[1,2]=np.nan\nprint(df)\n'''\n             A     B     C   D\n2018-03-10   0   NaN   2.0   3\n2018-03-11   4   5.0   NaN   7\n2018-03-12   8   9.0  10.0  11\n2018-03-13  12  13.0  14.0  15\n2018-03-14  16  17.0  18.0  19\n2018-03-15  20  21.0  22.0  23\n'''\n```\n使用dropna（）函数去掉NaN的行或列\n```\nprint(df.dropna(axis=0,how='any'#))#0对行进行操作 1对列进行操作 any:只要存在NaN即可drop掉 all:必须全部是NaN才可drop\n'''\n             A     B     C   D\n2018-03-12   8   9.0  10.0  11\n2018-03-13  12  13.0  14.0  15\n2018-03-14  16  17.0  18.0  19\n2018-03-15  20  21.0  22.0  23\n '''\n```\n使用fillna（）函数替换NaN值 \n```\nprint(df.fillna(value=0))#将NaN值替换为0\n'''\n             A     B     C   D\n2018-03-10   0   0.0   2.0   3\n2018-03-11   4   5.0   0.0   7\n2018-03-12   8   9.0  10.0  11\n2018-03-13  12  13.0  14.0  15\n2018-03-14  16  17.0  18.0  19\n2018-03-15  20  21.0  22.0  23\n '''\n```\n使用isnull()函数判断数据是否丢失\n```\nprint(pd.isnull(df))#矩阵用布尔来进行表示 是nan为ture 不是nan为false\n'''\n                A      B      C      D\n2018-03-10  False   True  False  False\n2018-03-11  False  False   True  False\n2018-03-12  False  False  False  False\n2018-03-13  False  False  False  False\n2018-03-14  False  False  False  False\n2018-03-15  False  False  False  False\n '''\nprint(np.any(df.isnull()))#判断数据中是否会存在NaN值\n#True\n```\n### 8.Pandas导入导出\npandas可以读取与存取像csv、excel、json、html、pickle等格式的资料，详细说明请看[官方资料](http://pandas.pydata.org/pandas-docs/stable/io.html)\n```\ndata=pd.read_csv('test1.csv')#读取csv文件\ndata.to_pickle('test2.pickle')#将资料存取成pickle文件 \n#其他文件导入导出方式相同\n```\n### 9.Pandas合并数据\naxis合并方向\n```\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])\ndf3 = pd.DataFrame(np.ones((3,4))*2, columns=['a','b','c','d'])\nres = pd.concat([df1, df2, df3], axis=0, ignore_index=True)#0表示竖项合并 1表示横项合并 ingnore_index重置序列index index变为0 1 2 3 4 5 6 7 8\nprint(res)\n'''\n     a    b    c    d\n0  0.0  0.0  0.0  0.0\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  1.0  1.0  1.0  1.0\n4  1.0  1.0  1.0  1.0\n5  1.0  1.0  1.0  1.0\n6  2.0  2.0  2.0  2.0\n7  2.0  2.0  2.0  2.0\n8  2.0  2.0  2.0  2.0\n '''\n```\njoin合并方式\n```\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'], index=[1,2,3])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=['b','c','d', 'e'], index=[2,3,4])\nprint(df1)\n'''\n     a    b    c    d\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  0.0  0.0  0.0  0.0\n '''\nprint(df2)\n'''\n     b    c    d    e\n2  1.0  1.0  1.0  1.0\n3  1.0  1.0  1.0  1.0\n4  1.0  1.0  1.0  1.0\n '''\nres=pd.concat([df1,df2],axis=1,join='outer')#行往外进行合并\nprint(res)\n'''\n     a    b    c    d    b    c    d    e\n1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN\n2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n4  NaN  NaN  NaN  NaN  1.0  1.0  1.0  1.0\n '''\n\nres=pd.concat([df1,df2],axis=1,join='outer')#行相同的进行合并\nprint(res)\n'''\n     a    b    c    d    b    c    d    e\n2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n'''\n\nres=pd.concat([df1,df2],axis=1,join_axes=[df1.index])#以df1的序列进行合并 df2中没有的序列NaN值填充\nprint(res)\n'''\n     a    b    c    d    b    c    d    e\n1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN\n2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n'''\n```\nappend添加数据\n```\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])\ndf3 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])\ns1 = pd.Series([1,2,3,4], index=['a','b','c','d'])\n\nres=df1.append(df2,ignore_index=True)#将df2合并到df1的下面 并重置index\nprint(res)\n'''\n     a    b    c    d\n0  0.0  0.0  0.0  0.0\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  1.0  1.0  1.0  1.0\n4  1.0  1.0  1.0  1.0\n5  1.0  1.0  1.0  1.0\n'''\n\nres=df1.append(s1,ignore_index=True)#将s1合并到df1下面 并重置index\nprint(res)\n'''\n     a    b    c    d\n0  0.0  0.0  0.0  0.0\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  1.0  2.0  3.0  4.0\n'''\n```\n### 10.Pandas合并merge\n依据一组key合并\n```\nleft = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                     'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3']})\nprint(left)\n'''\n    A   B key\n0  A0  B0  K0\n1  A1  B1  K1\n2  A2  B2  K2\n3  A3  B3  K3\n'''\nright = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                      'C': ['C0', 'C1', 'C2',  'C3'],\n                      'D': ['D0', 'D1', 'D2', 'D3']})\nprint(right)\n'''\n    C   D key\n0  C0  D0  K0\n1  C1  D1  K1\n2  C2  D2  K2\n3  C3  D3  K3\n'''\nres=pd.merge(left,right,on='key')\nprint(res)\n'''\n    A   B key   C   D\n0  A0  B0  K0  C0  D0\n1  A1  B1  K1  C1  D1\n2  A2  B2  K2  C2  D2\n3  A3  B3  K3  C3  D3\n'''\n```\n依据两组key合并\n```\nleft = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n                             'key2': ['K0', 'K1', 'K0', 'K1'],\n                             'A': ['A0', 'A1', 'A2', 'A3'],\n                             'B': ['B0', 'B1', 'B2', 'B3']})\nprint(left)\n'''\n    A   B key1 key2\n0  A0  B0   K0   K0\n1  A1  B1   K0   K1\n2  A2  B2   K1   K0\n3  A3  B3   K2   K1\n '''\nright = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n                              'key2': ['K0', 'K0', 'K0', 'K0'],\n                              'C': ['C0', 'C1', 'C2', 'C3'],\n                              'D': ['D0', 'D1', 'D2', 'D3']})\nprint(right)\n'''\n    C   D key1 key2\n0  C0  D0   K0   K0\n1  C1  D1   K1   K0\n2  C2  D2   K1   K0\n3  C3  D3   K2   K0\n '''\n\nres=pd.merge(left,right,on=['key1','key2'],how='inner')#内联合并\nprint(res)\n'''\n    A   B key1 key2   C   D\n0  A0  B0   K0   K0  C0  D0\n1  A2  B2   K1   K0  C1  D1\n2  A2  B2   K1   K0  C2  D2\n'''\n\nres=pd.merge(left,right,on=['key1','key2'],how='outer')#外联合并\nprint(res)\n'''\n     A    B key1 key2    C    D\n0   A0   B0   K0   K0   C0   D0\n1   A1   B1   K0   K1  NaN  NaN\n2   A2   B2   K1   K0   C1   D1\n3   A2   B2   K1   K0   C2   D2\n4   A3   B3   K2   K1  NaN  NaN\n5  NaN  NaN   K2   K0   C3   D3\n'''\n\nres=pd.merge(left,right,on=['key1','key2'],how='left')#左联合并\n'''\n    A   B key1 key2    C    D\n0  A0  B0   K0   K0   C0   D0\n1  A1  B1   K0   K1  NaN  NaN\n2  A2  B2   K1   K0   C1   D1\n3  A2  B2   K1   K0   C2   D2\n4  A3  B3   K2   K1  NaN  NaN\n'''\n\nres=pd.merge(left,right,on=['key1','key2'],how='right')#右联合并\nprint(res)\n'''\n     A    B key1 key2   C   D\n0   A0   B0   K0   K0  C0  D0\n1   A2   B2   K1   K0  C1  D1\n2   A2   B2   K1   K0  C2  D2\n3  NaN  NaN   K2   K0  C3  D3\n'''\n```\nIndicator合并\n```\ndf1 = pd.DataFrame({'col1':[0,1], 'col_left':['a','b']})\nprint(df1)\n'''\n   col1 col_left\n0     0        a\n1     1        b\n '''\ndf2 = pd.DataFrame({'col1':[1,2,2],'col_right':[2,2,2]})\nprint(df2)\n'''\n   col1  col_right\n0     1          2\n1     2          2\n2     2          2\n '''\n\nres=pd.merge(df1,df2,on='col1',how='outer',indicator=True)#依据col1进行合并 并启用indicator=True输出每项合并方式\nprint(res)\n'''\n   col1 col_left  col_right      _merge\n0     0        a        NaN   left_only\n1     1        b        2.0        both\n2     2      NaN        2.0  right_only\n3     2      NaN        2.0  right_only\n'''\n\nres = pd.merge(df1, df2, on='col1', how='outer', indicator='indicator_column')#自定义indicator column名称\nprint(res)\n'''\n   col1 col_left  col_right indicator_column\n0     0        a        NaN        left_only\n1     1        b        2.0             both\n2     2      NaN        2.0       right_only\n3     2      NaN        2.0       right_only\n'''\n```\n依据index合并\n```\nleft = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n                                  'B': ['B0', 'B1', 'B2']},\n                                  index=['K0', 'K1', 'K2'])\nprint(left)\n'''\n     A   B\nK0  A0  B0\nK1  A1  B1\nK2  A2  B2\n '''\nright = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n                                     'D': ['D0', 'D2', 'D3']},\n                                      index=['K0', 'K2', 'K3'])\nprint(right)\n'''\n     C   D\nK0  C0  D0\nK2  C2  D2\nK3  C3  D3\n'''\n\nres=pd.merge(left,right,left_index=True,right_index=True,how='outer')#根据index索引进行合并 并选择外联合并\nprint(res)\n'''\n      A    B    C    D\nK0   A0   B0   C0   D0\nK1   A1   B1  NaN  NaN\nK2   A2   B2   C2   D2\nK3  NaN  NaN   C3   D3\n'''\n\nres=pd.merge(left,right,left_index=True,right_index=True,how='inner')\nprint(res)\n'''\n     A   B   C   D\nK0  A0  B0  C0  D0\nK2  A2  B2  C2  D2\n'''\n```\n----------\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活...\n<div align=center>![公众号](http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)","source":"_posts/Python之Pandas使用教程.md","raw":"---\ntitle: Python之Pandas使用教程\ndate: 2018-03-12 13:18:48\ntags: python\ntoc: true\ncategories: Python库\ncomments: true\n---\n### 1.Pandas概述\n\n 1. Pandas是Python的一个数据分析包，该工具为解决数据分析任务而创建。\n 2. Pandas纳入大量库和标准数据模型，提供高效的操作数据集所需的工具。\n 3. Pandas提供大量能使我们快速便捷地处理数据的函数和方法。\n 4. Pandas是字典形式，基于NumPy创建，让NumPy为中心的应用变得更加简单。   \n### 2.Pandas安装\n```\npip3 install pandas\n```\n### 3.Pandas引入\n```\nimport pandas as pd#为了方便实用pandas 采用pd简写\n```\n### 4.Pandas数据结构\n#### 4.1Series\n```\nimport numpy as np\nimport pandas as pd\ns=pd.Series([1,2,3,np.nan,5,6])\nprint(s)#索引在左边 值在右边\n'''\n0    1.0\n1    2.0\n2    3.0\n3    NaN\n4    5.0\n5    6.0\ndtype: float64\n '''\n```\n#### 4.2DataFrame\nDataFrame是表格型数据结构，包含一组有序的列，每列可以是不同的值类型。DataFrame有行索引和列索引，可以看成由Series组成的字典。\n```\ndates=pd.date_range('20180310',periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=['A','B','C','D'])#生成6行4列位置\nprint(df)#输出6行4列的表格\n'''\n                   A         B         C         D\n2018-03-10 -0.092889 -0.503172  0.692763 -1.261313\n2018-03-11 -0.895628 -2.300249 -1.098069  0.468986\n2018-03-12  0.084732 -1.275078  1.638007 -0.291145\n2018-03-13 -0.561528  0.431088  0.430414  1.065939\n2018-03-14  1.485434 -0.341404  0.267613 -1.493366\n2018-03-15 -1.671474  0.110933  1.688264 -0.910599\n  '''\nprint(df['B'])\n'''\n2018-03-10   -0.927291\n2018-03-11   -0.406842\n2018-03-12   -0.088316\n2018-03-13   -1.631055\n2018-03-14   -0.929926\n2018-03-15   -0.010904\nFreq: D, Name: B, dtype: float64\n '''\n\n#创建特定数据的DataFrame\ndf_1=pd.DataFrame({'A' : 1.,\n                    'B' : pd.Timestamp('20180310'),\n                    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n                    'D' : np.array([3] * 4,dtype='int32'),\n                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n                    'F' : 'foo'\n                    })\nprint(df_1)\n'''\n     A          B    C  D      E    F\n0  1.0 2018-03-10  1.0  3   test  foo\n1  1.0 2018-03-10  1.0  3  train  foo\n2  1.0 2018-03-10  1.0  3   test  foo\n3  1.0 2018-03-10  1.0  3  train  foo\n'''\nprint(df_1.dtypes)\n'''\nA           float64\nB    datetime64[ns]\nC           float32\nD             int32\nE          category\nF            object\ndtype: object\n'''\nprint(df_1.index)#行的序号\n#Int64Index([0, 1, 2, 3], dtype='int64')\nprint(df_1.columns)#列的序号名字\n#Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')\nprint(df_1.values)#把每个值进行打印出来\n'''\n[[1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']]\n '''\nprint(df_1.describe())#数字总结\n'''\n         A    C    D\ncount  4.0  4.0  4.0\nmean   1.0  1.0  3.0\nstd    0.0  0.0  0.0\nmin    1.0  1.0  3.0\n25%    1.0  1.0  3.0\n50%    1.0  1.0  3.0\n75%    1.0  1.0  3.0\nmax    1.0  1.0  3.0\n'''\nprint(df_1.T)#翻转数据\n'''\n                     0                    1                    2  \\\nA                    1                    1                    1   \nB  2018-03-10 00:00:00  2018-03-10 00:00:00  2018-03-10 00:00:00   \nC                    1                    1                    1   \nD                    3                    3                    3   \nE                 test                train                 test   \nF                  foo                  foo                  foo   \n\n                     3  \nA                    1  \nB  2018-03-10 00:00:00  \nC                    1  \nD                    3  \nE                train  \nF                  foo  \n'''\nprint(df_1.sort_index(axis=1, ascending=False))#axis等于1按列进行排序 如ABCDEFG 然后ascending倒叙进行显示\n'''\n     F      E  D    C          B    A\n0  foo   test  3  1.0 2018-03-10  1.0\n1  foo  train  3  1.0 2018-03-10  1.0\n2  foo   test  3  1.0 2018-03-10  1.0\n3  foo  train  3  1.0 2018-03-10  1.0\n'''\nprint(df_1.sort_values(by='E'))#按值进行排序\n'''\n     A          B    C  D      E    F\n0  1.0 2018-03-10  1.0  3   test  foo\n2  1.0 2018-03-10  1.0  3   test  foo\n1  1.0 2018-03-10  1.0  3  train  foo\n3  1.0 2018-03-10  1.0  3  train  foo\n'''\n```\n###5.Pandas选择数据\n```\ndates=pd.date_range('20180310',periods=6)\ndf = pd.DataFrame(np.random.randn(6,4), index=dates, columns=['A','B','C','D'])#生成6行4列位置\nprint(df)\n'''\n                   A         B         C         D\n2018-03-10 -0.520509 -0.136602 -0.516984  1.357505\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465\n2018-03-13  0.540385  0.427337 -0.591381  0.126503\n2018-03-14  0.191962  1.237843  1.903370  2.155366\n2018-03-15 -0.188331 -0.578581 -0.845854 -0.056373\n '''\nprint(df['A'])#或者df.A 选择某列\n'''\n2018-03-10   -0.520509\n2018-03-11    0.332656\n2018-03-12    0.499960\n2018-03-13    0.540385\n2018-03-14    0.191962\n2018-03-15   -0.188331\n'''\n```\n切片选择\n```\nprint(df[0:3], df['20180310':'20180314'])#两次进行选择 第一次切片选择 第二次按照筛选条件进行选择\n'''\n                   A         B         C         D\n2018-03-10 -0.520509 -0.136602 -0.516984  1.357505\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465                    \n                  A         B         C         D\n2018-03-10 -0.520509 -0.136602 -0.516984  1.357505\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465\n2018-03-13  0.540385  0.427337 -0.591381  0.126503\n2018-03-14  0.191962  1.237843  1.903370  2.155366\n '''\n```\n根据标签loc-行标签进行选择数据\n```\nprint(df.loc['20180312', ['A','B']])#按照行标签进行选择 精确选择\n '''\nA    0.499960\nB    1.576897\nName: 2018-03-12 00:00:00, dtype: float64\n'''\n```\n根据序列iloc-行号进行选择数据\n```\nprint(df.iloc[3, 1])#输出第三行第一列的数据\n#0.427336827399\n\nprint(df.iloc[3:5,0:2])#进行切片选择\n '''\n                   A         B\n2018-03-13  0.540385  0.427337\n2018-03-14  0.191962  1.237843\n '''\n\nprint(df.iloc[[1,2,4],[0,2]])#进行不连续筛选\n'''\n                   A         C\n2018-03-11  0.332656  0.382384\n2018-03-12  0.499960  2.128730\n2018-03-14  0.191962  1.903370\n '''\n```\n根据混合的两种ix\n```\nprint(df.ix[:3, ['A', 'C']])\n'''\n                   A         C\n2018-03-10 -0.919275 -1.356037\n2018-03-11  0.010171 -0.380010\n2018-03-12  0.285251 -1.174265\n '''\n```\n\n根据判断筛选\n```\nprint(df[df.A > 0])#筛选出df.A大于0的元素 布尔条件筛选\n'''\n                   A         B         C         D\n2018-03-11  0.332656 -0.094633  0.382384 -0.914339\n2018-03-12  0.499960  1.576897  2.128730  2.197465\n2018-03-13  0.540385  0.427337 -0.591381  0.126503\n2018-03-14  0.191962  1.237843  1.903370  2.155366\n '''\n```\n### 6.Pandas设置数据\n根据loc和iloc设置\n```\ndates = pd.date_range('20180310', periods=6)\ndf = pd.DataFrame(np.arange(24).reshape((6,4)), index=dates, columns=['A', 'B', 'C', 'D'])\nprint(df)\n'''\n             A   B     C   D\n2018-03-10   0   1     2   3\n2018-03-11   4   5     6   7\n2018-03-12   8   9  1111  11\n2018-03-13  12  13    14  15\n2018-03-14  16  17    18  19\n2018-03-15  20  21    22  23\n'''\n\ndf.iloc[2,2] = 999#单点设置\ndf.loc['2018-03-13', 'D'] = 999\nprint(df)\n'''\n            A   B    C    D\n2018-03-10  0   1    2    3\n2018-03-11  0   5    6    7\n2018-03-12  0   9  999   11\n2018-03-13  0  13   14  999\n2018-03-14  0  17   18   19\n2018-03-15  0  21   22   23\n'''\n```\n根据条件设置\n```\ndf[df.A>0]=999#将df.A大于0的值改变\nprint(df)\n'''\n              A   B    C    D\n2018-03-10    0   1    2    3\n2018-03-11  999   5    6    7\n2018-03-12  999   9  999   11\n2018-03-13  999  13   14  999\n2018-03-14  999  17   18   19\n2018-03-15  999  21   22   23\n '''\n```\n根据行或列设置\n```\ndf['F']=np.nan\nprint(df)\n'''\n              A   B    C   D\n2018-03-10    0   1    2 NaN\n2018-03-11  999   5    6 NaN\n2018-03-12  999   9  999 NaN\n2018-03-13  999  13   14 NaN\n2018-03-14  999  17   18 NaN\n2018-03-15  999  21   22 NaN\n '''\n```\n添加数据\n```\ndf['E']  = pd.Series([1,2,3,4,5,6], index=pd.date_range('20180313', periods=6))#增加一列\nprint(df)\n'''\n              A   B    C   D    E\n2018-03-10    0   1    2 NaN  NaN\n2018-03-11  999   5    6 NaN  NaN\n2018-03-12  999   9  999 NaN  NaN\n2018-03-13  999  13   14 NaN  1.0\n2018-03-14  999  17   18 NaN  2.0\n2018-03-15  999  21   22 NaN  3.0\n'''\n```\n### 7.Pandas处理丢失数据\n处理数据中NaN数据\n```\ndates = pd.date_range('20180310', periods=6)\ndf = pd.DataFrame(np.arange(24).reshape((6,4)), index=dates, columns=['A', 'B', 'C', 'D'])\ndf.iloc[0,1]=np.nan\ndf.iloc[1,2]=np.nan\nprint(df)\n'''\n             A     B     C   D\n2018-03-10   0   NaN   2.0   3\n2018-03-11   4   5.0   NaN   7\n2018-03-12   8   9.0  10.0  11\n2018-03-13  12  13.0  14.0  15\n2018-03-14  16  17.0  18.0  19\n2018-03-15  20  21.0  22.0  23\n'''\n```\n使用dropna（）函数去掉NaN的行或列\n```\nprint(df.dropna(axis=0,how='any'#))#0对行进行操作 1对列进行操作 any:只要存在NaN即可drop掉 all:必须全部是NaN才可drop\n'''\n             A     B     C   D\n2018-03-12   8   9.0  10.0  11\n2018-03-13  12  13.0  14.0  15\n2018-03-14  16  17.0  18.0  19\n2018-03-15  20  21.0  22.0  23\n '''\n```\n使用fillna（）函数替换NaN值 \n```\nprint(df.fillna(value=0))#将NaN值替换为0\n'''\n             A     B     C   D\n2018-03-10   0   0.0   2.0   3\n2018-03-11   4   5.0   0.0   7\n2018-03-12   8   9.0  10.0  11\n2018-03-13  12  13.0  14.0  15\n2018-03-14  16  17.0  18.0  19\n2018-03-15  20  21.0  22.0  23\n '''\n```\n使用isnull()函数判断数据是否丢失\n```\nprint(pd.isnull(df))#矩阵用布尔来进行表示 是nan为ture 不是nan为false\n'''\n                A      B      C      D\n2018-03-10  False   True  False  False\n2018-03-11  False  False   True  False\n2018-03-12  False  False  False  False\n2018-03-13  False  False  False  False\n2018-03-14  False  False  False  False\n2018-03-15  False  False  False  False\n '''\nprint(np.any(df.isnull()))#判断数据中是否会存在NaN值\n#True\n```\n### 8.Pandas导入导出\npandas可以读取与存取像csv、excel、json、html、pickle等格式的资料，详细说明请看[官方资料](http://pandas.pydata.org/pandas-docs/stable/io.html)\n```\ndata=pd.read_csv('test1.csv')#读取csv文件\ndata.to_pickle('test2.pickle')#将资料存取成pickle文件 \n#其他文件导入导出方式相同\n```\n### 9.Pandas合并数据\naxis合并方向\n```\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])\ndf3 = pd.DataFrame(np.ones((3,4))*2, columns=['a','b','c','d'])\nres = pd.concat([df1, df2, df3], axis=0, ignore_index=True)#0表示竖项合并 1表示横项合并 ingnore_index重置序列index index变为0 1 2 3 4 5 6 7 8\nprint(res)\n'''\n     a    b    c    d\n0  0.0  0.0  0.0  0.0\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  1.0  1.0  1.0  1.0\n4  1.0  1.0  1.0  1.0\n5  1.0  1.0  1.0  1.0\n6  2.0  2.0  2.0  2.0\n7  2.0  2.0  2.0  2.0\n8  2.0  2.0  2.0  2.0\n '''\n```\njoin合并方式\n```\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'], index=[1,2,3])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=['b','c','d', 'e'], index=[2,3,4])\nprint(df1)\n'''\n     a    b    c    d\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  0.0  0.0  0.0  0.0\n '''\nprint(df2)\n'''\n     b    c    d    e\n2  1.0  1.0  1.0  1.0\n3  1.0  1.0  1.0  1.0\n4  1.0  1.0  1.0  1.0\n '''\nres=pd.concat([df1,df2],axis=1,join='outer')#行往外进行合并\nprint(res)\n'''\n     a    b    c    d    b    c    d    e\n1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN\n2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n4  NaN  NaN  NaN  NaN  1.0  1.0  1.0  1.0\n '''\n\nres=pd.concat([df1,df2],axis=1,join='outer')#行相同的进行合并\nprint(res)\n'''\n     a    b    c    d    b    c    d    e\n2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n'''\n\nres=pd.concat([df1,df2],axis=1,join_axes=[df1.index])#以df1的序列进行合并 df2中没有的序列NaN值填充\nprint(res)\n'''\n     a    b    c    d    b    c    d    e\n1  0.0  0.0  0.0  0.0  NaN  NaN  NaN  NaN\n2  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n3  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0\n'''\n```\nappend添加数据\n```\ndf1 = pd.DataFrame(np.ones((3,4))*0, columns=['a','b','c','d'])\ndf2 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])\ndf3 = pd.DataFrame(np.ones((3,4))*1, columns=['a','b','c','d'])\ns1 = pd.Series([1,2,3,4], index=['a','b','c','d'])\n\nres=df1.append(df2,ignore_index=True)#将df2合并到df1的下面 并重置index\nprint(res)\n'''\n     a    b    c    d\n0  0.0  0.0  0.0  0.0\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  1.0  1.0  1.0  1.0\n4  1.0  1.0  1.0  1.0\n5  1.0  1.0  1.0  1.0\n'''\n\nres=df1.append(s1,ignore_index=True)#将s1合并到df1下面 并重置index\nprint(res)\n'''\n     a    b    c    d\n0  0.0  0.0  0.0  0.0\n1  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  1.0  2.0  3.0  4.0\n'''\n```\n### 10.Pandas合并merge\n依据一组key合并\n```\nleft = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                     'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3']})\nprint(left)\n'''\n    A   B key\n0  A0  B0  K0\n1  A1  B1  K1\n2  A2  B2  K2\n3  A3  B3  K3\n'''\nright = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                      'C': ['C0', 'C1', 'C2',  'C3'],\n                      'D': ['D0', 'D1', 'D2', 'D3']})\nprint(right)\n'''\n    C   D key\n0  C0  D0  K0\n1  C1  D1  K1\n2  C2  D2  K2\n3  C3  D3  K3\n'''\nres=pd.merge(left,right,on='key')\nprint(res)\n'''\n    A   B key   C   D\n0  A0  B0  K0  C0  D0\n1  A1  B1  K1  C1  D1\n2  A2  B2  K2  C2  D2\n3  A3  B3  K3  C3  D3\n'''\n```\n依据两组key合并\n```\nleft = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n                             'key2': ['K0', 'K1', 'K0', 'K1'],\n                             'A': ['A0', 'A1', 'A2', 'A3'],\n                             'B': ['B0', 'B1', 'B2', 'B3']})\nprint(left)\n'''\n    A   B key1 key2\n0  A0  B0   K0   K0\n1  A1  B1   K0   K1\n2  A2  B2   K1   K0\n3  A3  B3   K2   K1\n '''\nright = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n                              'key2': ['K0', 'K0', 'K0', 'K0'],\n                              'C': ['C0', 'C1', 'C2', 'C3'],\n                              'D': ['D0', 'D1', 'D2', 'D3']})\nprint(right)\n'''\n    C   D key1 key2\n0  C0  D0   K0   K0\n1  C1  D1   K1   K0\n2  C2  D2   K1   K0\n3  C3  D3   K2   K0\n '''\n\nres=pd.merge(left,right,on=['key1','key2'],how='inner')#内联合并\nprint(res)\n'''\n    A   B key1 key2   C   D\n0  A0  B0   K0   K0  C0  D0\n1  A2  B2   K1   K0  C1  D1\n2  A2  B2   K1   K0  C2  D2\n'''\n\nres=pd.merge(left,right,on=['key1','key2'],how='outer')#外联合并\nprint(res)\n'''\n     A    B key1 key2    C    D\n0   A0   B0   K0   K0   C0   D0\n1   A1   B1   K0   K1  NaN  NaN\n2   A2   B2   K1   K0   C1   D1\n3   A2   B2   K1   K0   C2   D2\n4   A3   B3   K2   K1  NaN  NaN\n5  NaN  NaN   K2   K0   C3   D3\n'''\n\nres=pd.merge(left,right,on=['key1','key2'],how='left')#左联合并\n'''\n    A   B key1 key2    C    D\n0  A0  B0   K0   K0   C0   D0\n1  A1  B1   K0   K1  NaN  NaN\n2  A2  B2   K1   K0   C1   D1\n3  A2  B2   K1   K0   C2   D2\n4  A3  B3   K2   K1  NaN  NaN\n'''\n\nres=pd.merge(left,right,on=['key1','key2'],how='right')#右联合并\nprint(res)\n'''\n     A    B key1 key2   C   D\n0   A0   B0   K0   K0  C0  D0\n1   A2   B2   K1   K0  C1  D1\n2   A2   B2   K1   K0  C2  D2\n3  NaN  NaN   K2   K0  C3  D3\n'''\n```\nIndicator合并\n```\ndf1 = pd.DataFrame({'col1':[0,1], 'col_left':['a','b']})\nprint(df1)\n'''\n   col1 col_left\n0     0        a\n1     1        b\n '''\ndf2 = pd.DataFrame({'col1':[1,2,2],'col_right':[2,2,2]})\nprint(df2)\n'''\n   col1  col_right\n0     1          2\n1     2          2\n2     2          2\n '''\n\nres=pd.merge(df1,df2,on='col1',how='outer',indicator=True)#依据col1进行合并 并启用indicator=True输出每项合并方式\nprint(res)\n'''\n   col1 col_left  col_right      _merge\n0     0        a        NaN   left_only\n1     1        b        2.0        both\n2     2      NaN        2.0  right_only\n3     2      NaN        2.0  right_only\n'''\n\nres = pd.merge(df1, df2, on='col1', how='outer', indicator='indicator_column')#自定义indicator column名称\nprint(res)\n'''\n   col1 col_left  col_right indicator_column\n0     0        a        NaN        left_only\n1     1        b        2.0             both\n2     2      NaN        2.0       right_only\n3     2      NaN        2.0       right_only\n'''\n```\n依据index合并\n```\nleft = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n                                  'B': ['B0', 'B1', 'B2']},\n                                  index=['K0', 'K1', 'K2'])\nprint(left)\n'''\n     A   B\nK0  A0  B0\nK1  A1  B1\nK2  A2  B2\n '''\nright = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n                                     'D': ['D0', 'D2', 'D3']},\n                                      index=['K0', 'K2', 'K3'])\nprint(right)\n'''\n     C   D\nK0  C0  D0\nK2  C2  D2\nK3  C3  D3\n'''\n\nres=pd.merge(left,right,left_index=True,right_index=True,how='outer')#根据index索引进行合并 并选择外联合并\nprint(res)\n'''\n      A    B    C    D\nK0   A0   B0   C0   D0\nK1   A1   B1  NaN  NaN\nK2   A2   B2   C2   D2\nK3  NaN  NaN   C3   D3\n'''\n\nres=pd.merge(left,right,left_index=True,right_index=True,how='inner')\nprint(res)\n'''\n     A   B   C   D\nK0  A0  B0  C0  D0\nK2  A2  B2  C2  D2\n'''\n```\n----------\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活...\n<div align=center>![公众号](http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)","slug":"Python之Pandas使用教程","published":1,"updated":"2018-03-15T02:04:04.778Z","layout":"post","photos":[],"link":"","_id":"cjg7s0pqa000a3201qxhen6xx","content":"<h3 id=\"1-Pandas概述\"><a href=\"#1-Pandas概述\" class=\"headerlink\" title=\"1.Pandas概述\"></a>1.Pandas概述</h3><ol>\n<li>Pandas是Python的一个数据分析包，该工具为解决数据分析任务而创建。</li>\n<li>Pandas纳入大量库和标准数据模型，提供高效的操作数据集所需的工具。</li>\n<li>Pandas提供大量能使我们快速便捷地处理数据的函数和方法。</li>\n<li>Pandas是字典形式，基于NumPy创建，让NumPy为中心的应用变得更加简单。   <h3 id=\"2-Pandas安装\"><a href=\"#2-Pandas安装\" class=\"headerlink\" title=\"2.Pandas安装\"></a>2.Pandas安装</h3><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip3 <span class=\"keyword\">install</span> pandas</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"3-Pandas引入\"><a href=\"#3-Pandas引入\" class=\"headerlink\" title=\"3.Pandas引入\"></a>3.Pandas引入</h3><figure class=\"highlight capnproto\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd<span class=\"comment\">#为了方便实用pandas 采用pd简写</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-Pandas数据结构\"><a href=\"#4-Pandas数据结构\" class=\"headerlink\" title=\"4.Pandas数据结构\"></a>4.Pandas数据结构</h3><h4 id=\"4-1Series\"><a href=\"#4-1Series\" class=\"headerlink\" title=\"4.1Series\"></a>4.1Series</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\">s=pd.Series([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,np.nan,<span class=\"number\">5</span>,<span class=\"number\">6</span>])</span><br><span class=\"line\">print(s)<span class=\"comment\">#索引在左边 值在右边</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">0    1.0</span></span><br><span class=\"line\"><span class=\"string\">1    2.0</span></span><br><span class=\"line\"><span class=\"string\">2    3.0</span></span><br><span class=\"line\"><span class=\"string\">3    NaN</span></span><br><span class=\"line\"><span class=\"string\">4    5.0</span></span><br><span class=\"line\"><span class=\"string\">5    6.0</span></span><br><span class=\"line\"><span class=\"string\">dtype: float64</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"4-2DataFrame\"><a href=\"#4-2DataFrame\" class=\"headerlink\" title=\"4.2DataFrame\"></a>4.2DataFrame</h4><p>DataFrame是表格型数据结构，包含一组有序的列，每列可以是不同的值类型。DataFrame有行索引和列索引，可以看成由Series组成的字典。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates=pd.date_range(<span class=\"string\">'20180310'</span>,periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.random.randn(<span class=\"number\">6</span>,<span class=\"number\">4</span>), index=dates, columns=[<span class=\"string\">'A'</span>,<span class=\"string\">'B'</span>,<span class=\"string\">'C'</span>,<span class=\"string\">'D'</span>])<span class=\"comment\">#生成6行4列位置</span></span><br><span class=\"line\">print(df)<span class=\"comment\">#输出6行4列的表格</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                   A         B         C         D</span></span><br><span class=\"line\"><span class=\"string\">2018-03-10 -0.092889 -0.503172  0.692763 -1.261313</span></span><br><span class=\"line\"><span class=\"string\">2018-03-11 -0.895628 -2.300249 -1.098069  0.468986</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12  0.084732 -1.275078  1.638007 -0.291145</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13 -0.561528  0.431088  0.430414  1.065939</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  1.485434 -0.341404  0.267613 -1.493366</span></span><br><span class=\"line\"><span class=\"string\">2018-03-15 -1.671474  0.110933  1.688264 -0.910599</span></span><br><span class=\"line\"><span class=\"string\">  '''</span></span><br><span class=\"line\">print(df[<span class=\"string\">'B'</span>])</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">2018-03-10   -0.927291</span></span><br><span class=\"line\"><span class=\"string\">2018-03-11   -0.406842</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12   -0.088316</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13   -1.631055</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14   -0.929926</span></span><br><span class=\"line\"><span class=\"string\">2018-03-15   -0.010904</span></span><br><span class=\"line\"><span class=\"string\">Freq: D, Name: B, dtype: float64</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#创建特定数据的DataFrame</span></span><br><span class=\"line\">df_1=pd.DataFrame(&#123;<span class=\"string\">'A'</span> : <span class=\"number\">1.</span>,</span><br><span class=\"line\">                    <span class=\"string\">'B'</span> : pd.Timestamp(<span class=\"string\">'20180310'</span>),</span><br><span class=\"line\">                    <span class=\"string\">'C'</span> : pd.Series(<span class=\"number\">1</span>,index=list(range(<span class=\"number\">4</span>)),dtype=<span class=\"string\">'float32'</span>),</span><br><span class=\"line\">                    <span class=\"string\">'D'</span> : np.array([<span class=\"number\">3</span>] * <span class=\"number\">4</span>,dtype=<span class=\"string\">'int32'</span>),</span><br><span class=\"line\">                    <span class=\"string\">'E'</span> : pd.Categorical([<span class=\"string\">\"test\"</span>,<span class=\"string\">\"train\"</span>,<span class=\"string\">\"test\"</span>,<span class=\"string\">\"train\"</span>]),</span><br><span class=\"line\">                    <span class=\"string\">'F'</span> : <span class=\"string\">'foo'</span></span><br><span class=\"line\">                    &#125;)</span><br><span class=\"line\">print(df_1)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A          B    C  D      E    F</span></span><br><span class=\"line\"><span class=\"string\">0  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">1  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">2  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">3  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.dtypes)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">A           float64</span></span><br><span class=\"line\"><span class=\"string\">B    datetime64[ns]</span></span><br><span class=\"line\"><span class=\"string\">C           float32</span></span><br><span class=\"line\"><span class=\"string\">D             int32</span></span><br><span class=\"line\"><span class=\"string\">E          category</span></span><br><span class=\"line\"><span class=\"string\">F            object</span></span><br><span class=\"line\"><span class=\"string\">dtype: object</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.index)<span class=\"comment\">#行的序号</span></span><br><span class=\"line\"><span class=\"comment\">#Int64Index([0, 1, 2, 3], dtype='int64')</span></span><br><span class=\"line\">print(df_1.columns)<span class=\"comment\">#列的序号名字</span></span><br><span class=\"line\"><span class=\"comment\">#Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')</span></span><br><span class=\"line\">print(df_1.values)<span class=\"comment\">#把每个值进行打印出来</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']</span></span><br><span class=\"line\"><span class=\"string\"> [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']</span></span><br><span class=\"line\"><span class=\"string\"> [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']</span></span><br><span class=\"line\"><span class=\"string\"> [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(df_1.describe())<span class=\"comment\">#数字总结</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">         A    C    D</span></span><br><span class=\"line\"><span class=\"string\">count  4.0  4.0  4.0</span></span><br><span class=\"line\"><span class=\"string\">mean   1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">std    0.0  0.0  0.0</span></span><br><span class=\"line\"><span class=\"string\">min    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">25%    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">50%    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">75%    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">max    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.T)<span class=\"comment\">#翻转数据</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                     0                    1                    2  \\</span></span><br><span class=\"line\"><span class=\"string\">A                    1                    1                    1   </span></span><br><span class=\"line\"><span class=\"string\">B  2018-03-10 00:00:00  2018-03-10 00:00:00  2018-03-10 00:00:00   </span></span><br><span class=\"line\"><span class=\"string\">C                    1                    1                    1   </span></span><br><span class=\"line\"><span class=\"string\">D                    3                    3                    3   </span></span><br><span class=\"line\"><span class=\"string\">E                 test                train                 test   </span></span><br><span class=\"line\"><span class=\"string\">F                  foo                  foo                  foo   </span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">                     3  </span></span><br><span class=\"line\"><span class=\"string\">A                    1  </span></span><br><span class=\"line\"><span class=\"string\">B  2018-03-10 00:00:00  </span></span><br><span class=\"line\"><span class=\"string\">C                    1  </span></span><br><span class=\"line\"><span class=\"string\">D                    3  </span></span><br><span class=\"line\"><span class=\"string\">E                train  </span></span><br><span class=\"line\"><span class=\"string\">F                  foo  </span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.sort_index(axis=<span class=\"number\">1</span>, ascending=<span class=\"keyword\">False</span>))<span class=\"comment\">#axis等于1按列进行排序 如ABCDEFG 然后ascending倒叙进行显示</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     F      E  D    C          B    A</span></span><br><span class=\"line\"><span class=\"string\">0  foo   test  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">1  foo  train  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">2  foo   test  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">3  foo  train  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.sort_values(by=<span class=\"string\">'E'</span>))<span class=\"comment\">#按值进行排序</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A          B    C  D      E    F</span></span><br><span class=\"line\"><span class=\"string\">0  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">2  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">1  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">3  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"5-Pandas选择数据\"><a href=\"#5-Pandas选择数据\" class=\"headerlink\" title=\"5.Pandas选择数据\"></a>5.Pandas选择数据</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates=pd.date_range('<span class=\"number\">20180310</span>',periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.random.randn(<span class=\"number\">6</span>,<span class=\"number\">4</span>), index=dates, columns=['A','B','C','D'])#生成<span class=\"number\">6</span>行<span class=\"number\">4</span>列位置</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span> <span class=\"number\">-0.520509</span> <span class=\"number\">-0.136602</span> <span class=\"number\">-0.516984</span>  <span class=\"number\">1.357505</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">0.332656</span> <span class=\"number\">-0.094633</span>  <span class=\"number\">0.382384</span> <span class=\"number\">-0.914339</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">0.499960</span>  <span class=\"number\">1.576897</span>  <span class=\"number\">2.128730</span>  <span class=\"number\">2.197465</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">0.540385</span>  <span class=\"number\">0.427337</span> <span class=\"number\">-0.591381</span>  <span class=\"number\">0.126503</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">0.191962</span>  <span class=\"number\">1.237843</span>  <span class=\"number\">1.903370</span>  <span class=\"number\">2.155366</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span> <span class=\"number\">-0.188331</span> <span class=\"number\">-0.578581</span> <span class=\"number\">-0.845854</span> <span class=\"number\">-0.056373</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(df['A'])#或者df.A 选择某列</span><br><span class=\"line\">'''</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">-0.520509</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>    <span class=\"number\">0.332656</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>    <span class=\"number\">0.499960</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>    <span class=\"number\">0.540385</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>    <span class=\"number\">0.191962</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>   <span class=\"number\">-0.188331</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure>\n<p>切片选择<br><figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df[<span class=\"number\">0</span>:<span class=\"number\">3</span>], df['<span class=\"number\">20180310</span>':'<span class=\"number\">20180314</span>'])<span class=\"meta\">#两次进行选择 第一次切片选择 第二次按照筛选条件进行选择</span></span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018-03-10</span> -0.<span class=\"number\">520509</span> -0.<span class=\"number\">136602</span> -0.<span class=\"number\">516984</span>  1.<span class=\"number\">357505</span></span><br><span class=\"line\"><span class=\"number\">2018-03-11</span>  0.<span class=\"number\">332656</span> -0.<span class=\"number\">094633</span>  0.<span class=\"number\">382384</span> -0.<span class=\"number\">914339</span></span><br><span class=\"line\"><span class=\"number\">2018-03-12</span>  0.<span class=\"number\">499960</span>  1.<span class=\"number\">576897</span>  2.<span class=\"number\">128730</span>  2.<span class=\"number\">197465</span>                    </span><br><span class=\"line\">                  A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018-03-10</span> -0.<span class=\"number\">520509</span> -0.<span class=\"number\">136602</span> -0.<span class=\"number\">516984</span>  1.<span class=\"number\">357505</span></span><br><span class=\"line\"><span class=\"number\">2018-03-11</span>  0.<span class=\"number\">332656</span> -0.<span class=\"number\">094633</span>  0.<span class=\"number\">382384</span> -0.<span class=\"number\">914339</span></span><br><span class=\"line\"><span class=\"number\">2018-03-12</span>  0.<span class=\"number\">499960</span>  1.<span class=\"number\">576897</span>  2.<span class=\"number\">128730</span>  2.<span class=\"number\">197465</span></span><br><span class=\"line\"><span class=\"number\">2018-03-13</span>  0.<span class=\"number\">540385</span>  0.<span class=\"number\">427337</span> -0.<span class=\"number\">591381</span>  0.<span class=\"number\">126503</span></span><br><span class=\"line\"><span class=\"number\">2018-03-14</span>  0.<span class=\"number\">191962</span>  1.<span class=\"number\">237843</span>  1.<span class=\"number\">903370</span>  2.<span class=\"number\">155366</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>根据标签loc-行标签进行选择数据<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.loc[<span class=\"string\">'20180312'</span>, [<span class=\"string\">'A'</span>,<span class=\"string\">'B'</span>]])<span class=\"comment\">#按照行标签进行选择 精确选择</span></span><br><span class=\"line\"> <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">A    0.499960</span></span><br><span class=\"line\"><span class=\"string\">B    1.576897</span></span><br><span class=\"line\"><span class=\"string\">Name: 2018-03-12 00:00:00, dtype: float64</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>根据序列iloc-行号进行选择数据<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.iloc[<span class=\"number\">3</span>, <span class=\"number\">1</span>])<span class=\"comment\">#输出第三行第一列的数据</span></span><br><span class=\"line\"><span class=\"comment\">#0.427336827399</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(df.iloc[<span class=\"number\">3</span>:<span class=\"number\">5</span>,<span class=\"number\">0</span>:<span class=\"number\">2</span>])<span class=\"comment\">#进行切片选择</span></span><br><span class=\"line\"> <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                   A         B</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13  0.540385  0.427337</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  0.191962  1.237843</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(df.iloc[[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">4</span>],[<span class=\"number\">0</span>,<span class=\"number\">2</span>]])<span class=\"comment\">#进行不连续筛选</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                   A         C</span></span><br><span class=\"line\"><span class=\"string\">2018-03-11  0.332656  0.382384</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12  0.499960  2.128730</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  0.191962  1.903370</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>根据混合的两种ix<br><figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.ix[:<span class=\"number\">3</span>, ['A', 'C']])</span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         C</span><br><span class=\"line\"><span class=\"number\">2018-03-10</span> -0.<span class=\"number\">919275</span> -1.<span class=\"number\">356037</span></span><br><span class=\"line\"><span class=\"number\">2018-03-11</span>  0.<span class=\"number\">010171</span> -0.<span class=\"number\">380010</span></span><br><span class=\"line\"><span class=\"number\">2018-03-12</span>  0.<span class=\"number\">285251</span> -1.<span class=\"number\">174265</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>根据判断筛选<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df[df.A &gt; <span class=\"number\">0</span>])#筛选出df.A大于<span class=\"number\">0</span>的元素 布尔条件筛选</span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">0.332656</span> <span class=\"number\">-0.094633</span>  <span class=\"number\">0.382384</span> <span class=\"number\">-0.914339</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">0.499960</span>  <span class=\"number\">1.576897</span>  <span class=\"number\">2.128730</span>  <span class=\"number\">2.197465</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">0.540385</span>  <span class=\"number\">0.427337</span> <span class=\"number\">-0.591381</span>  <span class=\"number\">0.126503</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">0.191962</span>  <span class=\"number\">1.237843</span>  <span class=\"number\">1.903370</span>  <span class=\"number\">2.155366</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"6-Pandas设置数据\"><a href=\"#6-Pandas设置数据\" class=\"headerlink\" title=\"6.Pandas设置数据\"></a>6.Pandas设置数据</h3><p>根据loc和iloc设置<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates = pd.date_range('<span class=\"number\">20180310</span>', periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.arange(<span class=\"number\">24</span>).reshape((<span class=\"number\">6</span>,<span class=\"number\">4</span>)), index=dates, columns=['A', 'B', 'C', 'D'])</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">             A   B     C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">0</span>   <span class=\"number\">1</span>     <span class=\"number\">2</span>   <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>   <span class=\"number\">4</span>   <span class=\"number\">5</span>     <span class=\"number\">6</span>   <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>   <span class=\"number\">8</span>   <span class=\"number\">9</span>  <span class=\"number\">1111</span>  <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">12</span>  <span class=\"number\">13</span>    <span class=\"number\">14</span>  <span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">16</span>  <span class=\"number\">17</span>    <span class=\"number\">18</span>  <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">20</span>  <span class=\"number\">21</span>    <span class=\"number\">22</span>  <span class=\"number\">23</span></span><br><span class=\"line\">'''</span><br><span class=\"line\"></span><br><span class=\"line\">df.iloc[<span class=\"number\">2</span>,<span class=\"number\">2</span>] = <span class=\"number\">999</span>#单点设置</span><br><span class=\"line\">df.loc['<span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>', 'D'] = <span class=\"number\">999</span></span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">            A   B    C    D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>  <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span>    <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">0</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span>    <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">0</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span>   <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">0</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span>  <span class=\"number\">999</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">0</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span>   <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">0</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span>   <span class=\"number\">23</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<p>根据条件设置<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[df.A&gt;<span class=\"number\">0</span>]=<span class=\"number\">999</span>#将df.A大于<span class=\"number\">0</span>的值改变</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">              A   B    C    D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>    <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span>    <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">999</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span>    <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">999</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span>   <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">999</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span>  <span class=\"number\">999</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">999</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span>   <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">999</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span>   <span class=\"number\">23</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>根据行或列设置<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df['F']=np.nan</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">              A   B    C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>    <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">999</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">999</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">999</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">999</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">999</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span> NaN</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>添加数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df['E']  = pd.Series([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>], index=pd.date_range('<span class=\"number\">20180313</span>', periods=<span class=\"number\">6</span>))#增加一列</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">              A   B    C   D    E</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>    <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span> NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">999</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span> NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">999</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span> NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">999</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span> NaN  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">999</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span> NaN  <span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">999</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span> NaN  <span class=\"number\">3.0</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"7-Pandas处理丢失数据\"><a href=\"#7-Pandas处理丢失数据\" class=\"headerlink\" title=\"7.Pandas处理丢失数据\"></a>7.Pandas处理丢失数据</h3><p>处理数据中NaN数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates = pd.date_range('<span class=\"number\">20180310</span>', periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.arange(<span class=\"number\">24</span>).reshape((<span class=\"number\">6</span>,<span class=\"number\">4</span>)), index=dates, columns=['A', 'B', 'C', 'D'])</span><br><span class=\"line\">df.iloc[<span class=\"number\">0</span>,<span class=\"number\">1</span>]=np.nan</span><br><span class=\"line\">df.iloc[<span class=\"number\">1</span>,<span class=\"number\">2</span>]=np.nan</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">             A     B     C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">0</span>   NaN   <span class=\"number\">2.0</span>   <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>   <span class=\"number\">4</span>   <span class=\"number\">5.0</span>   NaN   <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>   <span class=\"number\">8</span>   <span class=\"number\">9.0</span>  <span class=\"number\">10.0</span>  <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">12</span>  <span class=\"number\">13.0</span>  <span class=\"number\">14.0</span>  <span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">16</span>  <span class=\"number\">17.0</span>  <span class=\"number\">18.0</span>  <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">20</span>  <span class=\"number\">21.0</span>  <span class=\"number\">22.0</span>  <span class=\"number\">23</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<p>使用dropna（）函数去掉NaN的行或列<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.dropna(axis=<span class=\"number\">0</span>,how=<span class=\"string\">'any'</span><span class=\"comment\">#))#0对行进行操作 1对列进行操作 any:只要存在NaN即可drop掉 all:必须全部是NaN才可drop</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">             A     B     C   D</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12   8   9.0  10.0  11</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13  12  13.0  14.0  15</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  16  17.0  18.0  19</span></span><br><span class=\"line\"><span class=\"string\">2018-03-15  20  21.0  22.0  23</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>使用fillna（）函数替换NaN值<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.fillna(value=<span class=\"number\">0</span>))#将NaN值替换为<span class=\"number\">0</span></span><br><span class=\"line\">'''</span><br><span class=\"line\">             A     B     C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">0</span>   <span class=\"number\">0.0</span>   <span class=\"number\">2.0</span>   <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>   <span class=\"number\">4</span>   <span class=\"number\">5.0</span>   <span class=\"number\">0.0</span>   <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>   <span class=\"number\">8</span>   <span class=\"number\">9.0</span>  <span class=\"number\">10.0</span>  <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">12</span>  <span class=\"number\">13.0</span>  <span class=\"number\">14.0</span>  <span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">16</span>  <span class=\"number\">17.0</span>  <span class=\"number\">18.0</span>  <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">20</span>  <span class=\"number\">21.0</span>  <span class=\"number\">22.0</span>  <span class=\"number\">23</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>使用isnull()函数判断数据是否丢失<br><figure class=\"highlight vbnet\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(pd.isnull(df))<span class=\"meta\">#矩阵用布尔来进行表示 是nan为ture 不是nan为false</span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">'''</span></span></span><br><span class=\"line\">                A      B      C      D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>  <span class=\"literal\">False</span>   <span class=\"literal\">True</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>   <span class=\"literal\">True</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"> <span class=\"comment\"><span class=\"doctag\">'''</span></span></span><br><span class=\"line\">print(np.any(df.isnull()))<span class=\"meta\">#判断数据中是否会存在NaN值</span></span><br><span class=\"line\"><span class=\"meta\">#True</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"8-Pandas导入导出\"><a href=\"#8-Pandas导入导出\" class=\"headerlink\" title=\"8.Pandas导入导出\"></a>8.Pandas导入导出</h3><p>pandas可以读取与存取像csv、excel、json、html、pickle等格式的资料，详细说明请看<a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html\" target=\"_blank\" rel=\"noopener\">官方资料</a><br><figure class=\"highlight haskell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">data</span>=pd.read_csv('<span class=\"title\">test1</span>.<span class=\"title\">csv'</span>)#读取csv文件</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">data</span>.to_pickle('<span class=\"title\">test2</span>.<span class=\"title\">pickle'</span>)#将资料存取成pickle文件 </span></span><br><span class=\"line\"><span class=\"meta\">#其他文件导入导出方式相同</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"9-Pandas合并数据\"><a href=\"#9-Pandas合并数据\" class=\"headerlink\" title=\"9.Pandas合并数据\"></a>9.Pandas合并数据</h3><p>axis合并方向<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">0</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df2 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df3 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">2</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">res = pd.concat([df1, df2, df3], axis=<span class=\"number\">0</span>, ignore_index=True)#<span class=\"number\">0</span>表示竖项合并 <span class=\"number\">1</span>表示横项合并 ingnore_index重置序列index index变为<span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span> <span class=\"number\">7</span> <span class=\"number\">8</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">5</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">6</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">7</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">8</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>join合并方式<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">0</span>, columns=['a','b','c','d'], index=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">df2 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['b','c','d', 'e'], index=[<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>])</span><br><span class=\"line\">print(df1)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(df2)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     b    c    d    e</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\">res=pd.concat([df1,df2],axis=<span class=\"number\">1</span>,join='outer')#行往外进行合并</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d    b    c    d    e</span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  NaN  NaN  NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  NaN  NaN  NaN  NaN  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.concat([df1,df2],axis=<span class=\"number\">1</span>,join='outer')#行相同的进行合并</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d    b    c    d    e</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\">'''</span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.concat([df1,df2],axis=<span class=\"number\">1</span>,join_axes=[df1.index])#以df1的序列进行合并 df2中没有的序列NaN值填充</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d    b    c    d    e</span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  NaN  NaN  NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<p>append添加数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">0</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df2 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df3 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">s1 = pd.Series([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>], index=['a','b','c','d'])</span><br><span class=\"line\"></span><br><span class=\"line\">res=df1.append(df2,ignore_index=True)#将df2合并到df1的下面 并重置index</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">5</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\">'''</span><br><span class=\"line\"></span><br><span class=\"line\">res=df1.append(s1,ignore_index=True)#将s1合并到df1下面 并重置index</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">3.0</span>  <span class=\"number\">4.0</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"10-Pandas合并merge\"><a href=\"#10-Pandas合并merge\" class=\"headerlink\" title=\"10.Pandas合并merge\"></a>10.Pandas合并merge</h3><p>依据一组key合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">left = pd.DataFrame(&#123;<span class=\"string\">'key'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>, <span class=\"string\">'K3'</span>],</span><br><span class=\"line\">                     <span class=\"string\">'A'</span>: [<span class=\"string\">'A0'</span>, <span class=\"string\">'A1'</span>, <span class=\"string\">'A2'</span>, <span class=\"string\">'A3'</span>],</span><br><span class=\"line\">                     <span class=\"string\">'B'</span>: [<span class=\"string\">'B0'</span>, <span class=\"string\">'B1'</span>, <span class=\"string\">'B2'</span>, <span class=\"string\">'B3'</span>]&#125;)</span><br><span class=\"line\">print(left)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0  K0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1  K1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2  K2</span></span><br><span class=\"line\"><span class=\"string\">3  A3  B3  K3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">right = pd.DataFrame(&#123;<span class=\"string\">'key'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>, <span class=\"string\">'K3'</span>],</span><br><span class=\"line\">                      <span class=\"string\">'C'</span>: [<span class=\"string\">'C0'</span>, <span class=\"string\">'C1'</span>, <span class=\"string\">'C2'</span>,  <span class=\"string\">'C3'</span>],</span><br><span class=\"line\">                      <span class=\"string\">'D'</span>: [<span class=\"string\">'D0'</span>, <span class=\"string\">'D1'</span>, <span class=\"string\">'D2'</span>, <span class=\"string\">'D3'</span>]&#125;)</span><br><span class=\"line\">print(right)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    C   D key</span></span><br><span class=\"line\"><span class=\"string\">0  C0  D0  K0</span></span><br><span class=\"line\"><span class=\"string\">1  C1  D1  K1</span></span><br><span class=\"line\"><span class=\"string\">2  C2  D2  K2</span></span><br><span class=\"line\"><span class=\"string\">3  C3  D3  K3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">res=pd.merge(left,right,on=<span class=\"string\">'key'</span>)</span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key   C   D</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0  K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1  K1  C1  D1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2  K2  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">3  A3  B3  K3  C3  D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>依据两组key合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">left = pd.DataFrame(&#123;<span class=\"string\">'key1'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>],</span><br><span class=\"line\">                             <span class=\"string\">'key2'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>],</span><br><span class=\"line\">                             <span class=\"string\">'A'</span>: [<span class=\"string\">'A0'</span>, <span class=\"string\">'A1'</span>, <span class=\"string\">'A2'</span>, <span class=\"string\">'A3'</span>],</span><br><span class=\"line\">                             <span class=\"string\">'B'</span>: [<span class=\"string\">'B0'</span>, <span class=\"string\">'B1'</span>, <span class=\"string\">'B2'</span>, <span class=\"string\">'B3'</span>]&#125;)</span><br><span class=\"line\">print(left)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key1 key2</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0   K0   K0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1   K0   K1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2   K1   K0</span></span><br><span class=\"line\"><span class=\"string\">3  A3  B3   K2   K1</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">right = pd.DataFrame(&#123;<span class=\"string\">'key1'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>],</span><br><span class=\"line\">                              <span class=\"string\">'key2'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>],</span><br><span class=\"line\">                              <span class=\"string\">'C'</span>: [<span class=\"string\">'C0'</span>, <span class=\"string\">'C1'</span>, <span class=\"string\">'C2'</span>, <span class=\"string\">'C3'</span>],</span><br><span class=\"line\">                              <span class=\"string\">'D'</span>: [<span class=\"string\">'D0'</span>, <span class=\"string\">'D1'</span>, <span class=\"string\">'D2'</span>, <span class=\"string\">'D3'</span>]&#125;)</span><br><span class=\"line\">print(right)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    C   D key1 key2</span></span><br><span class=\"line\"><span class=\"string\">0  C0  D0   K0   K0</span></span><br><span class=\"line\"><span class=\"string\">1  C1  D1   K1   K0</span></span><br><span class=\"line\"><span class=\"string\">2  C2  D2   K1   K0</span></span><br><span class=\"line\"><span class=\"string\">3  C3  D3   K2   K0</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'inner'</span>)<span class=\"comment\">#内联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key1 key2   C   D</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0   K0   K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">1  A2  B2   K1   K0  C1  D1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2   K1   K0  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'outer'</span>)<span class=\"comment\">#外联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A    B key1 key2    C    D</span></span><br><span class=\"line\"><span class=\"string\">0   A0   B0   K0   K0   C0   D0</span></span><br><span class=\"line\"><span class=\"string\">1   A1   B1   K0   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">2   A2   B2   K1   K0   C1   D1</span></span><br><span class=\"line\"><span class=\"string\">3   A2   B2   K1   K0   C2   D2</span></span><br><span class=\"line\"><span class=\"string\">4   A3   B3   K2   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">5  NaN  NaN   K2   K0   C3   D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'left'</span>)<span class=\"comment\">#左联合并</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key1 key2    C    D</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0   K0   K0   C0   D0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1   K0   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2   K1   K0   C1   D1</span></span><br><span class=\"line\"><span class=\"string\">3  A2  B2   K1   K0   C2   D2</span></span><br><span class=\"line\"><span class=\"string\">4  A3  B3   K2   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'right'</span>)<span class=\"comment\">#右联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A    B key1 key2   C   D</span></span><br><span class=\"line\"><span class=\"string\">0   A0   B0   K0   K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">1   A2   B2   K1   K0  C1  D1</span></span><br><span class=\"line\"><span class=\"string\">2   A2   B2   K1   K0  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">3  NaN  NaN   K2   K0  C3  D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>Indicator合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(&#123;<span class=\"string\">'col1'</span>:[<span class=\"number\">0</span>,<span class=\"number\">1</span>], <span class=\"string\">'col_left'</span>:[<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>]&#125;)</span><br><span class=\"line\">print(df1)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1 col_left</span></span><br><span class=\"line\"><span class=\"string\">0     0        a</span></span><br><span class=\"line\"><span class=\"string\">1     1        b</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">df2 = pd.DataFrame(&#123;<span class=\"string\">'col1'</span>:[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>],<span class=\"string\">'col_right'</span>:[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>]&#125;)</span><br><span class=\"line\">print(df2)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1  col_right</span></span><br><span class=\"line\"><span class=\"string\">0     1          2</span></span><br><span class=\"line\"><span class=\"string\">1     2          2</span></span><br><span class=\"line\"><span class=\"string\">2     2          2</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(df1,df2,on=<span class=\"string\">'col1'</span>,how=<span class=\"string\">'outer'</span>,indicator=<span class=\"keyword\">True</span>)<span class=\"comment\">#依据col1进行合并 并启用indicator=True输出每项合并方式</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1 col_left  col_right      _merge</span></span><br><span class=\"line\"><span class=\"string\">0     0        a        NaN   left_only</span></span><br><span class=\"line\"><span class=\"string\">1     1        b        2.0        both</span></span><br><span class=\"line\"><span class=\"string\">2     2      NaN        2.0  right_only</span></span><br><span class=\"line\"><span class=\"string\">3     2      NaN        2.0  right_only</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res = pd.merge(df1, df2, on=<span class=\"string\">'col1'</span>, how=<span class=\"string\">'outer'</span>, indicator=<span class=\"string\">'indicator_column'</span>)<span class=\"comment\">#自定义indicator column名称</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1 col_left  col_right indicator_column</span></span><br><span class=\"line\"><span class=\"string\">0     0        a        NaN        left_only</span></span><br><span class=\"line\"><span class=\"string\">1     1        b        2.0             both</span></span><br><span class=\"line\"><span class=\"string\">2     2      NaN        2.0       right_only</span></span><br><span class=\"line\"><span class=\"string\">3     2      NaN        2.0       right_only</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>依据index合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">left = pd.DataFrame(&#123;<span class=\"string\">'A'</span>: [<span class=\"string\">'A0'</span>, <span class=\"string\">'A1'</span>, <span class=\"string\">'A2'</span>],</span><br><span class=\"line\">                                  <span class=\"string\">'B'</span>: [<span class=\"string\">'B0'</span>, <span class=\"string\">'B1'</span>, <span class=\"string\">'B2'</span>]&#125;,</span><br><span class=\"line\">                                  index=[<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>])</span><br><span class=\"line\">print(left)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A   B</span></span><br><span class=\"line\"><span class=\"string\">K0  A0  B0</span></span><br><span class=\"line\"><span class=\"string\">K1  A1  B1</span></span><br><span class=\"line\"><span class=\"string\">K2  A2  B2</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">right = pd.DataFrame(&#123;<span class=\"string\">'C'</span>: [<span class=\"string\">'C0'</span>, <span class=\"string\">'C2'</span>, <span class=\"string\">'C3'</span>],</span><br><span class=\"line\">                                     <span class=\"string\">'D'</span>: [<span class=\"string\">'D0'</span>, <span class=\"string\">'D2'</span>, <span class=\"string\">'D3'</span>]&#125;,</span><br><span class=\"line\">                                      index=[<span class=\"string\">'K0'</span>, <span class=\"string\">'K2'</span>, <span class=\"string\">'K3'</span>])</span><br><span class=\"line\">print(right)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     C   D</span></span><br><span class=\"line\"><span class=\"string\">K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">K2  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">K3  C3  D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,left_index=<span class=\"keyword\">True</span>,right_index=<span class=\"keyword\">True</span>,how=<span class=\"string\">'outer'</span>)<span class=\"comment\">#根据index索引进行合并 并选择外联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">      A    B    C    D</span></span><br><span class=\"line\"><span class=\"string\">K0   A0   B0   C0   D0</span></span><br><span class=\"line\"><span class=\"string\">K1   A1   B1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">K2   A2   B2   C2   D2</span></span><br><span class=\"line\"><span class=\"string\">K3  NaN  NaN   C3   D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,left_index=<span class=\"keyword\">True</span>,right_index=<span class=\"keyword\">True</span>,how=<span class=\"string\">'inner'</span>)</span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A   B   C   D</span></span><br><span class=\"line\"><span class=\"string\">K0  A0  B0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">K2  A2  B2  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活…</p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"公众号\"></div></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-Pandas概述\"><a href=\"#1-Pandas概述\" class=\"headerlink\" title=\"1.Pandas概述\"></a>1.Pandas概述</h3><ol>\n<li>Pandas是Python的一个数据分析包，该工具为解决数据分析任务而创建。</li>\n<li>Pandas纳入大量库和标准数据模型，提供高效的操作数据集所需的工具。</li>\n<li>Pandas提供大量能使我们快速便捷地处理数据的函数和方法。</li>\n<li>Pandas是字典形式，基于NumPy创建，让NumPy为中心的应用变得更加简单。   <h3 id=\"2-Pandas安装\"><a href=\"#2-Pandas安装\" class=\"headerlink\" title=\"2.Pandas安装\"></a>2.Pandas安装</h3><figure class=\"highlight cmake\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip3 <span class=\"keyword\">install</span> pandas</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h3 id=\"3-Pandas引入\"><a href=\"#3-Pandas引入\" class=\"headerlink\" title=\"3.Pandas引入\"></a>3.Pandas引入</h3><figure class=\"highlight capnproto\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd<span class=\"comment\">#为了方便实用pandas 采用pd简写</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-Pandas数据结构\"><a href=\"#4-Pandas数据结构\" class=\"headerlink\" title=\"4.Pandas数据结构\"></a>4.Pandas数据结构</h3><h4 id=\"4-1Series\"><a href=\"#4-1Series\" class=\"headerlink\" title=\"4.1Series\"></a>4.1Series</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\">s=pd.Series([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,np.nan,<span class=\"number\">5</span>,<span class=\"number\">6</span>])</span><br><span class=\"line\">print(s)<span class=\"comment\">#索引在左边 值在右边</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">0    1.0</span></span><br><span class=\"line\"><span class=\"string\">1    2.0</span></span><br><span class=\"line\"><span class=\"string\">2    3.0</span></span><br><span class=\"line\"><span class=\"string\">3    NaN</span></span><br><span class=\"line\"><span class=\"string\">4    5.0</span></span><br><span class=\"line\"><span class=\"string\">5    6.0</span></span><br><span class=\"line\"><span class=\"string\">dtype: float64</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure>\n<h4 id=\"4-2DataFrame\"><a href=\"#4-2DataFrame\" class=\"headerlink\" title=\"4.2DataFrame\"></a>4.2DataFrame</h4><p>DataFrame是表格型数据结构，包含一组有序的列，每列可以是不同的值类型。DataFrame有行索引和列索引，可以看成由Series组成的字典。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates=pd.date_range(<span class=\"string\">'20180310'</span>,periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.random.randn(<span class=\"number\">6</span>,<span class=\"number\">4</span>), index=dates, columns=[<span class=\"string\">'A'</span>,<span class=\"string\">'B'</span>,<span class=\"string\">'C'</span>,<span class=\"string\">'D'</span>])<span class=\"comment\">#生成6行4列位置</span></span><br><span class=\"line\">print(df)<span class=\"comment\">#输出6行4列的表格</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                   A         B         C         D</span></span><br><span class=\"line\"><span class=\"string\">2018-03-10 -0.092889 -0.503172  0.692763 -1.261313</span></span><br><span class=\"line\"><span class=\"string\">2018-03-11 -0.895628 -2.300249 -1.098069  0.468986</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12  0.084732 -1.275078  1.638007 -0.291145</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13 -0.561528  0.431088  0.430414  1.065939</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  1.485434 -0.341404  0.267613 -1.493366</span></span><br><span class=\"line\"><span class=\"string\">2018-03-15 -1.671474  0.110933  1.688264 -0.910599</span></span><br><span class=\"line\"><span class=\"string\">  '''</span></span><br><span class=\"line\">print(df[<span class=\"string\">'B'</span>])</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">2018-03-10   -0.927291</span></span><br><span class=\"line\"><span class=\"string\">2018-03-11   -0.406842</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12   -0.088316</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13   -1.631055</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14   -0.929926</span></span><br><span class=\"line\"><span class=\"string\">2018-03-15   -0.010904</span></span><br><span class=\"line\"><span class=\"string\">Freq: D, Name: B, dtype: float64</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#创建特定数据的DataFrame</span></span><br><span class=\"line\">df_1=pd.DataFrame(&#123;<span class=\"string\">'A'</span> : <span class=\"number\">1.</span>,</span><br><span class=\"line\">                    <span class=\"string\">'B'</span> : pd.Timestamp(<span class=\"string\">'20180310'</span>),</span><br><span class=\"line\">                    <span class=\"string\">'C'</span> : pd.Series(<span class=\"number\">1</span>,index=list(range(<span class=\"number\">4</span>)),dtype=<span class=\"string\">'float32'</span>),</span><br><span class=\"line\">                    <span class=\"string\">'D'</span> : np.array([<span class=\"number\">3</span>] * <span class=\"number\">4</span>,dtype=<span class=\"string\">'int32'</span>),</span><br><span class=\"line\">                    <span class=\"string\">'E'</span> : pd.Categorical([<span class=\"string\">\"test\"</span>,<span class=\"string\">\"train\"</span>,<span class=\"string\">\"test\"</span>,<span class=\"string\">\"train\"</span>]),</span><br><span class=\"line\">                    <span class=\"string\">'F'</span> : <span class=\"string\">'foo'</span></span><br><span class=\"line\">                    &#125;)</span><br><span class=\"line\">print(df_1)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A          B    C  D      E    F</span></span><br><span class=\"line\"><span class=\"string\">0  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">1  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">2  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">3  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.dtypes)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">A           float64</span></span><br><span class=\"line\"><span class=\"string\">B    datetime64[ns]</span></span><br><span class=\"line\"><span class=\"string\">C           float32</span></span><br><span class=\"line\"><span class=\"string\">D             int32</span></span><br><span class=\"line\"><span class=\"string\">E          category</span></span><br><span class=\"line\"><span class=\"string\">F            object</span></span><br><span class=\"line\"><span class=\"string\">dtype: object</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.index)<span class=\"comment\">#行的序号</span></span><br><span class=\"line\"><span class=\"comment\">#Int64Index([0, 1, 2, 3], dtype='int64')</span></span><br><span class=\"line\">print(df_1.columns)<span class=\"comment\">#列的序号名字</span></span><br><span class=\"line\"><span class=\"comment\">#Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')</span></span><br><span class=\"line\">print(df_1.values)<span class=\"comment\">#把每个值进行打印出来</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']</span></span><br><span class=\"line\"><span class=\"string\"> [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']</span></span><br><span class=\"line\"><span class=\"string\"> [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']</span></span><br><span class=\"line\"><span class=\"string\"> [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">print(df_1.describe())<span class=\"comment\">#数字总结</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">         A    C    D</span></span><br><span class=\"line\"><span class=\"string\">count  4.0  4.0  4.0</span></span><br><span class=\"line\"><span class=\"string\">mean   1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">std    0.0  0.0  0.0</span></span><br><span class=\"line\"><span class=\"string\">min    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">25%    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">50%    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">75%    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">max    1.0  1.0  3.0</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.T)<span class=\"comment\">#翻转数据</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                     0                    1                    2  \\</span></span><br><span class=\"line\"><span class=\"string\">A                    1                    1                    1   </span></span><br><span class=\"line\"><span class=\"string\">B  2018-03-10 00:00:00  2018-03-10 00:00:00  2018-03-10 00:00:00   </span></span><br><span class=\"line\"><span class=\"string\">C                    1                    1                    1   </span></span><br><span class=\"line\"><span class=\"string\">D                    3                    3                    3   </span></span><br><span class=\"line\"><span class=\"string\">E                 test                train                 test   </span></span><br><span class=\"line\"><span class=\"string\">F                  foo                  foo                  foo   </span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">                     3  </span></span><br><span class=\"line\"><span class=\"string\">A                    1  </span></span><br><span class=\"line\"><span class=\"string\">B  2018-03-10 00:00:00  </span></span><br><span class=\"line\"><span class=\"string\">C                    1  </span></span><br><span class=\"line\"><span class=\"string\">D                    3  </span></span><br><span class=\"line\"><span class=\"string\">E                train  </span></span><br><span class=\"line\"><span class=\"string\">F                  foo  </span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.sort_index(axis=<span class=\"number\">1</span>, ascending=<span class=\"keyword\">False</span>))<span class=\"comment\">#axis等于1按列进行排序 如ABCDEFG 然后ascending倒叙进行显示</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     F      E  D    C          B    A</span></span><br><span class=\"line\"><span class=\"string\">0  foo   test  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">1  foo  train  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">2  foo   test  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">3  foo  train  3  1.0 2018-03-10  1.0</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(df_1.sort_values(by=<span class=\"string\">'E'</span>))<span class=\"comment\">#按值进行排序</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A          B    C  D      E    F</span></span><br><span class=\"line\"><span class=\"string\">0  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">2  1.0 2018-03-10  1.0  3   test  foo</span></span><br><span class=\"line\"><span class=\"string\">1  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">3  1.0 2018-03-10  1.0  3  train  foo</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"5-Pandas选择数据\"><a href=\"#5-Pandas选择数据\" class=\"headerlink\" title=\"5.Pandas选择数据\"></a>5.Pandas选择数据</h3><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates=pd.date_range('<span class=\"number\">20180310</span>',periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.random.randn(<span class=\"number\">6</span>,<span class=\"number\">4</span>), index=dates, columns=['A','B','C','D'])#生成<span class=\"number\">6</span>行<span class=\"number\">4</span>列位置</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span> <span class=\"number\">-0.520509</span> <span class=\"number\">-0.136602</span> <span class=\"number\">-0.516984</span>  <span class=\"number\">1.357505</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">0.332656</span> <span class=\"number\">-0.094633</span>  <span class=\"number\">0.382384</span> <span class=\"number\">-0.914339</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">0.499960</span>  <span class=\"number\">1.576897</span>  <span class=\"number\">2.128730</span>  <span class=\"number\">2.197465</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">0.540385</span>  <span class=\"number\">0.427337</span> <span class=\"number\">-0.591381</span>  <span class=\"number\">0.126503</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">0.191962</span>  <span class=\"number\">1.237843</span>  <span class=\"number\">1.903370</span>  <span class=\"number\">2.155366</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span> <span class=\"number\">-0.188331</span> <span class=\"number\">-0.578581</span> <span class=\"number\">-0.845854</span> <span class=\"number\">-0.056373</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(df['A'])#或者df.A 选择某列</span><br><span class=\"line\">'''</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">-0.520509</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>    <span class=\"number\">0.332656</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>    <span class=\"number\">0.499960</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>    <span class=\"number\">0.540385</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>    <span class=\"number\">0.191962</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>   <span class=\"number\">-0.188331</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure>\n<p>切片选择<br><figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df[<span class=\"number\">0</span>:<span class=\"number\">3</span>], df['<span class=\"number\">20180310</span>':'<span class=\"number\">20180314</span>'])<span class=\"meta\">#两次进行选择 第一次切片选择 第二次按照筛选条件进行选择</span></span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018-03-10</span> -0.<span class=\"number\">520509</span> -0.<span class=\"number\">136602</span> -0.<span class=\"number\">516984</span>  1.<span class=\"number\">357505</span></span><br><span class=\"line\"><span class=\"number\">2018-03-11</span>  0.<span class=\"number\">332656</span> -0.<span class=\"number\">094633</span>  0.<span class=\"number\">382384</span> -0.<span class=\"number\">914339</span></span><br><span class=\"line\"><span class=\"number\">2018-03-12</span>  0.<span class=\"number\">499960</span>  1.<span class=\"number\">576897</span>  2.<span class=\"number\">128730</span>  2.<span class=\"number\">197465</span>                    </span><br><span class=\"line\">                  A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018-03-10</span> -0.<span class=\"number\">520509</span> -0.<span class=\"number\">136602</span> -0.<span class=\"number\">516984</span>  1.<span class=\"number\">357505</span></span><br><span class=\"line\"><span class=\"number\">2018-03-11</span>  0.<span class=\"number\">332656</span> -0.<span class=\"number\">094633</span>  0.<span class=\"number\">382384</span> -0.<span class=\"number\">914339</span></span><br><span class=\"line\"><span class=\"number\">2018-03-12</span>  0.<span class=\"number\">499960</span>  1.<span class=\"number\">576897</span>  2.<span class=\"number\">128730</span>  2.<span class=\"number\">197465</span></span><br><span class=\"line\"><span class=\"number\">2018-03-13</span>  0.<span class=\"number\">540385</span>  0.<span class=\"number\">427337</span> -0.<span class=\"number\">591381</span>  0.<span class=\"number\">126503</span></span><br><span class=\"line\"><span class=\"number\">2018-03-14</span>  0.<span class=\"number\">191962</span>  1.<span class=\"number\">237843</span>  1.<span class=\"number\">903370</span>  2.<span class=\"number\">155366</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>根据标签loc-行标签进行选择数据<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.loc[<span class=\"string\">'20180312'</span>, [<span class=\"string\">'A'</span>,<span class=\"string\">'B'</span>]])<span class=\"comment\">#按照行标签进行选择 精确选择</span></span><br><span class=\"line\"> <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">A    0.499960</span></span><br><span class=\"line\"><span class=\"string\">B    1.576897</span></span><br><span class=\"line\"><span class=\"string\">Name: 2018-03-12 00:00:00, dtype: float64</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>根据序列iloc-行号进行选择数据<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.iloc[<span class=\"number\">3</span>, <span class=\"number\">1</span>])<span class=\"comment\">#输出第三行第一列的数据</span></span><br><span class=\"line\"><span class=\"comment\">#0.427336827399</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(df.iloc[<span class=\"number\">3</span>:<span class=\"number\">5</span>,<span class=\"number\">0</span>:<span class=\"number\">2</span>])<span class=\"comment\">#进行切片选择</span></span><br><span class=\"line\"> <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                   A         B</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13  0.540385  0.427337</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  0.191962  1.237843</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\">print(df.iloc[[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">4</span>],[<span class=\"number\">0</span>,<span class=\"number\">2</span>]])<span class=\"comment\">#进行不连续筛选</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">                   A         C</span></span><br><span class=\"line\"><span class=\"string\">2018-03-11  0.332656  0.382384</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12  0.499960  2.128730</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  0.191962  1.903370</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>根据混合的两种ix<br><figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.ix[:<span class=\"number\">3</span>, ['A', 'C']])</span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         C</span><br><span class=\"line\"><span class=\"number\">2018-03-10</span> -0.<span class=\"number\">919275</span> -1.<span class=\"number\">356037</span></span><br><span class=\"line\"><span class=\"number\">2018-03-11</span>  0.<span class=\"number\">010171</span> -0.<span class=\"number\">380010</span></span><br><span class=\"line\"><span class=\"number\">2018-03-12</span>  0.<span class=\"number\">285251</span> -1.<span class=\"number\">174265</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>根据判断筛选<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df[df.A &gt; <span class=\"number\">0</span>])#筛选出df.A大于<span class=\"number\">0</span>的元素 布尔条件筛选</span><br><span class=\"line\">'''</span><br><span class=\"line\">                   A         B         C         D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">0.332656</span> <span class=\"number\">-0.094633</span>  <span class=\"number\">0.382384</span> <span class=\"number\">-0.914339</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">0.499960</span>  <span class=\"number\">1.576897</span>  <span class=\"number\">2.128730</span>  <span class=\"number\">2.197465</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">0.540385</span>  <span class=\"number\">0.427337</span> <span class=\"number\">-0.591381</span>  <span class=\"number\">0.126503</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">0.191962</span>  <span class=\"number\">1.237843</span>  <span class=\"number\">1.903370</span>  <span class=\"number\">2.155366</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"6-Pandas设置数据\"><a href=\"#6-Pandas设置数据\" class=\"headerlink\" title=\"6.Pandas设置数据\"></a>6.Pandas设置数据</h3><p>根据loc和iloc设置<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates = pd.date_range('<span class=\"number\">20180310</span>', periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.arange(<span class=\"number\">24</span>).reshape((<span class=\"number\">6</span>,<span class=\"number\">4</span>)), index=dates, columns=['A', 'B', 'C', 'D'])</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">             A   B     C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">0</span>   <span class=\"number\">1</span>     <span class=\"number\">2</span>   <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>   <span class=\"number\">4</span>   <span class=\"number\">5</span>     <span class=\"number\">6</span>   <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>   <span class=\"number\">8</span>   <span class=\"number\">9</span>  <span class=\"number\">1111</span>  <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">12</span>  <span class=\"number\">13</span>    <span class=\"number\">14</span>  <span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">16</span>  <span class=\"number\">17</span>    <span class=\"number\">18</span>  <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">20</span>  <span class=\"number\">21</span>    <span class=\"number\">22</span>  <span class=\"number\">23</span></span><br><span class=\"line\">'''</span><br><span class=\"line\"></span><br><span class=\"line\">df.iloc[<span class=\"number\">2</span>,<span class=\"number\">2</span>] = <span class=\"number\">999</span>#单点设置</span><br><span class=\"line\">df.loc['<span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>', 'D'] = <span class=\"number\">999</span></span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">            A   B    C    D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>  <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span>    <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">0</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span>    <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">0</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span>   <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">0</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span>  <span class=\"number\">999</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">0</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span>   <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">0</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span>   <span class=\"number\">23</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<p>根据条件设置<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[df.A&gt;<span class=\"number\">0</span>]=<span class=\"number\">999</span>#将df.A大于<span class=\"number\">0</span>的值改变</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">              A   B    C    D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>    <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span>    <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">999</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span>    <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">999</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span>   <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">999</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span>  <span class=\"number\">999</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">999</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span>   <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">999</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span>   <span class=\"number\">23</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>根据行或列设置<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df['F']=np.nan</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">              A   B    C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>    <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">999</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">999</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">999</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">999</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span> NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">999</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span> NaN</span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>添加数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df['E']  = pd.Series([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>,<span class=\"number\">5</span>,<span class=\"number\">6</span>], index=pd.date_range('<span class=\"number\">20180313</span>', periods=<span class=\"number\">6</span>))#增加一列</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">              A   B    C   D    E</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>    <span class=\"number\">0</span>   <span class=\"number\">1</span>    <span class=\"number\">2</span> NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"number\">999</span>   <span class=\"number\">5</span>    <span class=\"number\">6</span> NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"number\">999</span>   <span class=\"number\">9</span>  <span class=\"number\">999</span> NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">999</span>  <span class=\"number\">13</span>   <span class=\"number\">14</span> NaN  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">999</span>  <span class=\"number\">17</span>   <span class=\"number\">18</span> NaN  <span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">999</span>  <span class=\"number\">21</span>   <span class=\"number\">22</span> NaN  <span class=\"number\">3.0</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"7-Pandas处理丢失数据\"><a href=\"#7-Pandas处理丢失数据\" class=\"headerlink\" title=\"7.Pandas处理丢失数据\"></a>7.Pandas处理丢失数据</h3><p>处理数据中NaN数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dates = pd.date_range('<span class=\"number\">20180310</span>', periods=<span class=\"number\">6</span>)</span><br><span class=\"line\">df = pd.DataFrame(np.arange(<span class=\"number\">24</span>).reshape((<span class=\"number\">6</span>,<span class=\"number\">4</span>)), index=dates, columns=['A', 'B', 'C', 'D'])</span><br><span class=\"line\">df.iloc[<span class=\"number\">0</span>,<span class=\"number\">1</span>]=np.nan</span><br><span class=\"line\">df.iloc[<span class=\"number\">1</span>,<span class=\"number\">2</span>]=np.nan</span><br><span class=\"line\">print(df)</span><br><span class=\"line\">'''</span><br><span class=\"line\">             A     B     C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">0</span>   NaN   <span class=\"number\">2.0</span>   <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>   <span class=\"number\">4</span>   <span class=\"number\">5.0</span>   NaN   <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>   <span class=\"number\">8</span>   <span class=\"number\">9.0</span>  <span class=\"number\">10.0</span>  <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">12</span>  <span class=\"number\">13.0</span>  <span class=\"number\">14.0</span>  <span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">16</span>  <span class=\"number\">17.0</span>  <span class=\"number\">18.0</span>  <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">20</span>  <span class=\"number\">21.0</span>  <span class=\"number\">22.0</span>  <span class=\"number\">23</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<p>使用dropna（）函数去掉NaN的行或列<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.dropna(axis=<span class=\"number\">0</span>,how=<span class=\"string\">'any'</span><span class=\"comment\">#))#0对行进行操作 1对列进行操作 any:只要存在NaN即可drop掉 all:必须全部是NaN才可drop</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">             A     B     C   D</span></span><br><span class=\"line\"><span class=\"string\">2018-03-12   8   9.0  10.0  11</span></span><br><span class=\"line\"><span class=\"string\">2018-03-13  12  13.0  14.0  15</span></span><br><span class=\"line\"><span class=\"string\">2018-03-14  16  17.0  18.0  19</span></span><br><span class=\"line\"><span class=\"string\">2018-03-15  20  21.0  22.0  23</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br></pre></td></tr></table></figure></p>\n<p>使用fillna（）函数替换NaN值<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(df.fillna(value=<span class=\"number\">0</span>))#将NaN值替换为<span class=\"number\">0</span></span><br><span class=\"line\">'''</span><br><span class=\"line\">             A     B     C   D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>   <span class=\"number\">0</span>   <span class=\"number\">0.0</span>   <span class=\"number\">2.0</span>   <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>   <span class=\"number\">4</span>   <span class=\"number\">5.0</span>   <span class=\"number\">0.0</span>   <span class=\"number\">7</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>   <span class=\"number\">8</span>   <span class=\"number\">9.0</span>  <span class=\"number\">10.0</span>  <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"number\">12</span>  <span class=\"number\">13.0</span>  <span class=\"number\">14.0</span>  <span class=\"number\">15</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"number\">16</span>  <span class=\"number\">17.0</span>  <span class=\"number\">18.0</span>  <span class=\"number\">19</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"number\">20</span>  <span class=\"number\">21.0</span>  <span class=\"number\">22.0</span>  <span class=\"number\">23</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>使用isnull()函数判断数据是否丢失<br><figure class=\"highlight vbnet\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(pd.isnull(df))<span class=\"meta\">#矩阵用布尔来进行表示 是nan为ture 不是nan为false</span></span><br><span class=\"line\"><span class=\"comment\"><span class=\"doctag\">'''</span></span></span><br><span class=\"line\">                A      B      C      D</span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-10</span>  <span class=\"literal\">False</span>   <span class=\"literal\">True</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-11</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>   <span class=\"literal\">True</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-12</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-13</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-14</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"number\">2018</span><span class=\"number\">-03</span><span class=\"number\">-15</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span>  <span class=\"literal\">False</span></span><br><span class=\"line\"> <span class=\"comment\"><span class=\"doctag\">'''</span></span></span><br><span class=\"line\">print(np.any(df.isnull()))<span class=\"meta\">#判断数据中是否会存在NaN值</span></span><br><span class=\"line\"><span class=\"meta\">#True</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"8-Pandas导入导出\"><a href=\"#8-Pandas导入导出\" class=\"headerlink\" title=\"8.Pandas导入导出\"></a>8.Pandas导入导出</h3><p>pandas可以读取与存取像csv、excel、json、html、pickle等格式的资料，详细说明请看<a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html\" target=\"_blank\" rel=\"noopener\">官方资料</a><br><figure class=\"highlight haskell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">data</span>=pd.read_csv('<span class=\"title\">test1</span>.<span class=\"title\">csv'</span>)#读取csv文件</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">data</span>.to_pickle('<span class=\"title\">test2</span>.<span class=\"title\">pickle'</span>)#将资料存取成pickle文件 </span></span><br><span class=\"line\"><span class=\"meta\">#其他文件导入导出方式相同</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"9-Pandas合并数据\"><a href=\"#9-Pandas合并数据\" class=\"headerlink\" title=\"9.Pandas合并数据\"></a>9.Pandas合并数据</h3><p>axis合并方向<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">0</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df2 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df3 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">2</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">res = pd.concat([df1, df2, df3], axis=<span class=\"number\">0</span>, ignore_index=True)#<span class=\"number\">0</span>表示竖项合并 <span class=\"number\">1</span>表示横项合并 ingnore_index重置序列index index变为<span class=\"number\">0</span> <span class=\"number\">1</span> <span class=\"number\">2</span> <span class=\"number\">3</span> <span class=\"number\">4</span> <span class=\"number\">5</span> <span class=\"number\">6</span> <span class=\"number\">7</span> <span class=\"number\">8</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">5</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">6</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">7</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span></span><br><span class=\"line\"><span class=\"number\">8</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">2.0</span></span><br><span class=\"line\"> '''</span><br></pre></td></tr></table></figure></p>\n<p>join合并方式<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">0</span>, columns=['a','b','c','d'], index=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>])</span><br><span class=\"line\">df2 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['b','c','d', 'e'], index=[<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>])</span><br><span class=\"line\">print(df1)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\">print(df2)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     b    c    d    e</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\">res=pd.concat([df1,df2],axis=<span class=\"number\">1</span>,join='outer')#行往外进行合并</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d    b    c    d    e</span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  NaN  NaN  NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  NaN  NaN  NaN  NaN  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"> '''</span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.concat([df1,df2],axis=<span class=\"number\">1</span>,join='outer')#行相同的进行合并</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d    b    c    d    e</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\">'''</span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.concat([df1,df2],axis=<span class=\"number\">1</span>,join_axes=[df1.index])#以df1的序列进行合并 df2中没有的序列NaN值填充</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d    b    c    d    e</span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  NaN  NaN  NaN  NaN</span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<p>append添加数据<br><figure class=\"highlight lsl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">0</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df2 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">df3 = pd.DataFrame(np.ones((<span class=\"number\">3</span>,<span class=\"number\">4</span>))*<span class=\"number\">1</span>, columns=['a','b','c','d'])</span><br><span class=\"line\">s1 = pd.Series([<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>,<span class=\"number\">4</span>], index=['a','b','c','d'])</span><br><span class=\"line\"></span><br><span class=\"line\">res=df1.append(df2,ignore_index=True)#将df2合并到df1的下面 并重置index</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">4</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\"><span class=\"number\">5</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span>  <span class=\"number\">1.0</span></span><br><span class=\"line\">'''</span><br><span class=\"line\"></span><br><span class=\"line\">res=df1.append(s1,ignore_index=True)#将s1合并到df1下面 并重置index</span><br><span class=\"line\">print(res)</span><br><span class=\"line\">'''</span><br><span class=\"line\">     a    b    c    d</span><br><span class=\"line\"><span class=\"number\">0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">1</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">2</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span>  <span class=\"number\">0.0</span></span><br><span class=\"line\"><span class=\"number\">3</span>  <span class=\"number\">1.0</span>  <span class=\"number\">2.0</span>  <span class=\"number\">3.0</span>  <span class=\"number\">4.0</span></span><br><span class=\"line\">'''</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"10-Pandas合并merge\"><a href=\"#10-Pandas合并merge\" class=\"headerlink\" title=\"10.Pandas合并merge\"></a>10.Pandas合并merge</h3><p>依据一组key合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">left = pd.DataFrame(&#123;<span class=\"string\">'key'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>, <span class=\"string\">'K3'</span>],</span><br><span class=\"line\">                     <span class=\"string\">'A'</span>: [<span class=\"string\">'A0'</span>, <span class=\"string\">'A1'</span>, <span class=\"string\">'A2'</span>, <span class=\"string\">'A3'</span>],</span><br><span class=\"line\">                     <span class=\"string\">'B'</span>: [<span class=\"string\">'B0'</span>, <span class=\"string\">'B1'</span>, <span class=\"string\">'B2'</span>, <span class=\"string\">'B3'</span>]&#125;)</span><br><span class=\"line\">print(left)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0  K0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1  K1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2  K2</span></span><br><span class=\"line\"><span class=\"string\">3  A3  B3  K3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">right = pd.DataFrame(&#123;<span class=\"string\">'key'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>, <span class=\"string\">'K3'</span>],</span><br><span class=\"line\">                      <span class=\"string\">'C'</span>: [<span class=\"string\">'C0'</span>, <span class=\"string\">'C1'</span>, <span class=\"string\">'C2'</span>,  <span class=\"string\">'C3'</span>],</span><br><span class=\"line\">                      <span class=\"string\">'D'</span>: [<span class=\"string\">'D0'</span>, <span class=\"string\">'D1'</span>, <span class=\"string\">'D2'</span>, <span class=\"string\">'D3'</span>]&#125;)</span><br><span class=\"line\">print(right)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    C   D key</span></span><br><span class=\"line\"><span class=\"string\">0  C0  D0  K0</span></span><br><span class=\"line\"><span class=\"string\">1  C1  D1  K1</span></span><br><span class=\"line\"><span class=\"string\">2  C2  D2  K2</span></span><br><span class=\"line\"><span class=\"string\">3  C3  D3  K3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">res=pd.merge(left,right,on=<span class=\"string\">'key'</span>)</span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key   C   D</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0  K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1  K1  C1  D1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2  K2  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">3  A3  B3  K3  C3  D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>依据两组key合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">left = pd.DataFrame(&#123;<span class=\"string\">'key1'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>],</span><br><span class=\"line\">                             <span class=\"string\">'key2'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>],</span><br><span class=\"line\">                             <span class=\"string\">'A'</span>: [<span class=\"string\">'A0'</span>, <span class=\"string\">'A1'</span>, <span class=\"string\">'A2'</span>, <span class=\"string\">'A3'</span>],</span><br><span class=\"line\">                             <span class=\"string\">'B'</span>: [<span class=\"string\">'B0'</span>, <span class=\"string\">'B1'</span>, <span class=\"string\">'B2'</span>, <span class=\"string\">'B3'</span>]&#125;)</span><br><span class=\"line\">print(left)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key1 key2</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0   K0   K0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1   K0   K1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2   K1   K0</span></span><br><span class=\"line\"><span class=\"string\">3  A3  B3   K2   K1</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">right = pd.DataFrame(&#123;<span class=\"string\">'key1'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>],</span><br><span class=\"line\">                              <span class=\"string\">'key2'</span>: [<span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>, <span class=\"string\">'K0'</span>],</span><br><span class=\"line\">                              <span class=\"string\">'C'</span>: [<span class=\"string\">'C0'</span>, <span class=\"string\">'C1'</span>, <span class=\"string\">'C2'</span>, <span class=\"string\">'C3'</span>],</span><br><span class=\"line\">                              <span class=\"string\">'D'</span>: [<span class=\"string\">'D0'</span>, <span class=\"string\">'D1'</span>, <span class=\"string\">'D2'</span>, <span class=\"string\">'D3'</span>]&#125;)</span><br><span class=\"line\">print(right)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    C   D key1 key2</span></span><br><span class=\"line\"><span class=\"string\">0  C0  D0   K0   K0</span></span><br><span class=\"line\"><span class=\"string\">1  C1  D1   K1   K0</span></span><br><span class=\"line\"><span class=\"string\">2  C2  D2   K1   K0</span></span><br><span class=\"line\"><span class=\"string\">3  C3  D3   K2   K0</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'inner'</span>)<span class=\"comment\">#内联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key1 key2   C   D</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0   K0   K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">1  A2  B2   K1   K0  C1  D1</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2   K1   K0  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'outer'</span>)<span class=\"comment\">#外联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A    B key1 key2    C    D</span></span><br><span class=\"line\"><span class=\"string\">0   A0   B0   K0   K0   C0   D0</span></span><br><span class=\"line\"><span class=\"string\">1   A1   B1   K0   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">2   A2   B2   K1   K0   C1   D1</span></span><br><span class=\"line\"><span class=\"string\">3   A2   B2   K1   K0   C2   D2</span></span><br><span class=\"line\"><span class=\"string\">4   A3   B3   K2   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">5  NaN  NaN   K2   K0   C3   D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'left'</span>)<span class=\"comment\">#左联合并</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    A   B key1 key2    C    D</span></span><br><span class=\"line\"><span class=\"string\">0  A0  B0   K0   K0   C0   D0</span></span><br><span class=\"line\"><span class=\"string\">1  A1  B1   K0   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">2  A2  B2   K1   K0   C1   D1</span></span><br><span class=\"line\"><span class=\"string\">3  A2  B2   K1   K0   C2   D2</span></span><br><span class=\"line\"><span class=\"string\">4  A3  B3   K2   K1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,on=[<span class=\"string\">'key1'</span>,<span class=\"string\">'key2'</span>],how=<span class=\"string\">'right'</span>)<span class=\"comment\">#右联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A    B key1 key2   C   D</span></span><br><span class=\"line\"><span class=\"string\">0   A0   B0   K0   K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">1   A2   B2   K1   K0  C1  D1</span></span><br><span class=\"line\"><span class=\"string\">2   A2   B2   K1   K0  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">3  NaN  NaN   K2   K0  C3  D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>Indicator合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df1 = pd.DataFrame(&#123;<span class=\"string\">'col1'</span>:[<span class=\"number\">0</span>,<span class=\"number\">1</span>], <span class=\"string\">'col_left'</span>:[<span class=\"string\">'a'</span>,<span class=\"string\">'b'</span>]&#125;)</span><br><span class=\"line\">print(df1)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1 col_left</span></span><br><span class=\"line\"><span class=\"string\">0     0        a</span></span><br><span class=\"line\"><span class=\"string\">1     1        b</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">df2 = pd.DataFrame(&#123;<span class=\"string\">'col1'</span>:[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>],<span class=\"string\">'col_right'</span>:[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>]&#125;)</span><br><span class=\"line\">print(df2)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1  col_right</span></span><br><span class=\"line\"><span class=\"string\">0     1          2</span></span><br><span class=\"line\"><span class=\"string\">1     2          2</span></span><br><span class=\"line\"><span class=\"string\">2     2          2</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(df1,df2,on=<span class=\"string\">'col1'</span>,how=<span class=\"string\">'outer'</span>,indicator=<span class=\"keyword\">True</span>)<span class=\"comment\">#依据col1进行合并 并启用indicator=True输出每项合并方式</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1 col_left  col_right      _merge</span></span><br><span class=\"line\"><span class=\"string\">0     0        a        NaN   left_only</span></span><br><span class=\"line\"><span class=\"string\">1     1        b        2.0        both</span></span><br><span class=\"line\"><span class=\"string\">2     2      NaN        2.0  right_only</span></span><br><span class=\"line\"><span class=\"string\">3     2      NaN        2.0  right_only</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res = pd.merge(df1, df2, on=<span class=\"string\">'col1'</span>, how=<span class=\"string\">'outer'</span>, indicator=<span class=\"string\">'indicator_column'</span>)<span class=\"comment\">#自定义indicator column名称</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">   col1 col_left  col_right indicator_column</span></span><br><span class=\"line\"><span class=\"string\">0     0        a        NaN        left_only</span></span><br><span class=\"line\"><span class=\"string\">1     1        b        2.0             both</span></span><br><span class=\"line\"><span class=\"string\">2     2      NaN        2.0       right_only</span></span><br><span class=\"line\"><span class=\"string\">3     2      NaN        2.0       right_only</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<p>依据index合并<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">left = pd.DataFrame(&#123;<span class=\"string\">'A'</span>: [<span class=\"string\">'A0'</span>, <span class=\"string\">'A1'</span>, <span class=\"string\">'A2'</span>],</span><br><span class=\"line\">                                  <span class=\"string\">'B'</span>: [<span class=\"string\">'B0'</span>, <span class=\"string\">'B1'</span>, <span class=\"string\">'B2'</span>]&#125;,</span><br><span class=\"line\">                                  index=[<span class=\"string\">'K0'</span>, <span class=\"string\">'K1'</span>, <span class=\"string\">'K2'</span>])</span><br><span class=\"line\">print(left)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A   B</span></span><br><span class=\"line\"><span class=\"string\">K0  A0  B0</span></span><br><span class=\"line\"><span class=\"string\">K1  A1  B1</span></span><br><span class=\"line\"><span class=\"string\">K2  A2  B2</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\">right = pd.DataFrame(&#123;<span class=\"string\">'C'</span>: [<span class=\"string\">'C0'</span>, <span class=\"string\">'C2'</span>, <span class=\"string\">'C3'</span>],</span><br><span class=\"line\">                                     <span class=\"string\">'D'</span>: [<span class=\"string\">'D0'</span>, <span class=\"string\">'D2'</span>, <span class=\"string\">'D3'</span>]&#125;,</span><br><span class=\"line\">                                      index=[<span class=\"string\">'K0'</span>, <span class=\"string\">'K2'</span>, <span class=\"string\">'K3'</span>])</span><br><span class=\"line\">print(right)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     C   D</span></span><br><span class=\"line\"><span class=\"string\">K0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">K2  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">K3  C3  D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,left_index=<span class=\"keyword\">True</span>,right_index=<span class=\"keyword\">True</span>,how=<span class=\"string\">'outer'</span>)<span class=\"comment\">#根据index索引进行合并 并选择外联合并</span></span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">      A    B    C    D</span></span><br><span class=\"line\"><span class=\"string\">K0   A0   B0   C0   D0</span></span><br><span class=\"line\"><span class=\"string\">K1   A1   B1  NaN  NaN</span></span><br><span class=\"line\"><span class=\"string\">K2   A2   B2   C2   D2</span></span><br><span class=\"line\"><span class=\"string\">K3  NaN  NaN   C3   D3</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\">res=pd.merge(left,right,left_index=<span class=\"keyword\">True</span>,right_index=<span class=\"keyword\">True</span>,how=<span class=\"string\">'inner'</span>)</span><br><span class=\"line\">print(res)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">     A   B   C   D</span></span><br><span class=\"line\"><span class=\"string\">K0  A0  B0  C0  D0</span></span><br><span class=\"line\"><span class=\"string\">K2  A2  B2  C2  D2</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活…</p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"公众号\"></div></p>\n"},{"title":"Python之Sklearn使用教程","date":"2018-04-15T03:43:18.000Z","_content":"\n### 1.Sklearn简介\n\nScikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。当我们面临机器学习问题时，便可根据下图来选择相应的方法。Sklearn具有以下特点：\n\n+ 简单高效的数据挖掘和数据分析工具\n\n\n+ 让每个人能够在复杂环境中重复使用\n+ 建立NumPy、Scipy、MatPlotLib之上\n\n![Python之Sklearn使用教程图片01](Python之Sklearn使用教程/Python之Sklearn使用教程图片01.png)\n\n### 2.Sklearn安装\n\nSklearn安装要求`Python(>=2.7 or >=3.3)`、`NumPy (>= 1.8.2)`、`SciPy (>= 0.13.3)`。如果已经安装NumPy和SciPy，安装scikit-learn可以使用`pip install -U scikit-learn`。\n\n### 3.Sklearn通用学习模式\n\nSklearn中包含众多机器学习方法，但各种学习方法大致相同，我们在这里介绍Sklearn通用学习模式。首先引入需要训练的数据，Sklearn自带部分数据集，也可以通过相应方法进行构造，`4.Sklearn datasets`中我们会介绍如何构造数据。然后选择相应机器学习方法进行训练，训练过程中可以通过一些技巧调整参数，使得学习准确率更高。模型训练完成之后便可预测新数据，然后我们还可以通过`MatPlotLib`等方法来直观的展示数据。另外还可以将我们已训练好的Model进行保存，方便移动到其他平台，不必重新训练。\n\n```python\nfrom sklearn import datasets#引入数据集,sklearn包含众多数据集\nfrom sklearn.model_selection import train_test_split#将数据分为测试集和训练集\nfrom sklearn.neighbors import KNeighborsClassifier#利用邻近点方式训练数据\n\n###引入数据###\niris=datasets.load_iris()#引入iris鸢尾花数据,iris数据包含4个特征变量\niris_X=iris.data#特征变量\niris_y=iris.target#目标值\nX_train,X_test,y_train,y_test=train_test_split(iris_X,iris_y,test_size=0.3)#利用train_test_split进行将训练集和测试集进行分开，test_size占30%\nprint(y_train)#我们看到训练数据的特征值分为3类\n'''\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n '''\n\n###训练数据###\nknn=KNeighborsClassifier()#引入训练方法\nknn.fit(X_train,y_train)#进行填充测试数据进行训练\n\n###预测数据###\nprint(knn.predict(X_test))#预测特征值\n'''\n[1 1 1 0 2 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0\n 1 2 1 0 0 1 0 2]\n'''\nprint(y_test)#真实特征值\n'''\n[1 1 1 0 1 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0\n 1 2 1 0 0 1 0 2]\n'''\n```\n\n### 4.Sklearn datasets\n\nSklearn提供一些标准数据，我们不必再从其他网站寻找数据进行训练。例如我们上面用来训练的`load_iris`数据，可以很方便的返回数据特征变量和目标值。除了引入数据之外，我们还可以通过`load_sample_images()`来引入图片。\n\n![Python之Sklearn使用教程图片02](Python之Sklearn使用教程/Python之Sklearn使用教程图片02.png)\n\n除了sklearn提供的一些数据之外，还可以自己来构造一些数据帮助我们学习。\n\n```python\nfrom sklearn import datasets#引入数据集\n#构造的各种参数可以根据自己需要调整\nX,y=datasets.make_regression(n_samples=100,n_features=1,n_targets=1,noise=1)\n\n###绘制构造的数据###\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.scatter(X,y)\nplt.show()\n```\n\n![Python之Sklearn使用教程03](Python之Sklearn使用教程/Python之Sklearn使用教程03.png)\n\n### 5.Sklearn Model的属性和功能\n\n数据训练完成之后得到模型，我们可以根据不同模型得到相应的属性和功能，并将其输出得到直观结果。假如通过线性回归训练之后得到线性函数`y=0.3x+1`，我们可通过`_coef`得到模型的系数为0.3，通过`_intercept`得到模型的截距为1。\n\n```Python\nfrom sklearn import datasets\nfrom sklearn.linear_model import LinearRegression#引入线性回归模型\n\n###引入数据###\nload_data=datasets.load_boston()\ndata_X=load_data.data\ndata_y=load_data.target\nprint(data_X.shape)\n#(506, 13)data_X共13个特征变量\n\n###训练数据###\nmodel=LinearRegression()\nmodel.fit(data_X,data_y)\nmodel.predict(data_X[:4,:])#预测前4个数据\n\n###属性和功能###\nprint(model.coef_)\n'''\n[ -1.07170557e-01   4.63952195e-02   2.08602395e-02   2.68856140e+00\n  -1.77957587e+01   3.80475246e+00   7.51061703e-04  -1.47575880e+00\n   3.05655038e-01  -1.23293463e-02  -9.53463555e-01   9.39251272e-03\n  -5.25466633e-01]\n'''\nprint(model.intercept_)\n#36.4911032804\nprint(model.get_params())#得到模型的参数\n#{'copy_X': True, 'normalize': False, 'n_jobs': 1, 'fit_intercept': True}\nprint(model.score(data_X,data_y))#对训练情况进行打分\n#0.740607742865\n```\n\n### 6.Sklearn数据预处理\n\n数据集的标准化对于大部分机器学习算法来说都是一种常规要求，如果单个特征没有或多或少地接近于标准正态分布，那么它可能并不能在项目中表现出很好的性能。在实际情况中,我们经常忽略特征的分布形状，直接去均值来对某个特征进行中心化，再通过除以非常量特征(non-constant features)的标准差进行缩放。\n\n例如, 许多学习算法中目标函数的基础都是假设所有的特征都是零均值并且具有同一阶数上的方差(比如径向基函数、支持向量机以及L1L2正则化项等)。如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致学习器并不能像我们说期望的那样，从其他特征中学习。例如我们可以通过Scale将数据缩放，达到标准化的目的。\n\n```python\nfrom sklearn import preprocessing\nimport numpy as np\na=np.array([[10,2.7,3.6],\n            [-100,5,-2],\n            [120,20,40]],dtype=np.float64)\nprint(a)\nprint(preprocessing.scale(a))#将值的相差度减小\n'''\n[[  10.     2.7    3.6]\n [-100.     5.    -2. ]\n [ 120.    20.    40\n[[ 0.         -0.85170713 -0.55138018]\n [-1.22474487 -0.55187146 -0.852133  ]\n [ 1.22474487  1.40357859  1.40351318]]\n'''\n```\n\n我们来看下预处理前和预处理预处理后的差别，预处理之前模型评分为`0.511111111111`，预处理后模型评分为`0.933333333333`，可以看到预处理对模型评分有很大程度的提升。\n\n```Python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets.samples_generator import make_classification\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\n\n###生成的数据如下图所示###\nplt.figure\nX,y=make_classification(n_samples=300,n_features=2,n_redundant=0,n_informative=2,             random_state=22,n_clusters_per_class=1,scale=100)\nplt.scatter(X[:,0],X[:,1],c=y)\nplt.show()\n\n###利用minmax方式对数据进行规范化###\nX=preprocessing.minmax_scale(X)#feature_range=(-1,1)可设置重置范围\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\nclf=SVC()\nclf.fit(X_train,y_train)\nprint(clf.score(X_test,y_test))\n#0.933333333333\n#没有规范化之前我们的训练分数为0.511111111111,规范化后为0.933333333333,准确度有很大提升\n```\n\n![Python之Sklearn使用教程04](Python之Sklearn使用教程/Python之Sklearn使用教程04.png)\n\n### 7.交叉验证\n\n交叉验证的基本思想是将原始数据进行分组，一部分做为训练集来训练模型，另一部分做为测试集来评价模型。交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合。还可以从有限的数据中获取尽可能多的有效信息。\n\n机器学习任务中，拿到数据后，我们首先会将原始数据集分为三部分：**训练集、验证集和测试集**。 训练集用于训练模型，验证集用于模型的参数选择配置，测试集对于模型来说是未知数据，用于评估模型的泛化能力。不同的划分会得到不同的最终模型。\n\n以前我们是直接将数据分割成70%的训练数据和测试数据，现在我们利用K折交叉验证分割数据，首先将数据分为5组，然后再从5组数据之中选择不同数据进行训练。\n\n![Python之Sklearn使用教程05](Python之Sklearn使用教程/Python之Sklearn使用教程05.png)\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n###引入数据###\niris=load_iris()\nX=iris.data\ny=iris.target\n\n###训练数据###\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n#引入交叉验证,数据分为5组进行训练\nfrom sklearn.model_selection import cross_val_score\nknn=KNeighborsClassifier(n_neighbors=5)#选择邻近的5个点\nscores=cross_val_score(knn,X,y,cv=5,scoring='accuracy')#评分方式为accuracy\nprint(scores)#每组的评分结果\n#[ 0.96666667  1.          0.93333333  0.96666667  1.        ]5组数据\nprint(scores.mean())#平均评分结果\n#0.973333333333\n```\n\n那么是否**n_neighbor=5**便是最好呢，我们来调整参数来看模型最终训练分数。\n\n```Python\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score#引入交叉验证\nimport  matplotlib.pyplot as plt\n###引入数据###\niris=datasets.load_iris()\nX=iris.data\ny=iris.target\n###设置n_neighbors的值为1到30,通过绘图来看训练分数###\nk_range=range(1,31)\nk_score=[]\nfor k in k_range:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    scores=cross_val_score(knn,X,y,cv=10,scoring='accuracy')#for classfication\n    k_score.append(loss.mean())\nplt.figure()\nplt.plot(k_range,k_score)\nplt.xlabel('Value of k for KNN')\nplt.ylabel('CrossValidation accuracy')\nplt.show()\n#K过大会带来过拟合问题,我们可以选择12-18之间的值\n```\n\n我们可以看到n_neighbor在12-18之间评分比较高，实际项目之中我们可以通过这种方式来选择不同参数。另外我们还可以选择`2-fold Cross Validation`,`Leave-One-Out Cross Validation`等方法来分割数据，比较不同方法和参数得到最优结果。\n\n![Python之Sklearn使用教程06](Python之Sklearn使用教程/Python之Sklearn使用教程06.png)\n\n我们将上述代码中的循环部分改变一下，评分函数改为`neg_mean_squared_error`，便得到对于不同参数时的损失函数。\n\n```\nfor k in k_range:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    loss=-cross_val_score(knn,X,y,cv=10,scoring='neg_mean_squared_error')# for regression\n    k_score.append(loss.mean())\n```\n\n![Python之Sklearn使用教程07](Python之Sklearn使用教程/Python之Sklearn使用教程07.png)\n\n### 8.过拟合问题\n\n什么是过拟合问题呢？例如下面这张图片，黑色线已经可以很好的分类出红色点和蓝色点，但是在机器学习过程中，模型过于纠结准确度，便形成了绿色线的结果。然后在预测测试数据集结果的过程中往往会浪费很多时间并且准确率不是太好。\n\n![Python之Sklearn使用教程08](Python之Sklearn使用教程/Python之Sklearn使用教程08.png)\n\n我们先举例如何辨别**overfitting**问题。Sklearn.learning_curve中的learning curve可以很直观的看出Model学习的进度，对比发现有没有过拟合。\n\n```Python\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.datasets import load_digits\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#引入数据\ndigits=load_digits()\nX=digits.data\ny=digits.target\n\n#train_size表示记录学习过程中的某一步,比如在10%,25%...的过程中记录一下\ntrain_size,train_loss,test_loss=learning_curve(\n    SVC(gamma=0.1),X,y,cv=10,scoring='neg_mean_squared_error',\n    train_sizes=[0.1,0.25,0.5,0.75,1]\n)\ntrain_loss_mean=-np.mean(train_loss,axis=1)\ntest_loss_mean=-np.mean(test_loss,axis=1)\n\nplt.figure()\n#将每一步进行打印出来\nplt.plot(train_size,train_loss_mean,'o-',color='r',label='Training')\nplt.plot(train_size,test_loss_mean,'o-',color='g',label='Cross-validation')\nplt.legend('best')\nplt.show()\n```\n\n![Python之Sklearn使用教程09](Python之Sklearn使用教程/Python之Sklearn使用教程09.png)\n\n如果我们改变gamma的值，那么会改变相应的Loss函数。损失函数便在10左右停留，此时便能直观的看出过拟合。\n\n![Python之Sklearn使用教程10](Python之Sklearn使用教程/Python之Sklearn使用教程10.png)\n\n\n\n下面我们通过修改gamma参数来修正过拟合问题。\n\n```Python\nfrom sklearn.model_selection import  validation_curve#将learning_curve改为validation_curve\nfrom sklearn.datasets import load_digits\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nimport numpy as np\n#引入数据\ndigits=load_digits()\nX=digits.data\ny=digits.target\n\n#改变param来观察Loss函数情况\nparam_range=np.logspace(-6,-2.3,5)\ntrain_loss,test_loss=validation_curve(\n    SVC(),X,y,param_name='gamma',param_range=param_range,cv=10,\n    scoring='neg_mean_squared_error'\n)\ntrain_loss_mean=-np.mean(train_loss,axis=1)\ntest_loss_mean=-np.mean(test_loss,axis=1)\n\nplt.figure()\nplt.plot(param_range,train_loss_mean,'o-',color='r',label='Training')\nplt.plot(param_range,test_loss_mean,'o-',color='g',label='Cross-validation')\nplt.xlabel('gamma')\nplt.ylabel('loss')\nplt.legend(loc='best')\nplt.show()\n```\n\n通过改变不同的gamma值我们可以看到Loss函数的变化情况。从图中可以看到，如果gamma的值大于0.001便会出现过拟合的问题，那么我们构建模型时gamma参数设置应该小于0.001。\n\n![Python之Sklearn使用教程11.png](Python之Sklearn使用教程/Python之Sklearn使用教程11.png)\n\n### 9.保存模型\n\n我们花费很长时间用来训练数据，调整参数，得到最优模型。但如果改变平台，我们还需要重新训练数据和修正参数来得到模型，将会非常的浪费时间。此时我们可以先将model保存起来，然后便可以很方便的将模型迁移。\n\n```python\nfrom sklearn import svm\nfrom sklearn import datasets\n\n#引入和训练数据\niris=datasets.load_iris()\nX,y=iris.data,iris.target\nclf=svm.SVC()\nclf.fit(X,y)\n\n#引入sklearn中自带的保存模块\nfrom sklearn.externals import joblib\n#保存model\njoblib.dump(clf,'sklearn_save/clf.pkl')\n\n#重新加载model，只有保存一次后才能加载model\nclf3=joblib.load('sklearn_save/clf.pkl')\nprint(clf3.predict(X[0:1]))\n#存放model能够更快的获得以前的结果\n```\n\n### 10.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![Python之Sklearn使用教程推广](Python之Sklearn使用教程/Python之Sklearn使用教程推广.png)","source":"_posts/Python之Sklearn使用教程.md","raw":"---\ntitle: Python之Sklearn使用教程\ndate: 2018-04-15 11:43:18\ntags: [Python,机器学习]\ncategories: Python库\n---\n\n### 1.Sklearn简介\n\nScikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。当我们面临机器学习问题时，便可根据下图来选择相应的方法。Sklearn具有以下特点：\n\n+ 简单高效的数据挖掘和数据分析工具\n\n\n+ 让每个人能够在复杂环境中重复使用\n+ 建立NumPy、Scipy、MatPlotLib之上\n\n![Python之Sklearn使用教程图片01](Python之Sklearn使用教程/Python之Sklearn使用教程图片01.png)\n\n### 2.Sklearn安装\n\nSklearn安装要求`Python(>=2.7 or >=3.3)`、`NumPy (>= 1.8.2)`、`SciPy (>= 0.13.3)`。如果已经安装NumPy和SciPy，安装scikit-learn可以使用`pip install -U scikit-learn`。\n\n### 3.Sklearn通用学习模式\n\nSklearn中包含众多机器学习方法，但各种学习方法大致相同，我们在这里介绍Sklearn通用学习模式。首先引入需要训练的数据，Sklearn自带部分数据集，也可以通过相应方法进行构造，`4.Sklearn datasets`中我们会介绍如何构造数据。然后选择相应机器学习方法进行训练，训练过程中可以通过一些技巧调整参数，使得学习准确率更高。模型训练完成之后便可预测新数据，然后我们还可以通过`MatPlotLib`等方法来直观的展示数据。另外还可以将我们已训练好的Model进行保存，方便移动到其他平台，不必重新训练。\n\n```python\nfrom sklearn import datasets#引入数据集,sklearn包含众多数据集\nfrom sklearn.model_selection import train_test_split#将数据分为测试集和训练集\nfrom sklearn.neighbors import KNeighborsClassifier#利用邻近点方式训练数据\n\n###引入数据###\niris=datasets.load_iris()#引入iris鸢尾花数据,iris数据包含4个特征变量\niris_X=iris.data#特征变量\niris_y=iris.target#目标值\nX_train,X_test,y_train,y_test=train_test_split(iris_X,iris_y,test_size=0.3)#利用train_test_split进行将训练集和测试集进行分开，test_size占30%\nprint(y_train)#我们看到训练数据的特征值分为3类\n'''\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n '''\n\n###训练数据###\nknn=KNeighborsClassifier()#引入训练方法\nknn.fit(X_train,y_train)#进行填充测试数据进行训练\n\n###预测数据###\nprint(knn.predict(X_test))#预测特征值\n'''\n[1 1 1 0 2 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0\n 1 2 1 0 0 1 0 2]\n'''\nprint(y_test)#真实特征值\n'''\n[1 1 1 0 1 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0\n 1 2 1 0 0 1 0 2]\n'''\n```\n\n### 4.Sklearn datasets\n\nSklearn提供一些标准数据，我们不必再从其他网站寻找数据进行训练。例如我们上面用来训练的`load_iris`数据，可以很方便的返回数据特征变量和目标值。除了引入数据之外，我们还可以通过`load_sample_images()`来引入图片。\n\n![Python之Sklearn使用教程图片02](Python之Sklearn使用教程/Python之Sklearn使用教程图片02.png)\n\n除了sklearn提供的一些数据之外，还可以自己来构造一些数据帮助我们学习。\n\n```python\nfrom sklearn import datasets#引入数据集\n#构造的各种参数可以根据自己需要调整\nX,y=datasets.make_regression(n_samples=100,n_features=1,n_targets=1,noise=1)\n\n###绘制构造的数据###\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.scatter(X,y)\nplt.show()\n```\n\n![Python之Sklearn使用教程03](Python之Sklearn使用教程/Python之Sklearn使用教程03.png)\n\n### 5.Sklearn Model的属性和功能\n\n数据训练完成之后得到模型，我们可以根据不同模型得到相应的属性和功能，并将其输出得到直观结果。假如通过线性回归训练之后得到线性函数`y=0.3x+1`，我们可通过`_coef`得到模型的系数为0.3，通过`_intercept`得到模型的截距为1。\n\n```Python\nfrom sklearn import datasets\nfrom sklearn.linear_model import LinearRegression#引入线性回归模型\n\n###引入数据###\nload_data=datasets.load_boston()\ndata_X=load_data.data\ndata_y=load_data.target\nprint(data_X.shape)\n#(506, 13)data_X共13个特征变量\n\n###训练数据###\nmodel=LinearRegression()\nmodel.fit(data_X,data_y)\nmodel.predict(data_X[:4,:])#预测前4个数据\n\n###属性和功能###\nprint(model.coef_)\n'''\n[ -1.07170557e-01   4.63952195e-02   2.08602395e-02   2.68856140e+00\n  -1.77957587e+01   3.80475246e+00   7.51061703e-04  -1.47575880e+00\n   3.05655038e-01  -1.23293463e-02  -9.53463555e-01   9.39251272e-03\n  -5.25466633e-01]\n'''\nprint(model.intercept_)\n#36.4911032804\nprint(model.get_params())#得到模型的参数\n#{'copy_X': True, 'normalize': False, 'n_jobs': 1, 'fit_intercept': True}\nprint(model.score(data_X,data_y))#对训练情况进行打分\n#0.740607742865\n```\n\n### 6.Sklearn数据预处理\n\n数据集的标准化对于大部分机器学习算法来说都是一种常规要求，如果单个特征没有或多或少地接近于标准正态分布，那么它可能并不能在项目中表现出很好的性能。在实际情况中,我们经常忽略特征的分布形状，直接去均值来对某个特征进行中心化，再通过除以非常量特征(non-constant features)的标准差进行缩放。\n\n例如, 许多学习算法中目标函数的基础都是假设所有的特征都是零均值并且具有同一阶数上的方差(比如径向基函数、支持向量机以及L1L2正则化项等)。如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致学习器并不能像我们说期望的那样，从其他特征中学习。例如我们可以通过Scale将数据缩放，达到标准化的目的。\n\n```python\nfrom sklearn import preprocessing\nimport numpy as np\na=np.array([[10,2.7,3.6],\n            [-100,5,-2],\n            [120,20,40]],dtype=np.float64)\nprint(a)\nprint(preprocessing.scale(a))#将值的相差度减小\n'''\n[[  10.     2.7    3.6]\n [-100.     5.    -2. ]\n [ 120.    20.    40\n[[ 0.         -0.85170713 -0.55138018]\n [-1.22474487 -0.55187146 -0.852133  ]\n [ 1.22474487  1.40357859  1.40351318]]\n'''\n```\n\n我们来看下预处理前和预处理预处理后的差别，预处理之前模型评分为`0.511111111111`，预处理后模型评分为`0.933333333333`，可以看到预处理对模型评分有很大程度的提升。\n\n```Python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets.samples_generator import make_classification\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\n\n###生成的数据如下图所示###\nplt.figure\nX,y=make_classification(n_samples=300,n_features=2,n_redundant=0,n_informative=2,             random_state=22,n_clusters_per_class=1,scale=100)\nplt.scatter(X[:,0],X[:,1],c=y)\nplt.show()\n\n###利用minmax方式对数据进行规范化###\nX=preprocessing.minmax_scale(X)#feature_range=(-1,1)可设置重置范围\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\nclf=SVC()\nclf.fit(X_train,y_train)\nprint(clf.score(X_test,y_test))\n#0.933333333333\n#没有规范化之前我们的训练分数为0.511111111111,规范化后为0.933333333333,准确度有很大提升\n```\n\n![Python之Sklearn使用教程04](Python之Sklearn使用教程/Python之Sklearn使用教程04.png)\n\n### 7.交叉验证\n\n交叉验证的基本思想是将原始数据进行分组，一部分做为训练集来训练模型，另一部分做为测试集来评价模型。交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合。还可以从有限的数据中获取尽可能多的有效信息。\n\n机器学习任务中，拿到数据后，我们首先会将原始数据集分为三部分：**训练集、验证集和测试集**。 训练集用于训练模型，验证集用于模型的参数选择配置，测试集对于模型来说是未知数据，用于评估模型的泛化能力。不同的划分会得到不同的最终模型。\n\n以前我们是直接将数据分割成70%的训练数据和测试数据，现在我们利用K折交叉验证分割数据，首先将数据分为5组，然后再从5组数据之中选择不同数据进行训练。\n\n![Python之Sklearn使用教程05](Python之Sklearn使用教程/Python之Sklearn使用教程05.png)\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n###引入数据###\niris=load_iris()\nX=iris.data\ny=iris.target\n\n###训练数据###\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n#引入交叉验证,数据分为5组进行训练\nfrom sklearn.model_selection import cross_val_score\nknn=KNeighborsClassifier(n_neighbors=5)#选择邻近的5个点\nscores=cross_val_score(knn,X,y,cv=5,scoring='accuracy')#评分方式为accuracy\nprint(scores)#每组的评分结果\n#[ 0.96666667  1.          0.93333333  0.96666667  1.        ]5组数据\nprint(scores.mean())#平均评分结果\n#0.973333333333\n```\n\n那么是否**n_neighbor=5**便是最好呢，我们来调整参数来看模型最终训练分数。\n\n```Python\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score#引入交叉验证\nimport  matplotlib.pyplot as plt\n###引入数据###\niris=datasets.load_iris()\nX=iris.data\ny=iris.target\n###设置n_neighbors的值为1到30,通过绘图来看训练分数###\nk_range=range(1,31)\nk_score=[]\nfor k in k_range:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    scores=cross_val_score(knn,X,y,cv=10,scoring='accuracy')#for classfication\n    k_score.append(loss.mean())\nplt.figure()\nplt.plot(k_range,k_score)\nplt.xlabel('Value of k for KNN')\nplt.ylabel('CrossValidation accuracy')\nplt.show()\n#K过大会带来过拟合问题,我们可以选择12-18之间的值\n```\n\n我们可以看到n_neighbor在12-18之间评分比较高，实际项目之中我们可以通过这种方式来选择不同参数。另外我们还可以选择`2-fold Cross Validation`,`Leave-One-Out Cross Validation`等方法来分割数据，比较不同方法和参数得到最优结果。\n\n![Python之Sklearn使用教程06](Python之Sklearn使用教程/Python之Sklearn使用教程06.png)\n\n我们将上述代码中的循环部分改变一下，评分函数改为`neg_mean_squared_error`，便得到对于不同参数时的损失函数。\n\n```\nfor k in k_range:\n    knn=KNeighborsClassifier(n_neighbors=k)\n    loss=-cross_val_score(knn,X,y,cv=10,scoring='neg_mean_squared_error')# for regression\n    k_score.append(loss.mean())\n```\n\n![Python之Sklearn使用教程07](Python之Sklearn使用教程/Python之Sklearn使用教程07.png)\n\n### 8.过拟合问题\n\n什么是过拟合问题呢？例如下面这张图片，黑色线已经可以很好的分类出红色点和蓝色点，但是在机器学习过程中，模型过于纠结准确度，便形成了绿色线的结果。然后在预测测试数据集结果的过程中往往会浪费很多时间并且准确率不是太好。\n\n![Python之Sklearn使用教程08](Python之Sklearn使用教程/Python之Sklearn使用教程08.png)\n\n我们先举例如何辨别**overfitting**问题。Sklearn.learning_curve中的learning curve可以很直观的看出Model学习的进度，对比发现有没有过拟合。\n\n```Python\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.datasets import load_digits\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#引入数据\ndigits=load_digits()\nX=digits.data\ny=digits.target\n\n#train_size表示记录学习过程中的某一步,比如在10%,25%...的过程中记录一下\ntrain_size,train_loss,test_loss=learning_curve(\n    SVC(gamma=0.1),X,y,cv=10,scoring='neg_mean_squared_error',\n    train_sizes=[0.1,0.25,0.5,0.75,1]\n)\ntrain_loss_mean=-np.mean(train_loss,axis=1)\ntest_loss_mean=-np.mean(test_loss,axis=1)\n\nplt.figure()\n#将每一步进行打印出来\nplt.plot(train_size,train_loss_mean,'o-',color='r',label='Training')\nplt.plot(train_size,test_loss_mean,'o-',color='g',label='Cross-validation')\nplt.legend('best')\nplt.show()\n```\n\n![Python之Sklearn使用教程09](Python之Sklearn使用教程/Python之Sklearn使用教程09.png)\n\n如果我们改变gamma的值，那么会改变相应的Loss函数。损失函数便在10左右停留，此时便能直观的看出过拟合。\n\n![Python之Sklearn使用教程10](Python之Sklearn使用教程/Python之Sklearn使用教程10.png)\n\n\n\n下面我们通过修改gamma参数来修正过拟合问题。\n\n```Python\nfrom sklearn.model_selection import  validation_curve#将learning_curve改为validation_curve\nfrom sklearn.datasets import load_digits\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nimport numpy as np\n#引入数据\ndigits=load_digits()\nX=digits.data\ny=digits.target\n\n#改变param来观察Loss函数情况\nparam_range=np.logspace(-6,-2.3,5)\ntrain_loss,test_loss=validation_curve(\n    SVC(),X,y,param_name='gamma',param_range=param_range,cv=10,\n    scoring='neg_mean_squared_error'\n)\ntrain_loss_mean=-np.mean(train_loss,axis=1)\ntest_loss_mean=-np.mean(test_loss,axis=1)\n\nplt.figure()\nplt.plot(param_range,train_loss_mean,'o-',color='r',label='Training')\nplt.plot(param_range,test_loss_mean,'o-',color='g',label='Cross-validation')\nplt.xlabel('gamma')\nplt.ylabel('loss')\nplt.legend(loc='best')\nplt.show()\n```\n\n通过改变不同的gamma值我们可以看到Loss函数的变化情况。从图中可以看到，如果gamma的值大于0.001便会出现过拟合的问题，那么我们构建模型时gamma参数设置应该小于0.001。\n\n![Python之Sklearn使用教程11.png](Python之Sklearn使用教程/Python之Sklearn使用教程11.png)\n\n### 9.保存模型\n\n我们花费很长时间用来训练数据，调整参数，得到最优模型。但如果改变平台，我们还需要重新训练数据和修正参数来得到模型，将会非常的浪费时间。此时我们可以先将model保存起来，然后便可以很方便的将模型迁移。\n\n```python\nfrom sklearn import svm\nfrom sklearn import datasets\n\n#引入和训练数据\niris=datasets.load_iris()\nX,y=iris.data,iris.target\nclf=svm.SVC()\nclf.fit(X,y)\n\n#引入sklearn中自带的保存模块\nfrom sklearn.externals import joblib\n#保存model\njoblib.dump(clf,'sklearn_save/clf.pkl')\n\n#重新加载model，只有保存一次后才能加载model\nclf3=joblib.load('sklearn_save/clf.pkl')\nprint(clf3.predict(X[0:1]))\n#存放model能够更快的获得以前的结果\n```\n\n### 10.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![Python之Sklearn使用教程推广](Python之Sklearn使用教程/Python之Sklearn使用教程推广.png)","slug":"Python之Sklearn使用教程","published":1,"updated":"2018-04-19T01:26:26.055Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg7s0pqd000c3201xe39ytt3","content":"<h3 id=\"1-Sklearn简介\"><a href=\"#1-Sklearn简介\" class=\"headerlink\" title=\"1.Sklearn简介\"></a>1.Sklearn简介</h3><p>Scikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。当我们面临机器学习问题时，便可根据下图来选择相应的方法。Sklearn具有以下特点：</p>\n<ul>\n<li>简单高效的数据挖掘和数据分析工具</li>\n</ul>\n<ul>\n<li>让每个人能够在复杂环境中重复使用</li>\n<li>建立NumPy、Scipy、MatPlotLib之上</li>\n</ul>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程图片01.png\" alt=\"Python之Sklearn使用教程图片01\"></p>\n<h3 id=\"2-Sklearn安装\"><a href=\"#2-Sklearn安装\" class=\"headerlink\" title=\"2.Sklearn安装\"></a>2.Sklearn安装</h3><p>Sklearn安装要求<code>Python(&gt;=2.7 or &gt;=3.3)</code>、<code>NumPy (&gt;= 1.8.2)</code>、<code>SciPy (&gt;= 0.13.3)</code>。如果已经安装NumPy和SciPy，安装scikit-learn可以使用<code>pip install -U scikit-learn</code>。</p>\n<h3 id=\"3-Sklearn通用学习模式\"><a href=\"#3-Sklearn通用学习模式\" class=\"headerlink\" title=\"3.Sklearn通用学习模式\"></a>3.Sklearn通用学习模式</h3><p>Sklearn中包含众多机器学习方法，但各种学习方法大致相同，我们在这里介绍Sklearn通用学习模式。首先引入需要训练的数据，Sklearn自带部分数据集，也可以通过相应方法进行构造，<code>4.Sklearn datasets</code>中我们会介绍如何构造数据。然后选择相应机器学习方法进行训练，训练过程中可以通过一些技巧调整参数，使得学习准确率更高。模型训练完成之后便可预测新数据，然后我们还可以通过<code>MatPlotLib</code>等方法来直观的展示数据。另外还可以将我们已训练好的Model进行保存，方便移动到其他平台，不必重新训练。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets<span class=\"comment\">#引入数据集,sklearn包含众多数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split<span class=\"comment\">#将数据分为测试集和训练集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier<span class=\"comment\">#利用邻近点方式训练数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">iris=datasets.load_iris()<span class=\"comment\">#引入iris鸢尾花数据,iris数据包含4个特征变量</span></span><br><span class=\"line\">iris_X=iris.data<span class=\"comment\">#特征变量</span></span><br><span class=\"line\">iris_y=iris.target<span class=\"comment\">#目标值</span></span><br><span class=\"line\">X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_y,test_size=<span class=\"number\">0.3</span>)<span class=\"comment\">#利用train_test_split进行将训练集和测试集进行分开，test_size占30%</span></span><br><span class=\"line\">print(y_train)<span class=\"comment\">#我们看到训练数据的特征值分为3类</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span></span><br><span class=\"line\"><span class=\"string\"> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###训练数据###</span></span><br><span class=\"line\">knn=KNeighborsClassifier()<span class=\"comment\">#引入训练方法</span></span><br><span class=\"line\">knn.fit(X_train,y_train)<span class=\"comment\">#进行填充测试数据进行训练</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###预测数据###</span></span><br><span class=\"line\">print(knn.predict(X_test))<span class=\"comment\">#预测特征值</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[1 1 1 0 2 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0</span></span><br><span class=\"line\"><span class=\"string\"> 1 2 1 0 0 1 0 2]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(y_test)<span class=\"comment\">#真实特征值</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[1 1 1 0 1 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0</span></span><br><span class=\"line\"><span class=\"string\"> 1 2 1 0 0 1 0 2]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-Sklearn-datasets\"><a href=\"#4-Sklearn-datasets\" class=\"headerlink\" title=\"4.Sklearn datasets\"></a>4.Sklearn datasets</h3><p>Sklearn提供一些标准数据，我们不必再从其他网站寻找数据进行训练。例如我们上面用来训练的<code>load_iris</code>数据，可以很方便的返回数据特征变量和目标值。除了引入数据之外，我们还可以通过<code>load_sample_images()</code>来引入图片。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程图片02.png\" alt=\"Python之Sklearn使用教程图片02\"></p>\n<p>除了sklearn提供的一些数据之外，还可以自己来构造一些数据帮助我们学习。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets<span class=\"comment\">#引入数据集</span></span><br><span class=\"line\"><span class=\"comment\">#构造的各种参数可以根据自己需要调整</span></span><br><span class=\"line\">X,y=datasets.make_regression(n_samples=<span class=\"number\">100</span>,n_features=<span class=\"number\">1</span>,n_targets=<span class=\"number\">1</span>,noise=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###绘制构造的数据###</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(X,y)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程03.png\" alt=\"Python之Sklearn使用教程03\"></p>\n<h3 id=\"5-Sklearn-Model的属性和功能\"><a href=\"#5-Sklearn-Model的属性和功能\" class=\"headerlink\" title=\"5.Sklearn Model的属性和功能\"></a>5.Sklearn Model的属性和功能</h3><p>数据训练完成之后得到模型，我们可以根据不同模型得到相应的属性和功能，并将其输出得到直观结果。假如通过线性回归训练之后得到线性函数<code>y=0.3x+1</code>，我们可通过<code>_coef</code>得到模型的系数为0.3，通过<code>_intercept</code>得到模型的截距为1。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression<span class=\"comment\">#引入线性回归模型</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">load_data=datasets.load_boston()</span><br><span class=\"line\">data_X=load_data.data</span><br><span class=\"line\">data_y=load_data.target</span><br><span class=\"line\">print(data_X.shape)</span><br><span class=\"line\"><span class=\"comment\">#(506, 13)data_X共13个特征变量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###训练数据###</span></span><br><span class=\"line\">model=LinearRegression()</span><br><span class=\"line\">model.fit(data_X,data_y)</span><br><span class=\"line\">model.predict(data_X[:<span class=\"number\">4</span>,:])<span class=\"comment\">#预测前4个数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###属性和功能###</span></span><br><span class=\"line\">print(model.coef_)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[ -1.07170557e-01   4.63952195e-02   2.08602395e-02   2.68856140e+00</span></span><br><span class=\"line\"><span class=\"string\">  -1.77957587e+01   3.80475246e+00   7.51061703e-04  -1.47575880e+00</span></span><br><span class=\"line\"><span class=\"string\">   3.05655038e-01  -1.23293463e-02  -9.53463555e-01   9.39251272e-03</span></span><br><span class=\"line\"><span class=\"string\">  -5.25466633e-01]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(model.intercept_)</span><br><span class=\"line\"><span class=\"comment\">#36.4911032804</span></span><br><span class=\"line\">print(model.get_params())<span class=\"comment\">#得到模型的参数</span></span><br><span class=\"line\"><span class=\"comment\">#&#123;'copy_X': True, 'normalize': False, 'n_jobs': 1, 'fit_intercept': True&#125;</span></span><br><span class=\"line\">print(model.score(data_X,data_y))<span class=\"comment\">#对训练情况进行打分</span></span><br><span class=\"line\"><span class=\"comment\">#0.740607742865</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"6-Sklearn数据预处理\"><a href=\"#6-Sklearn数据预处理\" class=\"headerlink\" title=\"6.Sklearn数据预处理\"></a>6.Sklearn数据预处理</h3><p>数据集的标准化对于大部分机器学习算法来说都是一种常规要求，如果单个特征没有或多或少地接近于标准正态分布，那么它可能并不能在项目中表现出很好的性能。在实际情况中,我们经常忽略特征的分布形状，直接去均值来对某个特征进行中心化，再通过除以非常量特征(non-constant features)的标准差进行缩放。</p>\n<p>例如, 许多学习算法中目标函数的基础都是假设所有的特征都是零均值并且具有同一阶数上的方差(比如径向基函数、支持向量机以及L1L2正则化项等)。如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致学习器并不能像我们说期望的那样，从其他特征中学习。例如我们可以通过Scale将数据缩放，达到标准化的目的。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> preprocessing</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">a=np.array([[<span class=\"number\">10</span>,<span class=\"number\">2.7</span>,<span class=\"number\">3.6</span>],</span><br><span class=\"line\">            [<span class=\"number\">-100</span>,<span class=\"number\">5</span>,<span class=\"number\">-2</span>],</span><br><span class=\"line\">            [<span class=\"number\">120</span>,<span class=\"number\">20</span>,<span class=\"number\">40</span>]],dtype=np.float64)</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">print(preprocessing.scale(a))<span class=\"comment\">#将值的相差度减小</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[  10.     2.7    3.6]</span></span><br><span class=\"line\"><span class=\"string\"> [-100.     5.    -2. ]</span></span><br><span class=\"line\"><span class=\"string\"> [ 120.    20.    40</span></span><br><span class=\"line\"><span class=\"string\">[[ 0.         -0.85170713 -0.55138018]</span></span><br><span class=\"line\"><span class=\"string\"> [-1.22474487 -0.55187146 -0.852133  ]</span></span><br><span class=\"line\"><span class=\"string\"> [ 1.22474487  1.40357859  1.40351318]]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure>\n<p>我们来看下预处理前和预处理预处理后的差别，预处理之前模型评分为<code>0.511111111111</code>，预处理后模型评分为<code>0.933333333333</code>，可以看到预处理对模型评分有很大程度的提升。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets.samples_generator <span class=\"keyword\">import</span> make_classification</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###生成的数据如下图所示###</span></span><br><span class=\"line\">plt.figure</span><br><span class=\"line\">X,y=make_classification(n_samples=<span class=\"number\">300</span>,n_features=<span class=\"number\">2</span>,n_redundant=<span class=\"number\">0</span>,n_informative=<span class=\"number\">2</span>,             random_state=<span class=\"number\">22</span>,n_clusters_per_class=<span class=\"number\">1</span>,scale=<span class=\"number\">100</span>)</span><br><span class=\"line\">plt.scatter(X[:,<span class=\"number\">0</span>],X[:,<span class=\"number\">1</span>],c=y)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###利用minmax方式对数据进行规范化###</span></span><br><span class=\"line\">X=preprocessing.minmax_scale(X)<span class=\"comment\">#feature_range=(-1,1)可设置重置范围</span></span><br><span class=\"line\">X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=<span class=\"number\">0.3</span>)</span><br><span class=\"line\">clf=SVC()</span><br><span class=\"line\">clf.fit(X_train,y_train)</span><br><span class=\"line\">print(clf.score(X_test,y_test))</span><br><span class=\"line\"><span class=\"comment\">#0.933333333333</span></span><br><span class=\"line\"><span class=\"comment\">#没有规范化之前我们的训练分数为0.511111111111,规范化后为0.933333333333,准确度有很大提升</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程04.png\" alt=\"Python之Sklearn使用教程04\"></p>\n<h3 id=\"7-交叉验证\"><a href=\"#7-交叉验证\" class=\"headerlink\" title=\"7.交叉验证\"></a>7.交叉验证</h3><p>交叉验证的基本思想是将原始数据进行分组，一部分做为训练集来训练模型，另一部分做为测试集来评价模型。交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合。还可以从有限的数据中获取尽可能多的有效信息。</p>\n<p>机器学习任务中，拿到数据后，我们首先会将原始数据集分为三部分：<strong>训练集、验证集和测试集</strong>。 训练集用于训练模型，验证集用于模型的参数选择配置，测试集对于模型来说是未知数据，用于评估模型的泛化能力。不同的划分会得到不同的最终模型。</p>\n<p>以前我们是直接将数据分割成70%的训练数据和测试数据，现在我们利用K折交叉验证分割数据，首先将数据分为5组，然后再从5组数据之中选择不同数据进行训练。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程05.png\" alt=\"Python之Sklearn使用教程05\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">iris=load_iris()</span><br><span class=\"line\">X=iris.data</span><br><span class=\"line\">y=iris.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###训练数据###</span></span><br><span class=\"line\">X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=<span class=\"number\">0.3</span>)</span><br><span class=\"line\"><span class=\"comment\">#引入交叉验证,数据分为5组进行训练</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> cross_val_score</span><br><span class=\"line\">knn=KNeighborsClassifier(n_neighbors=<span class=\"number\">5</span>)<span class=\"comment\">#选择邻近的5个点</span></span><br><span class=\"line\">scores=cross_val_score(knn,X,y,cv=<span class=\"number\">5</span>,scoring=<span class=\"string\">'accuracy'</span>)<span class=\"comment\">#评分方式为accuracy</span></span><br><span class=\"line\">print(scores)<span class=\"comment\">#每组的评分结果</span></span><br><span class=\"line\"><span class=\"comment\">#[ 0.96666667  1.          0.93333333  0.96666667  1.        ]5组数据</span></span><br><span class=\"line\">print(scores.mean())<span class=\"comment\">#平均评分结果</span></span><br><span class=\"line\"><span class=\"comment\">#0.973333333333</span></span><br></pre></td></tr></table></figure>\n<p>那么是否<strong>n_neighbor=5</strong>便是最好呢，我们来调整参数来看模型最终训练分数。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> cross_val_score<span class=\"comment\">#引入交叉验证</span></span><br><span class=\"line\"><span class=\"keyword\">import</span>  matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">iris=datasets.load_iris()</span><br><span class=\"line\">X=iris.data</span><br><span class=\"line\">y=iris.target</span><br><span class=\"line\"><span class=\"comment\">###设置n_neighbors的值为1到30,通过绘图来看训练分数###</span></span><br><span class=\"line\">k_range=range(<span class=\"number\">1</span>,<span class=\"number\">31</span>)</span><br><span class=\"line\">k_score=[]</span><br><span class=\"line\"><span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> k_range:</span><br><span class=\"line\">    knn=KNeighborsClassifier(n_neighbors=k)</span><br><span class=\"line\">    scores=cross_val_score(knn,X,y,cv=<span class=\"number\">10</span>,scoring=<span class=\"string\">'accuracy'</span>)<span class=\"comment\">#for classfication</span></span><br><span class=\"line\">    k_score.append(loss.mean())</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(k_range,k_score)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Value of k for KNN'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'CrossValidation accuracy'</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"><span class=\"comment\">#K过大会带来过拟合问题,我们可以选择12-18之间的值</span></span><br></pre></td></tr></table></figure>\n<p>我们可以看到n_neighbor在12-18之间评分比较高，实际项目之中我们可以通过这种方式来选择不同参数。另外我们还可以选择<code>2-fold Cross Validation</code>,<code>Leave-One-Out Cross Validation</code>等方法来分割数据，比较不同方法和参数得到最优结果。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程06.png\" alt=\"Python之Sklearn使用教程06\"></p>\n<p>我们将上述代码中的循环部分改变一下，评分函数改为<code>neg_mean_squared_error</code>，便得到对于不同参数时的损失函数。</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> k_range:</span><br><span class=\"line\">    <span class=\"attribute\">knn</span>=KNeighborsClassifier(n_neighbors=k)</span><br><span class=\"line\">    <span class=\"attribute\">loss</span>=-cross_val_score(knn,X,y,cv=10,scoring='neg_mean_squared_error')# <span class=\"keyword\">for</span> regression</span><br><span class=\"line\">    k_score.append(loss.mean())</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程07.png\" alt=\"Python之Sklearn使用教程07\"></p>\n<h3 id=\"8-过拟合问题\"><a href=\"#8-过拟合问题\" class=\"headerlink\" title=\"8.过拟合问题\"></a>8.过拟合问题</h3><p>什么是过拟合问题呢？例如下面这张图片，黑色线已经可以很好的分类出红色点和蓝色点，但是在机器学习过程中，模型过于纠结准确度，便形成了绿色线的结果。然后在预测测试数据集结果的过程中往往会浪费很多时间并且准确率不是太好。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程08.png\" alt=\"Python之Sklearn使用教程08\"></p>\n<p>我们先举例如何辨别<strong>overfitting</strong>问题。Sklearn.learning_curve中的learning curve可以很直观的看出Model学习的进度，对比发现有没有过拟合。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> learning_curve</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_digits</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入数据</span></span><br><span class=\"line\">digits=load_digits()</span><br><span class=\"line\">X=digits.data</span><br><span class=\"line\">y=digits.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#train_size表示记录学习过程中的某一步,比如在10%,25%...的过程中记录一下</span></span><br><span class=\"line\">train_size,train_loss,test_loss=learning_curve(</span><br><span class=\"line\">    SVC(gamma=<span class=\"number\">0.1</span>),X,y,cv=<span class=\"number\">10</span>,scoring=<span class=\"string\">'neg_mean_squared_error'</span>,</span><br><span class=\"line\">    train_sizes=[<span class=\"number\">0.1</span>,<span class=\"number\">0.25</span>,<span class=\"number\">0.5</span>,<span class=\"number\">0.75</span>,<span class=\"number\">1</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\">train_loss_mean=-np.mean(train_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">test_loss_mean=-np.mean(test_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\"><span class=\"comment\">#将每一步进行打印出来</span></span><br><span class=\"line\">plt.plot(train_size,train_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'r'</span>,label=<span class=\"string\">'Training'</span>)</span><br><span class=\"line\">plt.plot(train_size,test_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'g'</span>,label=<span class=\"string\">'Cross-validation'</span>)</span><br><span class=\"line\">plt.legend(<span class=\"string\">'best'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程09.png\" alt=\"Python之Sklearn使用教程09\"></p>\n<p>如果我们改变gamma的值，那么会改变相应的Loss函数。损失函数便在10左右停留，此时便能直观的看出过拟合。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程10.png\" alt=\"Python之Sklearn使用教程10\"></p>\n<p>下面我们通过修改gamma参数来修正过拟合问题。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span>  validation_curve<span class=\"comment\">#将learning_curve改为validation_curve</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_digits</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"comment\">#引入数据</span></span><br><span class=\"line\">digits=load_digits()</span><br><span class=\"line\">X=digits.data</span><br><span class=\"line\">y=digits.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#改变param来观察Loss函数情况</span></span><br><span class=\"line\">param_range=np.logspace(<span class=\"number\">-6</span>,<span class=\"number\">-2.3</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">train_loss,test_loss=validation_curve(</span><br><span class=\"line\">    SVC(),X,y,param_name=<span class=\"string\">'gamma'</span>,param_range=param_range,cv=<span class=\"number\">10</span>,</span><br><span class=\"line\">    scoring=<span class=\"string\">'neg_mean_squared_error'</span></span><br><span class=\"line\">)</span><br><span class=\"line\">train_loss_mean=-np.mean(train_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">test_loss_mean=-np.mean(test_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(param_range,train_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'r'</span>,label=<span class=\"string\">'Training'</span>)</span><br><span class=\"line\">plt.plot(param_range,test_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'g'</span>,label=<span class=\"string\">'Cross-validation'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'gamma'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'loss'</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">'best'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>通过改变不同的gamma值我们可以看到Loss函数的变化情况。从图中可以看到，如果gamma的值大于0.001便会出现过拟合的问题，那么我们构建模型时gamma参数设置应该小于0.001。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程11.png\" alt=\"Python之Sklearn使用教程11.png\"></p>\n<h3 id=\"9-保存模型\"><a href=\"#9-保存模型\" class=\"headerlink\" title=\"9.保存模型\"></a>9.保存模型</h3><p>我们花费很长时间用来训练数据，调整参数，得到最优模型。但如果改变平台，我们还需要重新训练数据和修正参数来得到模型，将会非常的浪费时间。此时我们可以先将model保存起来，然后便可以很方便的将模型迁移。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入和训练数据</span></span><br><span class=\"line\">iris=datasets.load_iris()</span><br><span class=\"line\">X,y=iris.data,iris.target</span><br><span class=\"line\">clf=svm.SVC()</span><br><span class=\"line\">clf.fit(X,y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入sklearn中自带的保存模块</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib</span><br><span class=\"line\"><span class=\"comment\">#保存model</span></span><br><span class=\"line\">joblib.dump(clf,<span class=\"string\">'sklearn_save/clf.pkl'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#重新加载model，只有保存一次后才能加载model</span></span><br><span class=\"line\">clf3=joblib.load(<span class=\"string\">'sklearn_save/clf.pkl'</span>)</span><br><span class=\"line\">print(clf3.predict(X[<span class=\"number\">0</span>:<span class=\"number\">1</span>]))</span><br><span class=\"line\"><span class=\"comment\">#存放model能够更快的获得以前的结果</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"10-推广\"><a href=\"#10-推广\" class=\"headerlink\" title=\"10.推广\"></a>10.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程推广.png\" alt=\"Python之Sklearn使用教程推广\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-Sklearn简介\"><a href=\"#1-Sklearn简介\" class=\"headerlink\" title=\"1.Sklearn简介\"></a>1.Sklearn简介</h3><p>Scikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。当我们面临机器学习问题时，便可根据下图来选择相应的方法。Sklearn具有以下特点：</p>\n<ul>\n<li>简单高效的数据挖掘和数据分析工具</li>\n</ul>\n<ul>\n<li>让每个人能够在复杂环境中重复使用</li>\n<li>建立NumPy、Scipy、MatPlotLib之上</li>\n</ul>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程图片01.png\" alt=\"Python之Sklearn使用教程图片01\"></p>\n<h3 id=\"2-Sklearn安装\"><a href=\"#2-Sklearn安装\" class=\"headerlink\" title=\"2.Sklearn安装\"></a>2.Sklearn安装</h3><p>Sklearn安装要求<code>Python(&gt;=2.7 or &gt;=3.3)</code>、<code>NumPy (&gt;= 1.8.2)</code>、<code>SciPy (&gt;= 0.13.3)</code>。如果已经安装NumPy和SciPy，安装scikit-learn可以使用<code>pip install -U scikit-learn</code>。</p>\n<h3 id=\"3-Sklearn通用学习模式\"><a href=\"#3-Sklearn通用学习模式\" class=\"headerlink\" title=\"3.Sklearn通用学习模式\"></a>3.Sklearn通用学习模式</h3><p>Sklearn中包含众多机器学习方法，但各种学习方法大致相同，我们在这里介绍Sklearn通用学习模式。首先引入需要训练的数据，Sklearn自带部分数据集，也可以通过相应方法进行构造，<code>4.Sklearn datasets</code>中我们会介绍如何构造数据。然后选择相应机器学习方法进行训练，训练过程中可以通过一些技巧调整参数，使得学习准确率更高。模型训练完成之后便可预测新数据，然后我们还可以通过<code>MatPlotLib</code>等方法来直观的展示数据。另外还可以将我们已训练好的Model进行保存，方便移动到其他平台，不必重新训练。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets<span class=\"comment\">#引入数据集,sklearn包含众多数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split<span class=\"comment\">#将数据分为测试集和训练集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier<span class=\"comment\">#利用邻近点方式训练数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">iris=datasets.load_iris()<span class=\"comment\">#引入iris鸢尾花数据,iris数据包含4个特征变量</span></span><br><span class=\"line\">iris_X=iris.data<span class=\"comment\">#特征变量</span></span><br><span class=\"line\">iris_y=iris.target<span class=\"comment\">#目标值</span></span><br><span class=\"line\">X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_y,test_size=<span class=\"number\">0.3</span>)<span class=\"comment\">#利用train_test_split进行将训练集和测试集进行分开，test_size占30%</span></span><br><span class=\"line\">print(y_train)<span class=\"comment\">#我们看到训练数据的特征值分为3类</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span></span><br><span class=\"line\"><span class=\"string\"> 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1</span></span><br><span class=\"line\"><span class=\"string\"> 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</span></span><br><span class=\"line\"><span class=\"string\"> 2 2]</span></span><br><span class=\"line\"><span class=\"string\"> '''</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###训练数据###</span></span><br><span class=\"line\">knn=KNeighborsClassifier()<span class=\"comment\">#引入训练方法</span></span><br><span class=\"line\">knn.fit(X_train,y_train)<span class=\"comment\">#进行填充测试数据进行训练</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###预测数据###</span></span><br><span class=\"line\">print(knn.predict(X_test))<span class=\"comment\">#预测特征值</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[1 1 1 0 2 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0</span></span><br><span class=\"line\"><span class=\"string\"> 1 2 1 0 0 1 0 2]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(y_test)<span class=\"comment\">#真实特征值</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[1 1 1 0 1 2 1 1 1 0 0 0 2 2 0 1 2 2 0 1 0 0 0 0 0 0 2 1 0 0 0 1 0 2 0 2 0</span></span><br><span class=\"line\"><span class=\"string\"> 1 2 1 0 0 1 0 2]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"4-Sklearn-datasets\"><a href=\"#4-Sklearn-datasets\" class=\"headerlink\" title=\"4.Sklearn datasets\"></a>4.Sklearn datasets</h3><p>Sklearn提供一些标准数据，我们不必再从其他网站寻找数据进行训练。例如我们上面用来训练的<code>load_iris</code>数据，可以很方便的返回数据特征变量和目标值。除了引入数据之外，我们还可以通过<code>load_sample_images()</code>来引入图片。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程图片02.png\" alt=\"Python之Sklearn使用教程图片02\"></p>\n<p>除了sklearn提供的一些数据之外，还可以自己来构造一些数据帮助我们学习。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets<span class=\"comment\">#引入数据集</span></span><br><span class=\"line\"><span class=\"comment\">#构造的各种参数可以根据自己需要调整</span></span><br><span class=\"line\">X,y=datasets.make_regression(n_samples=<span class=\"number\">100</span>,n_features=<span class=\"number\">1</span>,n_targets=<span class=\"number\">1</span>,noise=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###绘制构造的数据###</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.scatter(X,y)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程03.png\" alt=\"Python之Sklearn使用教程03\"></p>\n<h3 id=\"5-Sklearn-Model的属性和功能\"><a href=\"#5-Sklearn-Model的属性和功能\" class=\"headerlink\" title=\"5.Sklearn Model的属性和功能\"></a>5.Sklearn Model的属性和功能</h3><p>数据训练完成之后得到模型，我们可以根据不同模型得到相应的属性和功能，并将其输出得到直观结果。假如通过线性回归训练之后得到线性函数<code>y=0.3x+1</code>，我们可通过<code>_coef</code>得到模型的系数为0.3，通过<code>_intercept</code>得到模型的截距为1。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression<span class=\"comment\">#引入线性回归模型</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">load_data=datasets.load_boston()</span><br><span class=\"line\">data_X=load_data.data</span><br><span class=\"line\">data_y=load_data.target</span><br><span class=\"line\">print(data_X.shape)</span><br><span class=\"line\"><span class=\"comment\">#(506, 13)data_X共13个特征变量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###训练数据###</span></span><br><span class=\"line\">model=LinearRegression()</span><br><span class=\"line\">model.fit(data_X,data_y)</span><br><span class=\"line\">model.predict(data_X[:<span class=\"number\">4</span>,:])<span class=\"comment\">#预测前4个数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###属性和功能###</span></span><br><span class=\"line\">print(model.coef_)</span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[ -1.07170557e-01   4.63952195e-02   2.08602395e-02   2.68856140e+00</span></span><br><span class=\"line\"><span class=\"string\">  -1.77957587e+01   3.80475246e+00   7.51061703e-04  -1.47575880e+00</span></span><br><span class=\"line\"><span class=\"string\">   3.05655038e-01  -1.23293463e-02  -9.53463555e-01   9.39251272e-03</span></span><br><span class=\"line\"><span class=\"string\">  -5.25466633e-01]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\">print(model.intercept_)</span><br><span class=\"line\"><span class=\"comment\">#36.4911032804</span></span><br><span class=\"line\">print(model.get_params())<span class=\"comment\">#得到模型的参数</span></span><br><span class=\"line\"><span class=\"comment\">#&#123;'copy_X': True, 'normalize': False, 'n_jobs': 1, 'fit_intercept': True&#125;</span></span><br><span class=\"line\">print(model.score(data_X,data_y))<span class=\"comment\">#对训练情况进行打分</span></span><br><span class=\"line\"><span class=\"comment\">#0.740607742865</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"6-Sklearn数据预处理\"><a href=\"#6-Sklearn数据预处理\" class=\"headerlink\" title=\"6.Sklearn数据预处理\"></a>6.Sklearn数据预处理</h3><p>数据集的标准化对于大部分机器学习算法来说都是一种常规要求，如果单个特征没有或多或少地接近于标准正态分布，那么它可能并不能在项目中表现出很好的性能。在实际情况中,我们经常忽略特征的分布形状，直接去均值来对某个特征进行中心化，再通过除以非常量特征(non-constant features)的标准差进行缩放。</p>\n<p>例如, 许多学习算法中目标函数的基础都是假设所有的特征都是零均值并且具有同一阶数上的方差(比如径向基函数、支持向量机以及L1L2正则化项等)。如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致学习器并不能像我们说期望的那样，从其他特征中学习。例如我们可以通过Scale将数据缩放，达到标准化的目的。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> preprocessing</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">a=np.array([[<span class=\"number\">10</span>,<span class=\"number\">2.7</span>,<span class=\"number\">3.6</span>],</span><br><span class=\"line\">            [<span class=\"number\">-100</span>,<span class=\"number\">5</span>,<span class=\"number\">-2</span>],</span><br><span class=\"line\">            [<span class=\"number\">120</span>,<span class=\"number\">20</span>,<span class=\"number\">40</span>]],dtype=np.float64)</span><br><span class=\"line\">print(a)</span><br><span class=\"line\">print(preprocessing.scale(a))<span class=\"comment\">#将值的相差度减小</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">[[  10.     2.7    3.6]</span></span><br><span class=\"line\"><span class=\"string\"> [-100.     5.    -2. ]</span></span><br><span class=\"line\"><span class=\"string\"> [ 120.    20.    40</span></span><br><span class=\"line\"><span class=\"string\">[[ 0.         -0.85170713 -0.55138018]</span></span><br><span class=\"line\"><span class=\"string\"> [-1.22474487 -0.55187146 -0.852133  ]</span></span><br><span class=\"line\"><span class=\"string\"> [ 1.22474487  1.40357859  1.40351318]]</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br></pre></td></tr></table></figure>\n<p>我们来看下预处理前和预处理预处理后的差别，预处理之前模型评分为<code>0.511111111111</code>，预处理后模型评分为<code>0.933333333333</code>，可以看到预处理对模型评分有很大程度的提升。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets.samples_generator <span class=\"keyword\">import</span> make_classification</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###生成的数据如下图所示###</span></span><br><span class=\"line\">plt.figure</span><br><span class=\"line\">X,y=make_classification(n_samples=<span class=\"number\">300</span>,n_features=<span class=\"number\">2</span>,n_redundant=<span class=\"number\">0</span>,n_informative=<span class=\"number\">2</span>,             random_state=<span class=\"number\">22</span>,n_clusters_per_class=<span class=\"number\">1</span>,scale=<span class=\"number\">100</span>)</span><br><span class=\"line\">plt.scatter(X[:,<span class=\"number\">0</span>],X[:,<span class=\"number\">1</span>],c=y)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###利用minmax方式对数据进行规范化###</span></span><br><span class=\"line\">X=preprocessing.minmax_scale(X)<span class=\"comment\">#feature_range=(-1,1)可设置重置范围</span></span><br><span class=\"line\">X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=<span class=\"number\">0.3</span>)</span><br><span class=\"line\">clf=SVC()</span><br><span class=\"line\">clf.fit(X_train,y_train)</span><br><span class=\"line\">print(clf.score(X_test,y_test))</span><br><span class=\"line\"><span class=\"comment\">#0.933333333333</span></span><br><span class=\"line\"><span class=\"comment\">#没有规范化之前我们的训练分数为0.511111111111,规范化后为0.933333333333,准确度有很大提升</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程04.png\" alt=\"Python之Sklearn使用教程04\"></p>\n<h3 id=\"7-交叉验证\"><a href=\"#7-交叉验证\" class=\"headerlink\" title=\"7.交叉验证\"></a>7.交叉验证</h3><p>交叉验证的基本思想是将原始数据进行分组，一部分做为训练集来训练模型，另一部分做为测试集来评价模型。交叉验证用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，可以在一定程度上减小过拟合。还可以从有限的数据中获取尽可能多的有效信息。</p>\n<p>机器学习任务中，拿到数据后，我们首先会将原始数据集分为三部分：<strong>训练集、验证集和测试集</strong>。 训练集用于训练模型，验证集用于模型的参数选择配置，测试集对于模型来说是未知数据，用于评估模型的泛化能力。不同的划分会得到不同的最终模型。</p>\n<p>以前我们是直接将数据分割成70%的训练数据和测试数据，现在我们利用K折交叉验证分割数据，首先将数据分为5组，然后再从5组数据之中选择不同数据进行训练。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程05.png\" alt=\"Python之Sklearn使用教程05\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">iris=load_iris()</span><br><span class=\"line\">X=iris.data</span><br><span class=\"line\">y=iris.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###训练数据###</span></span><br><span class=\"line\">X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=<span class=\"number\">0.3</span>)</span><br><span class=\"line\"><span class=\"comment\">#引入交叉验证,数据分为5组进行训练</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> cross_val_score</span><br><span class=\"line\">knn=KNeighborsClassifier(n_neighbors=<span class=\"number\">5</span>)<span class=\"comment\">#选择邻近的5个点</span></span><br><span class=\"line\">scores=cross_val_score(knn,X,y,cv=<span class=\"number\">5</span>,scoring=<span class=\"string\">'accuracy'</span>)<span class=\"comment\">#评分方式为accuracy</span></span><br><span class=\"line\">print(scores)<span class=\"comment\">#每组的评分结果</span></span><br><span class=\"line\"><span class=\"comment\">#[ 0.96666667  1.          0.93333333  0.96666667  1.        ]5组数据</span></span><br><span class=\"line\">print(scores.mean())<span class=\"comment\">#平均评分结果</span></span><br><span class=\"line\"><span class=\"comment\">#0.973333333333</span></span><br></pre></td></tr></table></figure>\n<p>那么是否<strong>n_neighbor=5</strong>便是最好呢，我们来调整参数来看模型最终训练分数。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> cross_val_score<span class=\"comment\">#引入交叉验证</span></span><br><span class=\"line\"><span class=\"keyword\">import</span>  matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\">###引入数据###</span></span><br><span class=\"line\">iris=datasets.load_iris()</span><br><span class=\"line\">X=iris.data</span><br><span class=\"line\">y=iris.target</span><br><span class=\"line\"><span class=\"comment\">###设置n_neighbors的值为1到30,通过绘图来看训练分数###</span></span><br><span class=\"line\">k_range=range(<span class=\"number\">1</span>,<span class=\"number\">31</span>)</span><br><span class=\"line\">k_score=[]</span><br><span class=\"line\"><span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> k_range:</span><br><span class=\"line\">    knn=KNeighborsClassifier(n_neighbors=k)</span><br><span class=\"line\">    scores=cross_val_score(knn,X,y,cv=<span class=\"number\">10</span>,scoring=<span class=\"string\">'accuracy'</span>)<span class=\"comment\">#for classfication</span></span><br><span class=\"line\">    k_score.append(loss.mean())</span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(k_range,k_score)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'Value of k for KNN'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'CrossValidation accuracy'</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"><span class=\"comment\">#K过大会带来过拟合问题,我们可以选择12-18之间的值</span></span><br></pre></td></tr></table></figure>\n<p>我们可以看到n_neighbor在12-18之间评分比较高，实际项目之中我们可以通过这种方式来选择不同参数。另外我们还可以选择<code>2-fold Cross Validation</code>,<code>Leave-One-Out Cross Validation</code>等方法来分割数据，比较不同方法和参数得到最优结果。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程06.png\" alt=\"Python之Sklearn使用教程06\"></p>\n<p>我们将上述代码中的循环部分改变一下，评分函数改为<code>neg_mean_squared_error</code>，便得到对于不同参数时的损失函数。</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> k <span class=\"keyword\">in</span> k_range:</span><br><span class=\"line\">    <span class=\"attribute\">knn</span>=KNeighborsClassifier(n_neighbors=k)</span><br><span class=\"line\">    <span class=\"attribute\">loss</span>=-cross_val_score(knn,X,y,cv=10,scoring='neg_mean_squared_error')# <span class=\"keyword\">for</span> regression</span><br><span class=\"line\">    k_score.append(loss.mean())</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程07.png\" alt=\"Python之Sklearn使用教程07\"></p>\n<h3 id=\"8-过拟合问题\"><a href=\"#8-过拟合问题\" class=\"headerlink\" title=\"8.过拟合问题\"></a>8.过拟合问题</h3><p>什么是过拟合问题呢？例如下面这张图片，黑色线已经可以很好的分类出红色点和蓝色点，但是在机器学习过程中，模型过于纠结准确度，便形成了绿色线的结果。然后在预测测试数据集结果的过程中往往会浪费很多时间并且准确率不是太好。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程08.png\" alt=\"Python之Sklearn使用教程08\"></p>\n<p>我们先举例如何辨别<strong>overfitting</strong>问题。Sklearn.learning_curve中的learning curve可以很直观的看出Model学习的进度，对比发现有没有过拟合。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> learning_curve</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_digits</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入数据</span></span><br><span class=\"line\">digits=load_digits()</span><br><span class=\"line\">X=digits.data</span><br><span class=\"line\">y=digits.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#train_size表示记录学习过程中的某一步,比如在10%,25%...的过程中记录一下</span></span><br><span class=\"line\">train_size,train_loss,test_loss=learning_curve(</span><br><span class=\"line\">    SVC(gamma=<span class=\"number\">0.1</span>),X,y,cv=<span class=\"number\">10</span>,scoring=<span class=\"string\">'neg_mean_squared_error'</span>,</span><br><span class=\"line\">    train_sizes=[<span class=\"number\">0.1</span>,<span class=\"number\">0.25</span>,<span class=\"number\">0.5</span>,<span class=\"number\">0.75</span>,<span class=\"number\">1</span>]</span><br><span class=\"line\">)</span><br><span class=\"line\">train_loss_mean=-np.mean(train_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">test_loss_mean=-np.mean(test_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\"><span class=\"comment\">#将每一步进行打印出来</span></span><br><span class=\"line\">plt.plot(train_size,train_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'r'</span>,label=<span class=\"string\">'Training'</span>)</span><br><span class=\"line\">plt.plot(train_size,test_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'g'</span>,label=<span class=\"string\">'Cross-validation'</span>)</span><br><span class=\"line\">plt.legend(<span class=\"string\">'best'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程09.png\" alt=\"Python之Sklearn使用教程09\"></p>\n<p>如果我们改变gamma的值，那么会改变相应的Loss函数。损失函数便在10左右停留，此时便能直观的看出过拟合。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程10.png\" alt=\"Python之Sklearn使用教程10\"></p>\n<p>下面我们通过修改gamma参数来修正过拟合问题。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span>  validation_curve<span class=\"comment\">#将learning_curve改为validation_curve</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_digits</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> SVC</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"comment\">#引入数据</span></span><br><span class=\"line\">digits=load_digits()</span><br><span class=\"line\">X=digits.data</span><br><span class=\"line\">y=digits.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#改变param来观察Loss函数情况</span></span><br><span class=\"line\">param_range=np.logspace(<span class=\"number\">-6</span>,<span class=\"number\">-2.3</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">train_loss,test_loss=validation_curve(</span><br><span class=\"line\">    SVC(),X,y,param_name=<span class=\"string\">'gamma'</span>,param_range=param_range,cv=<span class=\"number\">10</span>,</span><br><span class=\"line\">    scoring=<span class=\"string\">'neg_mean_squared_error'</span></span><br><span class=\"line\">)</span><br><span class=\"line\">train_loss_mean=-np.mean(train_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">test_loss_mean=-np.mean(test_loss,axis=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(param_range,train_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'r'</span>,label=<span class=\"string\">'Training'</span>)</span><br><span class=\"line\">plt.plot(param_range,test_loss_mean,<span class=\"string\">'o-'</span>,color=<span class=\"string\">'g'</span>,label=<span class=\"string\">'Cross-validation'</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'gamma'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'loss'</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">'best'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p>通过改变不同的gamma值我们可以看到Loss函数的变化情况。从图中可以看到，如果gamma的值大于0.001便会出现过拟合的问题，那么我们构建模型时gamma参数设置应该小于0.001。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程11.png\" alt=\"Python之Sklearn使用教程11.png\"></p>\n<h3 id=\"9-保存模型\"><a href=\"#9-保存模型\" class=\"headerlink\" title=\"9.保存模型\"></a>9.保存模型</h3><p>我们花费很长时间用来训练数据，调整参数，得到最优模型。但如果改变平台，我们还需要重新训练数据和修正参数来得到模型，将会非常的浪费时间。此时我们可以先将model保存起来，然后便可以很方便的将模型迁移。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入和训练数据</span></span><br><span class=\"line\">iris=datasets.load_iris()</span><br><span class=\"line\">X,y=iris.data,iris.target</span><br><span class=\"line\">clf=svm.SVC()</span><br><span class=\"line\">clf.fit(X,y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入sklearn中自带的保存模块</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib</span><br><span class=\"line\"><span class=\"comment\">#保存model</span></span><br><span class=\"line\">joblib.dump(clf,<span class=\"string\">'sklearn_save/clf.pkl'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#重新加载model，只有保存一次后才能加载model</span></span><br><span class=\"line\">clf3=joblib.load(<span class=\"string\">'sklearn_save/clf.pkl'</span>)</span><br><span class=\"line\">print(clf3.predict(X[<span class=\"number\">0</span>:<span class=\"number\">1</span>]))</span><br><span class=\"line\"><span class=\"comment\">#存放model能够更快的获得以前的结果</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"10-推广\"><a href=\"#10-推广\" class=\"headerlink\" title=\"10.推广\"></a>10.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/04/15/Python之Sklearn使用教程/Python之Sklearn使用教程推广.png\" alt=\"Python之Sklearn使用教程推广\"></p>\n"},{"title":"机器学习之Logistic回归","date":"2018-03-27T09:49:33.000Z","comments":1,"mathjax":true,"_content":"\n### 1.Logistic回归简介\n\n线性回归能够找到一个假设函数来估计原函数，从而根据特征变量来得到假设值，但线性回归模型不能达到分类的效果。在线性回归的基础上，我们将假设值和概率结合得到分类器，达到分类的效果。虽然Logistic回归是回归模型，但在实际项目中我们经常用于分类问题。\n\n### 2.Sigmoid函数\n\n为什么选择Sigmoid函数呢？我们目标是寻找函数进行分类，首先假设任意多类的分类问题（不仅是两类）。Exponential假设第i个体征对第k类问题的贡献是$w_{ki}$，则数据点$(x_1,x_2,…,x_n)$属于第k类的概率正比于\n$$\nexp(w_{k1}x_1+…+w_{kn}x_n)。\n$$\n因为一个数据点属于各类的概率之和为1，所以可以得到\n$$\nP(y=k)=\\frac{exp(\\sum_{i=1}^{n}w_{ki}{x_i})}{\\sum_{k'}exp(\\sum_{i=1}^{n}w_{k'i}x_i)}\n$$\n现在回到两类（0,1）的情况，此时分母上只有两项\n$$\nP(y=1)=\\frac{exp(\\sum_{i=1}^{n}w_{1i}{x_i})}{exp(\\sum_{i=1}^{n}w_{1i}x_i)+exp(\\sum_{i=1}^{n}w_{0i}x_i)}\n$$\n公式分子、分母同时除以分子，并设$w_i=w_{1i}-w_{0i}$，则有\n$$\nP(y=1)=\\frac{1}{1+exp(-\\sum_{i=1}^{n}w_ix_i)}\n$$\n上述公式便是Logistic函数，参数$w_i$表示第i个特征对1类的贡献与0类的贡献的差值。\n$$\nSigmoid Function: f(x)=\\frac{1}{1+e^{-x}}\n$$\nSigmoid函数具有如下性质\n\n+ 函数连续且单调递增\n+ 函数关于（0,0.5）对称\n+ $x\\in(-\\infty,\\infty)$时$y\\in(0,1)$\n\n```python\n#plot sigmoid function \nimport numpy as np\nimport matplotlib.pyplot as plt\n\n##sigmoid function\nx=np.arange(-5,5,0.1)\ny=1/(1+np.exp(-x))\n\n#plot\nplt.figure()\nplt.plot(x,y,color='red',linewidth='2')\nax=plt.gca()\nax.spines['right'].set_color('none')\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')\nax.spines['bottom'].set_position(('data',0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data',0))\nplt.xlabel('independent variable')\nplt.ylabel('dependent variable')\nplt.show()\n```\n\n![机器学习之Logistic回归01](机器学习之Logistic回归/机器学习之Logistic回归01.png)\n\n### 3.Logistic回归推导\n\n+ 特征向量$X=(x_0,x_1,x_2…x_n)$，默认$x_0=1$。\n+ $\\theta=(\\theta_0,\\theta_1,\\theta_2…\\theta_n)$\n+ $n$表示特征数量\n+ $m$表示训练数据数量\n\n线性回归函数为$z=\\theta_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n=\\theta^TX$。对于Logistic回归来说，其思想也基于线性回归（Logistic回归属于广义线性回归模型）。结合线性回归和Sigmoid函数，将线性回归得到的结果映射到Sigmoid函数之中，我们便得到目标函数。\n$$\nh(X)=\\frac{1}{1+e^{-\\theta^TX}}\n$$\n我们可以把$h(X)$看成样本数据的概率密度函数，当$h(X)<0.5$是判断当前数据属于A类，当$h(X)>0.5$判断当前数据属于B类。对于上述函数$h(X)$，接下来我们需要做的便是怎样去估计参数$\\theta$。\n\n条件概率$P(y=1|X)$为某事件发生的概率，Logistic回归模型可以表示为\n$$\nP(y=1|X)=\\pi(X)=\\frac{1}{1+e^{-\\theta^TX}}\n$$\n条件概率$P(y=0|X)$为某事件不发生的概率，Logistic回归模型可以表示为\n$$\nP(y=0|X)=1-\\pi(X)=\\frac{1}{1+e^{\\theta^TX}}\n$$\n因此我们可以得到事件的发生比为\n$$\nodds=\\frac{P(y=1|X)}{P(y=0|X)}\n$$\n事件的发生和不发生为相互独立事件，样本数据结果记录为$(y_1,y_2…y_m)$。设$p_i=P(y_i=1|X_i)$为给定条件下得到$y_i=1$的概率，同样$1-p_i=P(y_i=0|X_i)$的概率，所以得到一个观测值的概率为$P(y_i)=p_i^{y_i}(1-p_i)^{1-y_i}$，最后参数估计时我们可以采用极大似然估计。\n\n各个观测样本之间相互独立，那么它们的联合分布为各边缘分布的乘积，得到如下极大似然函数\n$$\nL(\\theta)=\\prod_{i=1}^{m}[\\pi(X_i)]^{y_i}[1-\\pi(X_i)]^{1-y_i}\n$$\n目标便是求得使这一似然函数值最大的参数估计，于是函数取对数得到\n$$\nlnL(\\theta)=\\sum_{i=1}^{m}\\left \\{ y_iln[\\pi(X_i)] +(1-y_i)ln[1-\\pi(X_i)] \\right \\}\n$$\n\n$$\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_iln\\frac{\\pi(X_i)}{1-\\pi(X_i)}\n$$\n\n$$\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_i\\theta^TX\n$$\n\n$$\n=\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX\n$$\n\n通过上面得到的结论来求解使得似然函数最大化的参数向量，此处我们利用梯度下降算法求$\\theta$。首先在前面乘上负的系数$-\\frac{1}{m}$，所以$J(\\theta)$最小时的$\\theta$为最佳参数。\n$$\nJ(\\theta)=-\\frac{1}{m}lnL(\\theta)\n$$\n\n$$\n=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}\n$$\n\n### 4.梯度下降算法\n\n#### 4.1梯度下降算法简述\n\n实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都到达山脚，可能到达山峰的某个局部最低点。\n\n![器学习之Logistic回归0](机器学习之Logistic回归/机器学习之Logistic回归02.png)\n\n从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解Logistic回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。\n\n#### 4.2 梯度下降算法相关概念\n\n求解梯度下降算法之前，我们先了解相关概念。\n\n- **步长（Learning Rate）**：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。\n- **特征（Feature）**：即上述描述的$X$\n- **假设函数（Hypothesis Function）**：监督学习中，为了拟合输入样本，而使用假设函数。\n- **损失函数（Loss Function）**：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。Logistic损失函数为\n\n$$\nJ(\\theta)=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}\n$$\n\n我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。\n\n#### 4.3梯度下降算法过程\n\n- 随机选取一组$\\theta$。\n- 不断变化$\\theta$，让$J(\\theta)$变小，$\\alpha$为学习步长。\n\n$$\n\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\n$$\n\n+ 直到$J(\\theta)$得到最小值，$\\frac{\\partial}{\\partial\\theta_k}J(\\theta)$为$J(\\theta)$对$\\theta_k$的偏导。\n\n$$\n\\frac{\\partial J(\\theta)}{\\partial\\theta_j}=\\frac{1}{m}\\sum_{i=1}^{m}\\frac{1}{1+e^{\\theta^TX}}e^{\\theta^TX}X_{ij}-\\sum_{i=1}^{m}y_iX_{ij}\n$$\n\n$$\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\frac{e^{\\theta^TX}}{1+e^{\\theta^Tx}}-y_i]\n$$\n\n$$\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]\n$$\n\n因此梯度下降算法的迭代最终表述为\n$$\n\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]\n$$\n梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到Logistic函数。\n\n### 5.Logistic回归实现\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\ndef plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n    # setup marker generator and color map\n    markers = ('s', 'x', 'o', '^', 'v')\n    colors = ('red', 'blue', 'lightgreen', 'cyan', 'gray')\n    cmap = ListedColormap(colors[:len(np.unique(y))])\n    # plot the decision surface\n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot class samples\n    for idx, cl in enumerate(np.unique(y)):\n        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],alpha=0.8, c=cmap(idx),marker=markers[idx], label=cl)\n    # highlight test samples\n    if test_idx:\n        X_test, y_test = X[test_idx, :], y[test_idx]\n        plt.scatter(X_test[:, 0], X_test[:, 1], c='blue', alpha=1.0, linewidth=1, marker='o', s=55, label='test set')\n\niris = datasets.load_iris()\nX = iris.data[:, [2, 3]]\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n#为了追求机器学习的最佳性能，我们将特征缩放\nsc = StandardScaler()\nsc.fit(X_train)#估算每个特征的平均值和标准差\nX_train_std=sc.transform(X_train)#用同样的参数来标准化测试集，使得测试集和训练集之间有可比性\nX_test_std=sc.transform(X_test)\nX_combined_std = np.vstack((X_train_std, X_test_std))\ny_combined = np.hstack((y_train, y_test))\n\n#训练感知机模型\nlr = LogisticRegression(C=1000.0,random_state=0)#迭代次数为1000次,random_state设置随机种子，每次迭代都有相同的训练集顺序\nlr.fit(X_train_std, y_train)\nlr.predict_proba(X_test_std)\n\n#绘图\nplot_decision_regions(X_combined_std, y_combined, classifier=lr, test_idx=range(105,150))\nplt.xlabel('petal length [standardized]')\nplt.ylabel('petal width [standardized]')\nplt.legend(loc='upper left')\nplt.show()\n```\n\n![机器学习之Logistic回归03](机器学习之Logistic回归/机器学习之Logistic回归03.png)\n\n### 6.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![](机器学习之Logistic回归/推广.png)\n\n+ 参考\n\n[^1]: https://www.zhihu.com/people/maigo/activities\n[^2]: https://blog.csdn.net/programmer_wei/article/details/52072939\n[^3]: https://blog.csdn.net/javaisnotgood/article/details/78873819\n\n","source":"_posts/机器学习之Logistic回归.md","raw":"---\ntitle: 机器学习之Logistic回归\ndate: 2018-03-27 17:49:33\ntags: [机器学习,算法]\ncategories: 机器学习\ncomments: true\nmathjax: true\n---\n\n### 1.Logistic回归简介\n\n线性回归能够找到一个假设函数来估计原函数，从而根据特征变量来得到假设值，但线性回归模型不能达到分类的效果。在线性回归的基础上，我们将假设值和概率结合得到分类器，达到分类的效果。虽然Logistic回归是回归模型，但在实际项目中我们经常用于分类问题。\n\n### 2.Sigmoid函数\n\n为什么选择Sigmoid函数呢？我们目标是寻找函数进行分类，首先假设任意多类的分类问题（不仅是两类）。Exponential假设第i个体征对第k类问题的贡献是$w_{ki}$，则数据点$(x_1,x_2,…,x_n)$属于第k类的概率正比于\n$$\nexp(w_{k1}x_1+…+w_{kn}x_n)。\n$$\n因为一个数据点属于各类的概率之和为1，所以可以得到\n$$\nP(y=k)=\\frac{exp(\\sum_{i=1}^{n}w_{ki}{x_i})}{\\sum_{k'}exp(\\sum_{i=1}^{n}w_{k'i}x_i)}\n$$\n现在回到两类（0,1）的情况，此时分母上只有两项\n$$\nP(y=1)=\\frac{exp(\\sum_{i=1}^{n}w_{1i}{x_i})}{exp(\\sum_{i=1}^{n}w_{1i}x_i)+exp(\\sum_{i=1}^{n}w_{0i}x_i)}\n$$\n公式分子、分母同时除以分子，并设$w_i=w_{1i}-w_{0i}$，则有\n$$\nP(y=1)=\\frac{1}{1+exp(-\\sum_{i=1}^{n}w_ix_i)}\n$$\n上述公式便是Logistic函数，参数$w_i$表示第i个特征对1类的贡献与0类的贡献的差值。\n$$\nSigmoid Function: f(x)=\\frac{1}{1+e^{-x}}\n$$\nSigmoid函数具有如下性质\n\n+ 函数连续且单调递增\n+ 函数关于（0,0.5）对称\n+ $x\\in(-\\infty,\\infty)$时$y\\in(0,1)$\n\n```python\n#plot sigmoid function \nimport numpy as np\nimport matplotlib.pyplot as plt\n\n##sigmoid function\nx=np.arange(-5,5,0.1)\ny=1/(1+np.exp(-x))\n\n#plot\nplt.figure()\nplt.plot(x,y,color='red',linewidth='2')\nax=plt.gca()\nax.spines['right'].set_color('none')\nax.spines['top'].set_color('none')\nax.xaxis.set_ticks_position('bottom')\nax.spines['bottom'].set_position(('data',0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data',0))\nplt.xlabel('independent variable')\nplt.ylabel('dependent variable')\nplt.show()\n```\n\n![机器学习之Logistic回归01](机器学习之Logistic回归/机器学习之Logistic回归01.png)\n\n### 3.Logistic回归推导\n\n+ 特征向量$X=(x_0,x_1,x_2…x_n)$，默认$x_0=1$。\n+ $\\theta=(\\theta_0,\\theta_1,\\theta_2…\\theta_n)$\n+ $n$表示特征数量\n+ $m$表示训练数据数量\n\n线性回归函数为$z=\\theta_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n=\\theta^TX$。对于Logistic回归来说，其思想也基于线性回归（Logistic回归属于广义线性回归模型）。结合线性回归和Sigmoid函数，将线性回归得到的结果映射到Sigmoid函数之中，我们便得到目标函数。\n$$\nh(X)=\\frac{1}{1+e^{-\\theta^TX}}\n$$\n我们可以把$h(X)$看成样本数据的概率密度函数，当$h(X)<0.5$是判断当前数据属于A类，当$h(X)>0.5$判断当前数据属于B类。对于上述函数$h(X)$，接下来我们需要做的便是怎样去估计参数$\\theta$。\n\n条件概率$P(y=1|X)$为某事件发生的概率，Logistic回归模型可以表示为\n$$\nP(y=1|X)=\\pi(X)=\\frac{1}{1+e^{-\\theta^TX}}\n$$\n条件概率$P(y=0|X)$为某事件不发生的概率，Logistic回归模型可以表示为\n$$\nP(y=0|X)=1-\\pi(X)=\\frac{1}{1+e^{\\theta^TX}}\n$$\n因此我们可以得到事件的发生比为\n$$\nodds=\\frac{P(y=1|X)}{P(y=0|X)}\n$$\n事件的发生和不发生为相互独立事件，样本数据结果记录为$(y_1,y_2…y_m)$。设$p_i=P(y_i=1|X_i)$为给定条件下得到$y_i=1$的概率，同样$1-p_i=P(y_i=0|X_i)$的概率，所以得到一个观测值的概率为$P(y_i)=p_i^{y_i}(1-p_i)^{1-y_i}$，最后参数估计时我们可以采用极大似然估计。\n\n各个观测样本之间相互独立，那么它们的联合分布为各边缘分布的乘积，得到如下极大似然函数\n$$\nL(\\theta)=\\prod_{i=1}^{m}[\\pi(X_i)]^{y_i}[1-\\pi(X_i)]^{1-y_i}\n$$\n目标便是求得使这一似然函数值最大的参数估计，于是函数取对数得到\n$$\nlnL(\\theta)=\\sum_{i=1}^{m}\\left \\{ y_iln[\\pi(X_i)] +(1-y_i)ln[1-\\pi(X_i)] \\right \\}\n$$\n\n$$\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_iln\\frac{\\pi(X_i)}{1-\\pi(X_i)}\n$$\n\n$$\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_i\\theta^TX\n$$\n\n$$\n=\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX\n$$\n\n通过上面得到的结论来求解使得似然函数最大化的参数向量，此处我们利用梯度下降算法求$\\theta$。首先在前面乘上负的系数$-\\frac{1}{m}$，所以$J(\\theta)$最小时的$\\theta$为最佳参数。\n$$\nJ(\\theta)=-\\frac{1}{m}lnL(\\theta)\n$$\n\n$$\n=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}\n$$\n\n### 4.梯度下降算法\n\n#### 4.1梯度下降算法简述\n\n实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都到达山脚，可能到达山峰的某个局部最低点。\n\n![器学习之Logistic回归0](机器学习之Logistic回归/机器学习之Logistic回归02.png)\n\n从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解Logistic回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。\n\n#### 4.2 梯度下降算法相关概念\n\n求解梯度下降算法之前，我们先了解相关概念。\n\n- **步长（Learning Rate）**：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。\n- **特征（Feature）**：即上述描述的$X$\n- **假设函数（Hypothesis Function）**：监督学习中，为了拟合输入样本，而使用假设函数。\n- **损失函数（Loss Function）**：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。Logistic损失函数为\n\n$$\nJ(\\theta)=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}\n$$\n\n我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。\n\n#### 4.3梯度下降算法过程\n\n- 随机选取一组$\\theta$。\n- 不断变化$\\theta$，让$J(\\theta)$变小，$\\alpha$为学习步长。\n\n$$\n\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\n$$\n\n+ 直到$J(\\theta)$得到最小值，$\\frac{\\partial}{\\partial\\theta_k}J(\\theta)$为$J(\\theta)$对$\\theta_k$的偏导。\n\n$$\n\\frac{\\partial J(\\theta)}{\\partial\\theta_j}=\\frac{1}{m}\\sum_{i=1}^{m}\\frac{1}{1+e^{\\theta^TX}}e^{\\theta^TX}X_{ij}-\\sum_{i=1}^{m}y_iX_{ij}\n$$\n\n$$\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\frac{e^{\\theta^TX}}{1+e^{\\theta^Tx}}-y_i]\n$$\n\n$$\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]\n$$\n\n因此梯度下降算法的迭代最终表述为\n$$\n\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]\n$$\n梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到Logistic函数。\n\n### 5.Logistic回归实现\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\ndef plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n    # setup marker generator and color map\n    markers = ('s', 'x', 'o', '^', 'v')\n    colors = ('red', 'blue', 'lightgreen', 'cyan', 'gray')\n    cmap = ListedColormap(colors[:len(np.unique(y))])\n    # plot the decision surface\n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot class samples\n    for idx, cl in enumerate(np.unique(y)):\n        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],alpha=0.8, c=cmap(idx),marker=markers[idx], label=cl)\n    # highlight test samples\n    if test_idx:\n        X_test, y_test = X[test_idx, :], y[test_idx]\n        plt.scatter(X_test[:, 0], X_test[:, 1], c='blue', alpha=1.0, linewidth=1, marker='o', s=55, label='test set')\n\niris = datasets.load_iris()\nX = iris.data[:, [2, 3]]\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n#为了追求机器学习的最佳性能，我们将特征缩放\nsc = StandardScaler()\nsc.fit(X_train)#估算每个特征的平均值和标准差\nX_train_std=sc.transform(X_train)#用同样的参数来标准化测试集，使得测试集和训练集之间有可比性\nX_test_std=sc.transform(X_test)\nX_combined_std = np.vstack((X_train_std, X_test_std))\ny_combined = np.hstack((y_train, y_test))\n\n#训练感知机模型\nlr = LogisticRegression(C=1000.0,random_state=0)#迭代次数为1000次,random_state设置随机种子，每次迭代都有相同的训练集顺序\nlr.fit(X_train_std, y_train)\nlr.predict_proba(X_test_std)\n\n#绘图\nplot_decision_regions(X_combined_std, y_combined, classifier=lr, test_idx=range(105,150))\nplt.xlabel('petal length [standardized]')\nplt.ylabel('petal width [standardized]')\nplt.legend(loc='upper left')\nplt.show()\n```\n\n![机器学习之Logistic回归03](机器学习之Logistic回归/机器学习之Logistic回归03.png)\n\n### 6.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![](机器学习之Logistic回归/推广.png)\n\n+ 参考\n\n[^1]: https://www.zhihu.com/people/maigo/activities\n[^2]: https://blog.csdn.net/programmer_wei/article/details/52072939\n[^3]: https://blog.csdn.net/javaisnotgood/article/details/78873819\n\n","slug":"机器学习之Logistic回归","published":1,"updated":"2018-03-28T16:43:35.044Z","layout":"post","photos":[],"link":"","_id":"cjg7s0pqi000e32017bsdmusr","content":"<h3 id=\"1-Logistic回归简介\"><a href=\"#1-Logistic回归简介\" class=\"headerlink\" title=\"1.Logistic回归简介\"></a>1.Logistic回归简介</h3><p>线性回归能够找到一个假设函数来估计原函数，从而根据特征变量来得到假设值，但线性回归模型不能达到分类的效果。在线性回归的基础上，我们将假设值和概率结合得到分类器，达到分类的效果。虽然Logistic回归是回归模型，但在实际项目中我们经常用于分类问题。</p>\n<h3 id=\"2-Sigmoid函数\"><a href=\"#2-Sigmoid函数\" class=\"headerlink\" title=\"2.Sigmoid函数\"></a>2.Sigmoid函数</h3><p>为什么选择Sigmoid函数呢？我们目标是寻找函数进行分类，首先假设任意多类的分类问题（不仅是两类）。Exponential假设第i个体征对第k类问题的贡献是$w_{ki}$，则数据点$(x_1,x_2,…,x_n)$属于第k类的概率正比于</p>\n<script type=\"math/tex; mode=display\">\nexp(w_{k1}x_1+…+w_{kn}x_n)。</script><p>因为一个数据点属于各类的概率之和为1，所以可以得到</p>\n<script type=\"math/tex; mode=display\">\nP(y=k)=\\frac{exp(\\sum_{i=1}^{n}w_{ki}{x_i})}{\\sum_{k'}exp(\\sum_{i=1}^{n}w_{k'i}x_i)}</script><p>现在回到两类（0,1）的情况，此时分母上只有两项</p>\n<script type=\"math/tex; mode=display\">\nP(y=1)=\\frac{exp(\\sum_{i=1}^{n}w_{1i}{x_i})}{exp(\\sum_{i=1}^{n}w_{1i}x_i)+exp(\\sum_{i=1}^{n}w_{0i}x_i)}</script><p>公式分子、分母同时除以分子，并设$w_i=w_{1i}-w_{0i}$，则有</p>\n<script type=\"math/tex; mode=display\">\nP(y=1)=\\frac{1}{1+exp(-\\sum_{i=1}^{n}w_ix_i)}</script><p>上述公式便是Logistic函数，参数$w_i$表示第i个特征对1类的贡献与0类的贡献的差值。</p>\n<script type=\"math/tex; mode=display\">\nSigmoid Function: f(x)=\\frac{1}{1+e^{-x}}</script><p>Sigmoid函数具有如下性质</p>\n<ul>\n<li>函数连续且单调递增</li>\n<li>函数关于（0,0.5）对称</li>\n<li>$x\\in(-\\infty,\\infty)$时$y\\in(0,1)$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#plot sigmoid function </span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##sigmoid function</span></span><br><span class=\"line\">x=np.arange(<span class=\"number\">-5</span>,<span class=\"number\">5</span>,<span class=\"number\">0.1</span>)</span><br><span class=\"line\">y=<span class=\"number\">1</span>/(<span class=\"number\">1</span>+np.exp(-x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#plot</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(x,y,color=<span class=\"string\">'red'</span>,linewidth=<span class=\"string\">'2'</span>)</span><br><span class=\"line\">ax=plt.gca()</span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.xaxis.set_ticks_position(<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>,<span class=\"number\">0</span>))</span><br><span class=\"line\">ax.yaxis.set_ticks_position(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>,<span class=\"number\">0</span>))</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'independent variable'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'dependent variable'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/机器学习之Logistic回归01.png\" alt=\"机器学习之Logistic回归01\"></p>\n<h3 id=\"3-Logistic回归推导\"><a href=\"#3-Logistic回归推导\" class=\"headerlink\" title=\"3.Logistic回归推导\"></a>3.Logistic回归推导</h3><ul>\n<li>特征向量$X=(x_0,x_1,x_2…x_n)$，默认$x_0=1$。</li>\n<li>$\\theta=(\\theta_0,\\theta_1,\\theta_2…\\theta_n)$</li>\n<li>$n$表示特征数量</li>\n<li>$m$表示训练数据数量</li>\n</ul>\n<p>线性回归函数为$z=\\theta_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n=\\theta^TX$。对于Logistic回归来说，其思想也基于线性回归（Logistic回归属于广义线性回归模型）。结合线性回归和Sigmoid函数，将线性回归得到的结果映射到Sigmoid函数之中，我们便得到目标函数。</p>\n<script type=\"math/tex; mode=display\">\nh(X)=\\frac{1}{1+e^{-\\theta^TX}}</script><p>我们可以把$h(X)$看成样本数据的概率密度函数，当$h(X)<0.5$是判断当前数据属于a类，当$h(x)>0.5$判断当前数据属于B类。对于上述函数$h(X)$，接下来我们需要做的便是怎样去估计参数$\\theta$。</0.5$是判断当前数据属于a类，当$h(x)></p>\n<p>条件概率$P(y=1|X)$为某事件发生的概率，Logistic回归模型可以表示为</p>\n<script type=\"math/tex; mode=display\">\nP(y=1|X)=\\pi(X)=\\frac{1}{1+e^{-\\theta^TX}}</script><p>条件概率$P(y=0|X)$为某事件不发生的概率，Logistic回归模型可以表示为</p>\n<script type=\"math/tex; mode=display\">\nP(y=0|X)=1-\\pi(X)=\\frac{1}{1+e^{\\theta^TX}}</script><p>因此我们可以得到事件的发生比为</p>\n<script type=\"math/tex; mode=display\">\nodds=\\frac{P(y=1|X)}{P(y=0|X)}</script><p>事件的发生和不发生为相互独立事件，样本数据结果记录为$(y_1,y_2…y_m)$。设$p_i=P(y_i=1|X_i)$为给定条件下得到$y_i=1$的概率，同样$1-p_i=P(y_i=0|X_i)$的概率，所以得到一个观测值的概率为$P(y_i)=p_i^{y_i}(1-p_i)^{1-y_i}$，最后参数估计时我们可以采用极大似然估计。</p>\n<p>各个观测样本之间相互独立，那么它们的联合分布为各边缘分布的乘积，得到如下极大似然函数</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta)=\\prod_{i=1}^{m}[\\pi(X_i)]^{y_i}[1-\\pi(X_i)]^{1-y_i}</script><p>目标便是求得使这一似然函数值最大的参数估计，于是函数取对数得到</p>\n<script type=\"math/tex; mode=display\">\nlnL(\\theta)=\\sum_{i=1}^{m}\\left \\{ y_iln[\\pi(X_i)] +(1-y_i)ln[1-\\pi(X_i)] \\right \\}</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_iln\\frac{\\pi(X_i)}{1-\\pi(X_i)}</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_i\\theta^TX</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX</script><p>通过上面得到的结论来求解使得似然函数最大化的参数向量，此处我们利用梯度下降算法求$\\theta$。首先在前面乘上负的系数$-\\frac{1}{m}$，所以$J(\\theta)$最小时的$\\theta$为最佳参数。</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=-\\frac{1}{m}lnL(\\theta)</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}</script><h3 id=\"4-梯度下降算法\"><a href=\"#4-梯度下降算法\" class=\"headerlink\" title=\"4.梯度下降算法\"></a>4.梯度下降算法</h3><h4 id=\"4-1梯度下降算法简述\"><a href=\"#4-1梯度下降算法简述\" class=\"headerlink\" title=\"4.1梯度下降算法简述\"></a>4.1梯度下降算法简述</h4><p>实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都到达山脚，可能到达山峰的某个局部最低点。</p>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/机器学习之Logistic回归02.png\" alt=\"器学习之Logistic回归0\"></p>\n<p>从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解Logistic回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。</p>\n<h4 id=\"4-2-梯度下降算法相关概念\"><a href=\"#4-2-梯度下降算法相关概念\" class=\"headerlink\" title=\"4.2 梯度下降算法相关概念\"></a>4.2 梯度下降算法相关概念</h4><p>求解梯度下降算法之前，我们先了解相关概念。</p>\n<ul>\n<li><strong>步长（Learning Rate）</strong>：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。</li>\n<li><strong>特征（Feature）</strong>：即上述描述的$X$</li>\n<li><strong>假设函数（Hypothesis Function）</strong>：监督学习中，为了拟合输入样本，而使用假设函数。</li>\n<li><strong>损失函数（Loss Function）</strong>：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。Logistic损失函数为</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}</script><p>我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。</p>\n<h4 id=\"4-3梯度下降算法过程\"><a href=\"#4-3梯度下降算法过程\" class=\"headerlink\" title=\"4.3梯度下降算法过程\"></a>4.3梯度下降算法过程</h4><ul>\n<li>随机选取一组$\\theta$。</li>\n<li>不断变化$\\theta$，让$J(\\theta)$变小，$\\alpha$为学习步长。</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)</script><ul>\n<li>直到$J(\\theta)$得到最小值，$\\frac{\\partial}{\\partial\\theta_k}J(\\theta)$为$J(\\theta)$对$\\theta_k$的偏导。</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial J(\\theta)}{\\partial\\theta_j}=\\frac{1}{m}\\sum_{i=1}^{m}\\frac{1}{1+e^{\\theta^TX}}e^{\\theta^TX}X_{ij}-\\sum_{i=1}^{m}y_iX_{ij}</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\frac{e^{\\theta^TX}}{1+e^{\\theta^Tx}}-y_i]</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]</script><p>因此梯度下降算法的迭代最终表述为</p>\n<script type=\"math/tex; mode=display\">\n\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]</script><p>梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到Logistic函数。</p>\n<h3 id=\"5-Logistic回归实现\"><a href=\"#5-Logistic回归实现\" class=\"headerlink\" title=\"5.Logistic回归实现\"></a>5.Logistic回归实现</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.colors <span class=\"keyword\">import</span> ListedColormap</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_decision_regions</span><span class=\"params\">(X, y, classifier, test_idx=None, resolution=<span class=\"number\">0.02</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># setup marker generator and color map</span></span><br><span class=\"line\">    markers = (<span class=\"string\">'s'</span>, <span class=\"string\">'x'</span>, <span class=\"string\">'o'</span>, <span class=\"string\">'^'</span>, <span class=\"string\">'v'</span>)</span><br><span class=\"line\">    colors = (<span class=\"string\">'red'</span>, <span class=\"string\">'blue'</span>, <span class=\"string\">'lightgreen'</span>, <span class=\"string\">'cyan'</span>, <span class=\"string\">'gray'</span>)</span><br><span class=\"line\">    cmap = ListedColormap(colors[:len(np.unique(y))])</span><br><span class=\"line\">    <span class=\"comment\"># plot the decision surface</span></span><br><span class=\"line\">    x1_min, x1_max = X[:, <span class=\"number\">0</span>].min() - <span class=\"number\">1</span>, X[:, <span class=\"number\">0</span>].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    x2_min, x2_max = X[:, <span class=\"number\">1</span>].min() - <span class=\"number\">1</span>, X[:, <span class=\"number\">1</span>].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))</span><br><span class=\"line\">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class=\"line\">    Z = Z.reshape(xx1.shape)</span><br><span class=\"line\">    plt.contourf(xx1, xx2, Z, alpha=<span class=\"number\">0.4</span>, cmap=cmap)</span><br><span class=\"line\">    plt.xlim(xx1.min(), xx1.max())</span><br><span class=\"line\">    plt.ylim(xx2.min(), xx2.max())</span><br><span class=\"line\">    <span class=\"comment\"># plot class samples</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, cl <span class=\"keyword\">in</span> enumerate(np.unique(y)):</span><br><span class=\"line\">        plt.scatter(x=X[y == cl, <span class=\"number\">0</span>], y=X[y == cl, <span class=\"number\">1</span>],alpha=<span class=\"number\">0.8</span>, c=cmap(idx),marker=markers[idx], label=cl)</span><br><span class=\"line\">    <span class=\"comment\"># highlight test samples</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> test_idx:</span><br><span class=\"line\">        X_test, y_test = X[test_idx, :], y[test_idx]</span><br><span class=\"line\">        plt.scatter(X_test[:, <span class=\"number\">0</span>], X_test[:, <span class=\"number\">1</span>], c=<span class=\"string\">'blue'</span>, alpha=<span class=\"number\">1.0</span>, linewidth=<span class=\"number\">1</span>, marker=<span class=\"string\">'o'</span>, s=<span class=\"number\">55</span>, label=<span class=\"string\">'test set'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">X = iris.data[:, [<span class=\"number\">2</span>, <span class=\"number\">3</span>]]</span><br><span class=\"line\">y = iris.target</span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"number\">0.3</span>, random_state=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"comment\">#为了追求机器学习的最佳性能，我们将特征缩放</span></span><br><span class=\"line\">sc = StandardScaler()</span><br><span class=\"line\">sc.fit(X_train)<span class=\"comment\">#估算每个特征的平均值和标准差</span></span><br><span class=\"line\">X_train_std=sc.transform(X_train)<span class=\"comment\">#用同样的参数来标准化测试集，使得测试集和训练集之间有可比性</span></span><br><span class=\"line\">X_test_std=sc.transform(X_test)</span><br><span class=\"line\">X_combined_std = np.vstack((X_train_std, X_test_std))</span><br><span class=\"line\">y_combined = np.hstack((y_train, y_test))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练感知机模型</span></span><br><span class=\"line\">lr = LogisticRegression(C=<span class=\"number\">1000.0</span>,random_state=<span class=\"number\">0</span>)<span class=\"comment\">#迭代次数为1000次,random_state设置随机种子，每次迭代都有相同的训练集顺序</span></span><br><span class=\"line\">lr.fit(X_train_std, y_train)</span><br><span class=\"line\">lr.predict_proba(X_test_std)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘图</span></span><br><span class=\"line\">plot_decision_regions(X_combined_std, y_combined, classifier=lr, test_idx=range(<span class=\"number\">105</span>,<span class=\"number\">150</span>))</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'petal length [standardized]'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'petal width [standardized]'</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">'upper left'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/机器学习之Logistic回归03.png\" alt=\"机器学习之Logistic回归03\"></p>\n<h3 id=\"6-推广\"><a href=\"#6-推广\" class=\"headerlink\" title=\"6.推广\"></a>6.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/推广.png\" alt=\"\"></p>\n<ul>\n<li>参考</li>\n</ul>\n<blockquote id=\"fn_1\">\n<sup>1</sup>. <a href=\"https://www.zhihu.com/people/maigo/activities\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/people/maigo/activities</a><a href=\"#reffn_1\" title=\"Jump back to footnote [1] in the text.\"> &#8617;</a>\n</blockquote>\n<blockquote id=\"fn_2\">\n<sup>2</sup>. <a href=\"https://blog.csdn.net/programmer_wei/article/details/52072939\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/programmer_wei/article/details/52072939</a><a href=\"#reffn_2\" title=\"Jump back to footnote [2] in the text.\"> &#8617;</a>\n</blockquote>\n<blockquote id=\"fn_3\">\n<sup>3</sup>. <a href=\"https://blog.csdn.net/javaisnotgood/article/details/78873819\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/javaisnotgood/article/details/78873819</a><a href=\"#reffn_3\" title=\"Jump back to footnote [3] in the text.\"> &#8617;</a>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-Logistic回归简介\"><a href=\"#1-Logistic回归简介\" class=\"headerlink\" title=\"1.Logistic回归简介\"></a>1.Logistic回归简介</h3><p>线性回归能够找到一个假设函数来估计原函数，从而根据特征变量来得到假设值，但线性回归模型不能达到分类的效果。在线性回归的基础上，我们将假设值和概率结合得到分类器，达到分类的效果。虽然Logistic回归是回归模型，但在实际项目中我们经常用于分类问题。</p>\n<h3 id=\"2-Sigmoid函数\"><a href=\"#2-Sigmoid函数\" class=\"headerlink\" title=\"2.Sigmoid函数\"></a>2.Sigmoid函数</h3><p>为什么选择Sigmoid函数呢？我们目标是寻找函数进行分类，首先假设任意多类的分类问题（不仅是两类）。Exponential假设第i个体征对第k类问题的贡献是$w_{ki}$，则数据点$(x_1,x_2,…,x_n)$属于第k类的概率正比于</p>\n<script type=\"math/tex; mode=display\">\nexp(w_{k1}x_1+…+w_{kn}x_n)。</script><p>因为一个数据点属于各类的概率之和为1，所以可以得到</p>\n<script type=\"math/tex; mode=display\">\nP(y=k)=\\frac{exp(\\sum_{i=1}^{n}w_{ki}{x_i})}{\\sum_{k'}exp(\\sum_{i=1}^{n}w_{k'i}x_i)}</script><p>现在回到两类（0,1）的情况，此时分母上只有两项</p>\n<script type=\"math/tex; mode=display\">\nP(y=1)=\\frac{exp(\\sum_{i=1}^{n}w_{1i}{x_i})}{exp(\\sum_{i=1}^{n}w_{1i}x_i)+exp(\\sum_{i=1}^{n}w_{0i}x_i)}</script><p>公式分子、分母同时除以分子，并设$w_i=w_{1i}-w_{0i}$，则有</p>\n<script type=\"math/tex; mode=display\">\nP(y=1)=\\frac{1}{1+exp(-\\sum_{i=1}^{n}w_ix_i)}</script><p>上述公式便是Logistic函数，参数$w_i$表示第i个特征对1类的贡献与0类的贡献的差值。</p>\n<script type=\"math/tex; mode=display\">\nSigmoid Function: f(x)=\\frac{1}{1+e^{-x}}</script><p>Sigmoid函数具有如下性质</p>\n<ul>\n<li>函数连续且单调递增</li>\n<li>函数关于（0,0.5）对称</li>\n<li>$x\\in(-\\infty,\\infty)$时$y\\in(0,1)$</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#plot sigmoid function </span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##sigmoid function</span></span><br><span class=\"line\">x=np.arange(<span class=\"number\">-5</span>,<span class=\"number\">5</span>,<span class=\"number\">0.1</span>)</span><br><span class=\"line\">y=<span class=\"number\">1</span>/(<span class=\"number\">1</span>+np.exp(-x))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#plot</span></span><br><span class=\"line\">plt.figure()</span><br><span class=\"line\">plt.plot(x,y,color=<span class=\"string\">'red'</span>,linewidth=<span class=\"string\">'2'</span>)</span><br><span class=\"line\">ax=plt.gca()</span><br><span class=\"line\">ax.spines[<span class=\"string\">'right'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'top'</span>].set_color(<span class=\"string\">'none'</span>)</span><br><span class=\"line\">ax.xaxis.set_ticks_position(<span class=\"string\">'bottom'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'bottom'</span>].set_position((<span class=\"string\">'data'</span>,<span class=\"number\">0</span>))</span><br><span class=\"line\">ax.yaxis.set_ticks_position(<span class=\"string\">'left'</span>)</span><br><span class=\"line\">ax.spines[<span class=\"string\">'left'</span>].set_position((<span class=\"string\">'data'</span>,<span class=\"number\">0</span>))</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'independent variable'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'dependent variable'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/机器学习之Logistic回归01.png\" alt=\"机器学习之Logistic回归01\"></p>\n<h3 id=\"3-Logistic回归推导\"><a href=\"#3-Logistic回归推导\" class=\"headerlink\" title=\"3.Logistic回归推导\"></a>3.Logistic回归推导</h3><ul>\n<li>特征向量$X=(x_0,x_1,x_2…x_n)$，默认$x_0=1$。</li>\n<li>$\\theta=(\\theta_0,\\theta_1,\\theta_2…\\theta_n)$</li>\n<li>$n$表示特征数量</li>\n<li>$m$表示训练数据数量</li>\n</ul>\n<p>线性回归函数为$z=\\theta_0+\\theta_1x_1+\\theta_2x_2+…+\\theta_nx_n=\\theta^TX$。对于Logistic回归来说，其思想也基于线性回归（Logistic回归属于广义线性回归模型）。结合线性回归和Sigmoid函数，将线性回归得到的结果映射到Sigmoid函数之中，我们便得到目标函数。</p>\n<script type=\"math/tex; mode=display\">\nh(X)=\\frac{1}{1+e^{-\\theta^TX}}</script><p>我们可以把$h(X)$看成样本数据的概率密度函数，当$h(X)<0.5$是判断当前数据属于a类，当$h(x)>0.5$判断当前数据属于B类。对于上述函数$h(X)$，接下来我们需要做的便是怎样去估计参数$\\theta$。</0.5$是判断当前数据属于a类，当$h(x)></p>\n<p>条件概率$P(y=1|X)$为某事件发生的概率，Logistic回归模型可以表示为</p>\n<script type=\"math/tex; mode=display\">\nP(y=1|X)=\\pi(X)=\\frac{1}{1+e^{-\\theta^TX}}</script><p>条件概率$P(y=0|X)$为某事件不发生的概率，Logistic回归模型可以表示为</p>\n<script type=\"math/tex; mode=display\">\nP(y=0|X)=1-\\pi(X)=\\frac{1}{1+e^{\\theta^TX}}</script><p>因此我们可以得到事件的发生比为</p>\n<script type=\"math/tex; mode=display\">\nodds=\\frac{P(y=1|X)}{P(y=0|X)}</script><p>事件的发生和不发生为相互独立事件，样本数据结果记录为$(y_1,y_2…y_m)$。设$p_i=P(y_i=1|X_i)$为给定条件下得到$y_i=1$的概率，同样$1-p_i=P(y_i=0|X_i)$的概率，所以得到一个观测值的概率为$P(y_i)=p_i^{y_i}(1-p_i)^{1-y_i}$，最后参数估计时我们可以采用极大似然估计。</p>\n<p>各个观测样本之间相互独立，那么它们的联合分布为各边缘分布的乘积，得到如下极大似然函数</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta)=\\prod_{i=1}^{m}[\\pi(X_i)]^{y_i}[1-\\pi(X_i)]^{1-y_i}</script><p>目标便是求得使这一似然函数值最大的参数估计，于是函数取对数得到</p>\n<script type=\"math/tex; mode=display\">\nlnL(\\theta)=\\sum_{i=1}^{m}\\left \\{ y_iln[\\pi(X_i)] +(1-y_i)ln[1-\\pi(X_i)] \\right \\}</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_iln\\frac{\\pi(X_i)}{1-\\pi(X_i)}</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{m}ln[1-\\pi(X_i)]+\\sum_{i=1}^{m}y_i\\theta^TX</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX</script><p>通过上面得到的结论来求解使得似然函数最大化的参数向量，此处我们利用梯度下降算法求$\\theta$。首先在前面乘上负的系数$-\\frac{1}{m}$，所以$J(\\theta)$最小时的$\\theta$为最佳参数。</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=-\\frac{1}{m}lnL(\\theta)</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}</script><h3 id=\"4-梯度下降算法\"><a href=\"#4-梯度下降算法\" class=\"headerlink\" title=\"4.梯度下降算法\"></a>4.梯度下降算法</h3><h4 id=\"4-1梯度下降算法简述\"><a href=\"#4-1梯度下降算法简述\" class=\"headerlink\" title=\"4.1梯度下降算法简述\"></a>4.1梯度下降算法简述</h4><p>实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都到达山脚，可能到达山峰的某个局部最低点。</p>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/机器学习之Logistic回归02.png\" alt=\"器学习之Logistic回归0\"></p>\n<p>从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解Logistic回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。</p>\n<h4 id=\"4-2-梯度下降算法相关概念\"><a href=\"#4-2-梯度下降算法相关概念\" class=\"headerlink\" title=\"4.2 梯度下降算法相关概念\"></a>4.2 梯度下降算法相关概念</h4><p>求解梯度下降算法之前，我们先了解相关概念。</p>\n<ul>\n<li><strong>步长（Learning Rate）</strong>：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。</li>\n<li><strong>特征（Feature）</strong>：即上述描述的$X$</li>\n<li><strong>假设函数（Hypothesis Function）</strong>：监督学习中，为了拟合输入样本，而使用假设函数。</li>\n<li><strong>损失函数（Loss Function）</strong>：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。Logistic损失函数为</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=-\\frac{1}{m}\\left \\{\\sum_{i=1}^{m}-ln[1+e^{\\theta^Tx}]+\\sum_{i=1}^{m}y_i\\theta^TX \\right\\}</script><p>我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。</p>\n<h4 id=\"4-3梯度下降算法过程\"><a href=\"#4-3梯度下降算法过程\" class=\"headerlink\" title=\"4.3梯度下降算法过程\"></a>4.3梯度下降算法过程</h4><ul>\n<li>随机选取一组$\\theta$。</li>\n<li>不断变化$\\theta$，让$J(\\theta)$变小，$\\alpha$为学习步长。</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)</script><ul>\n<li>直到$J(\\theta)$得到最小值，$\\frac{\\partial}{\\partial\\theta_k}J(\\theta)$为$J(\\theta)$对$\\theta_k$的偏导。</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial J(\\theta)}{\\partial\\theta_j}=\\frac{1}{m}\\sum_{i=1}^{m}\\frac{1}{1+e^{\\theta^TX}}e^{\\theta^TX}X_{ij}-\\sum_{i=1}^{m}y_iX_{ij}</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\frac{e^{\\theta^TX}}{1+e^{\\theta^Tx}}-y_i]</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]</script><p>因此梯度下降算法的迭代最终表述为</p>\n<script type=\"math/tex; mode=display\">\n\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}X_{ij}[\\pi(X_i)-y_i]</script><p>梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到Logistic函数。</p>\n<h3 id=\"5-Logistic回归实现\"><a href=\"#5-Logistic回归实现\" class=\"headerlink\" title=\"5.Logistic回归实现\"></a>5.Logistic回归实现</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib.colors <span class=\"keyword\">import</span> ListedColormap</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_decision_regions</span><span class=\"params\">(X, y, classifier, test_idx=None, resolution=<span class=\"number\">0.02</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># setup marker generator and color map</span></span><br><span class=\"line\">    markers = (<span class=\"string\">'s'</span>, <span class=\"string\">'x'</span>, <span class=\"string\">'o'</span>, <span class=\"string\">'^'</span>, <span class=\"string\">'v'</span>)</span><br><span class=\"line\">    colors = (<span class=\"string\">'red'</span>, <span class=\"string\">'blue'</span>, <span class=\"string\">'lightgreen'</span>, <span class=\"string\">'cyan'</span>, <span class=\"string\">'gray'</span>)</span><br><span class=\"line\">    cmap = ListedColormap(colors[:len(np.unique(y))])</span><br><span class=\"line\">    <span class=\"comment\"># plot the decision surface</span></span><br><span class=\"line\">    x1_min, x1_max = X[:, <span class=\"number\">0</span>].min() - <span class=\"number\">1</span>, X[:, <span class=\"number\">0</span>].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    x2_min, x2_max = X[:, <span class=\"number\">1</span>].min() - <span class=\"number\">1</span>, X[:, <span class=\"number\">1</span>].max() + <span class=\"number\">1</span></span><br><span class=\"line\">    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))</span><br><span class=\"line\">    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)</span><br><span class=\"line\">    Z = Z.reshape(xx1.shape)</span><br><span class=\"line\">    plt.contourf(xx1, xx2, Z, alpha=<span class=\"number\">0.4</span>, cmap=cmap)</span><br><span class=\"line\">    plt.xlim(xx1.min(), xx1.max())</span><br><span class=\"line\">    plt.ylim(xx2.min(), xx2.max())</span><br><span class=\"line\">    <span class=\"comment\"># plot class samples</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> idx, cl <span class=\"keyword\">in</span> enumerate(np.unique(y)):</span><br><span class=\"line\">        plt.scatter(x=X[y == cl, <span class=\"number\">0</span>], y=X[y == cl, <span class=\"number\">1</span>],alpha=<span class=\"number\">0.8</span>, c=cmap(idx),marker=markers[idx], label=cl)</span><br><span class=\"line\">    <span class=\"comment\"># highlight test samples</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> test_idx:</span><br><span class=\"line\">        X_test, y_test = X[test_idx, :], y[test_idx]</span><br><span class=\"line\">        plt.scatter(X_test[:, <span class=\"number\">0</span>], X_test[:, <span class=\"number\">1</span>], c=<span class=\"string\">'blue'</span>, alpha=<span class=\"number\">1.0</span>, linewidth=<span class=\"number\">1</span>, marker=<span class=\"string\">'o'</span>, s=<span class=\"number\">55</span>, label=<span class=\"string\">'test set'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">X = iris.data[:, [<span class=\"number\">2</span>, <span class=\"number\">3</span>]]</span><br><span class=\"line\">y = iris.target</span><br><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class=\"number\">0.3</span>, random_state=<span class=\"number\">0</span>)</span><br><span class=\"line\"><span class=\"comment\">#为了追求机器学习的最佳性能，我们将特征缩放</span></span><br><span class=\"line\">sc = StandardScaler()</span><br><span class=\"line\">sc.fit(X_train)<span class=\"comment\">#估算每个特征的平均值和标准差</span></span><br><span class=\"line\">X_train_std=sc.transform(X_train)<span class=\"comment\">#用同样的参数来标准化测试集，使得测试集和训练集之间有可比性</span></span><br><span class=\"line\">X_test_std=sc.transform(X_test)</span><br><span class=\"line\">X_combined_std = np.vstack((X_train_std, X_test_std))</span><br><span class=\"line\">y_combined = np.hstack((y_train, y_test))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练感知机模型</span></span><br><span class=\"line\">lr = LogisticRegression(C=<span class=\"number\">1000.0</span>,random_state=<span class=\"number\">0</span>)<span class=\"comment\">#迭代次数为1000次,random_state设置随机种子，每次迭代都有相同的训练集顺序</span></span><br><span class=\"line\">lr.fit(X_train_std, y_train)</span><br><span class=\"line\">lr.predict_proba(X_test_std)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#绘图</span></span><br><span class=\"line\">plot_decision_regions(X_combined_std, y_combined, classifier=lr, test_idx=range(<span class=\"number\">105</span>,<span class=\"number\">150</span>))</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">'petal length [standardized]'</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">'petal width [standardized]'</span>)</span><br><span class=\"line\">plt.legend(loc=<span class=\"string\">'upper left'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/机器学习之Logistic回归03.png\" alt=\"机器学习之Logistic回归03\"></p>\n<h3 id=\"6-推广\"><a href=\"#6-推广\" class=\"headerlink\" title=\"6.推广\"></a>6.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/27/机器学习之Logistic回归/推广.png\" alt=\"\"></p>\n<ul>\n<li>参考</li>\n</ul>\n<blockquote id=\"fn_1\">\n<sup>1</sup>. <a href=\"https://www.zhihu.com/people/maigo/activities\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/people/maigo/activities</a><a href=\"#reffn_1\" title=\"Jump back to footnote [1] in the text.\"> &#8617;</a>\n</blockquote>\n<blockquote id=\"fn_2\">\n<sup>2</sup>. <a href=\"https://blog.csdn.net/programmer_wei/article/details/52072939\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/programmer_wei/article/details/52072939</a><a href=\"#reffn_2\" title=\"Jump back to footnote [2] in the text.\"> &#8617;</a>\n</blockquote>\n<blockquote id=\"fn_3\">\n<sup>3</sup>. <a href=\"https://blog.csdn.net/javaisnotgood/article/details/78873819\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/javaisnotgood/article/details/78873819</a><a href=\"#reffn_3\" title=\"Jump back to footnote [3] in the text.\"> &#8617;</a>\n</blockquote>\n"},{"title":"机器学习之SVM支持向量机（二）","date":"2018-04-04T13:06:26.000Z","mathjax":true,"comments":1,"_content":"\n### 1.知识回顾\n\n[机器学习之SVM支持向量机（一）](https://mp.weixin.qq.com/s?__biz=MzU3MjA2NTQzMw==&mid=2247483818&idx=1&sn=50c634d8b00877134558125c4a718fd7&chksm=fcd7d25ccba05b4a62adfb2717650441f30d636056fcb37529ef34a51b94e453a534b7ca0a48#rd)中我们介绍了**SVM损失函数**、**最大间隔分类**、**为什么SVM能形成最大间隔分类器**、**核函数**、**SVM中Gaussian Kernel的使用**知识点。上文我们从Logistic Regression损失函数中推出SVM损失函数，本篇文章我们将更加直观的分析得到SVM损失函数、如何求解SVM对偶问题、如何解决outliers点，并且最终利用sklearn实现SVM。\n\n### 2.函数间隔和几何间隔\n\n上文我们从logistic Regression损失函数推导出SVM损失函数，本文我们采用另一种方法得到SVM损失函数。首先定义超平面可以用分类函数$f(x)=w^Tx+b$表示，当$f(x)$等于0的时候，$x$便是位于超平面上的点，而$f(x)$大于0对应$y=1$的数据点，$f(x)$小于0对应于$y=-1$的点，如下图所示：\n\n![机器学习之SVM支持向量机（二）图像01](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F01.png)\n\n在超平面$w^Tx+b=0$确定的情况下，$|w^Tx+b|$能够表示点$x$到超平面的远近，而通过观察$w^Tx+b$的符号与类标记$y$的符号是否一致可判断分类是否正确。因此我们用$y*(w^Tx+b)$的正负性来判定分类的正确性，于是引出函数间隔的概念。\n\n定义函数间隔$\\hat{\\gamma}$：\n$$\n\\hat{\\gamma}=y(w^Tx+b)=yf(x)\n$$\n而超平面$(w,b)$关于训练数据集T中所有样本点$(x_i,y_i)$的函数间隔最小值，便为超平面$(w,b)$关于训练数据集T的函数间隔：\n$$\n\\hat{\\gamma}=min\\hat{\\gamma} \n$$\n但这样定义的函数间隔有问题，即如果成比例的改变$w$和$b$，则函数间隔的值$f(x)$却变成了原来的2倍(虽然此时超平面没有改变)，所以只有函数间隔还是不够的。\n\n但我们可以对法向量$w$增加些约束条件，从而引出真正定义点到超平面的距离。假设对于一点$x$，令其垂直投影到超平面上的点对应为$x_0$，$w$是垂直于超平面的一个向量，$r$为样本$x$到分类间隔的距离，如下图所示。\n\n![机器学习之SVM支持向量机（二）图像02](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F02.png)\n$$\nx=x_0+\\gamma\\frac{w}{||w||}\n$$\n其中$||w||$表示范数，又由于$x_0$是超平面上的点，满足$f(x_0)=0$，代入超平面的方程$w^Tx+b=0$，我们得到：\n$$\n\\gamma=\\frac{w^T+b}{||w||}=\\frac{f(x)}{||w||}\n$$\n为了得到$\\gamma$绝对值，将$\\gamma$乘上相应类别$y$，即可得到几何间隔：\n$$\n\\tilde{r}=yr=\\frac{\\hat{\\gamma}}{||w||}\n$$\n从上述定义我们能够看到，几何间隔就是函数间隔除以$||w||$，而且函数间隔$y*(w^Tx+b)=y*f(x)$，实际上就是$|f(x)|$，几何间隔$\\frac{f(x)}{||w||}$才是直观上的点到超平面的距离。\n\n对一个数据点进行分类，当超平面离数据点的间隔越大，分类的确信度也越大。所以，为了使得分类的确信度尽量高，需要让所选择的超平面能够最大化间隔值。于是最大间隔分类器的目标函数定义为$max\\tilde{\\gamma}$。同时需满足如下条件\n$$\ny_i(w^Tx_i+b)=\\hat{\\gamma_i}\\ge\\hat{\\gamma},i=1,2,3,...,n\n$$\n此处令函数间隔$\\hat{\\gamma}$等于1（之所以令$\\hat{\\gamma}=1$是为了方便推导，且这样做对目标函数的优化没有影响）。则上述目标函数转换成：\n$$\nmax\\frac{1}{||w||},s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n\n$$\n\n### 3.原始问题到对偶问题的求解\n\n接着考虑我们之前的目标函数，由于求$\\frac{1}{||w||}$的最大值相当于求$\\frac{1}{2}||w||^2$的最小值，所以目标函数转换为\n$$\nmin\\frac{1}{2}||w||^2 ,s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n\n$$\n现在目标函数是二次的，约束条件是线性的，所以它是一个凸二次规划问题。由于此问题的特殊结构，我们可以通过拉格朗日对偶性变换到对偶变量的优化问题，即通过求解与原问题等价的对偶问题得到原始问题的最优解。\n\n那什么是拉格朗日对偶性呢？简单来说就是通过给每一个约束条件加上一个拉格朗日乘子$\\alpha$，定义拉格朗日函数为：\n$$\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)\n$$\n然后令：\n$$\n\\theta(w)=\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)\n$$\n当某个条件不满足时，例如$y_i(w^Tx+b)<1$，那么有$\\theta(w)=\\infty$。而当所有约束条件都满足时，则有$\\theta(w)=\\frac{1}{2}||w||^2$，亦即最初要最小化的量。目标函数则转换为：\n$$\n\\min_{w,b}\\theta(w)=\\min_{w,b}\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)=p^*\n$$\n这里用$p^*$表示这个问题的最优值，和最初的问题是等价的。如果直接求解那么我们将面对$w,b$两个参数，而$\\alpha_i$又是不等式约束，这个求解过程不好做，我们把最小和最大的位置交换一下：\n$$\n\\max_{\\alpha_i\\ge0}\\min_{w,b}L(w,b,\\alpha)=d^*\n$$\n交换以后的新问题就是原始问题的对偶问题，新问题的最优值用$d^*$表示，而且有$d^*\\le p^*$，在**满足某些条件**的情况下，这两者相等，此时便可以通过求解对偶问题来间接的求解原始问题。\n\n此处**满足某些条件**的情况下，两者等价，此处的**满足某些条件**便是满足KKT条件。KKT最优化数学模型表示成下列标准形式:\n$$\n\\min f(x)\n$$\n\n$$\ns.t. h_j(x)=0,j=1,2,3,...,p\n$$\n\n$$\ng_k(x)\\le0,k=1,2,3,...,q\n$$\n\n$$\nx\\in X\\subset R^n\n$$\n\n其中$f(x)$是需要最小化的函数，$h(x)$是等式约束，$g(x)$是不等式约束，$p,q$分别为等式约束和不等式约束的数量。\n\n> 凸优化概念:$X\\subset R^n$为一凸集，$f:X->R$为一凸函数。凸优化便是寻找一点$x^*\\in X$，是的每一$x\\in X$满足$f(x^*)\\le f(x)$。\n>\n> KKT条件意义是非线性规划问题能有最优化解法的必要和充分条件。\n\nKKT条件就是上面最优化数学模型的标准形式中的最小点$x^*$必须满足下面的条件:\n$$\nh_j(x^*)=0,j=1,2,3,...,p\n$$\n\n$$\ng_k(x^*)\\le 0,k=1,2,3,...,q\n$$\n\n$$\n\\nabla f(x^*)+\\sum_{j=1}^{p}\\lambda_j\\nabla h_j(x^*)+\\sum_{k=1}^{q}\\mu_k \\nabla g_k(x^*)=0\n$$\n\n$$\n\\lambda_j \\neq0,\\mu \\ge0,\\mu_k g_k(x^*)=0\n$$\n\n此处我们不做详细证明为什么满足KKT条件。原始问题通过满足KKT条件，已经转换成对偶问题。求解对偶问题首先要让$L(w,b,\\alpha)$关于$w,b$的最小化，然后求对$\\alpha$的极大，最后利用SMO算法求解对偶问题中的拉格朗日乘子。下面为具体求解过程。\n\n首先固定$\\alpha$，要让L关于$w,b$最小化，我们分别对$w,b$求偏导数。\n$$\n\\frac{\\partial L}{\\partial w}=0 \\Rightarrow w= \\sum_{i=1}^{n}\\alpha_iy_ix_i\n$$\n\n$$\n\\frac{\\partial L}{\\partial b}=0 \\Rightarrow \\sum_{i=1}^{n}\\alpha_iy_i=0\n$$\n\n将上述结果代入到之前的L得到：\n$$\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)\n$$\n\n$$\n=\\frac{1}{2}w^Tw-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}(\\sum_{i=1}^{n}\\alpha_iy_ix_i)^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}\\sum_{i=1}^{n}\\alpha_iy_ix_i^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j\n$$\n\n然后求对$\\alpha$的极大，即是关于对偶问题的最优化问题。\n$$\n\\max_{\\alpha}\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j\n$$\n\n$$\ns.t.,\\alpha_i\\ge0,i=1,2,3,...,n\n$$\n\n$$\n\\sum_{i=1}^{n}\\alpha_iy_i=0\n$$\n\n我们已经知道$x_i,x_j$的值，便可利用**SMO算法**求解$\\alpha_i$，此处不详细介绍SMO算法。同时根据$w=\\sum_{i=1}^{n}\\alpha_iy_ix_i$我们便可求出$w$，然后通过下式得到$b$。\n$$\nb^*=-\\frac{\\max_{i:y(i)=-1}w^Tx_i+\\min_{i:y(i)=1}w^Tx_i}{2}\n$$\n至此我们便可得出分类超平面和分类决策函数。\n\n### 4.松弛变量处理outliers方法\n\n实际项目中会有数据点含有噪音，即偏离正常位置很远的数据点，我们称之为outlier。\n\n![机器学习之SVM支持向量机（二）图像03](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F03.png)\n\n为了处理这种情况，SVM允许在一定程度上偏离一下超平面。为此我们稍加改变以前的约束条件，即\n$$\ny_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n\n$$\n其中$\\varepsilon$称为松弛变量，对应数据点$x_i$允许偏离分类决策函数的量。当然如果我们允许$\\varepsilon_i$任意大的话，那任意的超平面都是符合条件的。所以我们在原来的目标函数后面再加上一项，使得这些$\\varepsilon_i$的总和也要尽量小。\n$$\n\\min\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i\n$$\n\n$$\ns.t.,y_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n\n$$\n\n$$\n\\varepsilon_i\\ge0,i=1,2,3,...,n\n$$\n\n此处和[机器学习之SVM支持向量机（一）](https://weizhixiaoyi.com/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89/)中的损失函数不同的是加入$\\varepsilon_i$后损失函数第一项便不为0。下述目标函数中第一项相当于现在的$\\varepsilon_i$。\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n那么现在用之前的方法将限制或约束条件加入到目标函数中，得到新的拉格朗日函数，如下所示:\n$$\nL(w,b,\\varepsilon,\\alpha,r)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1+\\varepsilon_i)-\\sum_{i=1}^{n}r_i\\varepsilon_i\n$$\n分析方法和前面相同，此处不再赘述。结合机器学习之SVM支持向量机（一）中的描述我们便能更好的理解C的作用和为什么C通常设置的都较大。\n\n### 5.Sklearn实现SVM支持向量机\n\n我们常用到的核函数包括线性核、多项式核、高斯核、sigmoid核。在**机器学习之SVM支持向量机（一）**中我们已经利用高斯核详细介绍了核函数的意义，所以不再利用其他核函数举例，有兴趣的同学可以去（一）中看详细内容。此处我们给出线性核和多项式核函数的代码，并使用了少量数据绘制出图形。因SVM选取核函数会涉及到较多内容，介于篇幅有限，不再这篇文章中解释，后续会详细写篇**SVM核函数的应用**。\n\n#### 5.1线性\n\n```Python\nfrom sklearn import svm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)\nx=np.r_[np.random.randn(20,2)-[2,2],np.random.randn(20,2)+[2,2]]#正态分布产生数字20行2列\ny=[0]*20+[1]*20#20个class0,20个class1\nclf=svm.SVC(kernel='linear')#使用线性核\nclf.fit(x,y)\nw=clf.coef_[0]#获取w\na=-w[0]/w[1]#斜率\n\n#画图\nxx=np.linspace(-5,5)\nyy=a*xx-(clf.intercept_[0])/w[1]\nb=clf.support_vectors_[0]\nyy_down=a*xx+(b[1]-a*b[0])\nb=clf.support_vectors_[-1]\nyy_up=a*xx+(b[1]-a*b[0])\nplt.figure(figsize=(8,4))\nplt.plot(xx,yy)\nplt.plot(xx,yy_down)\nplt.plot(xx,yy_up)\nplt.scatter(clf.support_vectors_[:,0],clf.support_vectors_[:,1],s=80)\nplt.scatter(x[:,0],x[:,1],c=y,cmap=plt.cm.Paired)\nplt.axis('tight')\nplt.show()\n```\n\n![机器学习之SVM支持向量机（二）图像05](机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像05.png)\n\n#### 5.2非线性\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import  Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nX, y = make_moons( n_samples=100, noise=0.15, random_state=42 )\n\ndef plot_dataset(X, y, axes):\n    plt.plot( X[:,0][y==0], X[:,1][y==0], \"bs\" )\n    plt.plot( X[:,0][y==1], X[:,1][y==1], \"g^\" )\n    plt.axis( axes )\n    plt.grid( True, which=\"both\" )\n    plt.xlabel(r\"$x_l$\")\n    plt.ylabel(r\"$x_2$\")\n\n# contour函数是画出轮廓，需要给出X和Y的网格，以及对应的Z，它会画出Z的边界（相当于边缘检测及可视化）\ndef plot_predict(clf, axes):\n    x0s = np.linspace(axes[0], axes[1], 100)\n    x1s = np.linspace(axes[2], axes[3], 100)\n    x0, x1 = np.meshgrid( x0s, x1s )\n    X = np.c_[x0.ravel(), x1.ravel()]\n    y_pred = clf.predict( X ).reshape( x0.shape )\n    y_decision = clf.decision_function( X ).reshape( x0.shape )\n    plt.contour( x0, x1, y_pred, cmap=plt.cm.winter, alpha=0.5 )\n    plt.contour( x0, x1, y_decision, cmap=plt.cm.winter, alpha=0.2 )\n\npolynomial_svm_clf = Pipeline([ (\"poly_featutres\", PolynomialFeatures(degree=3)),\n                                (\"scaler\", StandardScaler()),\n                                (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42)  )\n                            ])#多项式核函数\npolynomial_svm_clf.fit( X, y )\nplot_dataset( X, y, [-1.5, 2.5, -1, 1.5] )\nplot_predict( polynomial_svm_clf, [-1.5, 2.5, -1, 1.5] )\nplt.show()\n```\n\n![机器学习之SVM支持向量机（二）图像06](机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像06.png)\n\n### 6.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![机器学习之SVM支持向量机（二）图片推广](机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图片推广.png)\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/机器学习之SVM支持向量机（二）.md","raw":"---\ntitle: 机器学习之SVM支持向量机（二）\ndate: 2018-04-04 21:06:26\ntags: [机器学习,算法]\ncategories: 机器学习\nmathjax: true\ncomments: true\n---\n\n### 1.知识回顾\n\n[机器学习之SVM支持向量机（一）](https://mp.weixin.qq.com/s?__biz=MzU3MjA2NTQzMw==&mid=2247483818&idx=1&sn=50c634d8b00877134558125c4a718fd7&chksm=fcd7d25ccba05b4a62adfb2717650441f30d636056fcb37529ef34a51b94e453a534b7ca0a48#rd)中我们介绍了**SVM损失函数**、**最大间隔分类**、**为什么SVM能形成最大间隔分类器**、**核函数**、**SVM中Gaussian Kernel的使用**知识点。上文我们从Logistic Regression损失函数中推出SVM损失函数，本篇文章我们将更加直观的分析得到SVM损失函数、如何求解SVM对偶问题、如何解决outliers点，并且最终利用sklearn实现SVM。\n\n### 2.函数间隔和几何间隔\n\n上文我们从logistic Regression损失函数推导出SVM损失函数，本文我们采用另一种方法得到SVM损失函数。首先定义超平面可以用分类函数$f(x)=w^Tx+b$表示，当$f(x)$等于0的时候，$x$便是位于超平面上的点，而$f(x)$大于0对应$y=1$的数据点，$f(x)$小于0对应于$y=-1$的点，如下图所示：\n\n![机器学习之SVM支持向量机（二）图像01](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F01.png)\n\n在超平面$w^Tx+b=0$确定的情况下，$|w^Tx+b|$能够表示点$x$到超平面的远近，而通过观察$w^Tx+b$的符号与类标记$y$的符号是否一致可判断分类是否正确。因此我们用$y*(w^Tx+b)$的正负性来判定分类的正确性，于是引出函数间隔的概念。\n\n定义函数间隔$\\hat{\\gamma}$：\n$$\n\\hat{\\gamma}=y(w^Tx+b)=yf(x)\n$$\n而超平面$(w,b)$关于训练数据集T中所有样本点$(x_i,y_i)$的函数间隔最小值，便为超平面$(w,b)$关于训练数据集T的函数间隔：\n$$\n\\hat{\\gamma}=min\\hat{\\gamma} \n$$\n但这样定义的函数间隔有问题，即如果成比例的改变$w$和$b$，则函数间隔的值$f(x)$却变成了原来的2倍(虽然此时超平面没有改变)，所以只有函数间隔还是不够的。\n\n但我们可以对法向量$w$增加些约束条件，从而引出真正定义点到超平面的距离。假设对于一点$x$，令其垂直投影到超平面上的点对应为$x_0$，$w$是垂直于超平面的一个向量，$r$为样本$x$到分类间隔的距离，如下图所示。\n\n![机器学习之SVM支持向量机（二）图像02](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F02.png)\n$$\nx=x_0+\\gamma\\frac{w}{||w||}\n$$\n其中$||w||$表示范数，又由于$x_0$是超平面上的点，满足$f(x_0)=0$，代入超平面的方程$w^Tx+b=0$，我们得到：\n$$\n\\gamma=\\frac{w^T+b}{||w||}=\\frac{f(x)}{||w||}\n$$\n为了得到$\\gamma$绝对值，将$\\gamma$乘上相应类别$y$，即可得到几何间隔：\n$$\n\\tilde{r}=yr=\\frac{\\hat{\\gamma}}{||w||}\n$$\n从上述定义我们能够看到，几何间隔就是函数间隔除以$||w||$，而且函数间隔$y*(w^Tx+b)=y*f(x)$，实际上就是$|f(x)|$，几何间隔$\\frac{f(x)}{||w||}$才是直观上的点到超平面的距离。\n\n对一个数据点进行分类，当超平面离数据点的间隔越大，分类的确信度也越大。所以，为了使得分类的确信度尽量高，需要让所选择的超平面能够最大化间隔值。于是最大间隔分类器的目标函数定义为$max\\tilde{\\gamma}$。同时需满足如下条件\n$$\ny_i(w^Tx_i+b)=\\hat{\\gamma_i}\\ge\\hat{\\gamma},i=1,2,3,...,n\n$$\n此处令函数间隔$\\hat{\\gamma}$等于1（之所以令$\\hat{\\gamma}=1$是为了方便推导，且这样做对目标函数的优化没有影响）。则上述目标函数转换成：\n$$\nmax\\frac{1}{||w||},s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n\n$$\n\n### 3.原始问题到对偶问题的求解\n\n接着考虑我们之前的目标函数，由于求$\\frac{1}{||w||}$的最大值相当于求$\\frac{1}{2}||w||^2$的最小值，所以目标函数转换为\n$$\nmin\\frac{1}{2}||w||^2 ,s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n\n$$\n现在目标函数是二次的，约束条件是线性的，所以它是一个凸二次规划问题。由于此问题的特殊结构，我们可以通过拉格朗日对偶性变换到对偶变量的优化问题，即通过求解与原问题等价的对偶问题得到原始问题的最优解。\n\n那什么是拉格朗日对偶性呢？简单来说就是通过给每一个约束条件加上一个拉格朗日乘子$\\alpha$，定义拉格朗日函数为：\n$$\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)\n$$\n然后令：\n$$\n\\theta(w)=\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)\n$$\n当某个条件不满足时，例如$y_i(w^Tx+b)<1$，那么有$\\theta(w)=\\infty$。而当所有约束条件都满足时，则有$\\theta(w)=\\frac{1}{2}||w||^2$，亦即最初要最小化的量。目标函数则转换为：\n$$\n\\min_{w,b}\\theta(w)=\\min_{w,b}\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)=p^*\n$$\n这里用$p^*$表示这个问题的最优值，和最初的问题是等价的。如果直接求解那么我们将面对$w,b$两个参数，而$\\alpha_i$又是不等式约束，这个求解过程不好做，我们把最小和最大的位置交换一下：\n$$\n\\max_{\\alpha_i\\ge0}\\min_{w,b}L(w,b,\\alpha)=d^*\n$$\n交换以后的新问题就是原始问题的对偶问题，新问题的最优值用$d^*$表示，而且有$d^*\\le p^*$，在**满足某些条件**的情况下，这两者相等，此时便可以通过求解对偶问题来间接的求解原始问题。\n\n此处**满足某些条件**的情况下，两者等价，此处的**满足某些条件**便是满足KKT条件。KKT最优化数学模型表示成下列标准形式:\n$$\n\\min f(x)\n$$\n\n$$\ns.t. h_j(x)=0,j=1,2,3,...,p\n$$\n\n$$\ng_k(x)\\le0,k=1,2,3,...,q\n$$\n\n$$\nx\\in X\\subset R^n\n$$\n\n其中$f(x)$是需要最小化的函数，$h(x)$是等式约束，$g(x)$是不等式约束，$p,q$分别为等式约束和不等式约束的数量。\n\n> 凸优化概念:$X\\subset R^n$为一凸集，$f:X->R$为一凸函数。凸优化便是寻找一点$x^*\\in X$，是的每一$x\\in X$满足$f(x^*)\\le f(x)$。\n>\n> KKT条件意义是非线性规划问题能有最优化解法的必要和充分条件。\n\nKKT条件就是上面最优化数学模型的标准形式中的最小点$x^*$必须满足下面的条件:\n$$\nh_j(x^*)=0,j=1,2,3,...,p\n$$\n\n$$\ng_k(x^*)\\le 0,k=1,2,3,...,q\n$$\n\n$$\n\\nabla f(x^*)+\\sum_{j=1}^{p}\\lambda_j\\nabla h_j(x^*)+\\sum_{k=1}^{q}\\mu_k \\nabla g_k(x^*)=0\n$$\n\n$$\n\\lambda_j \\neq0,\\mu \\ge0,\\mu_k g_k(x^*)=0\n$$\n\n此处我们不做详细证明为什么满足KKT条件。原始问题通过满足KKT条件，已经转换成对偶问题。求解对偶问题首先要让$L(w,b,\\alpha)$关于$w,b$的最小化，然后求对$\\alpha$的极大，最后利用SMO算法求解对偶问题中的拉格朗日乘子。下面为具体求解过程。\n\n首先固定$\\alpha$，要让L关于$w,b$最小化，我们分别对$w,b$求偏导数。\n$$\n\\frac{\\partial L}{\\partial w}=0 \\Rightarrow w= \\sum_{i=1}^{n}\\alpha_iy_ix_i\n$$\n\n$$\n\\frac{\\partial L}{\\partial b}=0 \\Rightarrow \\sum_{i=1}^{n}\\alpha_iy_i=0\n$$\n\n将上述结果代入到之前的L得到：\n$$\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)\n$$\n\n$$\n=\\frac{1}{2}w^Tw-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}(\\sum_{i=1}^{n}\\alpha_iy_ix_i)^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}\\sum_{i=1}^{n}\\alpha_iy_ix_i^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i\n$$\n\n$$\n=\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j\n$$\n\n然后求对$\\alpha$的极大，即是关于对偶问题的最优化问题。\n$$\n\\max_{\\alpha}\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j\n$$\n\n$$\ns.t.,\\alpha_i\\ge0,i=1,2,3,...,n\n$$\n\n$$\n\\sum_{i=1}^{n}\\alpha_iy_i=0\n$$\n\n我们已经知道$x_i,x_j$的值，便可利用**SMO算法**求解$\\alpha_i$，此处不详细介绍SMO算法。同时根据$w=\\sum_{i=1}^{n}\\alpha_iy_ix_i$我们便可求出$w$，然后通过下式得到$b$。\n$$\nb^*=-\\frac{\\max_{i:y(i)=-1}w^Tx_i+\\min_{i:y(i)=1}w^Tx_i}{2}\n$$\n至此我们便可得出分类超平面和分类决策函数。\n\n### 4.松弛变量处理outliers方法\n\n实际项目中会有数据点含有噪音，即偏离正常位置很远的数据点，我们称之为outlier。\n\n![机器学习之SVM支持向量机（二）图像03](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F03.png)\n\n为了处理这种情况，SVM允许在一定程度上偏离一下超平面。为此我们稍加改变以前的约束条件，即\n$$\ny_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n\n$$\n其中$\\varepsilon$称为松弛变量，对应数据点$x_i$允许偏离分类决策函数的量。当然如果我们允许$\\varepsilon_i$任意大的话，那任意的超平面都是符合条件的。所以我们在原来的目标函数后面再加上一项，使得这些$\\varepsilon_i$的总和也要尽量小。\n$$\n\\min\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i\n$$\n\n$$\ns.t.,y_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n\n$$\n\n$$\n\\varepsilon_i\\ge0,i=1,2,3,...,n\n$$\n\n此处和[机器学习之SVM支持向量机（一）](https://weizhixiaoyi.com/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89/)中的损失函数不同的是加入$\\varepsilon_i$后损失函数第一项便不为0。下述目标函数中第一项相当于现在的$\\varepsilon_i$。\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n那么现在用之前的方法将限制或约束条件加入到目标函数中，得到新的拉格朗日函数，如下所示:\n$$\nL(w,b,\\varepsilon,\\alpha,r)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1+\\varepsilon_i)-\\sum_{i=1}^{n}r_i\\varepsilon_i\n$$\n分析方法和前面相同，此处不再赘述。结合机器学习之SVM支持向量机（一）中的描述我们便能更好的理解C的作用和为什么C通常设置的都较大。\n\n### 5.Sklearn实现SVM支持向量机\n\n我们常用到的核函数包括线性核、多项式核、高斯核、sigmoid核。在**机器学习之SVM支持向量机（一）**中我们已经利用高斯核详细介绍了核函数的意义，所以不再利用其他核函数举例，有兴趣的同学可以去（一）中看详细内容。此处我们给出线性核和多项式核函数的代码，并使用了少量数据绘制出图形。因SVM选取核函数会涉及到较多内容，介于篇幅有限，不再这篇文章中解释，后续会详细写篇**SVM核函数的应用**。\n\n#### 5.1线性\n\n```Python\nfrom sklearn import svm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(0)\nx=np.r_[np.random.randn(20,2)-[2,2],np.random.randn(20,2)+[2,2]]#正态分布产生数字20行2列\ny=[0]*20+[1]*20#20个class0,20个class1\nclf=svm.SVC(kernel='linear')#使用线性核\nclf.fit(x,y)\nw=clf.coef_[0]#获取w\na=-w[0]/w[1]#斜率\n\n#画图\nxx=np.linspace(-5,5)\nyy=a*xx-(clf.intercept_[0])/w[1]\nb=clf.support_vectors_[0]\nyy_down=a*xx+(b[1]-a*b[0])\nb=clf.support_vectors_[-1]\nyy_up=a*xx+(b[1]-a*b[0])\nplt.figure(figsize=(8,4))\nplt.plot(xx,yy)\nplt.plot(xx,yy_down)\nplt.plot(xx,yy_up)\nplt.scatter(clf.support_vectors_[:,0],clf.support_vectors_[:,1],s=80)\nplt.scatter(x[:,0],x[:,1],c=y,cmap=plt.cm.Paired)\nplt.axis('tight')\nplt.show()\n```\n\n![机器学习之SVM支持向量机（二）图像05](机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像05.png)\n\n#### 5.2非线性\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import  Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nX, y = make_moons( n_samples=100, noise=0.15, random_state=42 )\n\ndef plot_dataset(X, y, axes):\n    plt.plot( X[:,0][y==0], X[:,1][y==0], \"bs\" )\n    plt.plot( X[:,0][y==1], X[:,1][y==1], \"g^\" )\n    plt.axis( axes )\n    plt.grid( True, which=\"both\" )\n    plt.xlabel(r\"$x_l$\")\n    plt.ylabel(r\"$x_2$\")\n\n# contour函数是画出轮廓，需要给出X和Y的网格，以及对应的Z，它会画出Z的边界（相当于边缘检测及可视化）\ndef plot_predict(clf, axes):\n    x0s = np.linspace(axes[0], axes[1], 100)\n    x1s = np.linspace(axes[2], axes[3], 100)\n    x0, x1 = np.meshgrid( x0s, x1s )\n    X = np.c_[x0.ravel(), x1.ravel()]\n    y_pred = clf.predict( X ).reshape( x0.shape )\n    y_decision = clf.decision_function( X ).reshape( x0.shape )\n    plt.contour( x0, x1, y_pred, cmap=plt.cm.winter, alpha=0.5 )\n    plt.contour( x0, x1, y_decision, cmap=plt.cm.winter, alpha=0.2 )\n\npolynomial_svm_clf = Pipeline([ (\"poly_featutres\", PolynomialFeatures(degree=3)),\n                                (\"scaler\", StandardScaler()),\n                                (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42)  )\n                            ])#多项式核函数\npolynomial_svm_clf.fit( X, y )\nplot_dataset( X, y, [-1.5, 2.5, -1, 1.5] )\nplot_predict( polynomial_svm_clf, [-1.5, 2.5, -1, 1.5] )\nplt.show()\n```\n\n![机器学习之SVM支持向量机（二）图像06](机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像06.png)\n\n### 6.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![机器学习之SVM支持向量机（二）图片推广](机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图片推广.png)\n\n\n\n\n\n\n\n\n\n\n\n","slug":"机器学习之SVM支持向量机（二）","published":1,"updated":"2018-04-06T13:11:23.223Z","_id":"cjg7s0pqm000g320167v8kbw0","layout":"post","photos":[],"link":"","content":"<h3 id=\"1-知识回顾\"><a href=\"#1-知识回顾\" class=\"headerlink\" title=\"1.知识回顾\"></a>1.知识回顾</h3><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU3MjA2NTQzMw==&amp;mid=2247483818&amp;idx=1&amp;sn=50c634d8b00877134558125c4a718fd7&amp;chksm=fcd7d25ccba05b4a62adfb2717650441f30d636056fcb37529ef34a51b94e453a534b7ca0a48#rd\" target=\"_blank\" rel=\"noopener\">机器学习之SVM支持向量机（一）</a>中我们介绍了<strong>SVM损失函数</strong>、<strong>最大间隔分类</strong>、<strong>为什么SVM能形成最大间隔分类器</strong>、<strong>核函数</strong>、<strong>SVM中Gaussian Kernel的使用</strong>知识点。上文我们从Logistic Regression损失函数中推出SVM损失函数，本篇文章我们将更加直观的分析得到SVM损失函数、如何求解SVM对偶问题、如何解决outliers点，并且最终利用sklearn实现SVM。</p>\n<h3 id=\"2-函数间隔和几何间隔\"><a href=\"#2-函数间隔和几何间隔\" class=\"headerlink\" title=\"2.函数间隔和几何间隔\"></a>2.函数间隔和几何间隔</h3><p>上文我们从logistic Regression损失函数推导出SVM损失函数，本文我们采用另一种方法得到SVM损失函数。首先定义超平面可以用分类函数$f(x)=w^Tx+b$表示，当$f(x)$等于0的时候，$x$便是位于超平面上的点，而$f(x)$大于0对应$y=1$的数据点，$f(x)$小于0对应于$y=-1$的点，如下图所示：</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F01.png\" alt=\"机器学习之SVM支持向量机（二）图像01\"></p>\n<p>在超平面$w^Tx+b=0$确定的情况下，$|w^Tx+b|$能够表示点$x$到超平面的远近，而通过观察$w^Tx+b$的符号与类标记$y$的符号是否一致可判断分类是否正确。因此我们用$y*(w^Tx+b)$的正负性来判定分类的正确性，于是引出函数间隔的概念。</p>\n<p>定义函数间隔$\\hat{\\gamma}$：</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\gamma}=y(w^Tx+b)=yf(x)</script><p>而超平面$(w,b)$关于训练数据集T中所有样本点$(x_i,y_i)$的函数间隔最小值，便为超平面$(w,b)$关于训练数据集T的函数间隔：</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\gamma}=min\\hat{\\gamma}</script><p>但这样定义的函数间隔有问题，即如果成比例的改变$w$和$b$，则函数间隔的值$f(x)$却变成了原来的2倍(虽然此时超平面没有改变)，所以只有函数间隔还是不够的。</p>\n<p>但我们可以对法向量$w$增加些约束条件，从而引出真正定义点到超平面的距离。假设对于一点$x$，令其垂直投影到超平面上的点对应为$x_0$，$w$是垂直于超平面的一个向量，$r$为样本$x$到分类间隔的距离，如下图所示。</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F02.png\" alt=\"机器学习之SVM支持向量机（二）图像02\"></p>\n<script type=\"math/tex; mode=display\">\nx=x_0+\\gamma\\frac{w}{||w||}</script><p>其中$||w||$表示范数，又由于$x_0$是超平面上的点，满足$f(x_0)=0$，代入超平面的方程$w^Tx+b=0$，我们得到：</p>\n<script type=\"math/tex; mode=display\">\n\\gamma=\\frac{w^T+b}{||w||}=\\frac{f(x)}{||w||}</script><p>为了得到$\\gamma$绝对值，将$\\gamma$乘上相应类别$y$，即可得到几何间隔：</p>\n<script type=\"math/tex; mode=display\">\n\\tilde{r}=yr=\\frac{\\hat{\\gamma}}{||w||}</script><p>从上述定义我们能够看到，几何间隔就是函数间隔除以$||w||$，而且函数间隔$y<em>(w^Tx+b)=y</em>f(x)$，实际上就是$|f(x)|$，几何间隔$\\frac{f(x)}{||w||}$才是直观上的点到超平面的距离。</p>\n<p>对一个数据点进行分类，当超平面离数据点的间隔越大，分类的确信度也越大。所以，为了使得分类的确信度尽量高，需要让所选择的超平面能够最大化间隔值。于是最大间隔分类器的目标函数定义为$max\\tilde{\\gamma}$。同时需满足如下条件</p>\n<script type=\"math/tex; mode=display\">\ny_i(w^Tx_i+b)=\\hat{\\gamma_i}\\ge\\hat{\\gamma},i=1,2,3,...,n</script><p>此处令函数间隔$\\hat{\\gamma}$等于1（之所以令$\\hat{\\gamma}=1$是为了方便推导，且这样做对目标函数的优化没有影响）。则上述目标函数转换成：</p>\n<script type=\"math/tex; mode=display\">\nmax\\frac{1}{||w||},s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n</script><h3 id=\"3-原始问题到对偶问题的求解\"><a href=\"#3-原始问题到对偶问题的求解\" class=\"headerlink\" title=\"3.原始问题到对偶问题的求解\"></a>3.原始问题到对偶问题的求解</h3><p>接着考虑我们之前的目标函数，由于求$\\frac{1}{||w||}$的最大值相当于求$\\frac{1}{2}||w||^2$的最小值，所以目标函数转换为</p>\n<script type=\"math/tex; mode=display\">\nmin\\frac{1}{2}||w||^2 ,s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n</script><p>现在目标函数是二次的，约束条件是线性的，所以它是一个凸二次规划问题。由于此问题的特殊结构，我们可以通过拉格朗日对偶性变换到对偶变量的优化问题，即通过求解与原问题等价的对偶问题得到原始问题的最优解。</p>\n<p>那什么是拉格朗日对偶性呢？简单来说就是通过给每一个约束条件加上一个拉格朗日乘子$\\alpha$，定义拉格朗日函数为：</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)</script><p>然后令：</p>\n<script type=\"math/tex; mode=display\">\n\\theta(w)=\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)</script><p>当某个条件不满足时，例如$y_i(w^Tx+b)&lt;1$，那么有$\\theta(w)=\\infty$。而当所有约束条件都满足时，则有$\\theta(w)=\\frac{1}{2}||w||^2$，亦即最初要最小化的量。目标函数则转换为：</p>\n<script type=\"math/tex; mode=display\">\n\\min_{w,b}\\theta(w)=\\min_{w,b}\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)=p^*</script><p>这里用$p^*$表示这个问题的最优值，和最初的问题是等价的。如果直接求解那么我们将面对$w,b$两个参数，而$\\alpha_i$又是不等式约束，这个求解过程不好做，我们把最小和最大的位置交换一下：</p>\n<script type=\"math/tex; mode=display\">\n\\max_{\\alpha_i\\ge0}\\min_{w,b}L(w,b,\\alpha)=d^*</script><p>交换以后的新问题就是原始问题的对偶问题，新问题的最优值用$d^<em>$表示，而且有$d^</em>\\le p^<em>$，在<em>*满足某些条件</em></em>的情况下，这两者相等，此时便可以通过求解对偶问题来间接的求解原始问题。</p>\n<p>此处<strong>满足某些条件</strong>的情况下，两者等价，此处的<strong>满足某些条件</strong>便是满足KKT条件。KKT最优化数学模型表示成下列标准形式:</p>\n<script type=\"math/tex; mode=display\">\n\\min f(x)</script><script type=\"math/tex; mode=display\">\ns.t. h_j(x)=0,j=1,2,3,...,p</script><script type=\"math/tex; mode=display\">\ng_k(x)\\le0,k=1,2,3,...,q</script><script type=\"math/tex; mode=display\">\nx\\in X\\subset R^n</script><p>其中$f(x)$是需要最小化的函数，$h(x)$是等式约束，$g(x)$是不等式约束，$p,q$分别为等式约束和不等式约束的数量。</p>\n<blockquote>\n<p>凸优化概念:$X\\subset R^n$为一凸集，$f:X-&gt;R$为一凸函数。凸优化便是寻找一点$x^<em>\\in X$，是的每一$x\\in X$满足$f(x^</em>)\\le f(x)$。</p>\n<p>KKT条件意义是非线性规划问题能有最优化解法的必要和充分条件。</p>\n</blockquote>\n<p>KKT条件就是上面最优化数学模型的标准形式中的最小点$x^*$必须满足下面的条件:</p>\n<script type=\"math/tex; mode=display\">\nh_j(x^*)=0,j=1,2,3,...,p</script><script type=\"math/tex; mode=display\">\ng_k(x^*)\\le 0,k=1,2,3,...,q</script><script type=\"math/tex; mode=display\">\n\\nabla f(x^*)+\\sum_{j=1}^{p}\\lambda_j\\nabla h_j(x^*)+\\sum_{k=1}^{q}\\mu_k \\nabla g_k(x^*)=0</script><script type=\"math/tex; mode=display\">\n\\lambda_j \\neq0,\\mu \\ge0,\\mu_k g_k(x^*)=0</script><p>此处我们不做详细证明为什么满足KKT条件。原始问题通过满足KKT条件，已经转换成对偶问题。求解对偶问题首先要让$L(w,b,\\alpha)$关于$w,b$的最小化，然后求对$\\alpha$的极大，最后利用SMO算法求解对偶问题中的拉格朗日乘子。下面为具体求解过程。</p>\n<p>首先固定$\\alpha$，要让L关于$w,b$最小化，我们分别对$w,b$求偏导数。</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial w}=0 \\Rightarrow w= \\sum_{i=1}^{n}\\alpha_iy_ix_i</script><script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial b}=0 \\Rightarrow \\sum_{i=1}^{n}\\alpha_iy_i=0</script><p>将上述结果代入到之前的L得到：</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{2}w^Tw-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}(\\sum_{i=1}^{n}\\alpha_iy_ix_i)^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}\\sum_{i=1}^{n}\\alpha_iy_ix_i^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j</script><p>然后求对$\\alpha$的极大，即是关于对偶问题的最优化问题。</p>\n<script type=\"math/tex; mode=display\">\n\\max_{\\alpha}\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j</script><script type=\"math/tex; mode=display\">\ns.t.,\\alpha_i\\ge0,i=1,2,3,...,n</script><script type=\"math/tex; mode=display\">\n\\sum_{i=1}^{n}\\alpha_iy_i=0</script><p>我们已经知道$x_i,x_j$的值，便可利用<strong>SMO算法</strong>求解$\\alpha_i$，此处不详细介绍SMO算法。同时根据$w=\\sum_{i=1}^{n}\\alpha_iy_ix_i$我们便可求出$w$，然后通过下式得到$b$。</p>\n<script type=\"math/tex; mode=display\">\nb^*=-\\frac{\\max_{i:y(i)=-1}w^Tx_i+\\min_{i:y(i)=1}w^Tx_i}{2}</script><p>至此我们便可得出分类超平面和分类决策函数。</p>\n<h3 id=\"4-松弛变量处理outliers方法\"><a href=\"#4-松弛变量处理outliers方法\" class=\"headerlink\" title=\"4.松弛变量处理outliers方法\"></a>4.松弛变量处理outliers方法</h3><p>实际项目中会有数据点含有噪音，即偏离正常位置很远的数据点，我们称之为outlier。</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F03.png\" alt=\"机器学习之SVM支持向量机（二）图像03\"></p>\n<p>为了处理这种情况，SVM允许在一定程度上偏离一下超平面。为此我们稍加改变以前的约束条件，即</p>\n<script type=\"math/tex; mode=display\">\ny_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n</script><p>其中$\\varepsilon$称为松弛变量，对应数据点$x_i$允许偏离分类决策函数的量。当然如果我们允许$\\varepsilon_i$任意大的话，那任意的超平面都是符合条件的。所以我们在原来的目标函数后面再加上一项，使得这些$\\varepsilon_i$的总和也要尽量小。</p>\n<script type=\"math/tex; mode=display\">\n\\min\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i</script><script type=\"math/tex; mode=display\">\ns.t.,y_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n</script><script type=\"math/tex; mode=display\">\n\\varepsilon_i\\ge0,i=1,2,3,...,n</script><p>此处和<a href=\"https://weizhixiaoyi.com/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89/\">机器学习之SVM支持向量机（一）</a>中的损失函数不同的是加入$\\varepsilon_i$后损失函数第一项便不为0。下述目标函数中第一项相当于现在的$\\varepsilon_i$。</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>那么现在用之前的方法将限制或约束条件加入到目标函数中，得到新的拉格朗日函数，如下所示:</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\varepsilon,\\alpha,r)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1+\\varepsilon_i)-\\sum_{i=1}^{n}r_i\\varepsilon_i</script><p>分析方法和前面相同，此处不再赘述。结合机器学习之SVM支持向量机（一）中的描述我们便能更好的理解C的作用和为什么C通常设置的都较大。</p>\n<h3 id=\"5-Sklearn实现SVM支持向量机\"><a href=\"#5-Sklearn实现SVM支持向量机\" class=\"headerlink\" title=\"5.Sklearn实现SVM支持向量机\"></a>5.Sklearn实现SVM支持向量机</h3><p>我们常用到的核函数包括线性核、多项式核、高斯核、sigmoid核。在<strong>机器学习之SVM支持向量机（一）</strong>中我们已经利用高斯核详细介绍了核函数的意义，所以不再利用其他核函数举例，有兴趣的同学可以去（一）中看详细内容。此处我们给出线性核和多项式核函数的代码，并使用了少量数据绘制出图形。因SVM选取核函数会涉及到较多内容，介于篇幅有限，不再这篇文章中解释，后续会详细写篇<strong>SVM核函数的应用</strong>。</p>\n<h4 id=\"5-1线性\"><a href=\"#5-1线性\" class=\"headerlink\" title=\"5.1线性\"></a>5.1线性</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">np.random.seed(<span class=\"number\">0</span>)</span><br><span class=\"line\">x=np.r_[np.random.randn(<span class=\"number\">20</span>,<span class=\"number\">2</span>)-[<span class=\"number\">2</span>,<span class=\"number\">2</span>],np.random.randn(<span class=\"number\">20</span>,<span class=\"number\">2</span>)+[<span class=\"number\">2</span>,<span class=\"number\">2</span>]]<span class=\"comment\">#正态分布产生数字20行2列</span></span><br><span class=\"line\">y=[<span class=\"number\">0</span>]*<span class=\"number\">20</span>+[<span class=\"number\">1</span>]*<span class=\"number\">20</span><span class=\"comment\">#20个class0,20个class1</span></span><br><span class=\"line\">clf=svm.SVC(kernel=<span class=\"string\">'linear'</span>)<span class=\"comment\">#使用线性核</span></span><br><span class=\"line\">clf.fit(x,y)</span><br><span class=\"line\">w=clf.coef_[<span class=\"number\">0</span>]<span class=\"comment\">#获取w</span></span><br><span class=\"line\">a=-w[<span class=\"number\">0</span>]/w[<span class=\"number\">1</span>]<span class=\"comment\">#斜率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">xx=np.linspace(<span class=\"number\">-5</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">yy=a*xx-(clf.intercept_[<span class=\"number\">0</span>])/w[<span class=\"number\">1</span>]</span><br><span class=\"line\">b=clf.support_vectors_[<span class=\"number\">0</span>]</span><br><span class=\"line\">yy_down=a*xx+(b[<span class=\"number\">1</span>]-a*b[<span class=\"number\">0</span>])</span><br><span class=\"line\">b=clf.support_vectors_[<span class=\"number\">-1</span>]</span><br><span class=\"line\">yy_up=a*xx+(b[<span class=\"number\">1</span>]-a*b[<span class=\"number\">0</span>])</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">plt.plot(xx,yy)</span><br><span class=\"line\">plt.plot(xx,yy_down)</span><br><span class=\"line\">plt.plot(xx,yy_up)</span><br><span class=\"line\">plt.scatter(clf.support_vectors_[:,<span class=\"number\">0</span>],clf.support_vectors_[:,<span class=\"number\">1</span>],s=<span class=\"number\">80</span>)</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],c=y,cmap=plt.cm.Paired)</span><br><span class=\"line\">plt.axis(<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/04/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像05.png\" alt=\"机器学习之SVM支持向量机（二）图像05\"></p>\n<h4 id=\"5-2非线性\"><a href=\"#5-2非线性\" class=\"headerlink\" title=\"5.2非线性\"></a>5.2非线性</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.pipeline <span class=\"keyword\">import</span>  Pipeline</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> LinearSVC</span><br><span class=\"line\">X, y = make_moons( n_samples=<span class=\"number\">100</span>, noise=<span class=\"number\">0.15</span>, random_state=<span class=\"number\">42</span> )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_dataset</span><span class=\"params\">(X, y, axes)</span>:</span></span><br><span class=\"line\">    plt.plot( X[:,<span class=\"number\">0</span>][y==<span class=\"number\">0</span>], X[:,<span class=\"number\">1</span>][y==<span class=\"number\">0</span>], <span class=\"string\">\"bs\"</span> )</span><br><span class=\"line\">    plt.plot( X[:,<span class=\"number\">0</span>][y==<span class=\"number\">1</span>], X[:,<span class=\"number\">1</span>][y==<span class=\"number\">1</span>], <span class=\"string\">\"g^\"</span> )</span><br><span class=\"line\">    plt.axis( axes )</span><br><span class=\"line\">    plt.grid( <span class=\"keyword\">True</span>, which=<span class=\"string\">\"both\"</span> )</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">r\"$x_l$\"</span>)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">r\"$x_2$\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># contour函数是画出轮廓，需要给出X和Y的网格，以及对应的Z，它会画出Z的边界（相当于边缘检测及可视化）</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_predict</span><span class=\"params\">(clf, axes)</span>:</span></span><br><span class=\"line\">    x0s = np.linspace(axes[<span class=\"number\">0</span>], axes[<span class=\"number\">1</span>], <span class=\"number\">100</span>)</span><br><span class=\"line\">    x1s = np.linspace(axes[<span class=\"number\">2</span>], axes[<span class=\"number\">3</span>], <span class=\"number\">100</span>)</span><br><span class=\"line\">    x0, x1 = np.meshgrid( x0s, x1s )</span><br><span class=\"line\">    X = np.c_[x0.ravel(), x1.ravel()]</span><br><span class=\"line\">    y_pred = clf.predict( X ).reshape( x0.shape )</span><br><span class=\"line\">    y_decision = clf.decision_function( X ).reshape( x0.shape )</span><br><span class=\"line\">    plt.contour( x0, x1, y_pred, cmap=plt.cm.winter, alpha=<span class=\"number\">0.5</span> )</span><br><span class=\"line\">    plt.contour( x0, x1, y_decision, cmap=plt.cm.winter, alpha=<span class=\"number\">0.2</span> )</span><br><span class=\"line\"></span><br><span class=\"line\">polynomial_svm_clf = Pipeline([ (<span class=\"string\">\"poly_featutres\"</span>, PolynomialFeatures(degree=<span class=\"number\">3</span>)),</span><br><span class=\"line\">                                (<span class=\"string\">\"scaler\"</span>, StandardScaler()),</span><br><span class=\"line\">                                (<span class=\"string\">\"svm_clf\"</span>, LinearSVC(C=<span class=\"number\">10</span>, loss=<span class=\"string\">\"hinge\"</span>, random_state=<span class=\"number\">42</span>)  )</span><br><span class=\"line\">                            ])<span class=\"comment\">#多项式核函数</span></span><br><span class=\"line\">polynomial_svm_clf.fit( X, y )</span><br><span class=\"line\">plot_dataset( X, y, [<span class=\"number\">-1.5</span>, <span class=\"number\">2.5</span>, <span class=\"number\">-1</span>, <span class=\"number\">1.5</span>] )</span><br><span class=\"line\">plot_predict( polynomial_svm_clf, [<span class=\"number\">-1.5</span>, <span class=\"number\">2.5</span>, <span class=\"number\">-1</span>, <span class=\"number\">1.5</span>] )</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/04/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像06.png\" alt=\"机器学习之SVM支持向量机（二）图像06\"></p>\n<h3 id=\"6-推广\"><a href=\"#6-推广\" class=\"headerlink\" title=\"6.推广\"></a>6.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/04/04/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图片推广.png\" alt=\"机器学习之SVM支持向量机（二）图片推广\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-知识回顾\"><a href=\"#1-知识回顾\" class=\"headerlink\" title=\"1.知识回顾\"></a>1.知识回顾</h3><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU3MjA2NTQzMw==&amp;mid=2247483818&amp;idx=1&amp;sn=50c634d8b00877134558125c4a718fd7&amp;chksm=fcd7d25ccba05b4a62adfb2717650441f30d636056fcb37529ef34a51b94e453a534b7ca0a48#rd\" target=\"_blank\" rel=\"noopener\">机器学习之SVM支持向量机（一）</a>中我们介绍了<strong>SVM损失函数</strong>、<strong>最大间隔分类</strong>、<strong>为什么SVM能形成最大间隔分类器</strong>、<strong>核函数</strong>、<strong>SVM中Gaussian Kernel的使用</strong>知识点。上文我们从Logistic Regression损失函数中推出SVM损失函数，本篇文章我们将更加直观的分析得到SVM损失函数、如何求解SVM对偶问题、如何解决outliers点，并且最终利用sklearn实现SVM。</p>\n<h3 id=\"2-函数间隔和几何间隔\"><a href=\"#2-函数间隔和几何间隔\" class=\"headerlink\" title=\"2.函数间隔和几何间隔\"></a>2.函数间隔和几何间隔</h3><p>上文我们从logistic Regression损失函数推导出SVM损失函数，本文我们采用另一种方法得到SVM损失函数。首先定义超平面可以用分类函数$f(x)=w^Tx+b$表示，当$f(x)$等于0的时候，$x$便是位于超平面上的点，而$f(x)$大于0对应$y=1$的数据点，$f(x)$小于0对应于$y=-1$的点，如下图所示：</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F01.png\" alt=\"机器学习之SVM支持向量机（二）图像01\"></p>\n<p>在超平面$w^Tx+b=0$确定的情况下，$|w^Tx+b|$能够表示点$x$到超平面的远近，而通过观察$w^Tx+b$的符号与类标记$y$的符号是否一致可判断分类是否正确。因此我们用$y*(w^Tx+b)$的正负性来判定分类的正确性，于是引出函数间隔的概念。</p>\n<p>定义函数间隔$\\hat{\\gamma}$：</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\gamma}=y(w^Tx+b)=yf(x)</script><p>而超平面$(w,b)$关于训练数据集T中所有样本点$(x_i,y_i)$的函数间隔最小值，便为超平面$(w,b)$关于训练数据集T的函数间隔：</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\gamma}=min\\hat{\\gamma}</script><p>但这样定义的函数间隔有问题，即如果成比例的改变$w$和$b$，则函数间隔的值$f(x)$却变成了原来的2倍(虽然此时超平面没有改变)，所以只有函数间隔还是不够的。</p>\n<p>但我们可以对法向量$w$增加些约束条件，从而引出真正定义点到超平面的距离。假设对于一点$x$，令其垂直投影到超平面上的点对应为$x_0$，$w$是垂直于超平面的一个向量，$r$为样本$x$到分类间隔的距离，如下图所示。</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F02.png\" alt=\"机器学习之SVM支持向量机（二）图像02\"></p>\n<script type=\"math/tex; mode=display\">\nx=x_0+\\gamma\\frac{w}{||w||}</script><p>其中$||w||$表示范数，又由于$x_0$是超平面上的点，满足$f(x_0)=0$，代入超平面的方程$w^Tx+b=0$，我们得到：</p>\n<script type=\"math/tex; mode=display\">\n\\gamma=\\frac{w^T+b}{||w||}=\\frac{f(x)}{||w||}</script><p>为了得到$\\gamma$绝对值，将$\\gamma$乘上相应类别$y$，即可得到几何间隔：</p>\n<script type=\"math/tex; mode=display\">\n\\tilde{r}=yr=\\frac{\\hat{\\gamma}}{||w||}</script><p>从上述定义我们能够看到，几何间隔就是函数间隔除以$||w||$，而且函数间隔$y<em>(w^Tx+b)=y</em>f(x)$，实际上就是$|f(x)|$，几何间隔$\\frac{f(x)}{||w||}$才是直观上的点到超平面的距离。</p>\n<p>对一个数据点进行分类，当超平面离数据点的间隔越大，分类的确信度也越大。所以，为了使得分类的确信度尽量高，需要让所选择的超平面能够最大化间隔值。于是最大间隔分类器的目标函数定义为$max\\tilde{\\gamma}$。同时需满足如下条件</p>\n<script type=\"math/tex; mode=display\">\ny_i(w^Tx_i+b)=\\hat{\\gamma_i}\\ge\\hat{\\gamma},i=1,2,3,...,n</script><p>此处令函数间隔$\\hat{\\gamma}$等于1（之所以令$\\hat{\\gamma}=1$是为了方便推导，且这样做对目标函数的优化没有影响）。则上述目标函数转换成：</p>\n<script type=\"math/tex; mode=display\">\nmax\\frac{1}{||w||},s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n</script><h3 id=\"3-原始问题到对偶问题的求解\"><a href=\"#3-原始问题到对偶问题的求解\" class=\"headerlink\" title=\"3.原始问题到对偶问题的求解\"></a>3.原始问题到对偶问题的求解</h3><p>接着考虑我们之前的目标函数，由于求$\\frac{1}{||w||}$的最大值相当于求$\\frac{1}{2}||w||^2$的最小值，所以目标函数转换为</p>\n<script type=\"math/tex; mode=display\">\nmin\\frac{1}{2}||w||^2 ,s.t.,y_i(w^Tx_i+b)\\ge1,i=1,2,3,...,n</script><p>现在目标函数是二次的，约束条件是线性的，所以它是一个凸二次规划问题。由于此问题的特殊结构，我们可以通过拉格朗日对偶性变换到对偶变量的优化问题，即通过求解与原问题等价的对偶问题得到原始问题的最优解。</p>\n<p>那什么是拉格朗日对偶性呢？简单来说就是通过给每一个约束条件加上一个拉格朗日乘子$\\alpha$，定义拉格朗日函数为：</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)</script><p>然后令：</p>\n<script type=\"math/tex; mode=display\">\n\\theta(w)=\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)</script><p>当某个条件不满足时，例如$y_i(w^Tx+b)&lt;1$，那么有$\\theta(w)=\\infty$。而当所有约束条件都满足时，则有$\\theta(w)=\\frac{1}{2}||w||^2$，亦即最初要最小化的量。目标函数则转换为：</p>\n<script type=\"math/tex; mode=display\">\n\\min_{w,b}\\theta(w)=\\min_{w,b}\\max_{\\alpha_i\\ge0}L(w,b,\\alpha)=p^*</script><p>这里用$p^*$表示这个问题的最优值，和最初的问题是等价的。如果直接求解那么我们将面对$w,b$两个参数，而$\\alpha_i$又是不等式约束，这个求解过程不好做，我们把最小和最大的位置交换一下：</p>\n<script type=\"math/tex; mode=display\">\n\\max_{\\alpha_i\\ge0}\\min_{w,b}L(w,b,\\alpha)=d^*</script><p>交换以后的新问题就是原始问题的对偶问题，新问题的最优值用$d^<em>$表示，而且有$d^</em>\\le p^<em>$，在<em>*满足某些条件</em></em>的情况下，这两者相等，此时便可以通过求解对偶问题来间接的求解原始问题。</p>\n<p>此处<strong>满足某些条件</strong>的情况下，两者等价，此处的<strong>满足某些条件</strong>便是满足KKT条件。KKT最优化数学模型表示成下列标准形式:</p>\n<script type=\"math/tex; mode=display\">\n\\min f(x)</script><script type=\"math/tex; mode=display\">\ns.t. h_j(x)=0,j=1,2,3,...,p</script><script type=\"math/tex; mode=display\">\ng_k(x)\\le0,k=1,2,3,...,q</script><script type=\"math/tex; mode=display\">\nx\\in X\\subset R^n</script><p>其中$f(x)$是需要最小化的函数，$h(x)$是等式约束，$g(x)$是不等式约束，$p,q$分别为等式约束和不等式约束的数量。</p>\n<blockquote>\n<p>凸优化概念:$X\\subset R^n$为一凸集，$f:X-&gt;R$为一凸函数。凸优化便是寻找一点$x^<em>\\in X$，是的每一$x\\in X$满足$f(x^</em>)\\le f(x)$。</p>\n<p>KKT条件意义是非线性规划问题能有最优化解法的必要和充分条件。</p>\n</blockquote>\n<p>KKT条件就是上面最优化数学模型的标准形式中的最小点$x^*$必须满足下面的条件:</p>\n<script type=\"math/tex; mode=display\">\nh_j(x^*)=0,j=1,2,3,...,p</script><script type=\"math/tex; mode=display\">\ng_k(x^*)\\le 0,k=1,2,3,...,q</script><script type=\"math/tex; mode=display\">\n\\nabla f(x^*)+\\sum_{j=1}^{p}\\lambda_j\\nabla h_j(x^*)+\\sum_{k=1}^{q}\\mu_k \\nabla g_k(x^*)=0</script><script type=\"math/tex; mode=display\">\n\\lambda_j \\neq0,\\mu \\ge0,\\mu_k g_k(x^*)=0</script><p>此处我们不做详细证明为什么满足KKT条件。原始问题通过满足KKT条件，已经转换成对偶问题。求解对偶问题首先要让$L(w,b,\\alpha)$关于$w,b$的最小化，然后求对$\\alpha$的极大，最后利用SMO算法求解对偶问题中的拉格朗日乘子。下面为具体求解过程。</p>\n<p>首先固定$\\alpha$，要让L关于$w,b$最小化，我们分别对$w,b$求偏导数。</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial w}=0 \\Rightarrow w= \\sum_{i=1}^{n}\\alpha_iy_ix_i</script><script type=\"math/tex; mode=display\">\n\\frac{\\partial L}{\\partial b}=0 \\Rightarrow \\sum_{i=1}^{n}\\alpha_iy_i=0</script><p>将上述结果代入到之前的L得到：</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1)</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{2}w^Tw-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_iw^Tx_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-\\sum_{i=1}^{n}\\alpha_iy_ib+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}w^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}(\\sum_{i=1}^{n}\\alpha_iy_ix_i)^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}\\sum_{i=1}^{n}\\alpha_iy_ix_i^T\\sum_{i=1}^{n}\\alpha_iy_ix_i-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j-b\\sum_{i=1}^{n}\\alpha_iy_i+\\sum_{i=1}^{n}\\alpha_i</script><script type=\"math/tex; mode=display\">\n=\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_i\\alpha_jy_iy_jx_i^Tx_j</script><p>然后求对$\\alpha$的极大，即是关于对偶问题的最优化问题。</p>\n<script type=\"math/tex; mode=display\">\n\\max_{\\alpha}\\sum_{i=1}^{n}\\alpha_i-\\frac{1}{2}\\sum_{i=1,j=1}^{n}\\alpha_iy_ix_i^T\\alpha_jy_jx_j</script><script type=\"math/tex; mode=display\">\ns.t.,\\alpha_i\\ge0,i=1,2,3,...,n</script><script type=\"math/tex; mode=display\">\n\\sum_{i=1}^{n}\\alpha_iy_i=0</script><p>我们已经知道$x_i,x_j$的值，便可利用<strong>SMO算法</strong>求解$\\alpha_i$，此处不详细介绍SMO算法。同时根据$w=\\sum_{i=1}^{n}\\alpha_iy_ix_i$我们便可求出$w$，然后通过下式得到$b$。</p>\n<script type=\"math/tex; mode=display\">\nb^*=-\\frac{\\max_{i:y(i)=-1}w^Tx_i+\\min_{i:y(i)=1}w^Tx_i}{2}</script><p>至此我们便可得出分类超平面和分类决策函数。</p>\n<h3 id=\"4-松弛变量处理outliers方法\"><a href=\"#4-松弛变量处理outliers方法\" class=\"headerlink\" title=\"4.松弛变量处理outliers方法\"></a>4.松弛变量处理outliers方法</h3><p>实际项目中会有数据点含有噪音，即偏离正常位置很远的数据点，我们称之为outlier。</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%BA%8C%EF%BC%89%E5%9B%BE%E5%83%8F03.png\" alt=\"机器学习之SVM支持向量机（二）图像03\"></p>\n<p>为了处理这种情况，SVM允许在一定程度上偏离一下超平面。为此我们稍加改变以前的约束条件，即</p>\n<script type=\"math/tex; mode=display\">\ny_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n</script><p>其中$\\varepsilon$称为松弛变量，对应数据点$x_i$允许偏离分类决策函数的量。当然如果我们允许$\\varepsilon_i$任意大的话，那任意的超平面都是符合条件的。所以我们在原来的目标函数后面再加上一项，使得这些$\\varepsilon_i$的总和也要尽量小。</p>\n<script type=\"math/tex; mode=display\">\n\\min\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i</script><script type=\"math/tex; mode=display\">\ns.t.,y_i(w^Tx_i+b)\\ge1-\\varepsilon_i,i=1,2,3,...,n</script><script type=\"math/tex; mode=display\">\n\\varepsilon_i\\ge0,i=1,2,3,...,n</script><p>此处和<a href=\"https://weizhixiaoyi.com/2018/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8BSVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88%E4%B8%80%EF%BC%89/\">机器学习之SVM支持向量机（一）</a>中的损失函数不同的是加入$\\varepsilon_i$后损失函数第一项便不为0。下述目标函数中第一项相当于现在的$\\varepsilon_i$。</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>那么现在用之前的方法将限制或约束条件加入到目标函数中，得到新的拉格朗日函数，如下所示:</p>\n<script type=\"math/tex; mode=display\">\nL(w,b,\\varepsilon,\\alpha,r)=\\frac{1}{2}||w||^2+C\\sum_{i=1}^{n}\\varepsilon_i-\\sum_{i=1}^{n}\\alpha_i(y_i(w^Tx_i+b)-1+\\varepsilon_i)-\\sum_{i=1}^{n}r_i\\varepsilon_i</script><p>分析方法和前面相同，此处不再赘述。结合机器学习之SVM支持向量机（一）中的描述我们便能更好的理解C的作用和为什么C通常设置的都较大。</p>\n<h3 id=\"5-Sklearn实现SVM支持向量机\"><a href=\"#5-Sklearn实现SVM支持向量机\" class=\"headerlink\" title=\"5.Sklearn实现SVM支持向量机\"></a>5.Sklearn实现SVM支持向量机</h3><p>我们常用到的核函数包括线性核、多项式核、高斯核、sigmoid核。在<strong>机器学习之SVM支持向量机（一）</strong>中我们已经利用高斯核详细介绍了核函数的意义，所以不再利用其他核函数举例，有兴趣的同学可以去（一）中看详细内容。此处我们给出线性核和多项式核函数的代码，并使用了少量数据绘制出图形。因SVM选取核函数会涉及到较多内容，介于篇幅有限，不再这篇文章中解释，后续会详细写篇<strong>SVM核函数的应用</strong>。</p>\n<h4 id=\"5-1线性\"><a href=\"#5-1线性\" class=\"headerlink\" title=\"5.1线性\"></a>5.1线性</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> svm</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">np.random.seed(<span class=\"number\">0</span>)</span><br><span class=\"line\">x=np.r_[np.random.randn(<span class=\"number\">20</span>,<span class=\"number\">2</span>)-[<span class=\"number\">2</span>,<span class=\"number\">2</span>],np.random.randn(<span class=\"number\">20</span>,<span class=\"number\">2</span>)+[<span class=\"number\">2</span>,<span class=\"number\">2</span>]]<span class=\"comment\">#正态分布产生数字20行2列</span></span><br><span class=\"line\">y=[<span class=\"number\">0</span>]*<span class=\"number\">20</span>+[<span class=\"number\">1</span>]*<span class=\"number\">20</span><span class=\"comment\">#20个class0,20个class1</span></span><br><span class=\"line\">clf=svm.SVC(kernel=<span class=\"string\">'linear'</span>)<span class=\"comment\">#使用线性核</span></span><br><span class=\"line\">clf.fit(x,y)</span><br><span class=\"line\">w=clf.coef_[<span class=\"number\">0</span>]<span class=\"comment\">#获取w</span></span><br><span class=\"line\">a=-w[<span class=\"number\">0</span>]/w[<span class=\"number\">1</span>]<span class=\"comment\">#斜率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">xx=np.linspace(<span class=\"number\">-5</span>,<span class=\"number\">5</span>)</span><br><span class=\"line\">yy=a*xx-(clf.intercept_[<span class=\"number\">0</span>])/w[<span class=\"number\">1</span>]</span><br><span class=\"line\">b=clf.support_vectors_[<span class=\"number\">0</span>]</span><br><span class=\"line\">yy_down=a*xx+(b[<span class=\"number\">1</span>]-a*b[<span class=\"number\">0</span>])</span><br><span class=\"line\">b=clf.support_vectors_[<span class=\"number\">-1</span>]</span><br><span class=\"line\">yy_up=a*xx+(b[<span class=\"number\">1</span>]-a*b[<span class=\"number\">0</span>])</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>,<span class=\"number\">4</span>))</span><br><span class=\"line\">plt.plot(xx,yy)</span><br><span class=\"line\">plt.plot(xx,yy_down)</span><br><span class=\"line\">plt.plot(xx,yy_up)</span><br><span class=\"line\">plt.scatter(clf.support_vectors_[:,<span class=\"number\">0</span>],clf.support_vectors_[:,<span class=\"number\">1</span>],s=<span class=\"number\">80</span>)</span><br><span class=\"line\">plt.scatter(x[:,<span class=\"number\">0</span>],x[:,<span class=\"number\">1</span>],c=y,cmap=plt.cm.Paired)</span><br><span class=\"line\">plt.axis(<span class=\"string\">'tight'</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/04/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像05.png\" alt=\"机器学习之SVM支持向量机（二）图像05\"></p>\n<h4 id=\"5-2非线性\"><a href=\"#5-2非线性\" class=\"headerlink\" title=\"5.2非线性\"></a>5.2非线性</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_moons</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.pipeline <span class=\"keyword\">import</span>  Pipeline</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> StandardScaler</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.svm <span class=\"keyword\">import</span> LinearSVC</span><br><span class=\"line\">X, y = make_moons( n_samples=<span class=\"number\">100</span>, noise=<span class=\"number\">0.15</span>, random_state=<span class=\"number\">42</span> )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_dataset</span><span class=\"params\">(X, y, axes)</span>:</span></span><br><span class=\"line\">    plt.plot( X[:,<span class=\"number\">0</span>][y==<span class=\"number\">0</span>], X[:,<span class=\"number\">1</span>][y==<span class=\"number\">0</span>], <span class=\"string\">\"bs\"</span> )</span><br><span class=\"line\">    plt.plot( X[:,<span class=\"number\">0</span>][y==<span class=\"number\">1</span>], X[:,<span class=\"number\">1</span>][y==<span class=\"number\">1</span>], <span class=\"string\">\"g^\"</span> )</span><br><span class=\"line\">    plt.axis( axes )</span><br><span class=\"line\">    plt.grid( <span class=\"keyword\">True</span>, which=<span class=\"string\">\"both\"</span> )</span><br><span class=\"line\">    plt.xlabel(<span class=\"string\">r\"$x_l$\"</span>)</span><br><span class=\"line\">    plt.ylabel(<span class=\"string\">r\"$x_2$\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># contour函数是画出轮廓，需要给出X和Y的网格，以及对应的Z，它会画出Z的边界（相当于边缘检测及可视化）</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_predict</span><span class=\"params\">(clf, axes)</span>:</span></span><br><span class=\"line\">    x0s = np.linspace(axes[<span class=\"number\">0</span>], axes[<span class=\"number\">1</span>], <span class=\"number\">100</span>)</span><br><span class=\"line\">    x1s = np.linspace(axes[<span class=\"number\">2</span>], axes[<span class=\"number\">3</span>], <span class=\"number\">100</span>)</span><br><span class=\"line\">    x0, x1 = np.meshgrid( x0s, x1s )</span><br><span class=\"line\">    X = np.c_[x0.ravel(), x1.ravel()]</span><br><span class=\"line\">    y_pred = clf.predict( X ).reshape( x0.shape )</span><br><span class=\"line\">    y_decision = clf.decision_function( X ).reshape( x0.shape )</span><br><span class=\"line\">    plt.contour( x0, x1, y_pred, cmap=plt.cm.winter, alpha=<span class=\"number\">0.5</span> )</span><br><span class=\"line\">    plt.contour( x0, x1, y_decision, cmap=plt.cm.winter, alpha=<span class=\"number\">0.2</span> )</span><br><span class=\"line\"></span><br><span class=\"line\">polynomial_svm_clf = Pipeline([ (<span class=\"string\">\"poly_featutres\"</span>, PolynomialFeatures(degree=<span class=\"number\">3</span>)),</span><br><span class=\"line\">                                (<span class=\"string\">\"scaler\"</span>, StandardScaler()),</span><br><span class=\"line\">                                (<span class=\"string\">\"svm_clf\"</span>, LinearSVC(C=<span class=\"number\">10</span>, loss=<span class=\"string\">\"hinge\"</span>, random_state=<span class=\"number\">42</span>)  )</span><br><span class=\"line\">                            ])<span class=\"comment\">#多项式核函数</span></span><br><span class=\"line\">polynomial_svm_clf.fit( X, y )</span><br><span class=\"line\">plot_dataset( X, y, [<span class=\"number\">-1.5</span>, <span class=\"number\">2.5</span>, <span class=\"number\">-1</span>, <span class=\"number\">1.5</span>] )</span><br><span class=\"line\">plot_predict( polynomial_svm_clf, [<span class=\"number\">-1.5</span>, <span class=\"number\">2.5</span>, <span class=\"number\">-1</span>, <span class=\"number\">1.5</span>] )</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/04/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像06.png\" alt=\"机器学习之SVM支持向量机（二）图像06\"></p>\n<h3 id=\"6-推广\"><a href=\"#6-推广\" class=\"headerlink\" title=\"6.推广\"></a>6.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/04/04/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图片推广.png\" alt=\"机器学习之SVM支持向量机（二）图片推广\"></p>\n"},{"title":"机器学习之决策树(C4.5算法)","date":"2018-04-19T03:03:26.000Z","mathjax":true,"comments":1,"_content":"\n### 1.决策树简介\n\n我们已有如下所示数据集，特征属性包含天气、温度、湿度、风速，然后根据这些数据去分类或预测能否去打高尔夫球，针对此类问题你会怎么解决呢。\n\n| 序号 | 天气 | 温度 | 湿度 | 风速 | 高尔夫 |\n| ---- | :--: | :--: | :--: | :--: | :----: |\n| 1    |  晴  | 炎热 |  高  |  弱  |  进行  |\n| 2    |  晴  | 炎热 |  高  |  强  |  进行  |\n| 3    |  阴  | 炎热 |  高  |  弱  |  取消  |\n| 4    |  雨  | 适中 |  高  |  弱  |  取消  |\n| 5    |  雨  | 寒冷 | 正常 |  弱  |  取消  |\n| 6    |  雨  | 寒冷 | 正常 |  强  |  进行  |\n| 7    |  阴  | 寒冷 | 正常 |  强  |  进行  |\n| 8    |  晴  | 适中 |  高  |  弱  |  进行  |\n| 9    |  晴  | 寒冷 | 正常 |  弱  |  进行  |\n| 10   |  雨  | 适中 | 正常 |  弱  |  进行  |\n| 11   |  晴  | 适中 | 正常 |  强  |  进行  |\n| 12   |  阴  | 适中 |  高  |  强  |  进行  |\n| 13   |  阴  | 炎热 | 正常 |  弱  |  取消  |\n| 14   |  雨  | 适中 |  高  |  强  |  取消  |\n\n正当你苦思冥想之时，天空之中突然飘来一张决策图，发现这图好像一张倒着的树啊，于是你命名为决策树。你发现可直接根据决策树得到相应结果，高兴的像个300斤的孩子。但下次再面临这样的问题时，还能够那么好运嘛？于是你陷入苦苦思考之中，怎样才能得到分类决策树呢。\n\n![机器学习之决策树图片01](机器学习之决策树-C4-5算法/机器学习之决策树图片01.png)\n\n### 2.C4.5算法\n\n**上古之神赐予你智慧**：C4.5是一系列用在机器学习和数据挖掘中分类问题的算法，它的目标是监督学习。即给定一个数据集，其中的每一个元组都能用一组属性值描述，每一个元组属于一个互斥的类别中的某一类。C4.5的目标是通过学习，找到一个从属性值到类别的映射关系，并且这个映射能够用于对新的类别未知的实体进行分类。\n\nC4.5是在ID3的基础上提出的。ID3算法用来构造决策树。决策树是一种类似流程图的树结构，其中每个内部节点（非树叶节点）表示在一个属性上的测试，每个分枝代表一个测试输出，而每个树叶节点存放一个类标号。一旦建立好决策树，对于一个未给定类标号的元组，跟踪一条有根节点到叶节点的路径，该叶节点就存放着该元组的预测。上述数据集有4个属性，属性集合A={天气、温度、湿度、风速}，类别集合D={进行、取消}。我们先做一些假设\n\n+ 类标记元组训练集记为$D$，$|D|$表示元组个数，例如上述数据$|D|=14$。\n+ 类标号记为$m$，例如上述数据$m=2$，分别为进行、取消。\n+ 属性集合记为为$C$，例如$C_1$为天气情况，$C_iD$是$D$中$C_i$类元组的集合，$|C_iD|$为$C_iD$中元组个数。\n+ 属性标号记为$n$，例如上述数据$n=2$，分别为天气、温度、湿度、风速。\n+ $p_i$表示类别$i$的概率，比如$p(进行)=\\frac{9}{14}$。\n\n#### 2.1信息增益\n\n信息增益实际上是ID3算法中用来进行属性选择度量的，具有较高信息增益的属性来作为节点N的分裂属性。该属性使结果划分中的元组分类所需信息量最小。\n\n**计算类别信息熵**:类别信息熵表示的是所有样本中各种类别出现的不确定之和。根据熵的概念，熵越大，不确定性就越大，把事情理解清楚所需要的信息量就越多。对D中的元组分类所需的期望信息表达式如下，同时计算出上述数据的期望信息\n$$\nInfo(D)=-\\sum_{i=1}^{m}p_ilog_2(p_i)\n$$\n\n$$\nInfo(D)=-\\frac{9}{14}log_2\\frac{9}{14}-\\frac{5}{14}log_2\\frac{5}{14}=0.940\n$$\n\n**计算每个属性的信息熵**:每个属性的信息熵相当于条件熵。表示的是在某种属性的条件下，各种类别出现的不确定之和。属性的信息熵越大，表示这个属性中拥有的样本类别越乱。现在假定按照属性集合C划分D中的元组，且属性Ci将D划分成v个不同的类。在该划分之后，为了得到准确的分类还需要下式进行度量。\n$$\nInfo_A(D)=\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*Info(D_j)\n$$\n\n$$\nInfo(天气)=\\frac{5}{14}*[-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5}]+\\frac{4}{14}*[-\\frac{4}{4}log_2\\frac{4}{4}]+\\frac{5}{14}*[-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5}]=0.694\n$$\n\n$$\nInfo(温度)=0.911,Info(湿度)=0.739,Info(风速)=0.892\n$$\n\n**计算信息增益**:信息增益=熵-条件熵，在这里表示为类别信息熵-属性信息熵。它表示的是信息不确定性减少的程度。如果一个属性的信息增益越大，就表示用这个属性进行样本划分可以更好的减少划分后样本的不确定性，选择该属性就可以更快更好的完成我们的分类目标。\n$$\nGain(A)=Info(D)-Info_A(D)\n$$\n\n$$\nGain(天气)=Info(D)-Info(天气)=0.940-0.694=0.246\n$$\n\n$$\nGain(温度)=0.029,Gain(湿度)=0.15,Gain(风速)=0.048\n$$\n\n但是我们假设这种情况，每个属性中每个类别都只有一个样本，那这样属性信息熵就等于0，根据信息增益就无法选择出有效分类特征，所以C4.5算法选择使用信息增益率对ID3进行改进。\n\n#### 2.2信息增益率\n\n**计算属性分裂信息度量**:用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息。信息增益率用**信息增益 / 内在信息**表示，信息增益率会导致属性的重要性随着内在信息的增大而减小**（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）**，这样算是对单纯用信息增益有所补偿。信息增益率定义如下\n$$\nSplitInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*log_2\\frac{|D_j|}{|D|}\n$$\n\n$$\nSplitInfo(天气)=-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{4}{14}*log_2\\frac{4}{14}=1.577\n$$\n\n$$\nSplitInfo(温度)=1.556,SplitInfo(湿度)=1.0,SplitInfo(风速)=0.985\n$$\n\n$$\nGainRatio(A)=\\frac{Gain(A)}{SplitInfo(A)}\n$$\n\n$$\nGainRatio(天气)=\\frac{Gain(天气)}{SplitInfo(天气)}=\\frac{0.246}{1.577}=0.155\n$$\n\n$$\nGainRatio(温度)=0.0186,GainRatio(湿度)=0.151,GainRatio(风速)=0.048\n$$\n\n天气的信息增益率最高，选择天气为分裂属性。分裂之后，天气是“阴”的条件下无其他分裂点，所以把它定义为叶子节点，选择较乱的结点继续分裂。重复上述过程，直到算法完成，我们便可得到决策树。\n\n### 3.树剪枝\n\n决策树创建过程中，由于数据中的噪声和离群点，许多分支反应的是训练数据中的异常。剪枝方法是用来处理这种过分拟合的问题，通常剪枝方法都是使用统计度量，减去最不可靠的分支。减枝方法分为先减枝和后剪枝。\n\n#### 3.1先剪枝\n\n先剪枝方法通过提前停止树的构造(比如决定在某个节点不再分裂或划分训练元组的自己)。但先剪枝有个视野效果缺点问题，也就是说在相同的标准下，也许当前扩展不能满足要求，但更进一步又能满足要求，这样会过早停止树的生长。先剪枝可通过以下方法\n\n+ 当决策树达到一定的高度就停止决策树的生长。\n+ 到达节点的实例个数小于某个阈值的时候也可以停止树的生长，不足之处是不能处理那些数量比较小的特殊情况。\n+ 计算每次扩展对系统性能的增益，如果小于某个阈值就可以停止树的生长。\n\n#### 3.2后剪枝\n\n后剪枝是由完全生长的树剪去子树而形成，通过删除节点的分支并用树叶来替换它，树叶一般用子树中最频繁的类别来标记。C4.5采用悲观剪枝法，它使用训练集生成决策树，然后对生成的决策树进行剪枝，通过对比剪枝前后分类错误率来验证是否进行剪枝。\n\n把一颗子树的分类(具有多个叶子结点)的分类用一个叶子节点替换的话，在训练集上的误判率肯定是上升的，但是在新数据上则不一定，于是我们需要把子树的误判计算加上一个经验性的惩罚因子。对于一颗叶子节点，它覆盖了N个样本，其中有E个错误，那么该叶子节点的错误率为(E+0.5)/N。这个0.5就是惩罚因子，那么一颗子树，他有L个叶子节点，那么该子树的误判率为\n$$\n\\frac{\\sum (E_i+0.5*L)}{\\sum N_i}\n$$\n这样的话我们可以看到一颗子树虽然有多个子节点，但由于加上惩罚因子，所以子树的误判率未必占到便宜。剪枝后内部节点变成叶子节点，其误判个数J也需要加上一个惩罚因子，变成J+0.5。那么子树是否可以被剪枝就取决于剪枝后的错误J+0.5的标准范围内。对于样本的误差率e，我们可以根据经验把它估计成各种各样的分布模型，比如二项式分布或正态分布。\n\n假如决策树正确分类的样本值为1，错误分类的样本值为0，该树错误分类的概率(误判率)为e(**e为分布的固有属性，可以统计出来**)，那么树的误判次数就是伯努利分布，我们可以估计出概述的误差次数均值和标准值。\n$$\nE(subtree\\_err\\_count)=N*e\n$$\n\n$$\nvar(subtree\\_err\\_count)=\\sqrt{N*e*(1-e)}\n$$\n\n把子树替换成叶子节点后，该叶子的误判次数也是伯努利分布，其概率误判率为(E+0.5)/N，因此叶子节点的误判次数均值为\n$$\nE(leaf\\_err\\_count)=N*e\n$$\n使用训练数据时，子树总是比替换为一个叶节点后产生的误差小，但是使用校正后有误差计算方法却并非如此，当子树的误判个数减去标准差后大于对应叶节点的误判个数，就决定剪枝\n$$\nE(subtree\\_err\\_count)-var(subtree\\_err\\_count)>E(leaf\\_err\\_count)\n$$\n上述条件就是剪枝的标准。当然并不一定非要减去标准差，可以给定任意的置信区间，我们设定一定的显著性因子，就可以估算出误判次数的上下界。\n\n### 4.Sklearn实现决策树\n\n我们以sklearn中iris数据作为训练集，iris属性特征包括花萼长度、花萼宽度、花瓣长度、花瓣宽度，类别共三类，分别为Setosa、Versicolour、Virginca。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn import tree\n\n#引入数据\niris=load_iris()\nX=iris.data\ny=iris.target\n\n#训练数据和模型,采用ID3或C4.5训练\nclf=tree.DecisionTreeClassifier(criterion='entropy')\nclf=clf.fit(X,y)\n\n\n#引入graphviz模块用来导出图,结果图如下所示\nimport graphviz\ndot_data=tree.export_graphviz(clf,out_file=None,\n                              feature_names=iris.feature_names,\n                              class_names=iris.target_names,\n                              filled=True,rounded=True,\n                              special_characters=True)\n\ngraph=graphviz.Source(dot_data)\ngraph.view()\n```\n\n![机器学习之决策树图片02](机器学习之决策树-C4-5算法/机器学习之决策树图片02.png)\n\n### 5.实际使用技巧\n\n- 对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。\n- 训练之前平衡数据集，以防止决策树偏向于主导类。可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (`sample_weight`) 的和归一化为相同的值。\n- 考虑实现进行降维(PCA、ICA)，使决策树能够更好地找到具有分辨性的特征。\n- 通过 `export` 功能可以可视化您的决策树。使用 `max_depth=3`作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。\n- 填充树的样本数量会增加树的每个附加级别。使用 `max_depth` 来控制树的大小防止过拟合。\n- 通过使用 `min_samples_split` 和 `min_samples_leaf` 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/机器学习之决策树-C4-5算法.md","raw":"---\ntitle: 机器学习之决策树(C4.5算法)\ndate: 2018-04-19 11:03:26\ntags: [机器学习,算法]\ncategories: 机器学习\nmathjax: true\ncomments: true\n---\n\n### 1.决策树简介\n\n我们已有如下所示数据集，特征属性包含天气、温度、湿度、风速，然后根据这些数据去分类或预测能否去打高尔夫球，针对此类问题你会怎么解决呢。\n\n| 序号 | 天气 | 温度 | 湿度 | 风速 | 高尔夫 |\n| ---- | :--: | :--: | :--: | :--: | :----: |\n| 1    |  晴  | 炎热 |  高  |  弱  |  进行  |\n| 2    |  晴  | 炎热 |  高  |  强  |  进行  |\n| 3    |  阴  | 炎热 |  高  |  弱  |  取消  |\n| 4    |  雨  | 适中 |  高  |  弱  |  取消  |\n| 5    |  雨  | 寒冷 | 正常 |  弱  |  取消  |\n| 6    |  雨  | 寒冷 | 正常 |  强  |  进行  |\n| 7    |  阴  | 寒冷 | 正常 |  强  |  进行  |\n| 8    |  晴  | 适中 |  高  |  弱  |  进行  |\n| 9    |  晴  | 寒冷 | 正常 |  弱  |  进行  |\n| 10   |  雨  | 适中 | 正常 |  弱  |  进行  |\n| 11   |  晴  | 适中 | 正常 |  强  |  进行  |\n| 12   |  阴  | 适中 |  高  |  强  |  进行  |\n| 13   |  阴  | 炎热 | 正常 |  弱  |  取消  |\n| 14   |  雨  | 适中 |  高  |  强  |  取消  |\n\n正当你苦思冥想之时，天空之中突然飘来一张决策图，发现这图好像一张倒着的树啊，于是你命名为决策树。你发现可直接根据决策树得到相应结果，高兴的像个300斤的孩子。但下次再面临这样的问题时，还能够那么好运嘛？于是你陷入苦苦思考之中，怎样才能得到分类决策树呢。\n\n![机器学习之决策树图片01](机器学习之决策树-C4-5算法/机器学习之决策树图片01.png)\n\n### 2.C4.5算法\n\n**上古之神赐予你智慧**：C4.5是一系列用在机器学习和数据挖掘中分类问题的算法，它的目标是监督学习。即给定一个数据集，其中的每一个元组都能用一组属性值描述，每一个元组属于一个互斥的类别中的某一类。C4.5的目标是通过学习，找到一个从属性值到类别的映射关系，并且这个映射能够用于对新的类别未知的实体进行分类。\n\nC4.5是在ID3的基础上提出的。ID3算法用来构造决策树。决策树是一种类似流程图的树结构，其中每个内部节点（非树叶节点）表示在一个属性上的测试，每个分枝代表一个测试输出，而每个树叶节点存放一个类标号。一旦建立好决策树，对于一个未给定类标号的元组，跟踪一条有根节点到叶节点的路径，该叶节点就存放着该元组的预测。上述数据集有4个属性，属性集合A={天气、温度、湿度、风速}，类别集合D={进行、取消}。我们先做一些假设\n\n+ 类标记元组训练集记为$D$，$|D|$表示元组个数，例如上述数据$|D|=14$。\n+ 类标号记为$m$，例如上述数据$m=2$，分别为进行、取消。\n+ 属性集合记为为$C$，例如$C_1$为天气情况，$C_iD$是$D$中$C_i$类元组的集合，$|C_iD|$为$C_iD$中元组个数。\n+ 属性标号记为$n$，例如上述数据$n=2$，分别为天气、温度、湿度、风速。\n+ $p_i$表示类别$i$的概率，比如$p(进行)=\\frac{9}{14}$。\n\n#### 2.1信息增益\n\n信息增益实际上是ID3算法中用来进行属性选择度量的，具有较高信息增益的属性来作为节点N的分裂属性。该属性使结果划分中的元组分类所需信息量最小。\n\n**计算类别信息熵**:类别信息熵表示的是所有样本中各种类别出现的不确定之和。根据熵的概念，熵越大，不确定性就越大，把事情理解清楚所需要的信息量就越多。对D中的元组分类所需的期望信息表达式如下，同时计算出上述数据的期望信息\n$$\nInfo(D)=-\\sum_{i=1}^{m}p_ilog_2(p_i)\n$$\n\n$$\nInfo(D)=-\\frac{9}{14}log_2\\frac{9}{14}-\\frac{5}{14}log_2\\frac{5}{14}=0.940\n$$\n\n**计算每个属性的信息熵**:每个属性的信息熵相当于条件熵。表示的是在某种属性的条件下，各种类别出现的不确定之和。属性的信息熵越大，表示这个属性中拥有的样本类别越乱。现在假定按照属性集合C划分D中的元组，且属性Ci将D划分成v个不同的类。在该划分之后，为了得到准确的分类还需要下式进行度量。\n$$\nInfo_A(D)=\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*Info(D_j)\n$$\n\n$$\nInfo(天气)=\\frac{5}{14}*[-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5}]+\\frac{4}{14}*[-\\frac{4}{4}log_2\\frac{4}{4}]+\\frac{5}{14}*[-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5}]=0.694\n$$\n\n$$\nInfo(温度)=0.911,Info(湿度)=0.739,Info(风速)=0.892\n$$\n\n**计算信息增益**:信息增益=熵-条件熵，在这里表示为类别信息熵-属性信息熵。它表示的是信息不确定性减少的程度。如果一个属性的信息增益越大，就表示用这个属性进行样本划分可以更好的减少划分后样本的不确定性，选择该属性就可以更快更好的完成我们的分类目标。\n$$\nGain(A)=Info(D)-Info_A(D)\n$$\n\n$$\nGain(天气)=Info(D)-Info(天气)=0.940-0.694=0.246\n$$\n\n$$\nGain(温度)=0.029,Gain(湿度)=0.15,Gain(风速)=0.048\n$$\n\n但是我们假设这种情况，每个属性中每个类别都只有一个样本，那这样属性信息熵就等于0，根据信息增益就无法选择出有效分类特征，所以C4.5算法选择使用信息增益率对ID3进行改进。\n\n#### 2.2信息增益率\n\n**计算属性分裂信息度量**:用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息。信息增益率用**信息增益 / 内在信息**表示，信息增益率会导致属性的重要性随着内在信息的增大而减小**（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）**，这样算是对单纯用信息增益有所补偿。信息增益率定义如下\n$$\nSplitInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*log_2\\frac{|D_j|}{|D|}\n$$\n\n$$\nSplitInfo(天气)=-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{4}{14}*log_2\\frac{4}{14}=1.577\n$$\n\n$$\nSplitInfo(温度)=1.556,SplitInfo(湿度)=1.0,SplitInfo(风速)=0.985\n$$\n\n$$\nGainRatio(A)=\\frac{Gain(A)}{SplitInfo(A)}\n$$\n\n$$\nGainRatio(天气)=\\frac{Gain(天气)}{SplitInfo(天气)}=\\frac{0.246}{1.577}=0.155\n$$\n\n$$\nGainRatio(温度)=0.0186,GainRatio(湿度)=0.151,GainRatio(风速)=0.048\n$$\n\n天气的信息增益率最高，选择天气为分裂属性。分裂之后，天气是“阴”的条件下无其他分裂点，所以把它定义为叶子节点，选择较乱的结点继续分裂。重复上述过程，直到算法完成，我们便可得到决策树。\n\n### 3.树剪枝\n\n决策树创建过程中，由于数据中的噪声和离群点，许多分支反应的是训练数据中的异常。剪枝方法是用来处理这种过分拟合的问题，通常剪枝方法都是使用统计度量，减去最不可靠的分支。减枝方法分为先减枝和后剪枝。\n\n#### 3.1先剪枝\n\n先剪枝方法通过提前停止树的构造(比如决定在某个节点不再分裂或划分训练元组的自己)。但先剪枝有个视野效果缺点问题，也就是说在相同的标准下，也许当前扩展不能满足要求，但更进一步又能满足要求，这样会过早停止树的生长。先剪枝可通过以下方法\n\n+ 当决策树达到一定的高度就停止决策树的生长。\n+ 到达节点的实例个数小于某个阈值的时候也可以停止树的生长，不足之处是不能处理那些数量比较小的特殊情况。\n+ 计算每次扩展对系统性能的增益，如果小于某个阈值就可以停止树的生长。\n\n#### 3.2后剪枝\n\n后剪枝是由完全生长的树剪去子树而形成，通过删除节点的分支并用树叶来替换它，树叶一般用子树中最频繁的类别来标记。C4.5采用悲观剪枝法，它使用训练集生成决策树，然后对生成的决策树进行剪枝，通过对比剪枝前后分类错误率来验证是否进行剪枝。\n\n把一颗子树的分类(具有多个叶子结点)的分类用一个叶子节点替换的话，在训练集上的误判率肯定是上升的，但是在新数据上则不一定，于是我们需要把子树的误判计算加上一个经验性的惩罚因子。对于一颗叶子节点，它覆盖了N个样本，其中有E个错误，那么该叶子节点的错误率为(E+0.5)/N。这个0.5就是惩罚因子，那么一颗子树，他有L个叶子节点，那么该子树的误判率为\n$$\n\\frac{\\sum (E_i+0.5*L)}{\\sum N_i}\n$$\n这样的话我们可以看到一颗子树虽然有多个子节点，但由于加上惩罚因子，所以子树的误判率未必占到便宜。剪枝后内部节点变成叶子节点，其误判个数J也需要加上一个惩罚因子，变成J+0.5。那么子树是否可以被剪枝就取决于剪枝后的错误J+0.5的标准范围内。对于样本的误差率e，我们可以根据经验把它估计成各种各样的分布模型，比如二项式分布或正态分布。\n\n假如决策树正确分类的样本值为1，错误分类的样本值为0，该树错误分类的概率(误判率)为e(**e为分布的固有属性，可以统计出来**)，那么树的误判次数就是伯努利分布，我们可以估计出概述的误差次数均值和标准值。\n$$\nE(subtree\\_err\\_count)=N*e\n$$\n\n$$\nvar(subtree\\_err\\_count)=\\sqrt{N*e*(1-e)}\n$$\n\n把子树替换成叶子节点后，该叶子的误判次数也是伯努利分布，其概率误判率为(E+0.5)/N，因此叶子节点的误判次数均值为\n$$\nE(leaf\\_err\\_count)=N*e\n$$\n使用训练数据时，子树总是比替换为一个叶节点后产生的误差小，但是使用校正后有误差计算方法却并非如此，当子树的误判个数减去标准差后大于对应叶节点的误判个数，就决定剪枝\n$$\nE(subtree\\_err\\_count)-var(subtree\\_err\\_count)>E(leaf\\_err\\_count)\n$$\n上述条件就是剪枝的标准。当然并不一定非要减去标准差，可以给定任意的置信区间，我们设定一定的显著性因子，就可以估算出误判次数的上下界。\n\n### 4.Sklearn实现决策树\n\n我们以sklearn中iris数据作为训练集，iris属性特征包括花萼长度、花萼宽度、花瓣长度、花瓣宽度，类别共三类，分别为Setosa、Versicolour、Virginca。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn import tree\n\n#引入数据\niris=load_iris()\nX=iris.data\ny=iris.target\n\n#训练数据和模型,采用ID3或C4.5训练\nclf=tree.DecisionTreeClassifier(criterion='entropy')\nclf=clf.fit(X,y)\n\n\n#引入graphviz模块用来导出图,结果图如下所示\nimport graphviz\ndot_data=tree.export_graphviz(clf,out_file=None,\n                              feature_names=iris.feature_names,\n                              class_names=iris.target_names,\n                              filled=True,rounded=True,\n                              special_characters=True)\n\ngraph=graphviz.Source(dot_data)\ngraph.view()\n```\n\n![机器学习之决策树图片02](机器学习之决策树-C4-5算法/机器学习之决策树图片02.png)\n\n### 5.实际使用技巧\n\n- 对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。\n- 训练之前平衡数据集，以防止决策树偏向于主导类。可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (`sample_weight`) 的和归一化为相同的值。\n- 考虑实现进行降维(PCA、ICA)，使决策树能够更好地找到具有分辨性的特征。\n- 通过 `export` 功能可以可视化您的决策树。使用 `max_depth=3`作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。\n- 填充树的样本数量会增加树的每个附加级别。使用 `max_depth` 来控制树的大小防止过拟合。\n- 通过使用 `min_samples_split` 和 `min_samples_leaf` 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"机器学习之决策树-C4-5算法","published":1,"updated":"2018-04-20T10:04:44.901Z","_id":"cjg7s0pqp000j3201tm2u0kv8","layout":"post","photos":[],"link":"","content":"<h3 id=\"1-决策树简介\"><a href=\"#1-决策树简介\" class=\"headerlink\" title=\"1.决策树简介\"></a>1.决策树简介</h3><p>我们已有如下所示数据集，特征属性包含天气、温度、湿度、风速，然后根据这些数据去分类或预测能否去打高尔夫球，针对此类问题你会怎么解决呢。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th style=\"text-align:center\">天气</th>\n<th style=\"text-align:center\">温度</th>\n<th style=\"text-align:center\">湿度</th>\n<th style=\"text-align:center\">风速</th>\n<th style=\"text-align:center\">高尔夫</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>2</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>3</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>4</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>5</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>6</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>7</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>8</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>9</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>10</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>11</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>12</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>13</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>14</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>正当你苦思冥想之时，天空之中突然飘来一张决策图，发现这图好像一张倒着的树啊，于是你命名为决策树。你发现可直接根据决策树得到相应结果，高兴的像个300斤的孩子。但下次再面临这样的问题时，还能够那么好运嘛？于是你陷入苦苦思考之中，怎样才能得到分类决策树呢。</p>\n<p><img src=\"/2018/04/19/机器学习之决策树-C4-5算法/机器学习之决策树图片01.png\" alt=\"机器学习之决策树图片01\"></p>\n<h3 id=\"2-C4-5算法\"><a href=\"#2-C4-5算法\" class=\"headerlink\" title=\"2.C4.5算法\"></a>2.C4.5算法</h3><p><strong>上古之神赐予你智慧</strong>：C4.5是一系列用在机器学习和数据挖掘中分类问题的算法，它的目标是监督学习。即给定一个数据集，其中的每一个元组都能用一组属性值描述，每一个元组属于一个互斥的类别中的某一类。C4.5的目标是通过学习，找到一个从属性值到类别的映射关系，并且这个映射能够用于对新的类别未知的实体进行分类。</p>\n<p>C4.5是在ID3的基础上提出的。ID3算法用来构造决策树。决策树是一种类似流程图的树结构，其中每个内部节点（非树叶节点）表示在一个属性上的测试，每个分枝代表一个测试输出，而每个树叶节点存放一个类标号。一旦建立好决策树，对于一个未给定类标号的元组，跟踪一条有根节点到叶节点的路径，该叶节点就存放着该元组的预测。上述数据集有4个属性，属性集合A={天气、温度、湿度、风速}，类别集合D={进行、取消}。我们先做一些假设</p>\n<ul>\n<li>类标记元组训练集记为$D$，$|D|$表示元组个数，例如上述数据$|D|=14$。</li>\n<li>类标号记为$m$，例如上述数据$m=2$，分别为进行、取消。</li>\n<li>属性集合记为为$C$，例如$C_1$为天气情况，$C_iD$是$D$中$C_i$类元组的集合，$|C_iD|$为$C_iD$中元组个数。</li>\n<li>属性标号记为$n$，例如上述数据$n=2$，分别为天气、温度、湿度、风速。</li>\n<li>$p_i$表示类别$i$的概率，比如$p(进行)=\\frac{9}{14}$。</li>\n</ul>\n<h4 id=\"2-1信息增益\"><a href=\"#2-1信息增益\" class=\"headerlink\" title=\"2.1信息增益\"></a>2.1信息增益</h4><p>信息增益实际上是ID3算法中用来进行属性选择度量的，具有较高信息增益的属性来作为节点N的分裂属性。该属性使结果划分中的元组分类所需信息量最小。</p>\n<p><strong>计算类别信息熵</strong>:类别信息熵表示的是所有样本中各种类别出现的不确定之和。根据熵的概念，熵越大，不确定性就越大，把事情理解清楚所需要的信息量就越多。对D中的元组分类所需的期望信息表达式如下，同时计算出上述数据的期望信息</p>\n<script type=\"math/tex; mode=display\">\nInfo(D)=-\\sum_{i=1}^{m}p_ilog_2(p_i)</script><script type=\"math/tex; mode=display\">\nInfo(D)=-\\frac{9}{14}log_2\\frac{9}{14}-\\frac{5}{14}log_2\\frac{5}{14}=0.940</script><p><strong>计算每个属性的信息熵</strong>:每个属性的信息熵相当于条件熵。表示的是在某种属性的条件下，各种类别出现的不确定之和。属性的信息熵越大，表示这个属性中拥有的样本类别越乱。现在假定按照属性集合C划分D中的元组，且属性Ci将D划分成v个不同的类。在该划分之后，为了得到准确的分类还需要下式进行度量。</p>\n<script type=\"math/tex; mode=display\">\nInfo_A(D)=\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*Info(D_j)</script><script type=\"math/tex; mode=display\">\nInfo(天气)=\\frac{5}{14}*[-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5}]+\\frac{4}{14}*[-\\frac{4}{4}log_2\\frac{4}{4}]+\\frac{5}{14}*[-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5}]=0.694</script><script type=\"math/tex; mode=display\">\nInfo(温度)=0.911,Info(湿度)=0.739,Info(风速)=0.892</script><p><strong>计算信息增益</strong>:信息增益=熵-条件熵，在这里表示为类别信息熵-属性信息熵。它表示的是信息不确定性减少的程度。如果一个属性的信息增益越大，就表示用这个属性进行样本划分可以更好的减少划分后样本的不确定性，选择该属性就可以更快更好的完成我们的分类目标。</p>\n<script type=\"math/tex; mode=display\">\nGain(A)=Info(D)-Info_A(D)</script><script type=\"math/tex; mode=display\">\nGain(天气)=Info(D)-Info(天气)=0.940-0.694=0.246</script><script type=\"math/tex; mode=display\">\nGain(温度)=0.029,Gain(湿度)=0.15,Gain(风速)=0.048</script><p>但是我们假设这种情况，每个属性中每个类别都只有一个样本，那这样属性信息熵就等于0，根据信息增益就无法选择出有效分类特征，所以C4.5算法选择使用信息增益率对ID3进行改进。</p>\n<h4 id=\"2-2信息增益率\"><a href=\"#2-2信息增益率\" class=\"headerlink\" title=\"2.2信息增益率\"></a>2.2信息增益率</h4><p><strong>计算属性分裂信息度量</strong>:用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息。信息增益率用<strong>信息增益 / 内在信息</strong>表示，信息增益率会导致属性的重要性随着内在信息的增大而减小<strong>（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）</strong>，这样算是对单纯用信息增益有所补偿。信息增益率定义如下</p>\n<script type=\"math/tex; mode=display\">\nSplitInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*log_2\\frac{|D_j|}{|D|}</script><script type=\"math/tex; mode=display\">\nSplitInfo(天气)=-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{4}{14}*log_2\\frac{4}{14}=1.577</script><script type=\"math/tex; mode=display\">\nSplitInfo(温度)=1.556,SplitInfo(湿度)=1.0,SplitInfo(风速)=0.985</script><script type=\"math/tex; mode=display\">\nGainRatio(A)=\\frac{Gain(A)}{SplitInfo(A)}</script><script type=\"math/tex; mode=display\">\nGainRatio(天气)=\\frac{Gain(天气)}{SplitInfo(天气)}=\\frac{0.246}{1.577}=0.155</script><script type=\"math/tex; mode=display\">\nGainRatio(温度)=0.0186,GainRatio(湿度)=0.151,GainRatio(风速)=0.048</script><p>天气的信息增益率最高，选择天气为分裂属性。分裂之后，天气是“阴”的条件下无其他分裂点，所以把它定义为叶子节点，选择较乱的结点继续分裂。重复上述过程，直到算法完成，我们便可得到决策树。</p>\n<h3 id=\"3-树剪枝\"><a href=\"#3-树剪枝\" class=\"headerlink\" title=\"3.树剪枝\"></a>3.树剪枝</h3><p>决策树创建过程中，由于数据中的噪声和离群点，许多分支反应的是训练数据中的异常。剪枝方法是用来处理这种过分拟合的问题，通常剪枝方法都是使用统计度量，减去最不可靠的分支。减枝方法分为先减枝和后剪枝。</p>\n<h4 id=\"3-1先剪枝\"><a href=\"#3-1先剪枝\" class=\"headerlink\" title=\"3.1先剪枝\"></a>3.1先剪枝</h4><p>先剪枝方法通过提前停止树的构造(比如决定在某个节点不再分裂或划分训练元组的自己)。但先剪枝有个视野效果缺点问题，也就是说在相同的标准下，也许当前扩展不能满足要求，但更进一步又能满足要求，这样会过早停止树的生长。先剪枝可通过以下方法</p>\n<ul>\n<li>当决策树达到一定的高度就停止决策树的生长。</li>\n<li>到达节点的实例个数小于某个阈值的时候也可以停止树的生长，不足之处是不能处理那些数量比较小的特殊情况。</li>\n<li>计算每次扩展对系统性能的增益，如果小于某个阈值就可以停止树的生长。</li>\n</ul>\n<h4 id=\"3-2后剪枝\"><a href=\"#3-2后剪枝\" class=\"headerlink\" title=\"3.2后剪枝\"></a>3.2后剪枝</h4><p>后剪枝是由完全生长的树剪去子树而形成，通过删除节点的分支并用树叶来替换它，树叶一般用子树中最频繁的类别来标记。C4.5采用悲观剪枝法，它使用训练集生成决策树，然后对生成的决策树进行剪枝，通过对比剪枝前后分类错误率来验证是否进行剪枝。</p>\n<p>把一颗子树的分类(具有多个叶子结点)的分类用一个叶子节点替换的话，在训练集上的误判率肯定是上升的，但是在新数据上则不一定，于是我们需要把子树的误判计算加上一个经验性的惩罚因子。对于一颗叶子节点，它覆盖了N个样本，其中有E个错误，那么该叶子节点的错误率为(E+0.5)/N。这个0.5就是惩罚因子，那么一颗子树，他有L个叶子节点，那么该子树的误判率为</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\sum (E_i+0.5*L)}{\\sum N_i}</script><p>这样的话我们可以看到一颗子树虽然有多个子节点，但由于加上惩罚因子，所以子树的误判率未必占到便宜。剪枝后内部节点变成叶子节点，其误判个数J也需要加上一个惩罚因子，变成J+0.5。那么子树是否可以被剪枝就取决于剪枝后的错误J+0.5的标准范围内。对于样本的误差率e，我们可以根据经验把它估计成各种各样的分布模型，比如二项式分布或正态分布。</p>\n<p>假如决策树正确分类的样本值为1，错误分类的样本值为0，该树错误分类的概率(误判率)为e(<strong>e为分布的固有属性，可以统计出来</strong>)，那么树的误判次数就是伯努利分布，我们可以估计出概述的误差次数均值和标准值。</p>\n<script type=\"math/tex; mode=display\">\nE(subtree\\_err\\_count)=N*e</script><script type=\"math/tex; mode=display\">\nvar(subtree\\_err\\_count)=\\sqrt{N*e*(1-e)}</script><p>把子树替换成叶子节点后，该叶子的误判次数也是伯努利分布，其概率误判率为(E+0.5)/N，因此叶子节点的误判次数均值为</p>\n<script type=\"math/tex; mode=display\">\nE(leaf\\_err\\_count)=N*e</script><p>使用训练数据时，子树总是比替换为一个叶节点后产生的误差小，但是使用校正后有误差计算方法却并非如此，当子树的误判个数减去标准差后大于对应叶节点的误判个数，就决定剪枝</p>\n<script type=\"math/tex; mode=display\">\nE(subtree\\_err\\_count)-var(subtree\\_err\\_count)>E(leaf\\_err\\_count)</script><p>上述条件就是剪枝的标准。当然并不一定非要减去标准差，可以给定任意的置信区间，我们设定一定的显著性因子，就可以估算出误判次数的上下界。</p>\n<h3 id=\"4-Sklearn实现决策树\"><a href=\"#4-Sklearn实现决策树\" class=\"headerlink\" title=\"4.Sklearn实现决策树\"></a>4.Sklearn实现决策树</h3><p>我们以sklearn中iris数据作为训练集，iris属性特征包括花萼长度、花萼宽度、花瓣长度、花瓣宽度，类别共三类，分别为Setosa、Versicolour、Virginca。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入数据</span></span><br><span class=\"line\">iris=load_iris()</span><br><span class=\"line\">X=iris.data</span><br><span class=\"line\">y=iris.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练数据和模型,采用ID3或C4.5训练</span></span><br><span class=\"line\">clf=tree.DecisionTreeClassifier(criterion=<span class=\"string\">'entropy'</span>)</span><br><span class=\"line\">clf=clf.fit(X,y)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入graphviz模块用来导出图,结果图如下所示</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> graphviz</span><br><span class=\"line\">dot_data=tree.export_graphviz(clf,out_file=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">                              feature_names=iris.feature_names,</span><br><span class=\"line\">                              class_names=iris.target_names,</span><br><span class=\"line\">                              filled=<span class=\"keyword\">True</span>,rounded=<span class=\"keyword\">True</span>,</span><br><span class=\"line\">                              special_characters=<span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">graph=graphviz.Source(dot_data)</span><br><span class=\"line\">graph.view()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/19/机器学习之决策树-C4-5算法/机器学习之决策树图片02.png\" alt=\"机器学习之决策树图片02\"></p>\n<h3 id=\"5-实际使用技巧\"><a href=\"#5-实际使用技巧\" class=\"headerlink\" title=\"5.实际使用技巧\"></a>5.实际使用技巧</h3><ul>\n<li>对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。</li>\n<li>训练之前平衡数据集，以防止决策树偏向于主导类。可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (<code>sample_weight</code>) 的和归一化为相同的值。</li>\n<li>考虑实现进行降维(PCA、ICA)，使决策树能够更好地找到具有分辨性的特征。</li>\n<li>通过 <code>export</code> 功能可以可视化您的决策树。使用 <code>max_depth=3</code>作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。</li>\n<li>填充树的样本数量会增加树的每个附加级别。使用 <code>max_depth</code> 来控制树的大小防止过拟合。</li>\n<li>通过使用 <code>min_samples_split</code> 和 <code>min_samples_leaf</code> 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-决策树简介\"><a href=\"#1-决策树简介\" class=\"headerlink\" title=\"1.决策树简介\"></a>1.决策树简介</h3><p>我们已有如下所示数据集，特征属性包含天气、温度、湿度、风速，然后根据这些数据去分类或预测能否去打高尔夫球，针对此类问题你会怎么解决呢。</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th style=\"text-align:center\">天气</th>\n<th style=\"text-align:center\">温度</th>\n<th style=\"text-align:center\">湿度</th>\n<th style=\"text-align:center\">风速</th>\n<th style=\"text-align:center\">高尔夫</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>2</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>3</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>4</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>5</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>6</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>7</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>8</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>9</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">寒冷</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>10</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>11</td>\n<td style=\"text-align:center\">晴</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>12</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">进行</td>\n</tr>\n<tr>\n<td>13</td>\n<td style=\"text-align:center\">阴</td>\n<td style=\"text-align:center\">炎热</td>\n<td style=\"text-align:center\">正常</td>\n<td style=\"text-align:center\">弱</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n<tr>\n<td>14</td>\n<td style=\"text-align:center\">雨</td>\n<td style=\"text-align:center\">适中</td>\n<td style=\"text-align:center\">高</td>\n<td style=\"text-align:center\">强</td>\n<td style=\"text-align:center\">取消</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>正当你苦思冥想之时，天空之中突然飘来一张决策图，发现这图好像一张倒着的树啊，于是你命名为决策树。你发现可直接根据决策树得到相应结果，高兴的像个300斤的孩子。但下次再面临这样的问题时，还能够那么好运嘛？于是你陷入苦苦思考之中，怎样才能得到分类决策树呢。</p>\n<p><img src=\"/2018/04/19/机器学习之决策树-C4-5算法/机器学习之决策树图片01.png\" alt=\"机器学习之决策树图片01\"></p>\n<h3 id=\"2-C4-5算法\"><a href=\"#2-C4-5算法\" class=\"headerlink\" title=\"2.C4.5算法\"></a>2.C4.5算法</h3><p><strong>上古之神赐予你智慧</strong>：C4.5是一系列用在机器学习和数据挖掘中分类问题的算法，它的目标是监督学习。即给定一个数据集，其中的每一个元组都能用一组属性值描述，每一个元组属于一个互斥的类别中的某一类。C4.5的目标是通过学习，找到一个从属性值到类别的映射关系，并且这个映射能够用于对新的类别未知的实体进行分类。</p>\n<p>C4.5是在ID3的基础上提出的。ID3算法用来构造决策树。决策树是一种类似流程图的树结构，其中每个内部节点（非树叶节点）表示在一个属性上的测试，每个分枝代表一个测试输出，而每个树叶节点存放一个类标号。一旦建立好决策树，对于一个未给定类标号的元组，跟踪一条有根节点到叶节点的路径，该叶节点就存放着该元组的预测。上述数据集有4个属性，属性集合A={天气、温度、湿度、风速}，类别集合D={进行、取消}。我们先做一些假设</p>\n<ul>\n<li>类标记元组训练集记为$D$，$|D|$表示元组个数，例如上述数据$|D|=14$。</li>\n<li>类标号记为$m$，例如上述数据$m=2$，分别为进行、取消。</li>\n<li>属性集合记为为$C$，例如$C_1$为天气情况，$C_iD$是$D$中$C_i$类元组的集合，$|C_iD|$为$C_iD$中元组个数。</li>\n<li>属性标号记为$n$，例如上述数据$n=2$，分别为天气、温度、湿度、风速。</li>\n<li>$p_i$表示类别$i$的概率，比如$p(进行)=\\frac{9}{14}$。</li>\n</ul>\n<h4 id=\"2-1信息增益\"><a href=\"#2-1信息增益\" class=\"headerlink\" title=\"2.1信息增益\"></a>2.1信息增益</h4><p>信息增益实际上是ID3算法中用来进行属性选择度量的，具有较高信息增益的属性来作为节点N的分裂属性。该属性使结果划分中的元组分类所需信息量最小。</p>\n<p><strong>计算类别信息熵</strong>:类别信息熵表示的是所有样本中各种类别出现的不确定之和。根据熵的概念，熵越大，不确定性就越大，把事情理解清楚所需要的信息量就越多。对D中的元组分类所需的期望信息表达式如下，同时计算出上述数据的期望信息</p>\n<script type=\"math/tex; mode=display\">\nInfo(D)=-\\sum_{i=1}^{m}p_ilog_2(p_i)</script><script type=\"math/tex; mode=display\">\nInfo(D)=-\\frac{9}{14}log_2\\frac{9}{14}-\\frac{5}{14}log_2\\frac{5}{14}=0.940</script><p><strong>计算每个属性的信息熵</strong>:每个属性的信息熵相当于条件熵。表示的是在某种属性的条件下，各种类别出现的不确定之和。属性的信息熵越大，表示这个属性中拥有的样本类别越乱。现在假定按照属性集合C划分D中的元组，且属性Ci将D划分成v个不同的类。在该划分之后，为了得到准确的分类还需要下式进行度量。</p>\n<script type=\"math/tex; mode=display\">\nInfo_A(D)=\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*Info(D_j)</script><script type=\"math/tex; mode=display\">\nInfo(天气)=\\frac{5}{14}*[-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5}]+\\frac{4}{14}*[-\\frac{4}{4}log_2\\frac{4}{4}]+\\frac{5}{14}*[-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5}]=0.694</script><script type=\"math/tex; mode=display\">\nInfo(温度)=0.911,Info(湿度)=0.739,Info(风速)=0.892</script><p><strong>计算信息增益</strong>:信息增益=熵-条件熵，在这里表示为类别信息熵-属性信息熵。它表示的是信息不确定性减少的程度。如果一个属性的信息增益越大，就表示用这个属性进行样本划分可以更好的减少划分后样本的不确定性，选择该属性就可以更快更好的完成我们的分类目标。</p>\n<script type=\"math/tex; mode=display\">\nGain(A)=Info(D)-Info_A(D)</script><script type=\"math/tex; mode=display\">\nGain(天气)=Info(D)-Info(天气)=0.940-0.694=0.246</script><script type=\"math/tex; mode=display\">\nGain(温度)=0.029,Gain(湿度)=0.15,Gain(风速)=0.048</script><p>但是我们假设这种情况，每个属性中每个类别都只有一个样本，那这样属性信息熵就等于0，根据信息增益就无法选择出有效分类特征，所以C4.5算法选择使用信息增益率对ID3进行改进。</p>\n<h4 id=\"2-2信息增益率\"><a href=\"#2-2信息增益率\" class=\"headerlink\" title=\"2.2信息增益率\"></a>2.2信息增益率</h4><p><strong>计算属性分裂信息度量</strong>:用分裂信息度量来考虑某种属性进行分裂时分支的数量信息和尺寸信息，我们把这些信息称为属性的内在信息。信息增益率用<strong>信息增益 / 内在信息</strong>表示，信息增益率会导致属性的重要性随着内在信息的增大而减小<strong>（也就是说，如果这个属性本身不确定性就很大，那我就越不倾向于选取它）</strong>，这样算是对单纯用信息增益有所补偿。信息增益率定义如下</p>\n<script type=\"math/tex; mode=display\">\nSplitInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}*log_2\\frac{|D_j|}{|D|}</script><script type=\"math/tex; mode=display\">\nSplitInfo(天气)=-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{5}{14}*log_2\\frac{5}{14}-\\frac{4}{14}*log_2\\frac{4}{14}=1.577</script><script type=\"math/tex; mode=display\">\nSplitInfo(温度)=1.556,SplitInfo(湿度)=1.0,SplitInfo(风速)=0.985</script><script type=\"math/tex; mode=display\">\nGainRatio(A)=\\frac{Gain(A)}{SplitInfo(A)}</script><script type=\"math/tex; mode=display\">\nGainRatio(天气)=\\frac{Gain(天气)}{SplitInfo(天气)}=\\frac{0.246}{1.577}=0.155</script><script type=\"math/tex; mode=display\">\nGainRatio(温度)=0.0186,GainRatio(湿度)=0.151,GainRatio(风速)=0.048</script><p>天气的信息增益率最高，选择天气为分裂属性。分裂之后，天气是“阴”的条件下无其他分裂点，所以把它定义为叶子节点，选择较乱的结点继续分裂。重复上述过程，直到算法完成，我们便可得到决策树。</p>\n<h3 id=\"3-树剪枝\"><a href=\"#3-树剪枝\" class=\"headerlink\" title=\"3.树剪枝\"></a>3.树剪枝</h3><p>决策树创建过程中，由于数据中的噪声和离群点，许多分支反应的是训练数据中的异常。剪枝方法是用来处理这种过分拟合的问题，通常剪枝方法都是使用统计度量，减去最不可靠的分支。减枝方法分为先减枝和后剪枝。</p>\n<h4 id=\"3-1先剪枝\"><a href=\"#3-1先剪枝\" class=\"headerlink\" title=\"3.1先剪枝\"></a>3.1先剪枝</h4><p>先剪枝方法通过提前停止树的构造(比如决定在某个节点不再分裂或划分训练元组的自己)。但先剪枝有个视野效果缺点问题，也就是说在相同的标准下，也许当前扩展不能满足要求，但更进一步又能满足要求，这样会过早停止树的生长。先剪枝可通过以下方法</p>\n<ul>\n<li>当决策树达到一定的高度就停止决策树的生长。</li>\n<li>到达节点的实例个数小于某个阈值的时候也可以停止树的生长，不足之处是不能处理那些数量比较小的特殊情况。</li>\n<li>计算每次扩展对系统性能的增益，如果小于某个阈值就可以停止树的生长。</li>\n</ul>\n<h4 id=\"3-2后剪枝\"><a href=\"#3-2后剪枝\" class=\"headerlink\" title=\"3.2后剪枝\"></a>3.2后剪枝</h4><p>后剪枝是由完全生长的树剪去子树而形成，通过删除节点的分支并用树叶来替换它，树叶一般用子树中最频繁的类别来标记。C4.5采用悲观剪枝法，它使用训练集生成决策树，然后对生成的决策树进行剪枝，通过对比剪枝前后分类错误率来验证是否进行剪枝。</p>\n<p>把一颗子树的分类(具有多个叶子结点)的分类用一个叶子节点替换的话，在训练集上的误判率肯定是上升的，但是在新数据上则不一定，于是我们需要把子树的误判计算加上一个经验性的惩罚因子。对于一颗叶子节点，它覆盖了N个样本，其中有E个错误，那么该叶子节点的错误率为(E+0.5)/N。这个0.5就是惩罚因子，那么一颗子树，他有L个叶子节点，那么该子树的误判率为</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\sum (E_i+0.5*L)}{\\sum N_i}</script><p>这样的话我们可以看到一颗子树虽然有多个子节点，但由于加上惩罚因子，所以子树的误判率未必占到便宜。剪枝后内部节点变成叶子节点，其误判个数J也需要加上一个惩罚因子，变成J+0.5。那么子树是否可以被剪枝就取决于剪枝后的错误J+0.5的标准范围内。对于样本的误差率e，我们可以根据经验把它估计成各种各样的分布模型，比如二项式分布或正态分布。</p>\n<p>假如决策树正确分类的样本值为1，错误分类的样本值为0，该树错误分类的概率(误判率)为e(<strong>e为分布的固有属性，可以统计出来</strong>)，那么树的误判次数就是伯努利分布，我们可以估计出概述的误差次数均值和标准值。</p>\n<script type=\"math/tex; mode=display\">\nE(subtree\\_err\\_count)=N*e</script><script type=\"math/tex; mode=display\">\nvar(subtree\\_err\\_count)=\\sqrt{N*e*(1-e)}</script><p>把子树替换成叶子节点后，该叶子的误判次数也是伯努利分布，其概率误判率为(E+0.5)/N，因此叶子节点的误判次数均值为</p>\n<script type=\"math/tex; mode=display\">\nE(leaf\\_err\\_count)=N*e</script><p>使用训练数据时，子树总是比替换为一个叶节点后产生的误差小，但是使用校正后有误差计算方法却并非如此，当子树的误判个数减去标准差后大于对应叶节点的误判个数，就决定剪枝</p>\n<script type=\"math/tex; mode=display\">\nE(subtree\\_err\\_count)-var(subtree\\_err\\_count)>E(leaf\\_err\\_count)</script><p>上述条件就是剪枝的标准。当然并不一定非要减去标准差，可以给定任意的置信区间，我们设定一定的显著性因子，就可以估算出误判次数的上下界。</p>\n<h3 id=\"4-Sklearn实现决策树\"><a href=\"#4-Sklearn实现决策树\" class=\"headerlink\" title=\"4.Sklearn实现决策树\"></a>4.Sklearn实现决策树</h3><p>我们以sklearn中iris数据作为训练集，iris属性特征包括花萼长度、花萼宽度、花瓣长度、花瓣宽度，类别共三类，分别为Setosa、Versicolour、Virginca。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> load_iris</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入数据</span></span><br><span class=\"line\">iris=load_iris()</span><br><span class=\"line\">X=iris.data</span><br><span class=\"line\">y=iris.target</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练数据和模型,采用ID3或C4.5训练</span></span><br><span class=\"line\">clf=tree.DecisionTreeClassifier(criterion=<span class=\"string\">'entropy'</span>)</span><br><span class=\"line\">clf=clf.fit(X,y)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#引入graphviz模块用来导出图,结果图如下所示</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> graphviz</span><br><span class=\"line\">dot_data=tree.export_graphviz(clf,out_file=<span class=\"keyword\">None</span>,</span><br><span class=\"line\">                              feature_names=iris.feature_names,</span><br><span class=\"line\">                              class_names=iris.target_names,</span><br><span class=\"line\">                              filled=<span class=\"keyword\">True</span>,rounded=<span class=\"keyword\">True</span>,</span><br><span class=\"line\">                              special_characters=<span class=\"keyword\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">graph=graphviz.Source(dot_data)</span><br><span class=\"line\">graph.view()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2018/04/19/机器学习之决策树-C4-5算法/机器学习之决策树图片02.png\" alt=\"机器学习之决策树图片02\"></p>\n<h3 id=\"5-实际使用技巧\"><a href=\"#5-实际使用技巧\" class=\"headerlink\" title=\"5.实际使用技巧\"></a>5.实际使用技巧</h3><ul>\n<li>对于拥有大量特征的数据决策树会出现过拟合的现象。获得一个合适的样本比例和特征数量十分重要，因为在高维空间中只有少量的样本的树是十分容易过拟合的。</li>\n<li>训练之前平衡数据集，以防止决策树偏向于主导类。可以通过从每个类中抽取相等数量的样本来进行类平衡，或者优选地通过将每个类的样本权重 (<code>sample_weight</code>) 的和归一化为相同的值。</li>\n<li>考虑实现进行降维(PCA、ICA)，使决策树能够更好地找到具有分辨性的特征。</li>\n<li>通过 <code>export</code> 功能可以可视化您的决策树。使用 <code>max_depth=3</code>作为初始树深度，让决策树知道如何适应您的数据，然后再增加树的深度。</li>\n<li>填充树的样本数量会增加树的每个附加级别。使用 <code>max_depth</code> 来控制树的大小防止过拟合。</li>\n<li>通过使用 <code>min_samples_split</code> 和 <code>min_samples_leaf</code> 来控制叶节点上的样本数量。当这个值很小时意味着生成的决策树将会过拟合，然而当这个值很大时将会不利于决策树的对样本的学习。</li>\n</ul>\n"},{"title":"机器学习之线性回归","date":"2018-03-24T15:27:53.000Z","comments":1,"mathjax":true,"_content":"### 1.线性回归分析（ Linear Regression Analysis）\n**线性回归分析（Regression Analysis）**：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围内的。\n通俗来讲就是我们在做数学题的时候，解未知数的方法。假如给定自变量和函数，通过函数处理自变量，然后获得函数的解。而回归分析便是相当于给定自变量和函数的解，然后去求函数。如下图所示，我们已经知道红色点坐标，然后回归得到直线，回归分析属于**监督学习**。\n![图片01](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8701.png)\n上图只是简单的一元线性分析，回归后我们可以得到如$f(x)=a*x+b$的函数表达式，但更多情况下我们是求解多元线性回归问题，那应该如何解决呢。\n### 2.模型表达\n建立数学模型之前，我们先定义如下变量。\n-  $x_i$表示输入数据（Feature）\n-  $y_i$表示输出数据（Target）\n-  $(x_i,y_i)$表示一组训练数据（Training example）\n- m表示训练数据的个数\n-  n表示特征数量\n\n监督学习目标便是根据给定的训练数据，可以得到函数方法，使得假设函数$h$(hypothesis)满足$h(x)->y$。针对线性回归而言，函数$h(x)$表达式为\n\n$$h(x)=\\theta_0+\\theta_1*x_i+\\theta_2*x_2+...+\\theta_n*x_n$$\n\n$为$方便我们使用矩阵来表达，$h(x)=\\theta^T*x$，其中$\\theta^T$为$\\theta$的转置。为求解函数$h(x)$，我们希望找出一组$\\theta$，使得$h(x)-y$无限趋近0，此处我们引入梯度下降算法求解问题。\n\n### 3.梯度下降算法\n#### 3.1梯度下降算法简述\n实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都能到达山脚，可能到达山峰的某个局部最低点。\n\n![图片02](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8702.png)\n从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解线性回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。\n#### 3.2 梯度下降算法相关概念\n求解梯度下降算法之前，我们先了解相关概念。\n- **步长（Learning Rate）**：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。\n- **特征（Feature）**：即上述描述的$x_i,y_i$\n- **假设函数（Hypothesis Function）**：监督学习中，为了拟合输入样本，而使用假设函数$h(x)$\n- **损失函数（Loss Function）**：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。线性回归损失函数为$$J(\\theta)=\\frac{1}{2m}*\\sum_{i=1}^{n}(h(x)^{(i)}-y^{(i)})$$\n我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。\n\n#### 3.3梯度下降算法过程\n\n- 随机选取一组$\\theta$。\n- 不断变化$\\theta$，让$J(\\theta)$变小。\n    $$\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)$$\n$j=0,1,2...n$，$\\theta_j$是n+1个值同时变化。$\\alpha$表示学习速率，目标求最小值，因此沿负梯度方向下降，故$\\theta$前为负号。$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导。\n- 直到$J(\\theta)​$得到最小值。\n\n$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导求解过程如下：\n$$\\frac{\\partial}{\\partial\\theta_j}J(\\theta)=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}(h_\\theta(x)-y)^2$$\n$$=2\\cdot\\frac{1}{2}(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)$$\n$$=(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)$$\n$$=(h_\\theta(x)-y)\\cdot x_j$$\n因此梯度下降算法的最终表述为\nRepeat Until Convergence{\n$$\\theta_j:=\\theta_j-\\alpha\\sum_{i=1}^{n}((h_\\theta(x^{(i)})-y^{(i)})\\cdot x_j) $$ for every  $j$\n}\n梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到线性回归函数。\n### 4.线性回归算法实现\n为研究公司盈利提升幅度受电视、广播、报纸的投入的影响程度，利用多元线性回归来分析数据。其中数据下载地址为http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv ，为能够绘制出三维图片，此处只选择电视、广播的广告投入对公司盈利提升幅度的影响。\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom mpl_toolkits.mplot3d import axes3d\nimport seaborn as sns\n\n#read_csv\nreaddata=pd.read_csv('data/Advertising.csv')\ndata=np.array(readdata.values)\n\n#训练数据\nX_train=data[0:150,1:3]\nY_train=data[0:150,3]\n\n#测试数据\nX_test=data[150:200,1:3]\nY_test=data[150:200,3]\n\n#回归分析\nregr = linear_model.LinearRegression()\n#进行training set和test set的fit，即是训练的过程\nregr.fit(X_train, Y_train)\n\n# 打印出相关系数和截距等信息\nprint('Coefficients: \\n', regr.coef_)\nprint('Intercept: ', regr.intercept_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((regr.predict(X_test) - Y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regr.score(X_test, Y_test))\n\n#得出回归函数 并自定义数据\nX_line=np.linspace(0,300)\nY_line=np.linspace(0,50)\nZ_line=0.04699836*X_line+0.17913965*Y_line+3.00431061176\n\n#画图\nfig=plt.figure()\nax = plt.subplot(111, projection='3d')  # 创建一个三维的绘图工程\nax.scatter(data[:,1],data[:,2],data[:,3],c='red',)  # 绘制数据点\nax.plot(X_line,Y_line,Z_line,c='blue')#绘制回归曲线\nplt.show()\n```\n\n![图片](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8703.png)\n其中红色为数据点，蓝色线便为我们回归之后的曲线，这里我们是利用sklearn进行线性回归分析，后续会写出sklearn教程。如有错误之处还请指正，谢谢。\n\n------\n\n### 5.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n![推广](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%8E%A8%E5%B9%BF.png)\n\n\n\n","source":"_posts/机器学习之线性回归.md","raw":"---\ntitle: 机器学习之线性回归\ndate: 2018-03-24 23:27:53\ntags: [机器学习,算法]\ncategories: 机器学习\ncomments: true\nmathjax: true\n---\n### 1.线性回归分析（ Linear Regression Analysis）\n**线性回归分析（Regression Analysis）**：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围内的。\n通俗来讲就是我们在做数学题的时候，解未知数的方法。假如给定自变量和函数，通过函数处理自变量，然后获得函数的解。而回归分析便是相当于给定自变量和函数的解，然后去求函数。如下图所示，我们已经知道红色点坐标，然后回归得到直线，回归分析属于**监督学习**。\n![图片01](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8701.png)\n上图只是简单的一元线性分析，回归后我们可以得到如$f(x)=a*x+b$的函数表达式，但更多情况下我们是求解多元线性回归问题，那应该如何解决呢。\n### 2.模型表达\n建立数学模型之前，我们先定义如下变量。\n-  $x_i$表示输入数据（Feature）\n-  $y_i$表示输出数据（Target）\n-  $(x_i,y_i)$表示一组训练数据（Training example）\n- m表示训练数据的个数\n-  n表示特征数量\n\n监督学习目标便是根据给定的训练数据，可以得到函数方法，使得假设函数$h$(hypothesis)满足$h(x)->y$。针对线性回归而言，函数$h(x)$表达式为\n\n$$h(x)=\\theta_0+\\theta_1*x_i+\\theta_2*x_2+...+\\theta_n*x_n$$\n\n$为$方便我们使用矩阵来表达，$h(x)=\\theta^T*x$，其中$\\theta^T$为$\\theta$的转置。为求解函数$h(x)$，我们希望找出一组$\\theta$，使得$h(x)-y$无限趋近0，此处我们引入梯度下降算法求解问题。\n\n### 3.梯度下降算法\n#### 3.1梯度下降算法简述\n实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都能到达山脚，可能到达山峰的某个局部最低点。\n\n![图片02](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8702.png)\n从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解线性回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。\n#### 3.2 梯度下降算法相关概念\n求解梯度下降算法之前，我们先了解相关概念。\n- **步长（Learning Rate）**：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。\n- **特征（Feature）**：即上述描述的$x_i,y_i$\n- **假设函数（Hypothesis Function）**：监督学习中，为了拟合输入样本，而使用假设函数$h(x)$\n- **损失函数（Loss Function）**：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。线性回归损失函数为$$J(\\theta)=\\frac{1}{2m}*\\sum_{i=1}^{n}(h(x)^{(i)}-y^{(i)})$$\n我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。\n\n#### 3.3梯度下降算法过程\n\n- 随机选取一组$\\theta$。\n- 不断变化$\\theta$，让$J(\\theta)$变小。\n    $$\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)$$\n$j=0,1,2...n$，$\\theta_j$是n+1个值同时变化。$\\alpha$表示学习速率，目标求最小值，因此沿负梯度方向下降，故$\\theta$前为负号。$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导。\n- 直到$J(\\theta)​$得到最小值。\n\n$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导求解过程如下：\n$$\\frac{\\partial}{\\partial\\theta_j}J(\\theta)=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}(h_\\theta(x)-y)^2$$\n$$=2\\cdot\\frac{1}{2}(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)$$\n$$=(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)$$\n$$=(h_\\theta(x)-y)\\cdot x_j$$\n因此梯度下降算法的最终表述为\nRepeat Until Convergence{\n$$\\theta_j:=\\theta_j-\\alpha\\sum_{i=1}^{n}((h_\\theta(x^{(i)})-y^{(i)})\\cdot x_j) $$ for every  $j$\n}\n梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到线性回归函数。\n### 4.线性回归算法实现\n为研究公司盈利提升幅度受电视、广播、报纸的投入的影响程度，利用多元线性回归来分析数据。其中数据下载地址为http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv ，为能够绘制出三维图片，此处只选择电视、广播的广告投入对公司盈利提升幅度的影响。\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom mpl_toolkits.mplot3d import axes3d\nimport seaborn as sns\n\n#read_csv\nreaddata=pd.read_csv('data/Advertising.csv')\ndata=np.array(readdata.values)\n\n#训练数据\nX_train=data[0:150,1:3]\nY_train=data[0:150,3]\n\n#测试数据\nX_test=data[150:200,1:3]\nY_test=data[150:200,3]\n\n#回归分析\nregr = linear_model.LinearRegression()\n#进行training set和test set的fit，即是训练的过程\nregr.fit(X_train, Y_train)\n\n# 打印出相关系数和截距等信息\nprint('Coefficients: \\n', regr.coef_)\nprint('Intercept: ', regr.intercept_)\n# The mean square error\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((regr.predict(X_test) - Y_test) ** 2))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regr.score(X_test, Y_test))\n\n#得出回归函数 并自定义数据\nX_line=np.linspace(0,300)\nY_line=np.linspace(0,50)\nZ_line=0.04699836*X_line+0.17913965*Y_line+3.00431061176\n\n#画图\nfig=plt.figure()\nax = plt.subplot(111, projection='3d')  # 创建一个三维的绘图工程\nax.scatter(data[:,1],data[:,2],data[:,3],c='red',)  # 绘制数据点\nax.plot(X_line,Y_line,Z_line,c='blue')#绘制回归曲线\nplt.show()\n```\n\n![图片](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8703.png)\n其中红色为数据点，蓝色线便为我们回归之后的曲线，这里我们是利用sklearn进行线性回归分析，后续会写出sklearn教程。如有错误之处还请指正，谢谢。\n\n------\n\n### 5.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n![推广](http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%8E%A8%E5%B9%BF.png)\n\n\n\n","slug":"机器学习之线性回归","published":1,"updated":"2018-03-26T16:29:50.742Z","layout":"post","photos":[],"link":"","_id":"cjg7s0pqs000m3201cs3bssz4","content":"<h3 id=\"1-线性回归分析（-Linear-Regression-Analysis）\"><a href=\"#1-线性回归分析（-Linear-Regression-Analysis）\" class=\"headerlink\" title=\"1.线性回归分析（ Linear Regression Analysis）\"></a>1.线性回归分析（ Linear Regression Analysis）</h3><p><strong>线性回归分析（Regression Analysis）</strong>：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围内的。<br>通俗来讲就是我们在做数学题的时候，解未知数的方法。假如给定自变量和函数，通过函数处理自变量，然后获得函数的解。而回归分析便是相当于给定自变量和函数的解，然后去求函数。如下图所示，我们已经知道红色点坐标，然后回归得到直线，回归分析属于<strong>监督学习</strong>。<br><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8701.png\" alt=\"图片01\"><br>上图只是简单的一元线性分析，回归后我们可以得到如$f(x)=a*x+b$的函数表达式，但更多情况下我们是求解多元线性回归问题，那应该如何解决呢。</p>\n<h3 id=\"2-模型表达\"><a href=\"#2-模型表达\" class=\"headerlink\" title=\"2.模型表达\"></a>2.模型表达</h3><p>建立数学模型之前，我们先定义如下变量。</p>\n<ul>\n<li>$x_i$表示输入数据（Feature）</li>\n<li>$y_i$表示输出数据（Target）</li>\n<li>$(x_i,y_i)$表示一组训练数据（Training example）</li>\n<li>m表示训练数据的个数</li>\n<li>n表示特征数量</li>\n</ul>\n<p>监督学习目标便是根据给定的训练数据，可以得到函数方法，使得假设函数$h$(hypothesis)满足$h(x)-&gt;y$。针对线性回归而言，函数$h(x)$表达式为</p>\n<script type=\"math/tex; mode=display\">h(x)=\\theta_0+\\theta_1*x_i+\\theta_2*x_2+...+\\theta_n*x_n</script><p>$为$方便我们使用矩阵来表达，$h(x)=\\theta^T*x$，其中$\\theta^T$为$\\theta$的转置。为求解函数$h(x)$，我们希望找出一组$\\theta$，使得$h(x)-y$无限趋近0，此处我们引入梯度下降算法求解问题。</p>\n<h3 id=\"3-梯度下降算法\"><a href=\"#3-梯度下降算法\" class=\"headerlink\" title=\"3.梯度下降算法\"></a>3.梯度下降算法</h3><h4 id=\"3-1梯度下降算法简述\"><a href=\"#3-1梯度下降算法简述\" class=\"headerlink\" title=\"3.1梯度下降算法简述\"></a>3.1梯度下降算法简述</h4><p>实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都能到达山脚，可能到达山峰的某个局部最低点。</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8702.png\" alt=\"图片02\"><br>从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解线性回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。</p>\n<h4 id=\"3-2-梯度下降算法相关概念\"><a href=\"#3-2-梯度下降算法相关概念\" class=\"headerlink\" title=\"3.2 梯度下降算法相关概念\"></a>3.2 梯度下降算法相关概念</h4><p>求解梯度下降算法之前，我们先了解相关概念。</p>\n<ul>\n<li><strong>步长（Learning Rate）</strong>：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。</li>\n<li><strong>特征（Feature）</strong>：即上述描述的$x_i,y_i$</li>\n<li><strong>假设函数（Hypothesis Function）</strong>：监督学习中，为了拟合输入样本，而使用假设函数$h(x)$</li>\n<li><strong>损失函数（Loss Function）</strong>：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。线性回归损失函数为<script type=\"math/tex\">J(\\theta)=\\frac{1}{2m}*\\sum_{i=1}^{n}(h(x)^{(i)}-y^{(i)})</script><br>我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。</li>\n</ul>\n<h4 id=\"3-3梯度下降算法过程\"><a href=\"#3-3梯度下降算法过程\" class=\"headerlink\" title=\"3.3梯度下降算法过程\"></a>3.3梯度下降算法过程</h4><ul>\n<li>随机选取一组$\\theta$。</li>\n<li>不断变化$\\theta$，让$J(\\theta)$变小。<script type=\"math/tex; mode=display\">\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)</script>$j=0,1,2…n$，$\\theta_j$是n+1个值同时变化。$\\alpha$表示学习速率，目标求最小值，因此沿负梯度方向下降，故$\\theta$前为负号。$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导。</li>\n<li>直到$J(\\theta)​$得到最小值。</li>\n</ul>\n<p>$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导求解过程如下：</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial\\theta_j}J(\\theta)=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}(h_\\theta(x)-y)^2</script><script type=\"math/tex; mode=display\">=2\\cdot\\frac{1}{2}(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)</script><script type=\"math/tex; mode=display\">=(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)</script><script type=\"math/tex; mode=display\">=(h_\\theta(x)-y)\\cdot x_j</script><p>因此梯度下降算法的最终表述为<br>Repeat Until Convergence{</p>\n<p><script type=\"math/tex\">\\theta_j:=\\theta_j-\\alpha\\sum_{i=1}^{n}((h_\\theta(x^{(i)})-y^{(i)})\\cdot x_j)</script> for every  $j$<br>}<br>梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到线性回归函数。</p>\n<h3 id=\"4-线性回归算法实现\"><a href=\"#4-线性回归算法实现\" class=\"headerlink\" title=\"4.线性回归算法实现\"></a>4.线性回归算法实现</h3><p>为研究公司盈利提升幅度受电视、广播、报纸的投入的影响程度，利用多元线性回归来分析数据。其中数据下载地址为<a href=\"http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv\" target=\"_blank\" rel=\"noopener\">http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv</a> ，为能够绘制出三维图片，此处只选择电视、广播的广告投入对公司盈利提升幅度的影响。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> axes3d</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#read_csv</span></span><br><span class=\"line\">readdata=pd.read_csv(<span class=\"string\">'data/Advertising.csv'</span>)</span><br><span class=\"line\">data=np.array(readdata.values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练数据</span></span><br><span class=\"line\">X_train=data[<span class=\"number\">0</span>:<span class=\"number\">150</span>,<span class=\"number\">1</span>:<span class=\"number\">3</span>]</span><br><span class=\"line\">Y_train=data[<span class=\"number\">0</span>:<span class=\"number\">150</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#测试数据</span></span><br><span class=\"line\">X_test=data[<span class=\"number\">150</span>:<span class=\"number\">200</span>,<span class=\"number\">1</span>:<span class=\"number\">3</span>]</span><br><span class=\"line\">Y_test=data[<span class=\"number\">150</span>:<span class=\"number\">200</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#回归分析</span></span><br><span class=\"line\">regr = linear_model.LinearRegression()</span><br><span class=\"line\"><span class=\"comment\">#进行training set和test set的fit，即是训练的过程</span></span><br><span class=\"line\">regr.fit(X_train, Y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印出相关系数和截距等信息</span></span><br><span class=\"line\">print(<span class=\"string\">'Coefficients: \\n'</span>, regr.coef_)</span><br><span class=\"line\">print(<span class=\"string\">'Intercept: '</span>, regr.intercept_)</span><br><span class=\"line\"><span class=\"comment\"># The mean square error</span></span><br><span class=\"line\">print(<span class=\"string\">\"Residual sum of squares: %.2f\"</span></span><br><span class=\"line\">      % np.mean((regr.predict(X_test) - Y_test) ** <span class=\"number\">2</span>))</span><br><span class=\"line\"><span class=\"comment\"># Explained variance score: 1 is perfect prediction</span></span><br><span class=\"line\">print(<span class=\"string\">'Variance score: %.2f'</span> % regr.score(X_test, Y_test))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#得出回归函数 并自定义数据</span></span><br><span class=\"line\">X_line=np.linspace(<span class=\"number\">0</span>,<span class=\"number\">300</span>)</span><br><span class=\"line\">Y_line=np.linspace(<span class=\"number\">0</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">Z_line=<span class=\"number\">0.04699836</span>*X_line+<span class=\"number\">0.17913965</span>*Y_line+<span class=\"number\">3.00431061176</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">fig=plt.figure()</span><br><span class=\"line\">ax = plt.subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">'3d'</span>)  <span class=\"comment\"># 创建一个三维的绘图工程</span></span><br><span class=\"line\">ax.scatter(data[:,<span class=\"number\">1</span>],data[:,<span class=\"number\">2</span>],data[:,<span class=\"number\">3</span>],c=<span class=\"string\">'red'</span>,)  <span class=\"comment\"># 绘制数据点</span></span><br><span class=\"line\">ax.plot(X_line,Y_line,Z_line,c=<span class=\"string\">'blue'</span>)<span class=\"comment\">#绘制回归曲线</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8703.png\" alt=\"图片\"><br>其中红色为数据点，蓝色线便为我们回归之后的曲线，这里我们是利用sklearn进行线性回归分析，后续会写出sklearn教程。如有错误之处还请指正，谢谢。</p>\n<hr>\n<h3 id=\"5-推广\"><a href=\"#5-推广\" class=\"headerlink\" title=\"5.推广\"></a>5.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。<br><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%8E%A8%E5%B9%BF.png\" alt=\"推广\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-线性回归分析（-Linear-Regression-Analysis）\"><a href=\"#1-线性回归分析（-Linear-Regression-Analysis）\" class=\"headerlink\" title=\"1.线性回归分析（ Linear Regression Analysis）\"></a>1.线性回归分析（ Linear Regression Analysis）</h3><p><strong>线性回归分析（Regression Analysis）</strong>：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围内的。<br>通俗来讲就是我们在做数学题的时候，解未知数的方法。假如给定自变量和函数，通过函数处理自变量，然后获得函数的解。而回归分析便是相当于给定自变量和函数的解，然后去求函数。如下图所示，我们已经知道红色点坐标，然后回归得到直线，回归分析属于<strong>监督学习</strong>。<br><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8701.png\" alt=\"图片01\"><br>上图只是简单的一元线性分析，回归后我们可以得到如$f(x)=a*x+b$的函数表达式，但更多情况下我们是求解多元线性回归问题，那应该如何解决呢。</p>\n<h3 id=\"2-模型表达\"><a href=\"#2-模型表达\" class=\"headerlink\" title=\"2.模型表达\"></a>2.模型表达</h3><p>建立数学模型之前，我们先定义如下变量。</p>\n<ul>\n<li>$x_i$表示输入数据（Feature）</li>\n<li>$y_i$表示输出数据（Target）</li>\n<li>$(x_i,y_i)$表示一组训练数据（Training example）</li>\n<li>m表示训练数据的个数</li>\n<li>n表示特征数量</li>\n</ul>\n<p>监督学习目标便是根据给定的训练数据，可以得到函数方法，使得假设函数$h$(hypothesis)满足$h(x)-&gt;y$。针对线性回归而言，函数$h(x)$表达式为</p>\n<script type=\"math/tex; mode=display\">h(x)=\\theta_0+\\theta_1*x_i+\\theta_2*x_2+...+\\theta_n*x_n</script><p>$为$方便我们使用矩阵来表达，$h(x)=\\theta^T*x$，其中$\\theta^T$为$\\theta$的转置。为求解函数$h(x)$，我们希望找出一组$\\theta$，使得$h(x)-y$无限趋近0，此处我们引入梯度下降算法求解问题。</p>\n<h3 id=\"3-梯度下降算法\"><a href=\"#3-梯度下降算法\" class=\"headerlink\" title=\"3.梯度下降算法\"></a>3.梯度下降算法</h3><h4 id=\"3-1梯度下降算法简述\"><a href=\"#3-1梯度下降算法简述\" class=\"headerlink\" title=\"3.1梯度下降算法简述\"></a>3.1梯度下降算法简述</h4><p>实际生活中我们有时也利用梯度下降算法，比如我们处在一座山的某处位置，但我们并不知道如何下山，于是决定走一步算一步，但每次都沿着最陡峭的地点下山，也就是沿着梯度的负方向前进。但有事也会遇见问题，不能每次都能到达山脚，可能到达山峰的某个局部最低点。</p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8702.png\" alt=\"图片02\"><br>从上面解释可以看出，梯度下降不一定能够找到全局最优解，有可能是局部最优解，但此种方法已能帮助我们求解线性回归问题。另外如果求解的函数是凸函数，梯度下降法得到得解一定是全局最优解。</p>\n<h4 id=\"3-2-梯度下降算法相关概念\"><a href=\"#3-2-梯度下降算法相关概念\" class=\"headerlink\" title=\"3.2 梯度下降算法相关概念\"></a>3.2 梯度下降算法相关概念</h4><p>求解梯度下降算法之前，我们先了解相关概念。</p>\n<ul>\n<li><strong>步长（Learning Rate）</strong>：步长决定梯度下降算法过程中，每步沿梯度负方向前进的长度。</li>\n<li><strong>特征（Feature）</strong>：即上述描述的$x_i,y_i$</li>\n<li><strong>假设函数（Hypothesis Function）</strong>：监督学习中，为了拟合输入样本，而使用假设函数$h(x)$</li>\n<li><strong>损失函数（Loss Function）</strong>：为了评估模型拟合的好坏，通常用损失函数来度量拟合的程度。损失函数极小，意味着拟合的程度越好，对应的模型参数即为最优参数。线性回归损失函数为<script type=\"math/tex\">J(\\theta)=\\frac{1}{2m}*\\sum_{i=1}^{n}(h(x)^{(i)}-y^{(i)})</script><br>我们利用梯度下降算法，目标便是找到一组$\\theta$使得$J(\\theta)$达到最小。</li>\n</ul>\n<h4 id=\"3-3梯度下降算法过程\"><a href=\"#3-3梯度下降算法过程\" class=\"headerlink\" title=\"3.3梯度下降算法过程\"></a>3.3梯度下降算法过程</h4><ul>\n<li>随机选取一组$\\theta$。</li>\n<li>不断变化$\\theta$，让$J(\\theta)$变小。<script type=\"math/tex; mode=display\">\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)</script>$j=0,1,2…n$，$\\theta_j$是n+1个值同时变化。$\\alpha$表示学习速率，目标求最小值，因此沿负梯度方向下降，故$\\theta$前为负号。$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导。</li>\n<li>直到$J(\\theta)​$得到最小值。</li>\n</ul>\n<p>$\\alpha\\frac{\\partial}{\\partial\\theta_j}$是对$J(\\theta)$的偏导求解过程如下：</p>\n<script type=\"math/tex; mode=display\">\\frac{\\partial}{\\partial\\theta_j}J(\\theta)=\\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2m}(h_\\theta(x)-y)^2</script><script type=\"math/tex; mode=display\">=2\\cdot\\frac{1}{2}(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)</script><script type=\"math/tex; mode=display\">=(h_\\theta(x)-y)\\cdot\\frac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y)</script><script type=\"math/tex; mode=display\">=(h_\\theta(x)-y)\\cdot x_j</script><p>因此梯度下降算法的最终表述为<br>Repeat Until Convergence{</p>\n<p><script type=\"math/tex\">\\theta_j:=\\theta_j-\\alpha\\sum_{i=1}^{n}((h_\\theta(x^{(i)})-y^{(i)})\\cdot x_j)</script> for every  $j$<br>}<br>梯度下降算法需多次迭代、算法复杂度为$O(kn^2)$。当利用梯度下降算法求得一组$\\theta$时我们便能得到线性回归函数。</p>\n<h3 id=\"4-线性回归算法实现\"><a href=\"#4-线性回归算法实现\" class=\"headerlink\" title=\"4.线性回归算法实现\"></a>4.线性回归算法实现</h3><p>为研究公司盈利提升幅度受电视、广播、报纸的投入的影响程度，利用多元线性回归来分析数据。其中数据下载地址为<a href=\"http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv\" target=\"_blank\" rel=\"noopener\">http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv</a> ，为能够绘制出三维图片，此处只选择电视、广播的广告投入对公司盈利提升幅度的影响。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> axes3d</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#read_csv</span></span><br><span class=\"line\">readdata=pd.read_csv(<span class=\"string\">'data/Advertising.csv'</span>)</span><br><span class=\"line\">data=np.array(readdata.values)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练数据</span></span><br><span class=\"line\">X_train=data[<span class=\"number\">0</span>:<span class=\"number\">150</span>,<span class=\"number\">1</span>:<span class=\"number\">3</span>]</span><br><span class=\"line\">Y_train=data[<span class=\"number\">0</span>:<span class=\"number\">150</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#测试数据</span></span><br><span class=\"line\">X_test=data[<span class=\"number\">150</span>:<span class=\"number\">200</span>,<span class=\"number\">1</span>:<span class=\"number\">3</span>]</span><br><span class=\"line\">Y_test=data[<span class=\"number\">150</span>:<span class=\"number\">200</span>,<span class=\"number\">3</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#回归分析</span></span><br><span class=\"line\">regr = linear_model.LinearRegression()</span><br><span class=\"line\"><span class=\"comment\">#进行training set和test set的fit，即是训练的过程</span></span><br><span class=\"line\">regr.fit(X_train, Y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打印出相关系数和截距等信息</span></span><br><span class=\"line\">print(<span class=\"string\">'Coefficients: \\n'</span>, regr.coef_)</span><br><span class=\"line\">print(<span class=\"string\">'Intercept: '</span>, regr.intercept_)</span><br><span class=\"line\"><span class=\"comment\"># The mean square error</span></span><br><span class=\"line\">print(<span class=\"string\">\"Residual sum of squares: %.2f\"</span></span><br><span class=\"line\">      % np.mean((regr.predict(X_test) - Y_test) ** <span class=\"number\">2</span>))</span><br><span class=\"line\"><span class=\"comment\"># Explained variance score: 1 is perfect prediction</span></span><br><span class=\"line\">print(<span class=\"string\">'Variance score: %.2f'</span> % regr.score(X_test, Y_test))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#得出回归函数 并自定义数据</span></span><br><span class=\"line\">X_line=np.linspace(<span class=\"number\">0</span>,<span class=\"number\">300</span>)</span><br><span class=\"line\">Y_line=np.linspace(<span class=\"number\">0</span>,<span class=\"number\">50</span>)</span><br><span class=\"line\">Z_line=<span class=\"number\">0.04699836</span>*X_line+<span class=\"number\">0.17913965</span>*Y_line+<span class=\"number\">3.00431061176</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#画图</span></span><br><span class=\"line\">fig=plt.figure()</span><br><span class=\"line\">ax = plt.subplot(<span class=\"number\">111</span>, projection=<span class=\"string\">'3d'</span>)  <span class=\"comment\"># 创建一个三维的绘图工程</span></span><br><span class=\"line\">ax.scatter(data[:,<span class=\"number\">1</span>],data[:,<span class=\"number\">2</span>],data[:,<span class=\"number\">3</span>],c=<span class=\"string\">'red'</span>,)  <span class=\"comment\"># 绘制数据点</span></span><br><span class=\"line\">ax.plot(X_line,Y_line,Z_line,c=<span class=\"string\">'blue'</span>)<span class=\"comment\">#绘制回归曲线</span></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E5%9B%BE%E7%89%8703.png\" alt=\"图片\"><br>其中红色为数据点，蓝色线便为我们回归之后的曲线，这里我们是利用sklearn进行线性回归分析，后续会写出sklearn教程。如有错误之处还请指正，谢谢。</p>\n<hr>\n<h3 id=\"5-推广\"><a href=\"#5-推广\" class=\"headerlink\" title=\"5.推广\"></a>5.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。<br><img src=\"http://p66yyzg4i.bkt.clouddn.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/%E6%8E%A8%E5%B9%BF.png\" alt=\"推广\"></p>\n"},{"title":"机器学习之SVM支持向量机（一）","date":"2018-03-29T07:51:41.000Z","comment":true,"mathjax":true,"_content":"\n我们思考这样一个问题，给两个标签，蓝色和红色点，数据有两个特征(x,y)。我们想要一个分类器，给定一对(x,y)，能找到很好的分类边界，判断是蓝色点还是红色点。对于下图的数据，我们如何解决呢。本文通过引入Support Vector Machine（SVM）算法来详解此类问题。\n\n![器学习之SVM支持向量机0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片01.png)\n\n### 1.SVM损失函数\n\n针对前面介绍的机器学习之线性回归、机器学习之Logistic回归，我们已经了解Cost Function的概念，这里我们利用Logistic Regression的损失函数来引入SVM损失函数。\n\n首先我们先复习下Logistic Regression Function\n$$\nh_{\\theta}=\\frac{1}{1+e^{-\\theta^Tx}}\n$$\n如果$y=1$，我们希望$h_{\\theta}\\approx1$，那么$\\theta^Tx\\gg0$。如果$y=0$，我们希望$h_{\\theta}\\approx0$，那么$\\theta^Tx\\ll0$。我们以Logistic Regression为例\n\n$$\nLR Cost Example=-\\left( (ylogh_\\theta(x))+(1-y)log(1-h_\\theta(x))\\right)\n$$\n\n$$\n=-ylog\\frac{1}{1+e^{-\\theta^Tx}}-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})\n$$\n\n+ 当$y=1$时，此时$\\theta^Tx\\gg0$，上述公式为$-ylog\\frac{1}{1+e^{-\\theta^Tx}}$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=1$点，粉色线部分我们定义为$cost_1(z)$。\n+ 当$y=0$时，此时$\\theta^Tx\\ll0$，上述公式为$-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=-1$点，粉色线部分我们定义为$cost_0(z)$。\n+ $cost_1(z)$与$cost_0(z)$便是我们希望的Cost Function曲线，和Logistic Function曲线非常接近，$cost_1(z)$与$cost_0(z)$分别代表y=1和y=0时的目标函数定义。\n\n![幕快照 2018-04-02 下午9.57.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片02.png)\n\nLogistic Regression的损失函数:\n$$\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}(-logh_{\\theta}(x^{(i)}))+(1-y^{(i)})(-log(1-h_{\\theta}(x^{(i)})))]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n因此对于SVM，我们得到:\n$$\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n因为常数项对我们结果没有影响，因此去掉上述方程式之中的m。Logstic Regression损失函数中包含两项，训练样本的代价项和正则项，形式类似于$A+\\lambda B$，我们通过设置$\\lambda$来平衡这两项。对于SVM来说，我们依照惯例设置损失函数为$CA+B$，利用C对两项进行平衡。其中C与Logistic Regression损失函数中的$\\frac{1}{\\lambda}$作用一致，因此我们便得到SVM的损失函数。\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n\n### 2.最大间隔分类\n\nSVM希望最小化代价参数，应该如何做呢？我们现在来看当损失函数最小时，我们需要做什么。\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n\n+ 当为正样本时$y=1$，我们希望$\\theta^Tx\\ge1$，而不是 $\\theta^Tx\\ge0$。\n+ 当为正样本时$y=0$，我们希望$\\theta^Tx\\le-1$，而不是$\\theta^Tx\\le0$。\n\n![幕快照 2018-04-02 下午10.00.0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片03.png)\n\n我们设**C为非常大的值**，例如1000000。\n\n+ 当$y^{(i)}=1$时，$\\theta^Tx^{(i)}\\ge1$，此时SVM损失函数中第一项为0。\n+ 当$y^{(i)}=0$时，$\\theta^Tx^{(i)}\\le-1$，此时SVM损失函数中第一项为0。\n\n那么我们便得到:\n$$\nminC*0+\\frac{1}{2}\\sum_{i=1}^{m}\\theta_j^2\n$$\n\n+ 约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。\n+ 约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。\n\nSVM是一个**最大间隔分类器**，如下图所示，我们可以把黑线、红线、蓝线中任意一条当作decision boundary，但重点是哪一条最好呢？我们将在**模块3**中详细介绍为什么SVM能形成最大间隔分类器和如何正确选择分类边界。\n\n![幕快照 2018-04-02 下午3.57.3](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片04.png)\n\n我们希望一条直线可以很好的分开正样本和负样本，但当有一个异常点时，我们需要很大范围的改变直线，当然这是不理智的。黑色线时C很大的情况，红色线时C不是非常大，C设置很大表示对分类错误的惩罚。\n\n![幕快照 2018-04-02 下午4.02.5](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片05.png)\n\n### 3.SVM最大间隔分类\n\n首先我们来看两个向量内积的表现形式。假设向量u,v均为二维向量，我们知道u,v的内积为$u^Tv=u_1v_1+u_2v_2$，表现在坐标上便为下图所示。首先将v向量投影到u向量上，记长度为p。其中p值有正负，与u方向相同为正，方向相反为负。uv两向量内积可以表示为\n$$\nu^Tv=||u||\\cdot||v||\\cdot cos\\theta=||u||\\cdot p=u_1v_1+u_2v_2\n$$\n![幕快照 2018-04-02 下午4.11.5](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片06.png)\n\n现在我们来看SVM损失函数:\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n由于C设置的非常大，那么SVM损失函数为:\n$$\nmin_{\\theta} \\frac{1}{2}\\sum_{j=1}^{n}\\theta_j^2\n$$\n\n- 约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。\n- 约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。\n\n下面我们举例说明SVM，为了简化，假设n=2,$\\theta_0=0$，我们得到\n$$\nmin\\frac{1}{2}\\sum_{j=1}^{2}\\theta_j^2=\\frac{1}{2}{(\\theta_1^2+\\theta_2^2)}=\\frac{1}{2}\\left (\\sqrt{\\theta_1^2+\\theta_2^2}  \\right )^2=\\frac{1}{2}||\\theta||^2\n$$\n我们来更深层次的理解$\\theta^Tx^{(i)}$，表现形式和上述$u^Tv$相同。利用坐标表示则为\n$$\n\\theta^Tx^{(i)}=p^{(i)}\\cdot||\\theta||=\\theta_1x_1^{(i)}+\\theta_2x_1^{(2)}\n$$\n$\\theta^Tx^{(i)}$我们可以利用$p^{(i)}\\cdot||\\theta||$表示，同时SVM随时函数目标是极小化$||\\theta^2||$。\n\n![幕快照 2018-04-02 下午4.52.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片07.png)\n\n下面有两种分类方式，SVM为什么要选择第二种当作分类呢。我们想最小化$||\\theta||$，并且要满足$p^{(i)}\\cdot ||\\theta||\\ge1$，但左边坐标中$p^{(1)}$较小，那么我们便要让$||\\theta||$更大，不满足最小化$||\\theta||$的需求。坐标2中$p^{(1)}$更大，那么$||\\theta||$便较小，满足最小化$||\\theta||$的需求。SVM便是通过最大化分类间隔来让$||\\theta||$更小，这便是SVM中为什么要最大化分类间隔。\n\n![幕快照 2018-04-02 下午5.14.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片08.png)\n\n### 4.核函数\n\n上述介绍线性分类，但对于非线性问题我们如何解决呢？对于非线性的决策边界，我们可以利用多项式拟合的方式进行预测。对于下面图片中的决策边界，我们令$f_1=x_1,f2=x_2,f3=x_1x_2,f4=x_1^2,f5=x_2^2,...$\n\n+ $f_1,f_2,f_3…$为提取出来的特征。\n+ 定义预测方程$h_{\\theta}(x)$为多项式sigmoid函数。$h_{\\theta}(x)=g(\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n)$，其中$f_n$为x的幂次项组合。\n+ 当$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n\\ge0$时$h_{\\theta}(x)=1$，否则$h_{\\theta}(x)=0$。\n\n![幕快照 2018-04-02 下午5.40.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片09.png)\n\n那么除了将fn定义为x的幂次项组合，还有其他方法表示f吗？此处我们引入核函数，对于非线性拟合，我们通过输入原始向量与landmark点之间的相似度来计算核值f，我们称相似度函数为核函数，下述核函数为高斯核函数。\n\n![幕快照 2018-04-02 下午5.53.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片10.png)\n\nx和l越相似，f越接近于1。x和l相差越远，f越接近于0。\n\n![幕快照 2018-04-02 下午6.02.1](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片11.png)\n\n下图中横坐标为x的两个维度值，高为f。制高点为x=l的情况，此时f=1。随着x与l的远离，f逐渐下降，趋近于0。\n\n![幕快照 2018-04-02 下午6.36.0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片12.png)\n\n下面我们来看SVM核分类预测的结果。引入核函数后，代数上的区别在于f变了，原来的f是$x_1,x_1^2…$，即$x_i$的幂次项乘积，另外几何来说可以更直观的表示如何分类。\n\n+ 假如我们将坐标上的所有数据点分为两类，红色圈内希望预测为y=1，圈外希望预测为y=0。通过训练数据集，我们得到一组$\\theta(\\theta_0,\\theta_1,\\theta_2,\\theta_3)$值为$(-0.5,1,1,0)$以及三个landmark点(L1,L2,L3)。具体如何选取landmark点和训练生成$\\theta$值在下面会详细介绍。\n+ 对于每个数据集内的点，我们首先计算它到(L1,L2,L3)各自的相似度，也就是核函数的值$f_1,f_2,f_3$，然后带入多项式$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n$，当多项式大于0时预测结果为类内点，表示为正样本，y=1。否则预测为负样本，y=0。\n\n![幕快照 2018-04-02 下午6.44.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片13.png)\n\n### 5.SVM中Gaussian Kernel的使用\n\n上述中我们利用到$l^{(1)},l^{(2)},l^{(3)}$，但是我们如何达到这些landmark呢。首先我们来看L点的选取，上述提到Gaussian kernel $f_i$的计算。\n$$\nf_i=similarity(x,l^{(i)})=exp\\left ( -\\frac{||x-l^{(i)}||^2}{2\\sigma^2}\\right)\n$$\n我们选择m个训练数据，并取这m个训练数据为m个landmark点（不考虑正样本还是负样本）。\n\n![幕快照 2018-04-02 下午7.16.3](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片14.png)\n\n![幕快照 2018-04-02 下午7.17.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片15.png)\n\n那么在这m个训练数据中，每一个训练数据$x^{(i)}$所得的特征向量（核函数）f中，总有一维向量的值为1（因为$x^{(i)}=l^{(i)}$）。于是每个特征向量f有m+1为维度，在SVM训练中，将Gaussian Kernel带入SVM损失函数，通过最小化该函数就可于得到参数$\\theta$，并根据该参数$\\theta$进行预测。\n\n+ $\\theta^Tf\\ge0$，预测 y=1。\n+ $\\theta^Tf\\le0$，预测y=0。\n\n如下图所示，这里与之前的损失函数区别在于用kernel f代替了x。\n\n![幕快照 2018-04-02 下午7.26.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片16.png)\n\n最后我们介绍下如何选取C和$\\sigma^2$。由于$C=\\frac{1}{\\lambda}$，所以\n\n+ C大，$\\lambda$小，overfit，产生low bias，high variance。\n+ C小，$\\lambda$大，underfoot，underfoot，产生high bias，low variance。\n\n对于方差$\\sigma^2$\n\n+ $\\sigma^2$大，x-f相似性图像较为扁平。\n+ $\\sigma^2小$，x-f相似性图像较为窄尖。\n\n![幕快照 2018-04-02 下午8.03.0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片17.png)\n\n通常我们会从一些常用的核函数中选择，根据问题数据的不同，选择不同的参数，实际上就是得到不同的核函数。经常用到的核函数包括线性核、多项式核、高斯核。\n\n由于本篇幅文章过长，我们将在下篇文章内详细介绍SVM算法中对偶问题的求解、C为何设置非常大、几种不同的核函数、SVM应用。如你在文中发现错误，欢迎指出，我会尽快更正。\n\n### 5.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片推广.png.png)","source":"_posts/机器学习之SVM支持向量机（一）.md","raw":"---\ntitle: 机器学习之SVM支持向量机（一）\ndate: 2018-03-29 15:51:41\ntags: [机器学习,算法]\ncategories: 机器学习\ncomment: true\nmathjax: true\n---\n\n我们思考这样一个问题，给两个标签，蓝色和红色点，数据有两个特征(x,y)。我们想要一个分类器，给定一对(x,y)，能找到很好的分类边界，判断是蓝色点还是红色点。对于下图的数据，我们如何解决呢。本文通过引入Support Vector Machine（SVM）算法来详解此类问题。\n\n![器学习之SVM支持向量机0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片01.png)\n\n### 1.SVM损失函数\n\n针对前面介绍的机器学习之线性回归、机器学习之Logistic回归，我们已经了解Cost Function的概念，这里我们利用Logistic Regression的损失函数来引入SVM损失函数。\n\n首先我们先复习下Logistic Regression Function\n$$\nh_{\\theta}=\\frac{1}{1+e^{-\\theta^Tx}}\n$$\n如果$y=1$，我们希望$h_{\\theta}\\approx1$，那么$\\theta^Tx\\gg0$。如果$y=0$，我们希望$h_{\\theta}\\approx0$，那么$\\theta^Tx\\ll0$。我们以Logistic Regression为例\n\n$$\nLR Cost Example=-\\left( (ylogh_\\theta(x))+(1-y)log(1-h_\\theta(x))\\right)\n$$\n\n$$\n=-ylog\\frac{1}{1+e^{-\\theta^Tx}}-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})\n$$\n\n+ 当$y=1$时，此时$\\theta^Tx\\gg0$，上述公式为$-ylog\\frac{1}{1+e^{-\\theta^Tx}}$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=1$点，粉色线部分我们定义为$cost_1(z)$。\n+ 当$y=0$时，此时$\\theta^Tx\\ll0$，上述公式为$-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=-1$点，粉色线部分我们定义为$cost_0(z)$。\n+ $cost_1(z)$与$cost_0(z)$便是我们希望的Cost Function曲线，和Logistic Function曲线非常接近，$cost_1(z)$与$cost_0(z)$分别代表y=1和y=0时的目标函数定义。\n\n![幕快照 2018-04-02 下午9.57.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片02.png)\n\nLogistic Regression的损失函数:\n$$\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}(-logh_{\\theta}(x^{(i)}))+(1-y^{(i)})(-log(1-h_{\\theta}(x^{(i)})))]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n因此对于SVM，我们得到:\n$$\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n因为常数项对我们结果没有影响，因此去掉上述方程式之中的m。Logstic Regression损失函数中包含两项，训练样本的代价项和正则项，形式类似于$A+\\lambda B$，我们通过设置$\\lambda$来平衡这两项。对于SVM来说，我们依照惯例设置损失函数为$CA+B$，利用C对两项进行平衡。其中C与Logistic Regression损失函数中的$\\frac{1}{\\lambda}$作用一致，因此我们便得到SVM的损失函数。\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n\n### 2.最大间隔分类\n\nSVM希望最小化代价参数，应该如何做呢？我们现在来看当损失函数最小时，我们需要做什么。\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n\n+ 当为正样本时$y=1$，我们希望$\\theta^Tx\\ge1$，而不是 $\\theta^Tx\\ge0$。\n+ 当为正样本时$y=0$，我们希望$\\theta^Tx\\le-1$，而不是$\\theta^Tx\\le0$。\n\n![幕快照 2018-04-02 下午10.00.0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片03.png)\n\n我们设**C为非常大的值**，例如1000000。\n\n+ 当$y^{(i)}=1$时，$\\theta^Tx^{(i)}\\ge1$，此时SVM损失函数中第一项为0。\n+ 当$y^{(i)}=0$时，$\\theta^Tx^{(i)}\\le-1$，此时SVM损失函数中第一项为0。\n\n那么我们便得到:\n$$\nminC*0+\\frac{1}{2}\\sum_{i=1}^{m}\\theta_j^2\n$$\n\n+ 约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。\n+ 约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。\n\nSVM是一个**最大间隔分类器**，如下图所示，我们可以把黑线、红线、蓝线中任意一条当作decision boundary，但重点是哪一条最好呢？我们将在**模块3**中详细介绍为什么SVM能形成最大间隔分类器和如何正确选择分类边界。\n\n![幕快照 2018-04-02 下午3.57.3](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片04.png)\n\n我们希望一条直线可以很好的分开正样本和负样本，但当有一个异常点时，我们需要很大范围的改变直线，当然这是不理智的。黑色线时C很大的情况，红色线时C不是非常大，C设置很大表示对分类错误的惩罚。\n\n![幕快照 2018-04-02 下午4.02.5](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片05.png)\n\n### 3.SVM最大间隔分类\n\n首先我们来看两个向量内积的表现形式。假设向量u,v均为二维向量，我们知道u,v的内积为$u^Tv=u_1v_1+u_2v_2$，表现在坐标上便为下图所示。首先将v向量投影到u向量上，记长度为p。其中p值有正负，与u方向相同为正，方向相反为负。uv两向量内积可以表示为\n$$\nu^Tv=||u||\\cdot||v||\\cdot cos\\theta=||u||\\cdot p=u_1v_1+u_2v_2\n$$\n![幕快照 2018-04-02 下午4.11.5](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片06.png)\n\n现在我们来看SVM损失函数:\n$$\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}\n$$\n由于C设置的非常大，那么SVM损失函数为:\n$$\nmin_{\\theta} \\frac{1}{2}\\sum_{j=1}^{n}\\theta_j^2\n$$\n\n- 约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。\n- 约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。\n\n下面我们举例说明SVM，为了简化，假设n=2,$\\theta_0=0$，我们得到\n$$\nmin\\frac{1}{2}\\sum_{j=1}^{2}\\theta_j^2=\\frac{1}{2}{(\\theta_1^2+\\theta_2^2)}=\\frac{1}{2}\\left (\\sqrt{\\theta_1^2+\\theta_2^2}  \\right )^2=\\frac{1}{2}||\\theta||^2\n$$\n我们来更深层次的理解$\\theta^Tx^{(i)}$，表现形式和上述$u^Tv$相同。利用坐标表示则为\n$$\n\\theta^Tx^{(i)}=p^{(i)}\\cdot||\\theta||=\\theta_1x_1^{(i)}+\\theta_2x_1^{(2)}\n$$\n$\\theta^Tx^{(i)}$我们可以利用$p^{(i)}\\cdot||\\theta||$表示，同时SVM随时函数目标是极小化$||\\theta^2||$。\n\n![幕快照 2018-04-02 下午4.52.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片07.png)\n\n下面有两种分类方式，SVM为什么要选择第二种当作分类呢。我们想最小化$||\\theta||$，并且要满足$p^{(i)}\\cdot ||\\theta||\\ge1$，但左边坐标中$p^{(1)}$较小，那么我们便要让$||\\theta||$更大，不满足最小化$||\\theta||$的需求。坐标2中$p^{(1)}$更大，那么$||\\theta||$便较小，满足最小化$||\\theta||$的需求。SVM便是通过最大化分类间隔来让$||\\theta||$更小，这便是SVM中为什么要最大化分类间隔。\n\n![幕快照 2018-04-02 下午5.14.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片08.png)\n\n### 4.核函数\n\n上述介绍线性分类，但对于非线性问题我们如何解决呢？对于非线性的决策边界，我们可以利用多项式拟合的方式进行预测。对于下面图片中的决策边界，我们令$f_1=x_1,f2=x_2,f3=x_1x_2,f4=x_1^2,f5=x_2^2,...$\n\n+ $f_1,f_2,f_3…$为提取出来的特征。\n+ 定义预测方程$h_{\\theta}(x)$为多项式sigmoid函数。$h_{\\theta}(x)=g(\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n)$，其中$f_n$为x的幂次项组合。\n+ 当$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n\\ge0$时$h_{\\theta}(x)=1$，否则$h_{\\theta}(x)=0$。\n\n![幕快照 2018-04-02 下午5.40.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片09.png)\n\n那么除了将fn定义为x的幂次项组合，还有其他方法表示f吗？此处我们引入核函数，对于非线性拟合，我们通过输入原始向量与landmark点之间的相似度来计算核值f，我们称相似度函数为核函数，下述核函数为高斯核函数。\n\n![幕快照 2018-04-02 下午5.53.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片10.png)\n\nx和l越相似，f越接近于1。x和l相差越远，f越接近于0。\n\n![幕快照 2018-04-02 下午6.02.1](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片11.png)\n\n下图中横坐标为x的两个维度值，高为f。制高点为x=l的情况，此时f=1。随着x与l的远离，f逐渐下降，趋近于0。\n\n![幕快照 2018-04-02 下午6.36.0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片12.png)\n\n下面我们来看SVM核分类预测的结果。引入核函数后，代数上的区别在于f变了，原来的f是$x_1,x_1^2…$，即$x_i$的幂次项乘积，另外几何来说可以更直观的表示如何分类。\n\n+ 假如我们将坐标上的所有数据点分为两类，红色圈内希望预测为y=1，圈外希望预测为y=0。通过训练数据集，我们得到一组$\\theta(\\theta_0,\\theta_1,\\theta_2,\\theta_3)$值为$(-0.5,1,1,0)$以及三个landmark点(L1,L2,L3)。具体如何选取landmark点和训练生成$\\theta$值在下面会详细介绍。\n+ 对于每个数据集内的点，我们首先计算它到(L1,L2,L3)各自的相似度，也就是核函数的值$f_1,f_2,f_3$，然后带入多项式$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n$，当多项式大于0时预测结果为类内点，表示为正样本，y=1。否则预测为负样本，y=0。\n\n![幕快照 2018-04-02 下午6.44.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片13.png)\n\n### 5.SVM中Gaussian Kernel的使用\n\n上述中我们利用到$l^{(1)},l^{(2)},l^{(3)}$，但是我们如何达到这些landmark呢。首先我们来看L点的选取，上述提到Gaussian kernel $f_i$的计算。\n$$\nf_i=similarity(x,l^{(i)})=exp\\left ( -\\frac{||x-l^{(i)}||^2}{2\\sigma^2}\\right)\n$$\n我们选择m个训练数据，并取这m个训练数据为m个landmark点（不考虑正样本还是负样本）。\n\n![幕快照 2018-04-02 下午7.16.3](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片14.png)\n\n![幕快照 2018-04-02 下午7.17.2](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片15.png)\n\n那么在这m个训练数据中，每一个训练数据$x^{(i)}$所得的特征向量（核函数）f中，总有一维向量的值为1（因为$x^{(i)}=l^{(i)}$）。于是每个特征向量f有m+1为维度，在SVM训练中，将Gaussian Kernel带入SVM损失函数，通过最小化该函数就可于得到参数$\\theta$，并根据该参数$\\theta$进行预测。\n\n+ $\\theta^Tf\\ge0$，预测 y=1。\n+ $\\theta^Tf\\le0$，预测y=0。\n\n如下图所示，这里与之前的损失函数区别在于用kernel f代替了x。\n\n![幕快照 2018-04-02 下午7.26.4](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片16.png)\n\n最后我们介绍下如何选取C和$\\sigma^2$。由于$C=\\frac{1}{\\lambda}$，所以\n\n+ C大，$\\lambda$小，overfit，产生low bias，high variance。\n+ C小，$\\lambda$大，underfoot，underfoot，产生high bias，low variance。\n\n对于方差$\\sigma^2$\n\n+ $\\sigma^2$大，x-f相似性图像较为扁平。\n+ $\\sigma^2小$，x-f相似性图像较为窄尖。\n\n![幕快照 2018-04-02 下午8.03.0](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片17.png)\n\n通常我们会从一些常用的核函数中选择，根据问题数据的不同，选择不同的参数，实际上就是得到不同的核函数。经常用到的核函数包括线性核、多项式核、高斯核。\n\n由于本篇幅文章过长，我们将在下篇文章内详细介绍SVM算法中对偶问题的求解、C为何设置非常大、几种不同的核函数、SVM应用。如你在文中发现错误，欢迎指出，我会尽快更正。\n\n### 5.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![](机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片推广.png.png)","slug":"机器学习之SVM支持向量机（一）","published":1,"updated":"2018-04-03T02:52:42.498Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjg7s0pqu000q3201lzxvfqqe","content":"<p>我们思考这样一个问题，给两个标签，蓝色和红色点，数据有两个特征(x,y)。我们想要一个分类器，给定一对(x,y)，能找到很好的分类边界，判断是蓝色点还是红色点。对于下图的数据，我们如何解决呢。本文通过引入Support Vector Machine（SVM）算法来详解此类问题。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片01.png\" alt=\"器学习之SVM支持向量机0\"></p>\n<h3 id=\"1-SVM损失函数\"><a href=\"#1-SVM损失函数\" class=\"headerlink\" title=\"1.SVM损失函数\"></a>1.SVM损失函数</h3><p>针对前面介绍的机器学习之线性回归、机器学习之Logistic回归，我们已经了解Cost Function的概念，这里我们利用Logistic Regression的损失函数来引入SVM损失函数。</p>\n<p>首先我们先复习下Logistic Regression Function</p>\n<script type=\"math/tex; mode=display\">\nh_{\\theta}=\\frac{1}{1+e^{-\\theta^Tx}}</script><p>如果$y=1$，我们希望$h_{\\theta}\\approx1$，那么$\\theta^Tx\\gg0$。如果$y=0$，我们希望$h_{\\theta}\\approx0$，那么$\\theta^Tx\\ll0$。我们以Logistic Regression为例</p>\n<script type=\"math/tex; mode=display\">\nLR Cost Example=-\\left( (ylogh_\\theta(x))+(1-y)log(1-h_\\theta(x))\\right)</script><script type=\"math/tex; mode=display\">\n=-ylog\\frac{1}{1+e^{-\\theta^Tx}}-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})</script><ul>\n<li>当$y=1$时，此时$\\theta^Tx\\gg0$，上述公式为$-ylog\\frac{1}{1+e^{-\\theta^Tx}}$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=1$点，粉色线部分我们定义为$cost_1(z)$。</li>\n<li>当$y=0$时，此时$\\theta^Tx\\ll0$，上述公式为$-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=-1$点，粉色线部分我们定义为$cost_0(z)$。</li>\n<li>$cost_1(z)$与$cost_0(z)$便是我们希望的Cost Function曲线，和Logistic Function曲线非常接近，$cost_1(z)$与$cost_0(z)$分别代表y=1和y=0时的目标函数定义。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片02.png\" alt=\"幕快照 2018-04-02 下午9.57.2\"></p>\n<p>Logistic Regression的损失函数:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}(-logh_{\\theta}(x^{(i)}))+(1-y^{(i)})(-log(1-h_{\\theta}(x^{(i)})))]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>因此对于SVM，我们得到:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>因为常数项对我们结果没有影响，因此去掉上述方程式之中的m。Logstic Regression损失函数中包含两项，训练样本的代价项和正则项，形式类似于$A+\\lambda B$，我们通过设置$\\lambda$来平衡这两项。对于SVM来说，我们依照惯例设置损失函数为$CA+B$，利用C对两项进行平衡。其中C与Logistic Regression损失函数中的$\\frac{1}{\\lambda}$作用一致，因此我们便得到SVM的损失函数。</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><h3 id=\"2-最大间隔分类\"><a href=\"#2-最大间隔分类\" class=\"headerlink\" title=\"2.最大间隔分类\"></a>2.最大间隔分类</h3><p>SVM希望最小化代价参数，应该如何做呢？我们现在来看当损失函数最小时，我们需要做什么。</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><ul>\n<li>当为正样本时$y=1$，我们希望$\\theta^Tx\\ge1$，而不是 $\\theta^Tx\\ge0$。</li>\n<li>当为正样本时$y=0$，我们希望$\\theta^Tx\\le-1$，而不是$\\theta^Tx\\le0$。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片03.png\" alt=\"幕快照 2018-04-02 下午10.00.0\"></p>\n<p>我们设<strong>C为非常大的值</strong>，例如1000000。</p>\n<ul>\n<li>当$y^{(i)}=1$时，$\\theta^Tx^{(i)}\\ge1$，此时SVM损失函数中第一项为0。</li>\n<li>当$y^{(i)}=0$时，$\\theta^Tx^{(i)}\\le-1$，此时SVM损失函数中第一项为0。</li>\n</ul>\n<p>那么我们便得到:</p>\n<script type=\"math/tex; mode=display\">\nminC*0+\\frac{1}{2}\\sum_{i=1}^{m}\\theta_j^2</script><ul>\n<li>约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。</li>\n<li>约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。</li>\n</ul>\n<p>SVM是一个<strong>最大间隔分类器</strong>，如下图所示，我们可以把黑线、红线、蓝线中任意一条当作decision boundary，但重点是哪一条最好呢？我们将在<strong>模块3</strong>中详细介绍为什么SVM能形成最大间隔分类器和如何正确选择分类边界。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片04.png\" alt=\"幕快照 2018-04-02 下午3.57.3\"></p>\n<p>我们希望一条直线可以很好的分开正样本和负样本，但当有一个异常点时，我们需要很大范围的改变直线，当然这是不理智的。黑色线时C很大的情况，红色线时C不是非常大，C设置很大表示对分类错误的惩罚。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片05.png\" alt=\"幕快照 2018-04-02 下午4.02.5\"></p>\n<h3 id=\"3-SVM最大间隔分类\"><a href=\"#3-SVM最大间隔分类\" class=\"headerlink\" title=\"3.SVM最大间隔分类\"></a>3.SVM最大间隔分类</h3><p>首先我们来看两个向量内积的表现形式。假设向量u,v均为二维向量，我们知道u,v的内积为$u^Tv=u_1v_1+u_2v_2$，表现在坐标上便为下图所示。首先将v向量投影到u向量上，记长度为p。其中p值有正负，与u方向相同为正，方向相反为负。uv两向量内积可以表示为</p>\n<script type=\"math/tex; mode=display\">\nu^Tv=||u||\\cdot||v||\\cdot cos\\theta=||u||\\cdot p=u_1v_1+u_2v_2</script><p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片06.png\" alt=\"幕快照 2018-04-02 下午4.11.5\"></p>\n<p>现在我们来看SVM损失函数:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>由于C设置的非常大，那么SVM损失函数为:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta} \\frac{1}{2}\\sum_{j=1}^{n}\\theta_j^2</script><ul>\n<li>约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。</li>\n<li>约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。</li>\n</ul>\n<p>下面我们举例说明SVM，为了简化，假设n=2,$\\theta_0=0$，我们得到</p>\n<script type=\"math/tex; mode=display\">\nmin\\frac{1}{2}\\sum_{j=1}^{2}\\theta_j^2=\\frac{1}{2}{(\\theta_1^2+\\theta_2^2)}=\\frac{1}{2}\\left (\\sqrt{\\theta_1^2+\\theta_2^2}  \\right )^2=\\frac{1}{2}||\\theta||^2</script><p>我们来更深层次的理解$\\theta^Tx^{(i)}$，表现形式和上述$u^Tv$相同。利用坐标表示则为</p>\n<script type=\"math/tex; mode=display\">\n\\theta^Tx^{(i)}=p^{(i)}\\cdot||\\theta||=\\theta_1x_1^{(i)}+\\theta_2x_1^{(2)}</script><p>$\\theta^Tx^{(i)}$我们可以利用$p^{(i)}\\cdot||\\theta||$表示，同时SVM随时函数目标是极小化$||\\theta^2||$。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片07.png\" alt=\"幕快照 2018-04-02 下午4.52.4\"></p>\n<p>下面有两种分类方式，SVM为什么要选择第二种当作分类呢。我们想最小化$||\\theta||$，并且要满足$p^{(i)}\\cdot ||\\theta||\\ge1$，但左边坐标中$p^{(1)}$较小，那么我们便要让$||\\theta||$更大，不满足最小化$||\\theta||$的需求。坐标2中$p^{(1)}$更大，那么$||\\theta||$便较小，满足最小化$||\\theta||$的需求。SVM便是通过最大化分类间隔来让$||\\theta||$更小，这便是SVM中为什么要最大化分类间隔。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片08.png\" alt=\"幕快照 2018-04-02 下午5.14.2\"></p>\n<h3 id=\"4-核函数\"><a href=\"#4-核函数\" class=\"headerlink\" title=\"4.核函数\"></a>4.核函数</h3><p>上述介绍线性分类，但对于非线性问题我们如何解决呢？对于非线性的决策边界，我们可以利用多项式拟合的方式进行预测。对于下面图片中的决策边界，我们令$f_1=x_1,f2=x_2,f3=x_1x_2,f4=x_1^2,f5=x_2^2,…$</p>\n<ul>\n<li>$f_1,f_2,f_3…$为提取出来的特征。</li>\n<li>定义预测方程$h_{\\theta}(x)$为多项式sigmoid函数。$h_{\\theta}(x)=g(\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n)$，其中$f_n$为x的幂次项组合。</li>\n<li>当$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n\\ge0$时$h_{\\theta}(x)=1$，否则$h_{\\theta}(x)=0$。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片09.png\" alt=\"幕快照 2018-04-02 下午5.40.4\"></p>\n<p>那么除了将fn定义为x的幂次项组合，还有其他方法表示f吗？此处我们引入核函数，对于非线性拟合，我们通过输入原始向量与landmark点之间的相似度来计算核值f，我们称相似度函数为核函数，下述核函数为高斯核函数。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片10.png\" alt=\"幕快照 2018-04-02 下午5.53.4\"></p>\n<p>x和l越相似，f越接近于1。x和l相差越远，f越接近于0。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片11.png\" alt=\"幕快照 2018-04-02 下午6.02.1\"></p>\n<p>下图中横坐标为x的两个维度值，高为f。制高点为x=l的情况，此时f=1。随着x与l的远离，f逐渐下降，趋近于0。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片12.png\" alt=\"幕快照 2018-04-02 下午6.36.0\"></p>\n<p>下面我们来看SVM核分类预测的结果。引入核函数后，代数上的区别在于f变了，原来的f是$x_1,x_1^2…$，即$x_i$的幂次项乘积，另外几何来说可以更直观的表示如何分类。</p>\n<ul>\n<li>假如我们将坐标上的所有数据点分为两类，红色圈内希望预测为y=1，圈外希望预测为y=0。通过训练数据集，我们得到一组$\\theta(\\theta_0,\\theta_1,\\theta_2,\\theta_3)$值为$(-0.5,1,1,0)$以及三个landmark点(L1,L2,L3)。具体如何选取landmark点和训练生成$\\theta$值在下面会详细介绍。</li>\n<li>对于每个数据集内的点，我们首先计算它到(L1,L2,L3)各自的相似度，也就是核函数的值$f_1,f_2,f_3$，然后带入多项式$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n$，当多项式大于0时预测结果为类内点，表示为正样本，y=1。否则预测为负样本，y=0。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片13.png\" alt=\"幕快照 2018-04-02 下午6.44.2\"></p>\n<h3 id=\"5-SVM中Gaussian-Kernel的使用\"><a href=\"#5-SVM中Gaussian-Kernel的使用\" class=\"headerlink\" title=\"5.SVM中Gaussian Kernel的使用\"></a>5.SVM中Gaussian Kernel的使用</h3><p>上述中我们利用到$l^{(1)},l^{(2)},l^{(3)}$，但是我们如何达到这些landmark呢。首先我们来看L点的选取，上述提到Gaussian kernel $f_i$的计算。</p>\n<script type=\"math/tex; mode=display\">\nf_i=similarity(x,l^{(i)})=exp\\left ( -\\frac{||x-l^{(i)}||^2}{2\\sigma^2}\\right)</script><p>我们选择m个训练数据，并取这m个训练数据为m个landmark点（不考虑正样本还是负样本）。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片14.png\" alt=\"幕快照 2018-04-02 下午7.16.3\"></p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片15.png\" alt=\"幕快照 2018-04-02 下午7.17.2\"></p>\n<p>那么在这m个训练数据中，每一个训练数据$x^{(i)}$所得的特征向量（核函数）f中，总有一维向量的值为1（因为$x^{(i)}=l^{(i)}$）。于是每个特征向量f有m+1为维度，在SVM训练中，将Gaussian Kernel带入SVM损失函数，通过最小化该函数就可于得到参数$\\theta$，并根据该参数$\\theta$进行预测。</p>\n<ul>\n<li>$\\theta^Tf\\ge0$，预测 y=1。</li>\n<li>$\\theta^Tf\\le0$，预测y=0。</li>\n</ul>\n<p>如下图所示，这里与之前的损失函数区别在于用kernel f代替了x。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片16.png\" alt=\"幕快照 2018-04-02 下午7.26.4\"></p>\n<p>最后我们介绍下如何选取C和$\\sigma^2$。由于$C=\\frac{1}{\\lambda}$，所以</p>\n<ul>\n<li>C大，$\\lambda$小，overfit，产生low bias，high variance。</li>\n<li>C小，$\\lambda$大，underfoot，underfoot，产生high bias，low variance。</li>\n</ul>\n<p>对于方差$\\sigma^2$</p>\n<ul>\n<li>$\\sigma^2$大，x-f相似性图像较为扁平。</li>\n<li>$\\sigma^2小$，x-f相似性图像较为窄尖。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片17.png\" alt=\"幕快照 2018-04-02 下午8.03.0\"></p>\n<p>通常我们会从一些常用的核函数中选择，根据问题数据的不同，选择不同的参数，实际上就是得到不同的核函数。经常用到的核函数包括线性核、多项式核、高斯核。</p>\n<p>由于本篇幅文章过长，我们将在下篇文章内详细介绍SVM算法中对偶问题的求解、C为何设置非常大、几种不同的核函数、SVM应用。如你在文中发现错误，欢迎指出，我会尽快更正。</p>\n<h3 id=\"5-推广\"><a href=\"#5-推广\" class=\"headerlink\" title=\"5.推广\"></a>5.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片推广.png.png\" alt=\"\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>我们思考这样一个问题，给两个标签，蓝色和红色点，数据有两个特征(x,y)。我们想要一个分类器，给定一对(x,y)，能找到很好的分类边界，判断是蓝色点还是红色点。对于下图的数据，我们如何解决呢。本文通过引入Support Vector Machine（SVM）算法来详解此类问题。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片01.png\" alt=\"器学习之SVM支持向量机0\"></p>\n<h3 id=\"1-SVM损失函数\"><a href=\"#1-SVM损失函数\" class=\"headerlink\" title=\"1.SVM损失函数\"></a>1.SVM损失函数</h3><p>针对前面介绍的机器学习之线性回归、机器学习之Logistic回归，我们已经了解Cost Function的概念，这里我们利用Logistic Regression的损失函数来引入SVM损失函数。</p>\n<p>首先我们先复习下Logistic Regression Function</p>\n<script type=\"math/tex; mode=display\">\nh_{\\theta}=\\frac{1}{1+e^{-\\theta^Tx}}</script><p>如果$y=1$，我们希望$h_{\\theta}\\approx1$，那么$\\theta^Tx\\gg0$。如果$y=0$，我们希望$h_{\\theta}\\approx0$，那么$\\theta^Tx\\ll0$。我们以Logistic Regression为例</p>\n<script type=\"math/tex; mode=display\">\nLR Cost Example=-\\left( (ylogh_\\theta(x))+(1-y)log(1-h_\\theta(x))\\right)</script><script type=\"math/tex; mode=display\">\n=-ylog\\frac{1}{1+e^{-\\theta^Tx}}-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})</script><ul>\n<li>当$y=1$时，此时$\\theta^Tx\\gg0$，上述公式为$-ylog\\frac{1}{1+e^{-\\theta^Tx}}$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=1$点，粉色线部分我们定义为$cost_1(z)$。</li>\n<li>当$y=0$时，此时$\\theta^Tx\\ll0$，上述公式为$-(1-y)log(1-\\frac{1}{1+e^{-\\theta^Tx}})$，其中$z=\\theta^Tx$。我们将曲线分为两段，下图中取$z=-1$点，粉色线部分我们定义为$cost_0(z)$。</li>\n<li>$cost_1(z)$与$cost_0(z)$便是我们希望的Cost Function曲线，和Logistic Function曲线非常接近，$cost_1(z)$与$cost_0(z)$分别代表y=1和y=0时的目标函数定义。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片02.png\" alt=\"幕快照 2018-04-02 下午9.57.2\"></p>\n<p>Logistic Regression的损失函数:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}(-logh_{\\theta}(x^{(i)}))+(1-y^{(i)})(-log(1-h_{\\theta}(x^{(i)})))]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>因此对于SVM，我们得到:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>因为常数项对我们结果没有影响，因此去掉上述方程式之中的m。Logstic Regression损失函数中包含两项，训练样本的代价项和正则项，形式类似于$A+\\lambda B$，我们通过设置$\\lambda$来平衡这两项。对于SVM来说，我们依照惯例设置损失函数为$CA+B$，利用C对两项进行平衡。其中C与Logistic Regression损失函数中的$\\frac{1}{\\lambda}$作用一致，因此我们便得到SVM的损失函数。</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><h3 id=\"2-最大间隔分类\"><a href=\"#2-最大间隔分类\" class=\"headerlink\" title=\"2.最大间隔分类\"></a>2.最大间隔分类</h3><p>SVM希望最小化代价参数，应该如何做呢？我们现在来看当损失函数最小时，我们需要做什么。</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><ul>\n<li>当为正样本时$y=1$，我们希望$\\theta^Tx\\ge1$，而不是 $\\theta^Tx\\ge0$。</li>\n<li>当为正样本时$y=0$，我们希望$\\theta^Tx\\le-1$，而不是$\\theta^Tx\\le0$。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片03.png\" alt=\"幕快照 2018-04-02 下午10.00.0\"></p>\n<p>我们设<strong>C为非常大的值</strong>，例如1000000。</p>\n<ul>\n<li>当$y^{(i)}=1$时，$\\theta^Tx^{(i)}\\ge1$，此时SVM损失函数中第一项为0。</li>\n<li>当$y^{(i)}=0$时，$\\theta^Tx^{(i)}\\le-1$，此时SVM损失函数中第一项为0。</li>\n</ul>\n<p>那么我们便得到:</p>\n<script type=\"math/tex; mode=display\">\nminC*0+\\frac{1}{2}\\sum_{i=1}^{m}\\theta_j^2</script><ul>\n<li>约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。</li>\n<li>约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。</li>\n</ul>\n<p>SVM是一个<strong>最大间隔分类器</strong>，如下图所示，我们可以把黑线、红线、蓝线中任意一条当作decision boundary，但重点是哪一条最好呢？我们将在<strong>模块3</strong>中详细介绍为什么SVM能形成最大间隔分类器和如何正确选择分类边界。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片04.png\" alt=\"幕快照 2018-04-02 下午3.57.3\"></p>\n<p>我们希望一条直线可以很好的分开正样本和负样本，但当有一个异常点时，我们需要很大范围的改变直线，当然这是不理智的。黑色线时C很大的情况，红色线时C不是非常大，C设置很大表示对分类错误的惩罚。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片05.png\" alt=\"幕快照 2018-04-02 下午4.02.5\"></p>\n<h3 id=\"3-SVM最大间隔分类\"><a href=\"#3-SVM最大间隔分类\" class=\"headerlink\" title=\"3.SVM最大间隔分类\"></a>3.SVM最大间隔分类</h3><p>首先我们来看两个向量内积的表现形式。假设向量u,v均为二维向量，我们知道u,v的内积为$u^Tv=u_1v_1+u_2v_2$，表现在坐标上便为下图所示。首先将v向量投影到u向量上，记长度为p。其中p值有正负，与u方向相同为正，方向相反为负。uv两向量内积可以表示为</p>\n<script type=\"math/tex; mode=display\">\nu^Tv=||u||\\cdot||v||\\cdot cos\\theta=||u||\\cdot p=u_1v_1+u_2v_2</script><p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片06.png\" alt=\"幕快照 2018-04-02 下午4.11.5\"></p>\n<p>现在我们来看SVM损失函数:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta}C\\sum_{i=1}^{m}[y^{(i)}cost_1(\\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\\theta^Tx^{(i)})]+\\frac{1}{2}\\sum_{j=1}^{n}\\theta_{j}^{2}</script><p>由于C设置的非常大，那么SVM损失函数为:</p>\n<script type=\"math/tex; mode=display\">\nmin_{\\theta} \\frac{1}{2}\\sum_{j=1}^{n}\\theta_j^2</script><ul>\n<li>约束条件1:如果$y^{(i)}=1$，$\\theta^Tx^{(i)}\\ge1$。</li>\n<li>约束条件2:如果$y^{(i)}=0$，$\\theta^Tx^{(i)}\\le-1$。</li>\n</ul>\n<p>下面我们举例说明SVM，为了简化，假设n=2,$\\theta_0=0$，我们得到</p>\n<script type=\"math/tex; mode=display\">\nmin\\frac{1}{2}\\sum_{j=1}^{2}\\theta_j^2=\\frac{1}{2}{(\\theta_1^2+\\theta_2^2)}=\\frac{1}{2}\\left (\\sqrt{\\theta_1^2+\\theta_2^2}  \\right )^2=\\frac{1}{2}||\\theta||^2</script><p>我们来更深层次的理解$\\theta^Tx^{(i)}$，表现形式和上述$u^Tv$相同。利用坐标表示则为</p>\n<script type=\"math/tex; mode=display\">\n\\theta^Tx^{(i)}=p^{(i)}\\cdot||\\theta||=\\theta_1x_1^{(i)}+\\theta_2x_1^{(2)}</script><p>$\\theta^Tx^{(i)}$我们可以利用$p^{(i)}\\cdot||\\theta||$表示，同时SVM随时函数目标是极小化$||\\theta^2||$。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片07.png\" alt=\"幕快照 2018-04-02 下午4.52.4\"></p>\n<p>下面有两种分类方式，SVM为什么要选择第二种当作分类呢。我们想最小化$||\\theta||$，并且要满足$p^{(i)}\\cdot ||\\theta||\\ge1$，但左边坐标中$p^{(1)}$较小，那么我们便要让$||\\theta||$更大，不满足最小化$||\\theta||$的需求。坐标2中$p^{(1)}$更大，那么$||\\theta||$便较小，满足最小化$||\\theta||$的需求。SVM便是通过最大化分类间隔来让$||\\theta||$更小，这便是SVM中为什么要最大化分类间隔。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片08.png\" alt=\"幕快照 2018-04-02 下午5.14.2\"></p>\n<h3 id=\"4-核函数\"><a href=\"#4-核函数\" class=\"headerlink\" title=\"4.核函数\"></a>4.核函数</h3><p>上述介绍线性分类，但对于非线性问题我们如何解决呢？对于非线性的决策边界，我们可以利用多项式拟合的方式进行预测。对于下面图片中的决策边界，我们令$f_1=x_1,f2=x_2,f3=x_1x_2,f4=x_1^2,f5=x_2^2,…$</p>\n<ul>\n<li>$f_1,f_2,f_3…$为提取出来的特征。</li>\n<li>定义预测方程$h_{\\theta}(x)$为多项式sigmoid函数。$h_{\\theta}(x)=g(\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n)$，其中$f_n$为x的幂次项组合。</li>\n<li>当$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n\\ge0$时$h_{\\theta}(x)=1$，否则$h_{\\theta}(x)=0$。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片09.png\" alt=\"幕快照 2018-04-02 下午5.40.4\"></p>\n<p>那么除了将fn定义为x的幂次项组合，还有其他方法表示f吗？此处我们引入核函数，对于非线性拟合，我们通过输入原始向量与landmark点之间的相似度来计算核值f，我们称相似度函数为核函数，下述核函数为高斯核函数。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片10.png\" alt=\"幕快照 2018-04-02 下午5.53.4\"></p>\n<p>x和l越相似，f越接近于1。x和l相差越远，f越接近于0。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片11.png\" alt=\"幕快照 2018-04-02 下午6.02.1\"></p>\n<p>下图中横坐标为x的两个维度值，高为f。制高点为x=l的情况，此时f=1。随着x与l的远离，f逐渐下降，趋近于0。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片12.png\" alt=\"幕快照 2018-04-02 下午6.36.0\"></p>\n<p>下面我们来看SVM核分类预测的结果。引入核函数后，代数上的区别在于f变了，原来的f是$x_1,x_1^2…$，即$x_i$的幂次项乘积，另外几何来说可以更直观的表示如何分类。</p>\n<ul>\n<li>假如我们将坐标上的所有数据点分为两类，红色圈内希望预测为y=1，圈外希望预测为y=0。通过训练数据集，我们得到一组$\\theta(\\theta_0,\\theta_1,\\theta_2,\\theta_3)$值为$(-0.5,1,1,0)$以及三个landmark点(L1,L2,L3)。具体如何选取landmark点和训练生成$\\theta$值在下面会详细介绍。</li>\n<li>对于每个数据集内的点，我们首先计算它到(L1,L2,L3)各自的相似度，也就是核函数的值$f_1,f_2,f_3$，然后带入多项式$\\theta_0f_0+\\theta_1f_1+\\theta_2f_2+…+\\theta_nf_n$，当多项式大于0时预测结果为类内点，表示为正样本，y=1。否则预测为负样本，y=0。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片13.png\" alt=\"幕快照 2018-04-02 下午6.44.2\"></p>\n<h3 id=\"5-SVM中Gaussian-Kernel的使用\"><a href=\"#5-SVM中Gaussian-Kernel的使用\" class=\"headerlink\" title=\"5.SVM中Gaussian Kernel的使用\"></a>5.SVM中Gaussian Kernel的使用</h3><p>上述中我们利用到$l^{(1)},l^{(2)},l^{(3)}$，但是我们如何达到这些landmark呢。首先我们来看L点的选取，上述提到Gaussian kernel $f_i$的计算。</p>\n<script type=\"math/tex; mode=display\">\nf_i=similarity(x,l^{(i)})=exp\\left ( -\\frac{||x-l^{(i)}||^2}{2\\sigma^2}\\right)</script><p>我们选择m个训练数据，并取这m个训练数据为m个landmark点（不考虑正样本还是负样本）。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片14.png\" alt=\"幕快照 2018-04-02 下午7.16.3\"></p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片15.png\" alt=\"幕快照 2018-04-02 下午7.17.2\"></p>\n<p>那么在这m个训练数据中，每一个训练数据$x^{(i)}$所得的特征向量（核函数）f中，总有一维向量的值为1（因为$x^{(i)}=l^{(i)}$）。于是每个特征向量f有m+1为维度，在SVM训练中，将Gaussian Kernel带入SVM损失函数，通过最小化该函数就可于得到参数$\\theta$，并根据该参数$\\theta$进行预测。</p>\n<ul>\n<li>$\\theta^Tf\\ge0$，预测 y=1。</li>\n<li>$\\theta^Tf\\le0$，预测y=0。</li>\n</ul>\n<p>如下图所示，这里与之前的损失函数区别在于用kernel f代替了x。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片16.png\" alt=\"幕快照 2018-04-02 下午7.26.4\"></p>\n<p>最后我们介绍下如何选取C和$\\sigma^2$。由于$C=\\frac{1}{\\lambda}$，所以</p>\n<ul>\n<li>C大，$\\lambda$小，overfit，产生low bias，high variance。</li>\n<li>C小，$\\lambda$大，underfoot，underfoot，产生high bias，low variance。</li>\n</ul>\n<p>对于方差$\\sigma^2$</p>\n<ul>\n<li>$\\sigma^2$大，x-f相似性图像较为扁平。</li>\n<li>$\\sigma^2小$，x-f相似性图像较为窄尖。</li>\n</ul>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片17.png\" alt=\"幕快照 2018-04-02 下午8.03.0\"></p>\n<p>通常我们会从一些常用的核函数中选择，根据问题数据的不同，选择不同的参数，实际上就是得到不同的核函数。经常用到的核函数包括线性核、多项式核、高斯核。</p>\n<p>由于本篇幅文章过长，我们将在下篇文章内详细介绍SVM算法中对偶问题的求解、C为何设置非常大、几种不同的核函数、SVM应用。如你在文中发现错误，欢迎指出，我会尽快更正。</p>\n<h3 id=\"5-推广\"><a href=\"#5-推广\" class=\"headerlink\" title=\"5.推广\"></a>5.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/29/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片推广.png.png\" alt=\"\"></p>\n"},{"title":"机器学习知识体系","date":"2018-03-24T04:30:14.000Z","comments":1,"toc":true,"_content":"\n### 1.什么是机器学习\n\n>机器学习（Machine Learning, ML）是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。\n\n上述为**百度百科**定义，而在现实生活中，我们主要会碰到两类问题。一类是我们知道怎么去通过算法将输入转化为输出，通过学习此类模式得到相应输出结果。另一类是寻找不到此类模式，通过深度学习去做。\n\n+ 给定一定的输入，通过施加一定条件或算法，得到最终的输出，类似于下图模式。\n\n![图片01](机器学习知识体系/图片01.png)\n\n\n\n+ 以字符识别为例，输入的是手写数字图片，输出0-9字符串，我们并不知道怎么把输入转换成输出，因为手写体因人而异，随机性很大。换句话说就是我们缺的是知识如何映射，不过幸运的是我们有实例数据，而把这个知识通过机器学出来的过程叫做机器学习。\n\n![图片02](机器学习知识体系/图片02.png)\n\n### 2.机器学习体系概括\n\n机器学习包含多交叉学科，同时也在很多方面得到应用，如自然语言处理、图像处理、数据挖掘、推荐系统领域等。机器学习包含监督学习、无监督学习、半监督学习、强化学习、深度学习、迁移学习等，还有各种工具和框架的应用，因此Machine Learning的过程也是漫长而有趣的。\n\n![图片03](机器学习知识体系/图片03.png)\n\n下图为开发者平台CSDN上王小雷整理的机器学习算法汇总，其中包含很多机器学习算法，知识体系较为庞大。目前个人已掌握知识点主要在监督学习、无监督学习、集成学习算法、降维方面，所以先给大家介绍这几类机器学习算法，半监督学习、强化学习、深度学习和迁移学习个人会继续学习。\n\n![图片04](机器学习知识体系/图片04.png)\n\n机器学习算法中常用到的便是**监督学习**和**无监督学习**，监督学习包含**回归**和**分类**两方面，无监督学习为**聚类**。\n\n**监督学习（Supervised Learning）**\n\n当你有一些问题和他们的答案时，你要做的有监督学习就是学习这些已经知道答案的问题，当你具备此类学习的经验时，便是学习的成果。然后当你接受到一个新的此类问题时，便可通过学习得到的经验，得出新问题的答案。当我们有一些样本数据集时，对于每个单一的数据根据他的特征向量我们要去判断他的标签，那么就是监督学习。监督学习分为**回归分析（Regression Analysis）**和**分类（Classification）**两类。\n\n+ **回归分析（Regression Analysis）**：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围的。\n+ **分类（Classfication）**：其数据集由特征变量和标签组成，当你学习这些数据之后，给你一个只知道特征向量不知道标签的数据，让你求他的标签是哪一个？分类和回归的主要区别就是输出结果是连续还是离散。\n\n**无监督学习（Unsupervised Learning）**\n\n我们有一些问题，但是不知道答案，我们要做的无监督学习就是按照他们的性质把他们自动地分成很多组，每组的问题是具有类似性质的（比如数学问题会聚集在一组，英语问题聚集在一组……）。\n\n所有的数据只有特征向量没有标签，但是可以发现这些数据呈现出聚群的结构，本质是相似的类型会聚集在一起。把这些没有标签的数据分成各个组合便是聚类。比如每天都会搜到大量新闻，然后把它们全部聚类，就会自动分成几十个不同的组（比如娱乐、科技、政治…），每个组内新闻都具有相似的内容结构。\n\n### 3.如何开始学习\n\n开始机器学习之前必须要有一定的数学知识，因为各算法之中涉及很多公式推导，用到的主要数学知识点为微积分、概率论、大学中高等数学知识点，忘记的同学可以在学习算法的过程中复习下。另外我们还需要掌握一门编程语言，这里推荐大家学习Python，为什么选择Python在这儿也就不讨论了，知乎平台上有很多介绍。\n\n很好，我们掌握一门编程语言和数学知识之后便可开始Machine Learning，此过程中将使用相应Python标准库和第三方库，大家可以参考我以前写的文章，Python之NumPy使用教程、Python之Pandas使用教程、Python之MatPlotLib使用教程。中间过程中如涉及到其他Python库的使用，会及时写出相应教程。接下来一段时间将持续更新各种机器学习算法，包括线性回归、Logistic回归、支持向量机SVM、决策树、EM等算法。\n\n---\n\n### 4.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![推广](机器学习知识体系/推广.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/机器学习知识体系.md","raw":"---\ntitle: 机器学习知识体系\ndate: 2018-03-24 12:30:14\ntags: 机器学习\ncategories: 机器学习\ncomments: true\ntoc: true\n---\n\n### 1.什么是机器学习\n\n>机器学习（Machine Learning, ML）是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。\n\n上述为**百度百科**定义，而在现实生活中，我们主要会碰到两类问题。一类是我们知道怎么去通过算法将输入转化为输出，通过学习此类模式得到相应输出结果。另一类是寻找不到此类模式，通过深度学习去做。\n\n+ 给定一定的输入，通过施加一定条件或算法，得到最终的输出，类似于下图模式。\n\n![图片01](机器学习知识体系/图片01.png)\n\n\n\n+ 以字符识别为例，输入的是手写数字图片，输出0-9字符串，我们并不知道怎么把输入转换成输出，因为手写体因人而异，随机性很大。换句话说就是我们缺的是知识如何映射，不过幸运的是我们有实例数据，而把这个知识通过机器学出来的过程叫做机器学习。\n\n![图片02](机器学习知识体系/图片02.png)\n\n### 2.机器学习体系概括\n\n机器学习包含多交叉学科，同时也在很多方面得到应用，如自然语言处理、图像处理、数据挖掘、推荐系统领域等。机器学习包含监督学习、无监督学习、半监督学习、强化学习、深度学习、迁移学习等，还有各种工具和框架的应用，因此Machine Learning的过程也是漫长而有趣的。\n\n![图片03](机器学习知识体系/图片03.png)\n\n下图为开发者平台CSDN上王小雷整理的机器学习算法汇总，其中包含很多机器学习算法，知识体系较为庞大。目前个人已掌握知识点主要在监督学习、无监督学习、集成学习算法、降维方面，所以先给大家介绍这几类机器学习算法，半监督学习、强化学习、深度学习和迁移学习个人会继续学习。\n\n![图片04](机器学习知识体系/图片04.png)\n\n机器学习算法中常用到的便是**监督学习**和**无监督学习**，监督学习包含**回归**和**分类**两方面，无监督学习为**聚类**。\n\n**监督学习（Supervised Learning）**\n\n当你有一些问题和他们的答案时，你要做的有监督学习就是学习这些已经知道答案的问题，当你具备此类学习的经验时，便是学习的成果。然后当你接受到一个新的此类问题时，便可通过学习得到的经验，得出新问题的答案。当我们有一些样本数据集时，对于每个单一的数据根据他的特征向量我们要去判断他的标签，那么就是监督学习。监督学习分为**回归分析（Regression Analysis）**和**分类（Classification）**两类。\n\n+ **回归分析（Regression Analysis）**：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围的。\n+ **分类（Classfication）**：其数据集由特征变量和标签组成，当你学习这些数据之后，给你一个只知道特征向量不知道标签的数据，让你求他的标签是哪一个？分类和回归的主要区别就是输出结果是连续还是离散。\n\n**无监督学习（Unsupervised Learning）**\n\n我们有一些问题，但是不知道答案，我们要做的无监督学习就是按照他们的性质把他们自动地分成很多组，每组的问题是具有类似性质的（比如数学问题会聚集在一组，英语问题聚集在一组……）。\n\n所有的数据只有特征向量没有标签，但是可以发现这些数据呈现出聚群的结构，本质是相似的类型会聚集在一起。把这些没有标签的数据分成各个组合便是聚类。比如每天都会搜到大量新闻，然后把它们全部聚类，就会自动分成几十个不同的组（比如娱乐、科技、政治…），每个组内新闻都具有相似的内容结构。\n\n### 3.如何开始学习\n\n开始机器学习之前必须要有一定的数学知识，因为各算法之中涉及很多公式推导，用到的主要数学知识点为微积分、概率论、大学中高等数学知识点，忘记的同学可以在学习算法的过程中复习下。另外我们还需要掌握一门编程语言，这里推荐大家学习Python，为什么选择Python在这儿也就不讨论了，知乎平台上有很多介绍。\n\n很好，我们掌握一门编程语言和数学知识之后便可开始Machine Learning，此过程中将使用相应Python标准库和第三方库，大家可以参考我以前写的文章，Python之NumPy使用教程、Python之Pandas使用教程、Python之MatPlotLib使用教程。中间过程中如涉及到其他Python库的使用，会及时写出相应教程。接下来一段时间将持续更新各种机器学习算法，包括线性回归、Logistic回归、支持向量机SVM、决策树、EM等算法。\n\n---\n\n### 4.推广\n\n更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。\n\n![推广](机器学习知识体系/推广.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"机器学习知识体系","published":1,"updated":"2018-03-29T07:24:34.332Z","layout":"post","photos":[],"link":"","_id":"cjg7s0pqx000u3201aj5y4kn7","content":"<h3 id=\"1-什么是机器学习\"><a href=\"#1-什么是机器学习\" class=\"headerlink\" title=\"1.什么是机器学习\"></a>1.什么是机器学习</h3><blockquote>\n<p>机器学习（Machine Learning, ML）是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。</p>\n</blockquote>\n<p>上述为<strong>百度百科</strong>定义，而在现实生活中，我们主要会碰到两类问题。一类是我们知道怎么去通过算法将输入转化为输出，通过学习此类模式得到相应输出结果。另一类是寻找不到此类模式，通过深度学习去做。</p>\n<ul>\n<li>给定一定的输入，通过施加一定条件或算法，得到最终的输出，类似于下图模式。</li>\n</ul>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片01.png\" alt=\"图片01\"></p>\n<ul>\n<li>以字符识别为例，输入的是手写数字图片，输出0-9字符串，我们并不知道怎么把输入转换成输出，因为手写体因人而异，随机性很大。换句话说就是我们缺的是知识如何映射，不过幸运的是我们有实例数据，而把这个知识通过机器学出来的过程叫做机器学习。</li>\n</ul>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片02.png\" alt=\"图片02\"></p>\n<h3 id=\"2-机器学习体系概括\"><a href=\"#2-机器学习体系概括\" class=\"headerlink\" title=\"2.机器学习体系概括\"></a>2.机器学习体系概括</h3><p>机器学习包含多交叉学科，同时也在很多方面得到应用，如自然语言处理、图像处理、数据挖掘、推荐系统领域等。机器学习包含监督学习、无监督学习、半监督学习、强化学习、深度学习、迁移学习等，还有各种工具和框架的应用，因此Machine Learning的过程也是漫长而有趣的。</p>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片03.png\" alt=\"图片03\"></p>\n<p>下图为开发者平台CSDN上王小雷整理的机器学习算法汇总，其中包含很多机器学习算法，知识体系较为庞大。目前个人已掌握知识点主要在监督学习、无监督学习、集成学习算法、降维方面，所以先给大家介绍这几类机器学习算法，半监督学习、强化学习、深度学习和迁移学习个人会继续学习。</p>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片04.png\" alt=\"图片04\"></p>\n<p>机器学习算法中常用到的便是<strong>监督学习</strong>和<strong>无监督学习</strong>，监督学习包含<strong>回归</strong>和<strong>分类</strong>两方面，无监督学习为<strong>聚类</strong>。</p>\n<p><strong>监督学习（Supervised Learning）</strong></p>\n<p>当你有一些问题和他们的答案时，你要做的有监督学习就是学习这些已经知道答案的问题，当你具备此类学习的经验时，便是学习的成果。然后当你接受到一个新的此类问题时，便可通过学习得到的经验，得出新问题的答案。当我们有一些样本数据集时，对于每个单一的数据根据他的特征向量我们要去判断他的标签，那么就是监督学习。监督学习分为<strong>回归分析（Regression Analysis）</strong>和<strong>分类（Classification）</strong>两类。</p>\n<ul>\n<li><strong>回归分析（Regression Analysis）</strong>：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围的。</li>\n<li><strong>分类（Classfication）</strong>：其数据集由特征变量和标签组成，当你学习这些数据之后，给你一个只知道特征向量不知道标签的数据，让你求他的标签是哪一个？分类和回归的主要区别就是输出结果是连续还是离散。</li>\n</ul>\n<p><strong>无监督学习（Unsupervised Learning）</strong></p>\n<p>我们有一些问题，但是不知道答案，我们要做的无监督学习就是按照他们的性质把他们自动地分成很多组，每组的问题是具有类似性质的（比如数学问题会聚集在一组，英语问题聚集在一组……）。</p>\n<p>所有的数据只有特征向量没有标签，但是可以发现这些数据呈现出聚群的结构，本质是相似的类型会聚集在一起。把这些没有标签的数据分成各个组合便是聚类。比如每天都会搜到大量新闻，然后把它们全部聚类，就会自动分成几十个不同的组（比如娱乐、科技、政治…），每个组内新闻都具有相似的内容结构。</p>\n<h3 id=\"3-如何开始学习\"><a href=\"#3-如何开始学习\" class=\"headerlink\" title=\"3.如何开始学习\"></a>3.如何开始学习</h3><p>开始机器学习之前必须要有一定的数学知识，因为各算法之中涉及很多公式推导，用到的主要数学知识点为微积分、概率论、大学中高等数学知识点，忘记的同学可以在学习算法的过程中复习下。另外我们还需要掌握一门编程语言，这里推荐大家学习Python，为什么选择Python在这儿也就不讨论了，知乎平台上有很多介绍。</p>\n<p>很好，我们掌握一门编程语言和数学知识之后便可开始Machine Learning，此过程中将使用相应Python标准库和第三方库，大家可以参考我以前写的文章，Python之NumPy使用教程、Python之Pandas使用教程、Python之MatPlotLib使用教程。中间过程中如涉及到其他Python库的使用，会及时写出相应教程。接下来一段时间将持续更新各种机器学习算法，包括线性回归、Logistic回归、支持向量机SVM、决策树、EM等算法。</p>\n<hr>\n<h3 id=\"4-推广\"><a href=\"#4-推广\" class=\"headerlink\" title=\"4.推广\"></a>4.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/24/机器学习知识体系/推广.png\" alt=\"推广\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-什么是机器学习\"><a href=\"#1-什么是机器学习\" class=\"headerlink\" title=\"1.什么是机器学习\"></a>1.什么是机器学习</h3><blockquote>\n<p>机器学习（Machine Learning, ML）是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。</p>\n</blockquote>\n<p>上述为<strong>百度百科</strong>定义，而在现实生活中，我们主要会碰到两类问题。一类是我们知道怎么去通过算法将输入转化为输出，通过学习此类模式得到相应输出结果。另一类是寻找不到此类模式，通过深度学习去做。</p>\n<ul>\n<li>给定一定的输入，通过施加一定条件或算法，得到最终的输出，类似于下图模式。</li>\n</ul>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片01.png\" alt=\"图片01\"></p>\n<ul>\n<li>以字符识别为例，输入的是手写数字图片，输出0-9字符串，我们并不知道怎么把输入转换成输出，因为手写体因人而异，随机性很大。换句话说就是我们缺的是知识如何映射，不过幸运的是我们有实例数据，而把这个知识通过机器学出来的过程叫做机器学习。</li>\n</ul>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片02.png\" alt=\"图片02\"></p>\n<h3 id=\"2-机器学习体系概括\"><a href=\"#2-机器学习体系概括\" class=\"headerlink\" title=\"2.机器学习体系概括\"></a>2.机器学习体系概括</h3><p>机器学习包含多交叉学科，同时也在很多方面得到应用，如自然语言处理、图像处理、数据挖掘、推荐系统领域等。机器学习包含监督学习、无监督学习、半监督学习、强化学习、深度学习、迁移学习等，还有各种工具和框架的应用，因此Machine Learning的过程也是漫长而有趣的。</p>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片03.png\" alt=\"图片03\"></p>\n<p>下图为开发者平台CSDN上王小雷整理的机器学习算法汇总，其中包含很多机器学习算法，知识体系较为庞大。目前个人已掌握知识点主要在监督学习、无监督学习、集成学习算法、降维方面，所以先给大家介绍这几类机器学习算法，半监督学习、强化学习、深度学习和迁移学习个人会继续学习。</p>\n<p><img src=\"/2018/03/24/机器学习知识体系/图片04.png\" alt=\"图片04\"></p>\n<p>机器学习算法中常用到的便是<strong>监督学习</strong>和<strong>无监督学习</strong>，监督学习包含<strong>回归</strong>和<strong>分类</strong>两方面，无监督学习为<strong>聚类</strong>。</p>\n<p><strong>监督学习（Supervised Learning）</strong></p>\n<p>当你有一些问题和他们的答案时，你要做的有监督学习就是学习这些已经知道答案的问题，当你具备此类学习的经验时，便是学习的成果。然后当你接受到一个新的此类问题时，便可通过学习得到的经验，得出新问题的答案。当我们有一些样本数据集时，对于每个单一的数据根据他的特征向量我们要去判断他的标签，那么就是监督学习。监督学习分为<strong>回归分析（Regression Analysis）</strong>和<strong>分类（Classification）</strong>两类。</p>\n<ul>\n<li><strong>回归分析（Regression Analysis）</strong>：其数据集是给定一个函数和他的一些坐标点，然后通过回归分析的算法，来估计原函数的模型，求得最符合这些数据集的函数解析式。然后我们就可以用来预估未知数据，输入一个自变量便会根据这个模型解析式输出因变量，这些自变量就是特征向量，因变量即为标签，而且标签的值是建立在连续范围的。</li>\n<li><strong>分类（Classfication）</strong>：其数据集由特征变量和标签组成，当你学习这些数据之后，给你一个只知道特征向量不知道标签的数据，让你求他的标签是哪一个？分类和回归的主要区别就是输出结果是连续还是离散。</li>\n</ul>\n<p><strong>无监督学习（Unsupervised Learning）</strong></p>\n<p>我们有一些问题，但是不知道答案，我们要做的无监督学习就是按照他们的性质把他们自动地分成很多组，每组的问题是具有类似性质的（比如数学问题会聚集在一组，英语问题聚集在一组……）。</p>\n<p>所有的数据只有特征向量没有标签，但是可以发现这些数据呈现出聚群的结构，本质是相似的类型会聚集在一起。把这些没有标签的数据分成各个组合便是聚类。比如每天都会搜到大量新闻，然后把它们全部聚类，就会自动分成几十个不同的组（比如娱乐、科技、政治…），每个组内新闻都具有相似的内容结构。</p>\n<h3 id=\"3-如何开始学习\"><a href=\"#3-如何开始学习\" class=\"headerlink\" title=\"3.如何开始学习\"></a>3.如何开始学习</h3><p>开始机器学习之前必须要有一定的数学知识，因为各算法之中涉及很多公式推导，用到的主要数学知识点为微积分、概率论、大学中高等数学知识点，忘记的同学可以在学习算法的过程中复习下。另外我们还需要掌握一门编程语言，这里推荐大家学习Python，为什么选择Python在这儿也就不讨论了，知乎平台上有很多介绍。</p>\n<p>很好，我们掌握一门编程语言和数学知识之后便可开始Machine Learning，此过程中将使用相应Python标准库和第三方库，大家可以参考我以前写的文章，Python之NumPy使用教程、Python之Pandas使用教程、Python之MatPlotLib使用教程。中间过程中如涉及到其他Python库的使用，会及时写出相应教程。接下来一段时间将持续更新各种机器学习算法，包括线性回归、Logistic回归、支持向量机SVM、决策树、EM等算法。</p>\n<hr>\n<h3 id=\"4-推广\"><a href=\"#4-推广\" class=\"headerlink\" title=\"4.推广\"></a>4.推广</h3><p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，欢迎关注，内容转载请注明出处。</p>\n<p><img src=\"/2018/03/24/机器学习知识体系/推广.png\" alt=\"推广\"></p>\n"},{"title":"面向知乎的个性化推荐模型研究","date":"2018-03-12T05:18:48.000Z","toc":true,"comments":1,"_content":"### 面向知乎的个性化推荐模型研究\n《[面向知乎的个性化推荐模型研究](https://github.com/XiaoYiii/Paper/blob/master/Paper/%E9%9D%A2%E5%90%91%E7%9F%A5%E4%B9%8E%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6.pdf)》论文是大二暑假完成的，已投到《计算机应用与软件》中文核心期刊。论文主要对知乎提出一种基于混合算法的个性化推荐模型。论文基于用户模型、问题模型、推荐模型构建推荐系统，提出Person Rank、Problem Rank，并结合其他算法来优化推荐结果，利用数据训练推荐模型，最终得到面向知乎的个性化推荐模型。\n<div align=center>![论文图片01](http://img.blog.csdn.net/20180311003539161?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片02](http://img.blog.csdn.net/20180311003612378?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片03](http://img.blog.csdn.net/20180311003633906?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片04](http://img.blog.csdn.net/20180311003651675?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片05](http://img.blog.csdn.net/20180311003709174?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n----------\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活...\n<div align=center>![公众号](http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n","source":"_posts/面向知乎的个性化推荐模型研究论文.md","raw":"---\ntitle: 面向知乎的个性化推荐模型研究\ndate: 2018-03-12 13:18:48\ntags: 推荐系统\ntoc: true\ncategories: 推荐系统\ncomments: true\n---\n### 面向知乎的个性化推荐模型研究\n《[面向知乎的个性化推荐模型研究](https://github.com/XiaoYiii/Paper/blob/master/Paper/%E9%9D%A2%E5%90%91%E7%9F%A5%E4%B9%8E%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6.pdf)》论文是大二暑假完成的，已投到《计算机应用与软件》中文核心期刊。论文主要对知乎提出一种基于混合算法的个性化推荐模型。论文基于用户模型、问题模型、推荐模型构建推荐系统，提出Person Rank、Problem Rank，并结合其他算法来优化推荐结果，利用数据训练推荐模型，最终得到面向知乎的个性化推荐模型。\n<div align=center>![论文图片01](http://img.blog.csdn.net/20180311003539161?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片02](http://img.blog.csdn.net/20180311003612378?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片03](http://img.blog.csdn.net/20180311003633906?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片04](http://img.blog.csdn.net/20180311003651675?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n<div align=center>![论文图片05](http://img.blog.csdn.net/20180311003709174?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n\n----------\n更多内容请关注公众号'谓之小一'，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活...\n<div align=center>![公众号](http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n","slug":"面向知乎的个性化推荐模型研究论文","published":1,"updated":"2018-03-14T03:17:08.367Z","layout":"post","photos":[],"link":"","_id":"cjg7s0pr0000y3201r51ht389","content":"<h3 id=\"面向知乎的个性化推荐模型研究\"><a href=\"#面向知乎的个性化推荐模型研究\" class=\"headerlink\" title=\"面向知乎的个性化推荐模型研究\"></a>面向知乎的个性化推荐模型研究</h3><p>《<a href=\"https://github.com/XiaoYiii/Paper/blob/master/Paper/%E9%9D%A2%E5%90%91%E7%9F%A5%E4%B9%8E%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6.pdf\" target=\"_blank\" rel=\"noopener\">面向知乎的个性化推荐模型研究</a>》论文是大二暑假完成的，已投到《计算机应用与软件》中文核心期刊。论文主要对知乎提出一种基于混合算法的个性化推荐模型。论文基于用户模型、问题模型、推荐模型构建推荐系统，提出Person Rank、Problem Rank，并结合其他算法来优化推荐结果，利用数据训练推荐模型，最终得到面向知乎的个性化推荐模型。</p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003539161?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片01\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003612378?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片02\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003633906?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片03\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003651675?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片04\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003709174?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片05\"></div></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活…</p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"公众号\"></div></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"面向知乎的个性化推荐模型研究\"><a href=\"#面向知乎的个性化推荐模型研究\" class=\"headerlink\" title=\"面向知乎的个性化推荐模型研究\"></a>面向知乎的个性化推荐模型研究</h3><p>《<a href=\"https://github.com/XiaoYiii/Paper/blob/master/Paper/%E9%9D%A2%E5%90%91%E7%9F%A5%E4%B9%8E%E7%9A%84%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6.pdf\" target=\"_blank\" rel=\"noopener\">面向知乎的个性化推荐模型研究</a>》论文是大二暑假完成的，已投到《计算机应用与软件》中文核心期刊。论文主要对知乎提出一种基于混合算法的个性化推荐模型。论文基于用户模型、问题模型、推荐模型构建推荐系统，提出Person Rank、Problem Rank，并结合其他算法来优化推荐结果，利用数据训练推荐模型，最终得到面向知乎的个性化推荐模型。</p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003539161?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片01\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003612378?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片02\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003633906?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片03\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003651675?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片04\"></div></p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311003709174?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"论文图片05\"></div></p>\n<hr>\n<p>更多内容请关注公众号’谓之小一’，若有疑问可在公众号后台提问，随时回答，内容转载请注明出处。「谓之小一」希望提供给读者别处看不到的内容，关于互联网、机器学习、数据挖掘、编程、书籍、生活…</p>\n<p><div align=\"center\"><img src=\"http://img.blog.csdn.net/20180311001720557?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvWGlhb1lpX0VyaWM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" alt=\"公众号\"></div></p>\n"}],"PostAsset":[{"_id":"source/_posts/Markdown写作教程/图片03.png","slug":"图片03.png","post":"cjg7s0ppk000032016o409b0k","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/12.png","slug":"12.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程图片02.png","slug":"Python之Sklearn使用教程图片02.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片03.png","slug":"机器学习之SVM支持向量机（一）图片03.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片05.png","slug":"机器学习之SVM支持向量机（一）图片05.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像06.png","slug":"机器学习之SVM支持向量机（二）图像06.png","post":"cjg7s0pqm000g320167v8kbw0","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之线性回归/公式03.png","slug":"公式03.png","post":"cjg7s0pqs000m3201cs3bssz4","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之线性回归/公式01.png","slug":"公式01.png","post":"cjg7s0pqs000m3201cs3bssz4","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之线性回归/图片03.png","slug":"图片03.png","post":"cjg7s0pqs000m3201cs3bssz4","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.3.png","slug":"图片6.3.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程05.png","slug":"Python之Sklearn使用教程05.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片04.png","slug":"机器学习之SVM支持向量机（一）图片04.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片11.png","slug":"机器学习之SVM支持向量机（一）图片11.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片14.png","slug":"机器学习之SVM支持向量机（一）图片14.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片17.png","slug":"机器学习之SVM支持向量机（一）图片17.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之线性回归/公式02.png","slug":"公式02.png","post":"cjg7s0pqs000m3201cs3bssz4","modified":0,"renderable":0},{"_id":"source/_posts/机器学习知识体系/图片03.png","slug":"图片03.png","post":"cjg7s0pqx000u3201aj5y4kn7","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片7.2.png","slug":"图片7.2.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/15.png","slug":"15.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之Logistic回归/机器学习之Logistic回归02.png","slug":"机器学习之Logistic回归02.png","post":"cjg7s0pqi000e32017bsdmusr","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片02.png","slug":"机器学习之SVM支持向量机（一）图片02.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之线性回归/图片02.png","slug":"图片02.png","post":"cjg7s0pqs000m3201cs3bssz4","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之决策树-C4-5算法/机器学习之决策树图片01.png","slug":"机器学习之决策树图片01.png","post":"cjg7s0pqp000j3201tm2u0kv8","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之决策树-C4-5算法/机器学习之决策树图片02.png","slug":"机器学习之决策树图片02.png","post":"cjg7s0pqp000j3201tm2u0kv8","modified":0,"renderable":0},{"_id":"source/_posts/Markdown写作教程/图片01.png","slug":"图片01.png","post":"cjg7s0ppk000032016o409b0k","modified":0,"renderable":0},{"_id":"source/_posts/Markdown写作教程/图片02.png","slug":"图片02.png","post":"cjg7s0ppk000032016o409b0k","modified":0,"renderable":0},{"_id":"source/_posts/Markdown写作教程/推广.png","slug":"推广.png","post":"cjg7s0ppk000032016o409b0k","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之Logistic回归/推广.png","slug":"推广.png","post":"cjg7s0pqi000e32017bsdmusr","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之Logistic回归/机器学习之Logistic回归01.png","slug":"机器学习之Logistic回归01.png","post":"cjg7s0pqi000e32017bsdmusr","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之Logistic回归/机器学习之Logistic回归03.png","slug":"机器学习之Logistic回归03.png","post":"cjg7s0pqi000e32017bsdmusr","modified":0,"renderable":0},{"_id":"source/_posts/机器学习知识体系/图片01.png","slug":"图片01.png","post":"cjg7s0pqx000u3201aj5y4kn7","modified":0,"renderable":0},{"_id":"source/_posts/机器学习知识体系/图片02.png","slug":"图片02.png","post":"cjg7s0pqx000u3201aj5y4kn7","modified":0,"renderable":0},{"_id":"source/_posts/机器学习知识体系/图片04.png","slug":"图片04.png","post":"cjg7s0pqx000u3201aj5y4kn7","modified":0,"renderable":0},{"_id":"source/_posts/机器学习知识体系/推广.png","slug":"推广.png","post":"cjg7s0pqx000u3201aj5y4kn7","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像01.png","slug":"机器学习之SVM支持向量机（二）图像01.png","post":"cjg7s0pqm000g320167v8kbw0","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像02.png","slug":"机器学习之SVM支持向量机（二）图像02.png","post":"cjg7s0pqm000g320167v8kbw0","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像03.png","slug":"机器学习之SVM支持向量机（二）图像03.png","post":"cjg7s0pqm000g320167v8kbw0","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图像05.png","slug":"机器学习之SVM支持向量机（二）图像05.png","post":"cjg7s0pqm000g320167v8kbw0","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（二）/机器学习之SVM支持向量机（二）图片推广.png","slug":"机器学习之SVM支持向量机（二）图片推广.png","post":"cjg7s0pqm000g320167v8kbw0","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之线性回归/图片01.png","slug":"图片01.png","post":"cjg7s0pqs000m3201cs3bssz4","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之线性回归/推广.png","slug":"推广.png","post":"cjg7s0pqs000m3201cs3bssz4","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片3.3.png","slug":"图片3.3.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片4.1.png","slug":"图片4.1.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.1.png","slug":"图片6.1.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.2.png","slug":"图片6.2.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.4.png","slug":"图片6.4.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.5.png","slug":"图片6.5.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片6.6.png","slug":"图片6.6.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/图片7.1.png","slug":"图片7.1.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Mac+Hexo+GitHub博客搭建教程/推广.png","slug":"推广.png","post":"cjg7s0pq5000832011gewnfmc","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程03.png","slug":"Python之Sklearn使用教程03.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程04.png","slug":"Python之Sklearn使用教程04.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程06.png","slug":"Python之Sklearn使用教程06.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程07.png","slug":"Python之Sklearn使用教程07.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程08.png","slug":"Python之Sklearn使用教程08.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程09.png","slug":"Python之Sklearn使用教程09.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程10.png","slug":"Python之Sklearn使用教程10.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程11.png","slug":"Python之Sklearn使用教程11.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程图片01.png","slug":"Python之Sklearn使用教程图片01.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/Python之Sklearn使用教程/Python之Sklearn使用教程推广.png","slug":"Python之Sklearn使用教程推广.png","post":"cjg7s0pqd000c3201xe39ytt3","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片01.png","slug":"机器学习之SVM支持向量机（一）图片01.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片06.png","slug":"机器学习之SVM支持向量机（一）图片06.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片07.png","slug":"机器学习之SVM支持向量机（一）图片07.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片08.png","slug":"机器学习之SVM支持向量机（一）图片08.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片09.png","slug":"机器学习之SVM支持向量机（一）图片09.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片10.png","slug":"机器学习之SVM支持向量机（一）图片10.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片12.png","slug":"机器学习之SVM支持向量机（一）图片12.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片13.png","slug":"机器学习之SVM支持向量机（一）图片13.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片15.png","slug":"机器学习之SVM支持向量机（一）图片15.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片16.png","slug":"机器学习之SVM支持向量机（一）图片16.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/机器学习之SVM支持向量机（一）/机器学习之SVM支持向量机（一）图片推广.png.png","slug":"机器学习之SVM支持向量机（一）图片推广.png.png","post":"cjg7s0pqu000q3201lzxvfqqe","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/01.png","slug":"01.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/02.png","slug":"02.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/03.png","slug":"03.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/04.png","slug":"04.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/05.png","slug":"05.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/06.png","slug":"06.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/07.png","slug":"07.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/08.png","slug":"08.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/09.png","slug":"09.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/10.png","slug":"10.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/11.png","slug":"11.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/13.png","slug":"13.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/14.png","slug":"14.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像18.png","slug":"图像18.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像19.png","slug":"图像19.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像20.png","slug":"图像20.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像21.png","slug":"图像21.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像22.png","slug":"图像22.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图像23.png","slug":"图像23.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图片16.png","slug":"图片16.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/图片17.png","slug":"图片17.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0},{"_id":"source/_posts/Python之MatPlotLib使用教程/推广.png","slug":"推广.png","post":"cjg7s0pq000053201miuj4u8b","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cjg7s0pqa000a3201qxhen6xx","category_id":"cjg7s0pq400073201cbz65wzu","_id":"cjg7s0pqo000h3201ntfckltl"},{"post_id":"cjg7s0ppr000232011xydtxw6","category_id":"cjg7s0pq400073201cbz65wzu","_id":"cjg7s0pqq000k3201o1f0odi6"},{"post_id":"cjg7s0pqd000c3201xe39ytt3","category_id":"cjg7s0pq400073201cbz65wzu","_id":"cjg7s0pqt000n3201glz04k1p"},{"post_id":"cjg7s0pq000053201miuj4u8b","category_id":"cjg7s0pq400073201cbz65wzu","_id":"cjg7s0pqw000r3201ncq0swdo"},{"post_id":"cjg7s0pq5000832011gewnfmc","category_id":"cjg7s0pqo000i3201mtz3burd","_id":"cjg7s0pqz000v32010ru7bvcp"},{"post_id":"cjg7s0pqu000q3201lzxvfqqe","category_id":"cjg7s0pqt000o3201q3667juk","_id":"cjg7s0pr300113201a8sxykvo"},{"post_id":"cjg7s0pqi000e32017bsdmusr","category_id":"cjg7s0pqt000o3201q3667juk","_id":"cjg7s0pr500143201affxhhh6"},{"post_id":"cjg7s0pqx000u3201aj5y4kn7","category_id":"cjg7s0pqt000o3201q3667juk","_id":"cjg7s0pr500153201lr2m8hqf"},{"post_id":"cjg7s0pqm000g320167v8kbw0","category_id":"cjg7s0pqt000o3201q3667juk","_id":"cjg7s0pr600183201gqxdmuin"},{"post_id":"cjg7s0pqs000m3201cs3bssz4","category_id":"cjg7s0pqt000o3201q3667juk","_id":"cjg7s0pr7001a320107qlpe2r"},{"post_id":"cjg7s0pr0000y3201r51ht389","category_id":"cjg7s0pr500173201z8cfbskk","_id":"cjg7s0pr8001c32013f0k1oop"},{"post_id":"cjg7s0pqp000j3201tm2u0kv8","category_id":"cjg7s0pqt000o3201q3667juk","_id":"cjg7s2hlf002b3201bhf9wy8f"}],"PostTag":[{"post_id":"cjg7s0ppk000032016o409b0k","tag_id":"cjg7s0ppx000432018luxm6q3","_id":"cjg7s0pqu000p3201mtrwy7ij"},{"post_id":"cjg7s0ppk000032016o409b0k","tag_id":"cjg7s0pqc000b3201djisox0s","_id":"cjg7s0pqw000s3201js5cdoad"},{"post_id":"cjg7s0ppk000032016o409b0k","tag_id":"cjg7s0pql000f32010j724pdp","_id":"cjg7s0pqz000w32014xxyceob"},{"post_id":"cjg7s0ppr000232011xydtxw6","tag_id":"cjg7s0pqs000l3201i0o9w2sj","_id":"cjg7s0pr2000z3201hcd7a9la"},{"post_id":"cjg7s0pq000053201miuj4u8b","tag_id":"cjg7s0pqs000l3201i0o9w2sj","_id":"cjg7s0pr400133201umkaytwz"},{"post_id":"cjg7s0pq5000832011gewnfmc","tag_id":"cjg7s0pr2001032010y4mw5m5","_id":"cjg7s0pra001e3201lwqp5zr7"},{"post_id":"cjg7s0pq5000832011gewnfmc","tag_id":"cjg7s0pr500163201nyxvgqag","_id":"cjg7s0pra001f3201ra1xzcwy"},{"post_id":"cjg7s0pq5000832011gewnfmc","tag_id":"cjg7s0pr600193201buz215kh","_id":"cjg7s0prb001h32010l2dpa90"},{"post_id":"cjg7s0pq5000832011gewnfmc","tag_id":"cjg7s0pqc000b3201djisox0s","_id":"cjg7s0prb001i3201ydovhizj"},{"post_id":"cjg7s0pqa000a3201qxhen6xx","tag_id":"cjg7s0pqs000l3201i0o9w2sj","_id":"cjg7s0prb001k3201v98ze9w4"},{"post_id":"cjg7s0pqd000c3201xe39ytt3","tag_id":"cjg7s0pra001g3201fzw1r2r0","_id":"cjg7s0prd001m32012st0alh4"},{"post_id":"cjg7s0pqd000c3201xe39ytt3","tag_id":"cjg7s0prb001j3201d9v4ifrp","_id":"cjg7s0prd001n3201hm9lxhcl"},{"post_id":"cjg7s0pqi000e32017bsdmusr","tag_id":"cjg7s0prb001j3201d9v4ifrp","_id":"cjg7s0prf001q3201z6okxn2c"},{"post_id":"cjg7s0pqi000e32017bsdmusr","tag_id":"cjg7s0prd001o3201495q0fq5","_id":"cjg7s0prg001r3201uw9b7odh"},{"post_id":"cjg7s0pqm000g320167v8kbw0","tag_id":"cjg7s0prb001j3201d9v4ifrp","_id":"cjg7s0pri001u3201kni6jspn"},{"post_id":"cjg7s0pqm000g320167v8kbw0","tag_id":"cjg7s0prd001o3201495q0fq5","_id":"cjg7s0pri001v3201al9i0njp"},{"post_id":"cjg7s0pqp000j3201tm2u0kv8","tag_id":"cjg7s0prb001j3201d9v4ifrp","_id":"cjg7s0prl001y320150i2kh2r"},{"post_id":"cjg7s0pqp000j3201tm2u0kv8","tag_id":"cjg7s0prd001o3201495q0fq5","_id":"cjg7s0prl001z3201nh30t6ws"},{"post_id":"cjg7s0pqs000m3201cs3bssz4","tag_id":"cjg7s0prb001j3201d9v4ifrp","_id":"cjg7s0prn00223201egewvsru"},{"post_id":"cjg7s0pqs000m3201cs3bssz4","tag_id":"cjg7s0prd001o3201495q0fq5","_id":"cjg7s0pro002332011arhc2xk"},{"post_id":"cjg7s0pqu000q3201lzxvfqqe","tag_id":"cjg7s0prb001j3201d9v4ifrp","_id":"cjg7s0prq0026320137qhjha0"},{"post_id":"cjg7s0pqu000q3201lzxvfqqe","tag_id":"cjg7s0prd001o3201495q0fq5","_id":"cjg7s0prq00273201vyp4n1b3"},{"post_id":"cjg7s0pqx000u3201aj5y4kn7","tag_id":"cjg7s0prb001j3201d9v4ifrp","_id":"cjg7s0prr00293201so3k3by3"},{"post_id":"cjg7s0pr0000y3201r51ht389","tag_id":"cjg7s0prq002832011bm57nd0","_id":"cjg7s0prs002a3201ww5j7vfy"}],"Tag":[{"name":"Markdown","_id":"cjg7s0ppx000432018luxm6q3"},{"name":"博客","_id":"cjg7s0pqc000b3201djisox0s"},{"name":"教程","_id":"cjg7s0pql000f32010j724pdp"},{"name":"python","_id":"cjg7s0pqs000l3201i0o9w2sj"},{"name":"Mac","_id":"cjg7s0pr2001032010y4mw5m5"},{"name":"Hexo","_id":"cjg7s0pr500163201nyxvgqag"},{"name":"GitHub","_id":"cjg7s0pr600193201buz215kh"},{"name":"Python","_id":"cjg7s0pra001g3201fzw1r2r0"},{"name":"机器学习","_id":"cjg7s0prb001j3201d9v4ifrp"},{"name":"算法","_id":"cjg7s0prd001o3201495q0fq5"},{"name":"推荐系统","_id":"cjg7s0prq002832011bm57nd0"}]}}